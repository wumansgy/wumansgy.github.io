<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[通过blockchain-go分析区块链交易原理]]></title>
    <url>%2F2018%2F09%2F09%2F%E9%80%9A%E8%BF%87blockchain-go%E5%88%86%E6%9E%90%E5%8C%BA%E5%9D%97%E9%93%BE%E4%BA%A4%E6%98%93%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[1.背景在去中心化的区块链中进行交易（转账）是怎么实现的呢？本篇通过blockchain_go来分析一下。需要进行交易，首先就需要有交易的双方以及他们的认证机制，其次是各自的资金账户规则。在分布式账本系统里面，需要有机制能够准确验证一个用户身份以及对账户资金的精确计算，不能出现一丁点差错。在区块链中交易通过Transaction表示，自己的账户余额并不是在每个节点上保存各个用户的一个最终数字，而是通过历史交易信息计算而来（历史交易不可篡改），其中的关键机制是UTXO。 2.身份认证在区块链身份认证是采用RSA非对称加密体系完成，每个用户在会拥有一个“钱包”，钱包是通过安全的椭圆曲线加密算法生成，其中包括一对公私钥。私钥自己保留不能暴露，用作加密，签名等，公钥公开给所有人，用于信息验证等。只要是用私钥签名的信息，就可以通过配对的公钥解码认证，不可抵赖。在blockchain_go中，钱包实现如下： 1234567891011121314151617181920212223// Wallet stores private and public keystype Wallet struct &#123; PrivateKey ecdsa.PrivateKey PublicKey []byte&#125;// NewWallet creates and returns a Walletfunc NewWallet() *Wallet &#123; private, public := newKeyPair() wallet := Wallet&#123;private, public&#125; return &amp;wallet&#125;func newKeyPair() (ecdsa.PrivateKey, []byte) &#123; curve := elliptic.P256() //椭圆曲线 private, err := ecdsa.GenerateKey(curve, rand.Reader) //生成私钥 if err != nil &#123; log.Panic(err) &#125; pubKey := append(private.PublicKey.X.Bytes(),private.PublicKey.Y.Bytes()...) //合成公钥 return *private, pubKey&#125; 钱包最重要的功能就是为用户提供身份认证和加解密的公私钥对。 3.什么是Transaction区块链中的Transaction（交易）就是一批输入和输出的集合，比如A通过交易给B10个代币（token），那么交易就是A输入10代币，输出变成B得到10代币，这样A就减少10代币，B增加10代币，再将这个交易信息存储到区块链中固化后，A和B在区块链中的账号状态就发生了永久性不可逆的变化。 在blockchain_go中transaction的定义如下： 123456789101112131415161718// TXInput represents a transaction inputtype TXInput struct &#123; Txid []byte Vout int Signature []byte PubKey []byte&#125;// TXOutput represents a transaction outputtype TXOutput struct &#123; Value int PubKeyHash []byte&#125;type Transaction struct &#123; ID []byte //交易唯一ID Vin []TXInput //交易输入序列 Vout []TXOutput //交易输出序列&#125; 从定义可以看到Transaction就是输入和输出的集合，输入和输出的关系如下图： 其中tx0，tx1，tx2等是独立的交易，每个交易通过输入产生输出，下面重点看看一个交易的输入和输出单位是怎么回事。 先看输出TXOutput： Value : 表示这个输出中的代币数量PubKeyHash : 存放了一个用户的公钥的hash值，表示这个输出里面的Value是属于哪个用户的输入单元TXInput: Txid : 交易ID（这个输入使用的是哪个交易的输出）Vout : 该输入单元指向本次交易输出数组的下标，通俗讲就是，这个输入使用的是Txid中的第几个输出。Signature : 输入发起方（转账出去方）的私钥签名本Transaction，表示自己认证了这个输入TXInput。PubKey : 输入发起方的公钥通俗来讲，一个TXInput结构表示 : 1我要使用哪个交易(Txid)的哪个输出数组（Transaction.Vout）的下标(Vout)作为我本次输入的代币数值（TXOutput.Value) 因为交易的输入其实是需要指明要输入多少代币（Value），但是TXInput中并没有直接的代币字段，而唯一有代币字段的是在TXOuput中，所以这里使用的方式是在TXInput中指明了自己需要使用的代币在哪个TXOutput中。 TXInput中的Signature字段是发起用户对本次交易输入的签名，PubKey存放了用户的公钥，用于之前的验证（私钥签名，公钥验证）。 3.什么是UTXOUTXO 是 Unspent Transaction Output 的缩写，意指“为花费的交易输出”，是中本聪最早在比特币中采用的一种技术方案。因为比特币中没有账户的概念，也就没有保存用户余额数值的机制。因为区块链中的历史交易都是被保存且不可修改的，而每一个交易（如前所述的Transaction）中又保存了“谁转移了多少给谁”的信息，所以要计算用户账户余额，只需要遍历所有交易进行累计即可。 从第三节的交易图可以看到，每笔交易的输入TXInput都是使用的是其他交易的输出TXOutput（只有输出中保存了该输出是属于哪个用户，价值多少）。如果一笔交易的输出被另外一个交易的输入引用了（TXInput中的Vout指向了该TXOutput），那么这笔输出就是“已花费”。如果一笔交易的输出没有被任何交易的输入引用，那么就是“未花费”。分析上图的tx3交易： tx3有3个输入： input 0 ：来自tx0的output0，花费了这个tx0.output0.input 1 ：来自tx1的output1，花费了这个tx1.output1.input 2 ：来自了tx2的output0，花费了这个tx2.output0.tx3有2个输出： output 0 ：没有被任何后续交易引用，表示“未花费”。output 1 ：被tx4的input1引用，表示已经被花费。因为每一个output都包括一个value和一个公钥身份，所以遍历所有区块中的交易，找出其中所有“未花费”的输出，就可以计算出用户的账户余额。 4.查找未花费的Output如果一个账户需要进行一次交易，把自己的代币转给别人，由于没有一个账号系统可以直接查询余额和变更，而在utxo模型里面一个用户账户余额就是这个用户的所有utxo（未花费的输出）记录的合集，因此需要查询用户的转账额度是否足够，以及本次转账需要消耗哪些output（将“未花费”的output变成”已花费“的output），通过遍历区块链中每个区块中的每个交易中的output来得到结果。 下面看看怎么查找一个特定用户的utxo，utxo_set.go相关代码如下： 123456789101112131415161718192021222324252627282930// FindSpendableOutputs finds and returns unspent outputs to reference in inputsfunc (u UTXOSet) FindSpendableOutputs(pubkeyHash []byte, amount int) (int, map[string][]int) &#123; unspentOutputs := make(map[string][]int) accumulated := 0 db := u.Blockchain.db err := db.View(func(tx *bolt.Tx) error &#123; b := tx.Bucket([]byte(utxoBucket)) c := b.Cursor() for k, v := c.First(); k != nil; k, v = c.Next() &#123; txID := hex.EncodeToString(k) outs := DeserializeOutputs(v) for outIdx, out := range outs.Outputs &#123; if out.IsLockedWithKey(pubkeyHash) &amp;&amp; accumulated &lt; amount &#123; accumulated += out.Value unspentOutputs[txID] = append(unspentOutputs[txID], outIdx) &#125; &#125; &#125; return nil &#125;) if err != nil &#123; log.Panic(err) &#125; return accumulated, unspentOutputs&#125; FindSpendableOutputs查找区块链上pubkeyHash账户的utxo集合，直到这些集合的累计未花费金额达到需求的amount为止。 blockchain_go中使用嵌入式key-value数据库boltdb存储区块链和未花费输出等信息，其中utxoBucket是所有用户未花费输出的bucket，其中的key表示交易ID，value是这个交易中未被引用的所有output的集合。所以通过遍历查询本次交易需要花费的output，得到Transaction的txID和这个output在Transaction中的输出数组中的下标组合unspentOutputs。 另外一个重点是utxobucket中保存的未花费输出结合是关于所有账户的，要查询特定账户需要对账户进行判断，因为TXOutput中有pubkeyhash字段，用来表示该输出属于哪个用户，此处采用out.IsLockedWithKey(pubkeyHash)判断特定output是否是属于给定用户。 5.新建Transaction需要发起一笔交易的时候，需要新建一个Transaction，通过交易发起人的钱包得到足够的未花费输出，构建出交易的输入和输出，完成签名即可，blockchain_go中的实现如下： 1234567891011121314151617181920212223242526272829303132333435363738// NewUTXOTransaction creates a new transactionfunc NewUTXOTransaction(wallet *Wallet, to string, amount int, UTXOSet *UTXOSet) *Transaction &#123; var inputs []TXInput var outputs []TXOutput pubKeyHash := HashPubKey(wallet.PublicKey) acc, validOutputs := UTXOSet.FindSpendableOutputs(pubKeyHash, amount) if acc &lt; amount &#123; log.Panic(&quot;ERROR: Not enough funds&quot;) &#125; // Build a list of inputs for txid, outs := range validOutputs &#123; txID, err := hex.DecodeString(txid) if err != nil &#123; log.Panic(err) &#125; for _, out := range outs &#123; input := TXInput&#123;txID, out, nil, wallet.PublicKey&#125; inputs = append(inputs, input) &#125; &#125; // Build a list of outputs from := fmt.Sprintf(&quot;%s&quot;, wallet.GetAddress()) outputs = append(outputs, *NewTXOutput(amount, to)) if acc &gt; amount &#123; outputs = append(outputs, *NewTXOutput(acc-amount, from)) // a change &#125; tx := Transaction&#123;nil, inputs, outputs&#125; tx.ID = tx.Hash() UTXOSet.Blockchain.SignTransaction(&amp;tx, wallet.PrivateKey) return &amp;tx&#125; 函数参数： wallet : 用户钱包参数，存储用户的公私钥，用于交易的签名和验证。to : 交易转账的目的地址（转账给谁）。amount : 需要交易的代币额度。UTXOSet : uxto集合，查询用户的未花费输出。查询需要的未花费输出： 1acc, validOutputs := UTXOSet.FindSpendableOutputs(pubKeyHash, amount) 因为用户的总金额是通过若干未花费输出累计起来的，而每个output所携带金额不一而足，所以每次转账可能需要消耗多个不同的output，而且还可能涉及找零问题。以上查询返回了一批未花费输出列表validOutputs和他们总共的金额acc. 找出来的未花费输出列表就是本次交易的输入，并将输出结果构造output指向目的用户，并检查是否有找零，将找零返还。 如果交易顺利完成，转账发起人的“未花费输出”被消耗掉变成了花费状态，而转账接收人to得到了一笔新的“未花费输出”，之后他自己需要转账时，查询自己的未花费输出，即可使用这笔钱。 最后需要对交易进行签名，表示交易确实是由发起人本人发起（私钥签名），而不是被第三人冒充。 6.Transaction的签名和验证6.1 签名交易的有效性需要首先建立在发起人签名的基础上，防止他人冒充转账或者发起人抵赖，blockchain_go中交易签名实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// SignTransaction signs inputs of a Transactionfunc (bc *Blockchain) SignTransaction(tx *Transaction, privKey ecdsa.PrivateKey) &#123; prevTXs := make(map[string]Transaction) for _, vin := range tx.Vin &#123; prevTX, err := bc.FindTransaction(vin.Txid) if err != nil &#123; log.Panic(err) &#125; prevTXs[hex.EncodeToString(prevTX.ID)] = prevTX &#125; tx.Sign(privKey, prevTXs)&#125;// Sign signs each input of a Transactionfunc (tx *Transaction) Sign(privKey ecdsa.PrivateKey, prevTXs map[string]Transaction) &#123; if tx.IsCoinbase() &#123; return &#125; for _, vin := range tx.Vin &#123; if prevTXs[hex.EncodeToString(vin.Txid)].ID == nil &#123; log.Panic(&quot;ERROR: Previous transaction is not correct&quot;) &#125; &#125; txCopy := tx.TrimmedCopy() for inID, vin := range txCopy.Vin &#123; prevTx := prevTXs[hex.EncodeToString(vin.Txid)] txCopy.Vin[inID].Signature = nil txCopy.Vin[inID].PubKey = prevTx.Vout[vin.Vout].PubKeyHash dataToSign := fmt.Sprintf(&quot;%x\n&quot;, txCopy) r, s, err := ecdsa.Sign(rand.Reader, &amp;privKey, []byte(dataToSign)) if err != nil &#123; log.Panic(err) &#125; signature := append(r.Bytes(), s.Bytes()...) tx.Vin[inID].Signature = signature txCopy.Vin[inID].PubKey = nil &#125;&#125; 交易输入的签名信息是放在TXInput中的signature字段，其中需要包括用户的pubkey，用于之后的验证。需要对每一个输入做签名。 6.2 验证交易签名是发生在交易产生时，交易完成后，Transaction会把交易广播给邻居。节点在进行挖矿时，会整理一段时间的所有交易信息，将这些信息打包进入新的区块，成功加入区块链以后，这个交易就得到了最终的确认。但是在挖矿节点打包交易前，需要对交易的有效性做验证，以防虚假数据，验证实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879// MineBlock mines a new block with the provided transactionsfunc (bc *Blockchain) MineBlock(transactions []*Transaction) *Block &#123; var lastHash []byte var lastHeight int for _, tx := range transactions &#123; // TODO: ignore transaction if it&apos;s not valid if bc.VerifyTransaction(tx) != true &#123; log.Panic(&quot;ERROR: Invalid transaction&quot;) &#125; &#125; ... ... ... return block&#125;// VerifyTransaction verifies transaction input signaturesfunc (bc *Blockchain) VerifyTransaction(tx *Transaction) bool &#123; if tx.IsCoinbase() &#123; return true &#125; prevTXs := make(map[string]Transaction) for _, vin := range tx.Vin &#123; prevTX, err := bc.FindTransaction(vin.Txid) if err != nil &#123; log.Panic(err) &#125; prevTXs[hex.EncodeToString(prevTX.ID)] = prevTX &#125; return tx.Verify(prevTXs)&#125;// Verify verifies signatures of Transaction inputsfunc (tx *Transaction) Verify(prevTXs map[string]Transaction) bool &#123; if tx.IsCoinbase() &#123; return true &#125; for _, vin := range tx.Vin &#123; if prevTXs[hex.EncodeToString(vin.Txid)].ID == nil &#123; log.Panic(&quot;ERROR: Previous transaction is not correct&quot;) &#125; &#125; txCopy := tx.TrimmedCopy() curve := elliptic.P256() for inID, vin := range tx.Vin &#123; prevTx := prevTXs[hex.EncodeToString(vin.Txid)] txCopy.Vin[inID].Signature = nil txCopy.Vin[inID].PubKey = prevTx.Vout[vin.Vout].PubKeyHash r := big.Int&#123;&#125; s := big.Int&#123;&#125; sigLen := len(vin.Signature) r.SetBytes(vin.Signature[:(sigLen / 2)]) s.SetBytes(vin.Signature[(sigLen / 2):]) x := big.Int&#123;&#125; y := big.Int&#123;&#125; keyLen := len(vin.PubKey) x.SetBytes(vin.PubKey[:(keyLen / 2)]) y.SetBytes(vin.PubKey[(keyLen / 2):]) dataToVerify := fmt.Sprintf(&quot;%x\n&quot;, txCopy) rawPubKey := ecdsa.PublicKey&#123;Curve: curve, X: &amp;x, Y: &amp;y&#125; if ecdsa.Verify(&amp;rawPubKey, []byte(dataToVerify), &amp;r, &amp;s) == false &#123; return false &#125; txCopy.Vin[inID].PubKey = nil &#125; return true&#125; 可以看到验证的时候也是每个交易的每个TXInput都单独进行验证，和签名过程很相似，需要构造相同的交易数据txCopy，验证时会用到签名设置的TxInput.PubKeyHash生成一个原始的PublicKey，将前面的signature分拆后通过ecdsa.Verify进行验证。 7.总结 以上简单分析和整理了blockchain_go中的交易和UTXO机制的实现过程，加深了区块链中的挖矿，交易和转账的基础技术原理的理解。 转载自http://www.bugclosed.com/post/38]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go的几种死锁情况分析]]></title>
    <url>%2F2018%2F09%2F09%2Fgo%E7%9A%84%E5%87%A0%E7%A7%8D%E6%AD%BB%E9%94%81%E6%83%85%E5%86%B5%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[在go语言中用channel通信稍不注意就会发生死锁情况，下面我们来看一下几种常见的死锁情况 第一种：同一个goroutine中，使用同一个 channel 读写。123456package mainfunc main()&#123; ch:=make(chan int) //这就是在main程里面发生的死锁情况 ch&lt;-6 // 这里会发生一直阻塞的情况，执行不到下面一句 &lt;-ch&#125; 这是最简单的死锁情况 看运行结果 第二种：2个 以上的go程中， 使用同一个 channel 通信。 读写channel 先于 go程创建。123456789package mainfunc main()&#123; ch:=make(chan int) ch&lt;-666 //这里一直阻塞，运行不到下面 go func ()&#123; &lt;-ch //这里虽然创建了子go程用来读出数据，但是上面会一直阻塞运行不到下面 &#125;()&#125; 这里如果想不成为死锁那匿名函数go程就要放到ch&lt;-666这条语句前面 看运行结果 还是同样的错误，死锁。 第三种：2个以上的go程中，使用多个 channel 通信。 A go 程 获取channel 1 的同时，尝试使用channel 2， 同一时刻，B go 程 获取channel 2 的同时，尝试使用channel 112345678910111213141516171819package mainfunc main() &#123; ch1 := make(chan int) ch2 := make(chan int) go func() &#123; //匿名子go程 for &#123; select &#123; //这里互相等对方造成死锁 case &lt;-ch1: //这里ch1有数据读出才会执行下一句 ch2 &lt;- 777 &#125; &#125; &#125;() for &#123; //主go程 select &#123; case &lt;-ch2 : //这里ch2有数据读出才会执行下一句 ch1 &lt;- 999 &#125; &#125;&#125; 第三种是互相等对方造成死锁 第四种： 在go语言中， channel 和 读写锁、互斥锁 尽量避免交叉混用。——“隐形死锁”。如果必须使用。推荐借助“条件变量”12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package mainimport ( &quot;runtime&quot; &quot;math/rand&quot; &quot;time&quot; &quot;fmt&quot; &quot;sync&quot;)// 使用读写锁var rwMutex2 sync.RWMutexfunc readGo2(idx int, in &lt;-chan int) &#123; // 读go程 for &#123; time.Sleep(time.Millisecond * 500) // 放大实验现象// 一个go程可以读 无限 次。 rwMutex2.RLock() // 读模式加 读写锁 num := &lt;-in // 从 公共的 channel 中获取数据 fmt.Printf(&quot;%dth 读 go程，读到：%d\n&quot;, idx, num) rwMutex2.RUnlock() // 解锁 读写锁 &#125;&#125;func writeGo2(idx int, out chan&lt;- int) &#123; for &#123; // 一个go程可以写 无限 次。 // 生产一个随机数 num := rand.Intn(500) rwMutex2.Lock() // 写模式加 读写锁 out &lt;- num fmt.Printf(&quot;-----%dth 写 go程，写入：%d\n&quot;, idx, num) rwMutex2.Unlock() // 解锁 读写锁 //time.Sleep(time.Millisecond * 200) // 放大实验现象 &#125;&#125;func main() &#123; // 播种随机数种子。 rand.Seed(time.Now().UnixNano()) // 创建 模拟公共区的 channel ch := make(chan int, 5) for i:=0; i&lt;5; i++ &#123; // 同时创建 N 个 读go程 go readGo2(i+1, ch) &#125; for i:=0; i&lt;5; i++ &#123; // 同时创建 N 个 写go程 go writeGo2(i+1, ch) &#125; for &#123; // 防止 主 go 程 退出 runtime.GC() &#125;&#125; 这是一种隐形的死锁，我们来看一下结果 注意这几种的死锁情况]]></content>
      <categories>
        <category>GO语言</category>
      </categories>
      <tags>
        <tag>go语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git详解-git实战]]></title>
    <url>%2F2018%2F09%2F09%2Fgit%E8%AF%A6%E8%A7%A3-git%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[本章介绍开始使用 Git 前的相关知识。我们会先了解一些版本控制工具的历史背景，然后试着让 Git 在你的系统上跑起来，直到最后配置好，可以正常开始开发工作。读完本章，你就会明白为什么 Git 会如此流行，为什么你应该立即开始使用它。 关于版本控制什么是版本控制？我真的需要吗？版本控制是一种记录若干文件内容变化，以便将来查阅特定版本修订情况的系统。在本书所展示的例子中，我们仅对保存着软件源代码的文本文件作版本控制管理，但实际上，你可以对任何类型的文件进行版本控制。 如果你是位图形或网页设计师，可能会需要保存某一幅图片或页面布局文件的所有修订版本（这或许是你非常渴望拥有的功能）。采用版本控制系统 （VCS）是个明智的选择。有了它你就可以将某个文件回溯到之前的状态，甚至将整个项目都回退到过去某个时间点的状态。你可以比较文件的变化细节，查出最 后是谁修改了哪个地方，从而导致出现怪异问题，又是谁在何时报告了某个功能缺陷等等。使用版本控制系统通常还意味着，就算你乱来一气把整个项目中的文件改 的改删的删，你也照样可以轻松恢复到原先的样子。但额外增加的工作量却微乎其微。 本地版本控制系统 许多人习惯用复制整个项目目录的方式来保存不同的版本，或许还会改名加上备份时间以示区别。这么做唯一的好处就是简单。不过坏处也不少：有时候会混淆所在的工作目录，一旦弄错文件丢了数据就没法撤销恢复。 为了解决这个问题，人们很久以前就开发了许多种本地版本控制系统，大多都是采用某种简单的数据库来记录文件的历次更新差异 其中最流行的一种叫做 rcs，现今许多计算机系统上都还看得到它的踪影。甚至在流行的 Mac OS X 系统上安装了开发者工具包之后，也可以使用 rcs 命令。它的工作原理基本上就是保存并管理文件补丁（patch）。文件补丁是一种特定格式的文本文件，记录着对应文件修订前后的内容变化。所以，根据每次 修订后的补丁，rcs 可以通过不断打补丁，计算出各个版本的文件内容。 集中化的版本控制系统 接下来人们又遇到一个问题，如何让在不同系统上的开发者协同工作？于是，集中化的版本控制系统（ Centralized Version Control Systems，简称 CVCS ）应运而生。这类系统，诸如 CVS，Subversion 以及 Perforce 等，都有一个单一的集中管理的服务器，保存所有文件的修订版本，而协同工作的人们都通过客户端连到这台服务器，取出最新的文件或者提交更新。多年以来，这 已成为版本控制系统的标准做法。 这种做法带来了许多好处，特别是相较于老式的本地 VCS 来说。现在，每个人都可以在一定程度上看到项目中的其他人正在做些什么。而管理员也可以轻松掌控每个开发者的权限，并且管理一个 CVCS 要远比在各个客户端上维护本地数据库来得轻松容易。 事分两面，有好有坏。这么做最显而易见的缺点是中央服务器的单点故障。如果宕机一小时，那么在这一小时内，谁都无法提交更新，也就无法协同工作。要 是中央服务器的磁盘发生故障，碰巧没做备份，或者备份不够及时，就还是会有丢失数据的风险。最坏的情况是彻底丢失整个项目的所有历史更改记录，而被客户端 提取出来的某些快照数据除外，但这样的话依然是个问题，你不能保证所有的数据都已经有人事先完整提取出来过。本地版本控制系统也存在类似问题，只要整个项 目的历史记录被保存在单一位置，就有丢失所有历史更新记录的风险。 分布式版本控制系统 于是分布式版本控制系统（ Distributed Version Control System，简称 DVCS ）面世了。在这类系统中，像 Git，Mercurial，Bazaar 以及 Darcs 等，客户端并不只提取最新版本的文件快照，而是把原始的代码仓库完整地镜像下来。这么一来，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜 像出来的本地仓库恢复。因为每一次的提取操作，实际上都是一次对代码仓库的完整备份。 进一步，许多这类系统都可以指定和若干不同的远端代码仓库进行交互。籍此，你就可以在同一个项目中，分别和不同工作小组的人相互协作。你可以根据需要设定不同的协作流程，比如层次模型式的工作流，而这在以前的集中式系统中是无法实现的。 Git 基础 那么，简单地说，Git 究竟是怎样的一个系统呢？请注意，接下来的内容非常重要，若是理解了 Git 的思想和基本工作原理，用起来就会知其所以然，游刃有余。在开始学习 Git 的时候，请不要尝试把各种概念和其他版本控制系统（诸如 Subversion 和 Perforce 等）相比拟，否则容易混淆每个操作的实际意义。Git 在保存和处理各种信息的时候，虽然操作起来的命令形式非常相近，但它与其他版本控制系统的做法颇为不同。理解这些差异将有助于你准确地使用 Git 提供的各种工具。 直接记录快照，而非差异比较 Git 和其他版本控制系统的主要差别在于，Git 只关心文件数据的整体是否发生变化，而大多数其他系统则只关心文件内容的具体差异。这类系统 （CVS，Subversion，Perforce，Bazaar 等等）每次记录有哪些文件作了更新，以及都更新了哪些行的什么内容 Git 并不保存这些前后变化的差异数据。实际上，Git 更像是把变化的文件作快照后，记录在一个微型的文件系统中。每次提交更新时，它会纵览一遍所有文件的指纹信息并对文件作一快照，然后保存一个指向这次快照 的索引。为提高性能，若文件没有变化，Git 不会再次保存，而只对上次保存的快照作一链接。Git 的工作方式如图所示 这是 Git 同其他系统的重要区别。它完全颠覆了传统版本控制的套路，并对各个环节的实现方式作了新的设计。Git 更像是个小型的文件系统，但它同时还提供了许多以此为基础的超强工具，而不只是一个简单的 VCS。稍后在第三章讨论 Git 分支管理的时候，我们会再看看这样的设计究竟会带来哪些好处。 近乎所有操作都是本地执行 在 Git 中的绝大多数操作都只需要访问本地文件和资源，不用连网。但如果用 CVCS 的话，差不多所有操作都需要连接网络。因为 Git 在本地磁盘上就保存着所有当前项目的历史更新，所以处理起来速度飞快。 举个例子，如果要浏览项目的历史更新摘要，Git 不用跑到外面的服务器上去取数据回来，而直接从本地数据库读取后展示给你看。所以任何时候你都可以马上翻阅，无需等待。如果想要看当前版本的文件和一个月 前的版本之间有何差异，Git 会取出一个月前的快照和当前文件作一次差异运算，而不用请求远程服务器来做这件事，或是把老版本的文件拉到本地来作比较。 用 CVCS 的话，没有网络或者断开 VPN 你就无法做任何事情。但用 Git 的话，就算你在飞机或者火车上，都可以非常愉快地频繁提交更新，等到了有网络的时候再上传到远程仓库。同样，在回家的路上，不用连接 VPN 你也可以继续工作。换作其他版本控制系统，这么做几乎不可能，抑或非常麻烦。比如 Perforce，如果不连到服务器，几乎什么都做不了（译注：默认无法发出命令p4 edit file 开始编辑文件，因为 Perforce 需要联网通知系统声明该文件正在被谁修订。但实际上手工修改文件权限可以绕过这个限制，只是完成后还是无法提交更新。）；如果是 Subversion 或 CVS，虽然可以编辑文件，但无法提交更新，因为数据库在网络上。看上去好像这些都不是什么大问题，但实际体验过之后，你就会惊喜地发现，这其实是会带来很大不同的。 时刻保持数据完整性 在保存到 Git 之前，所有数据都要进行内容的校验和（checksum）计算，并将此结果作为数据的唯一标识和索引。换句话说，不可能在你修改了文件或目录之后，Git 一无所知。这项特性作为 Git 的设计哲学，建在整体架构的最底层。所以如果文件在传输时变得不完整，或者磁盘损坏导致文件数据缺失，Git 都能立即察觉。 Git 使用 SHA-1 算法计算数据的校验和，通过对文件的内容或目录的结构计算出一个 SHA-1 哈希值，作为指纹字符串。该字串由 40 个十六进制字符（0-9 及 a-f）组成，看起来就像是： 124b9da6552252987aa493b52f8696cd6d3b00373 Git 的工作完全依赖于这类指纹字串，所以你会经常看到这样的哈希值。实际上，所有保存在 Git 数据库中的东西都是用此哈希值来作索引的，而不是靠文件名。 多数操作仅添加数据 常用的 Git 操作大多仅仅是把数据添加到数据库。因为任何一种不可逆的操作，比如删除数据，都会使回退或重现历史版本变得困难重重。在别的 VCS 中，若还未提交更新，就有可能丢失或者混淆一些修改的内容，但在 Git 里，一旦提交快照之后就完全不用担心丢失数据，特别是养成定期推送到其他仓库的习惯的话。 这种高可靠性令我们的开发工作安心不少，尽管去做各种试验性的尝试好了，再怎样也不会弄丢数据。至于 Git 内部究竟是如何保存和恢复数据的，我们会在第九章讨论 Git 内部原理时再作详述。 文件的三种状态 好，现在请注意，接下来要讲的概念非常重要。对于任何一个文件，在 Git 内都只有三种状态：已提交（committed），已修改（modified）和已暂存（staged）。已提交表示该文件已经被安全地保存在本地数据库 中了；已修改表示修改了某个文件，但还没有提交保存；已暂存表示把已修改的文件放在下次提交时要保存的清单中。 由此我们看到 Git 管理项目时，文件流转的三个工作区域：Git 的工作目录，暂存区域，以及本地仓库。 每个项目都有一个 Git 目录（译注：如果 git clone 出来的话，就是其中 .git 的目录；如果git clone --bare 的话，新建的目录本身就是 Git 目录。），它是 Git 用来保存元数据和对象数据库的地方。该目录非常重要，每次克隆镜像仓库的时候，实际拷贝的就是这个目录里面的数据。 从项目中取出某个版本的所有文件和目录，用以开始后续工作的叫做工作目录。这些文件实际上都是从 Git 目录中的压缩对象数据库中提取出来的，接下来就可以在工作目录中对这些文件进行编辑。 所谓的暂存区域只不过是个简单的文件，一般都放在 Git 目录中。有时候人们会把这个文件叫做索引文件，不过标准说法还是叫暂存区域。 Git 工作流程如下 1. 在工作目录中修改某些文件。 2. 对修改后的文件进行快照，然后保存到暂存区域。 3. 提交更新，将保存在暂存区域的文件快照永久转储到 Git 目录中。 所以，我们可以从文件所处的位置来判断状态：如果是 Git 目录中保存着的特定版本文件，就属于已提交状态；如果作了修改并已放入暂存区域，就属于已暂存状态；如果自上次取出后，作了修 改但还没有放到暂存区域，就 是已修改状态。到第二章的时候，我们会进一步了解其中细节，并学会如何根据文件状态实施后续操作，以及怎样跳过暂存直接提交。 在正式使用前，我们还需要弄清楚Git的三种重要模式，分别是已提交、已修改、已暂存 已提交(committed):表示数据文件已经顺利提交到Git数据库中。 已修改(modified):表示数据文件已经被修改，但未被保存到Git数据库中。 已暂存(staged):表示数据文件已经被修改，并会在下次提交时提交到Git数据库中。 实战 先创建一个工程的目录mkdir test_project cd test_project git init 初始化git工作目录（git init –bare功能相同） git init的结果（这个隐藏的git目录里面的内容和–bare创建的相同） git init –bare 路径 4.touch readme 创建一个文件 5.git status 查看状态 第一次查看，这个文件还没有添加到暂存区的 6.git add readme 将readme文件添加到暂存区 既然有添加，那就有删除（此处说的是暂存区的操作，不会删除文件） git rm –cached readme 7.git status 再次查看暂存区的状态 将readme添加到暂存区后的状态 8.git commit -m “first commit” 提交到自己的中央仓库（init就是创建自己的中央仓库） 9.git log查看日志（相当与svn的提交日志） 到目前为止自己本地仓库就提交结束了 之后就是提交到远程仓库了 10.git remote –v 查看本地存储的远程仓库信息，如果是clone出来的工程这个结果如下 origin 表示的是远程仓库的别名（默认为origin，也可以自己起，fetch更新类似于update，push推数据相当于commit） 如果不是clone的工程，就不会有任何结果，要自己添加，命令如下： git remote add test ssh://root@10.0.0.5/usr/GitData/DingDang/.git 11.做完这步然后就是远程推数据了（必须保证本地仓库里面有提交，注意是本地仓库而不是暂存区） git push test 到此自己创建的文件就推到了远程的git仓库了 12.还有一个功能比较重要，本地仓库的版本回退 git reset –hard HEAD^ #还原历史提交版本上一次 git reset –hard 版本号 #就是上图黄色的部分，仅需要前7位即可 如果回退过头了，log是看不到未来的版本号的，想看可以用git reflog查看 转载链接Git详解之-Git实战]]></content>
      <categories>
        <category>git使用及讲解</category>
      </categories>
      <tags>
        <tag>git工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git分支详解]]></title>
    <url>%2F2018%2F09%2F08%2Fgit%E5%88%86%E6%94%AF%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[几乎每一种版本控制系统都以某种形式支持分支。使用分支意味着你可以从开发主线上分离开来，然后在不影响主线的同时继续工作。在很多版本控制系统中，这是个昂贵的过程，常常需要创建一个源代码目录的完整副本，对大型项目来说会花费很长时间。 有人把 Git 的分支模型称为“必杀技特性”，而正是因为它，将 Git 从版本控制系统家族里区分出来。Git 有何特别之处呢？Git 的分支可谓是难以置信的轻量级，它的新建操作几乎可以在瞬间完成，并且在不同分支间切换起来也差不多一样快。和许多其他版本控制系统不同，Git 鼓励在工作流程中频繁使用分支与合并，哪怕一天之内进行许多次都没有关系。理解分支的概念并熟练运用后，你才会意识到为什么 Git 是一个如此强大而独特的工具，并从此真正改变你的开发方式。 何谓分支 为了理解 Git 分支的实现方式，我们需要回顾一下 Git 是如何储存数据的。或许你还记得第一章的内容，Git 保存的不是文件差异或者变化量，而只是一系列文件快照。 在 Git 中提交时，会保存一个提交（commit）对象，该对象包含一个指向暂存内容快照的指针，包含本次提交的作者等相关附属信息，包含零个或多个指向该提交对 象的父对象指针：首次提交是没有直接祖先的，普通提交有一个祖先，由两个或多个分支合并产生的提交则有多个祖先。 为直观起见，我们假设在工作目录中有三个文件，准备将它们暂存后提交。暂存操作会对每一个文件计算校验和（即第一章中提到的 SHA-1 哈希字串），然后把当前版本的文件快照保存到 Git 仓库中（Git 使用 blob 类型的对象存储这些快照），并将校验和加入暂存区域： 121 $ git add README test.rb LICENSE2 $ git commit -m &apos;initial commit of my project&apos; 当使用 git commit 新建一个提交对象前，Git 会先计算每一个子目录（本例中就是项目根目录）的校验和，然后在 Git 仓库中将这些目录保存为树（tree）对象。之后 Git 创建的提交对象，除了包含相关提交信息以外，还包含着指向这个树对象（项目根目录）的指针，如此它就可以在将来需要的时候，重现此次快照的内容了。 现在，Git 仓库中有五个对象：三个表示文件快照内容的 blob 对象；一个记录着目录树内容及其中各个文件对应 blob 对象索引的 tree 对象；以及一个包含指向 tree 对象（根目录）的索引和其他提交信息元数据的 commit 对象。概念上来说，仓库中的各个对象保存的数据和相互关系看起来如图所示： 作些修改后再次提交，那么这次的提交对象会包含一个指向上次提交对象的指针（译注：即下图中的 parent 对象）。两次提交后，仓库历史会变成下图： 现在来谈分支。Git 中的分支，其实本质上仅仅是个指向 commit 对象的可变指针。Git 会使用 master 作为分支的默认名字。在若干次提交后，你其实已经有了一个指向最后一次提交对象的 master 分支，它在每次提交的时候都会自动向前移动。 那么，Git 又是如何创建一个新的分支的呢？答案很简单，创建一个新的分支指针。比如新建一个 testing 分支，可以使用 git branch 命令： 1 $ git branch testing 这会在当前 commit 对象上新建一个分支指针 那么，Git 是如何知道你当前在哪个分支上工作的呢？其实答案也很简单，它保存着一个名为 HEAD 的特别指针。请注意它和你熟知的许多其他版本控制系统（比如 Subversion 或 CVS）里的 HEAD 概念大不相同。在 Git 中，它是一个指向你正在工作中的本地分支的指针（译注：将 HEAD 想象为当前分支的别名。）。运行git branch 命令，仅仅是建立了一个新的分支，但不会自动切换到这个分支中去，所以在这个例子中，我们依然还在 master 分支里工作 要切换到其他分支，可以执行 git checkout 命令。我们现在转换到新建的 testing 分支： 1 $ git checkout testing 这样 HEAD 就指向了 testing 分支 这样的实现方式会给我们带来什么好处呢？好吧，现在不妨再提交一次： 12 $ vim test.rb $ git commit -a -m &apos;made a change&apos; 非常有趣，现在 testing 分支向前移动了一格，而 master 分支仍然指向原先 git checkout 时所在的 commit 对象。现在我们回到 master 分支看看： 1 $ git checkout master 这条命令做了两件事。它把 HEAD 指针移回到 master 分支，并把工作目录中的文件换成了 master 分支所指向的快照内容。也就是说，现在开始所做的改动，将始于本项目中一个较老的版本。它的主要作用是将 testing 分支里作出的修改暂时取消，这样你就可以向另一个方向进行开发。 我们作些修改后再次提交： 12 $ vim test.rb $ git commit -a -m &apos;made other changes&apos; 现在我们的项目提交历史产生了分叉，因为刚才我们创建了一个分支，转换到其中进行了一些工作，然后又回到原来的主分支进行了另外一些工作。这些改变分别孤立在不同的分支里：我们可以 在不同分支里反复切换，并在时机成熟时把它们合并到一起。而所有这些工作，仅仅需要branch 和 checkout 这两条命令就可以完成 由于 Git 中的分支实际上仅是一个包含所指对象校验和（40 个字符长度 SHA-1 字串）的文件，所以创建和销毁一个分支就变得非常廉价。说白了，新建一个分支就是向一个文件写入 41 个字节（外加一个换行符）那么简单，当然也就很快了。 这和大多数版本控制系统形成了鲜明对比，它们管理分支大多采取备份所有项目文件到特定目录的方式，所以根据项目文件数量和大小不同，可能花费的时间 也会有相当大的差别，快则几秒，慢则数分钟。而 Git 的实现与项目复杂度无关，它永远可以在几毫秒的时间内完成分支的创建和切换。同时，因为每次提交时都记录了祖先信息（译注：即parent 对象），将来要合并分支时，寻找恰当的合并基础（译注：即共同祖先）的工作其实已经自然而然地摆在那里了，所以实现起来非常容易。Git 鼓励开发者频繁使用分支，正是因为有着这些特性作保障。 接下来看看，我们为什么应该频繁使用分支。 分支的新建与合并 现在让我们来看一个简单的分支与合并的例子，实际工作中大体也会用到这样的工作流程： 1. 开发某个网站。 2. 为实现某个新的需求，创建一个分支。 3. 在这个分支上开展工作。 假设此时，你突然接到一个电话说有个很严重的问题需要紧急修补，那么可以按照下面的方式处理： 1. 返回到原先已经发布到生产服务器上的分支。 2. 为这次紧急修补建立一个新分支，并在其中修复问题。 3. 通过测试后，回到生产服务器所在的分支，将修补分支合并进来，然后再推送到生产服务器上。 4. 切换到之前实现新需求的分支，继续工作。 分支的新建与切换 首先，我们假设你正在项目中愉快地工作，并且已经提交了几次更新 现在，你决定要修补问题追踪系统上的 #53 问题。顺带说明下，Git 并不同任何特定的问题追踪系统打交道。这里为了说明要解决的问题，才把新建的分支取名为 iss53。要新建并切换到该分支，运行git checkout 并加上 -b参数： 12 $ git checkout -b iss53 Switched to a new branch &quot;iss53&quot; 这相当于执行下面这两条命令： 12 $ git branch iss53 $ git checkout iss53 接着你开始尝试修复问题，在提交了若干次更新后，iss53 分支的指针也会随着向前推进，因为它就是当前分支（换句话说，当前的 HEAD 指针正指向 iss53）： 12$ vim index.html$ git commit -a -m &apos;added a new footer [issue 53]&apos; 现在你就接到了那个网站问题的紧急电话，需要马上修补。有了 Git ，我们就不需要同时发布这个补丁和 iss53里作出的修改，也不需要在创建和发布该补丁到服务器之前花费大力气来复原这些修改。唯一需要的仅仅是切换回master 分支。 不过在此之前，留心你的暂存区或者工作目录里，那些还没有提交的修改，它会和你即将检出的分支产生冲突从而阻止 Git 为你切换分支。切换分支的时候最好保持一个清洁的工作区域。稍后会介绍几个绕过这种问题的办法（分别叫做 stashing 和 commit amending）。目前已经提交了所有的修改，所以接下来可以正常转换到master 分支： 12 $ git checkout master Switched to branch &quot;master&quot; 此时工作目录中的内容和你在解决问题 #53 之前一模一样，你可以集中精力进行紧急修补。这一点值得牢记：Git 会把工作目录的内容恢复为检出某分支时它所指向的那个提交对象的快照。它会自动添加、删除和修改文件以确保目录的内容和你当时提交时完全一样。 接下来，你得进行紧急修补。我们创建一个紧急修补分支 hotfix 来开展工作，直到搞定： 123456$ git checkout -b &apos;hotfix&apos;Switched to a new branch &quot;hotfix&quot;$ vim index.html$ git commit -a -m &apos;fixed the broken email address&apos;[hotfix]: created 3a0874c: &quot;fixed the broken email address&quot; 1 files changed, 0 insertions(+), 1 deletions(-) 有必要作些测试，确保修补是成功的，然后回到 master 分支并把它合并进来，然后发布到生产服务器。用 git merge 命令来进行合并： 123456$ git checkout master$ git merge hotfixUpdating f42c576..3a0874cFast forward README | 1 - 1 files changed, 0 insertions(+), 1 deletions(-) 请注意，合并时出现了“Fast forward”的提示。由于当前 master 分支所在的提交对象是要并入的 hotfix 分支的直接上游，Git 只需把master 分支指针直接右移。换句话说，如果顺着一个分支走下去可以到达另一个分支的话，那么 Git 在合并两者时，只会简单地把指针右移，因为这种单线的历史分支不存在任何需要解决的分歧，所以这种合并过程可以称为快进（Fast forward）。 现在最新的修改已经在当前 master 分支所指向的提交对象中了，可以部署到生产服务器上去了 在那个超级重要的修补发布以后，你想要回到被打扰之前的工作。由于当前 hotfix 分支和 master 都指向相同的提交对象，所以hotfix 已经完成了历史使命，可以删掉了。使用 git branch 的 -d 选项执行删除操作： 12 $ git branch -d hotfix Deleted branch hotfix (3a0874c). 现在回到之前未完成的 #53 问题修复分支上继续工作（图 3-15）： 123456$ git checkout iss53Switched to branch &quot;iss53&quot;$ vim index.html$ git commit -a -m &apos;finished the new footer [issue 53]&apos;[iss53]: created ad82d7a: &quot;finished the new footer [issue 53]&quot; 1 files changed, 1 insertions(+), 0 deletions(-) 不用担心之前 hotfix 分支的修改内容尚未包含到 iss53 中来。如果确实需要纳入此次修补，可以用git merge master 把 master 分支合并到 iss53；或者等 iss53 完成之后，再将iss53分支中的更新并入 master。 分支的合并 在问题 #53 相关的工作完成之后，可以合并回 master 分支。实际操作同前面合并 hotfix 分支差不多，只需回到master 分支，运行 git merge 命令指定要合并进来的分支： 12345$ git checkout master$ git merge iss53Merge made by recursive. README | 1 + 1 files changed, 1 insertions(+), 0 deletions(-) 请注意，这次合并操作的底层实现，并不同于之前 hotfix 的并入方式。因为这次你的开发历史是从更早的地方开始分叉的。由于当前 master 分支所指向的提交对象（C4）并不是 iss53 分支的直接祖先，Git 不得不进行一些额外处理。就此例而言，Git 会用两个分支的末端（C4 和 C5）以及它们的共同祖先（C2）进行一次简单的三方合并计算。图 3-16 用红框标出了 Git 用于合并的三个提交对象： 这次，Git 没有简单地把分支指针右移，而是对三方合并后的结果重新做一个新的快照，并自动创建一个指向它的提交对象（C6）。这个提交对象比较特殊，它有两个祖先（C4 和 C5）。 值得一提的是 Git 可以自己裁决哪个共同祖先才是最佳合并基础；这和 CVS 或 Subversion（1.5 以后的版本）不同，它们需要开发者手工指定合并基础。所以此特性让 Git 的合并操作比其他系统都要简单不少。 既然之前的工作成果已经合并到 master 了，那么 iss53 也就没用了。你可以就此删除它，并在问题追踪系统里关闭该问题。 1 $ git branch -d iss53 Checkout 历史版本从某个历史版本创建新的分支在 Git 中从当前分支创建并检出新分支的命令是 1git checkout -b name-of-new-branch 这个命令实际上是 1git checkout -b name-of-new-branch current-branch 的简写形式。也就是说，当我们不指定 checkout 起点时，Git 默认从当前活动分支开始创建新的分支。 Git 的每个提交都有一个 SHA1 散列值（Hash 值）作为 ID。我们可以在 checkout 命令中使用这些 ID 作为起点。比如： 1git checkout -b name-of-new-branch 169d2dc 这样，Git 的活动分支会切换到 name-of-new-branch 这个分支上，而它的内容与 169d2dc 这个分支一致。 注意：SHA1 的散列值有 40 个字母，相当长。所以 Git 允许我们在不引起歧义的情况下，使用散列值的前几位作为缩写。 提示：你也可以用 git branch name-of-new-branch 169d2dc 来创建一个历史分支，而不切换到该分支。 将某个历史版本 checkout 到工作区首先说明，这样做会产生一个分离的 HEAD 指针，所以个人不推荐这么做。 如果我们工作在 master 分支上，希望 checkout 到 dev 分支上，我们会这么做： 1git checkout dev 这里 dev 实际上是一个指针的别名，其本质也是一个 SHA1 散列值。所以，我们很自然地可以用 1git checkout &lt;sha1-of-a-commit&gt; 将某个历史版本 checkout 到工作区。 将某个文件的历史版本 checkout 到工作区大多数时候，我们可能只需要对某一个文件做细小的修补，因此只 checkout 该文件就行了，并不需要操作整个 commit 或分支。 上一节我们介绍了如何将某个历史版本完整地 checkout 到工作区。实际上，我们只需要在上一节的命令之后加上需要 checkout 的文件即可。 1git checkout &lt;sha1-of-a-commit&gt; &lt;/path/to/your/file&gt; 当然，有时候你需要将某个文件的历史版本 checkout 出来，并以一个新的名字保存。这时候可以这么做： 遇到冲突时的分支合并 有时候合并操作并不会如此顺利。如果在不同的分支中都修改了同一个文件的同一部分，Git 就无法干净地把两者合到一起（译注：逻辑上说，这种问题只能由人来裁决。）。如果你在解决问题 #53 的过程中修改了hotfix 中修改的部分，将得到类似下面的结果： 1234$ git merge iss53Auto-merging index.htmlCONFLICT (content): Merge conflict in index.htmlAutomatic merge failed; fix conflicts and then commit the result. Git 作了合并，但没有提交，它会停下来等你解决冲突。要看看哪些文件在合并时发生冲突，可以用 git status 查阅： 123456789101112[master*]$ git statusindex.html: needs merge# On branch master# Changed but not updated:# (use &quot;git add ...&quot; to update what will be committed)# (use &quot;git checkout -- ...&quot; to discard changes in working directory)## unmerged: index.html# 任何包含未解决冲突的文件都会以未合并（unmerged）的状态列出。Git 会在有冲突的文件里加入标准的冲突解决标记，可以通过它们来手工定位并解决这些冲突。可以看到此文件包含类似下面这样的部分： 12345&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD:index.htmlcontact : email.support@github.com=======please contact us at support@github.com&gt;&gt;&gt;&gt;&gt;&gt;&gt; iss53:index.html 可以看到 ======= 隔开的上半部分，是 HEAD（即 master 分支，在运行merge 命令时所切换到的分支）中的内容，下半部分是在 iss53 分支中的内容。解决冲突的办法无非是二者选其一或者由你亲自整合到一起。比如你可以通过把这段内容替换为下面这样来解决： please contact us at email.support@github.com 这个解决方案各采纳了两个分支中的一部分内容，而且我还删除了 &lt;&lt;&lt;&lt;&lt;&lt;&lt;，======= 和 &gt;&gt;&gt;&gt;&gt;&gt;&gt; 这些行。在解决了所有文件里的所有冲突后，运行 git add 将把它们标记为已解决状态（译注：实际上就是来一次快照保存到暂存区域。）。因为一旦暂存，就表示冲突已经解决。如果你想用一个有图形界面的工具来解决这些问题，不妨运行git mergetool，它会调用一个可视化的合并工具并引导你解决所有冲突： 12345678$ git mergetoolmerge tool candidates: kdiff3 tkdiff xxdiff meld gvimdiff opendiff emerge vimdiffMerging the files: index.htmlNormal merge conflict for &apos;index.html&apos;: &#123;local&#125;: modified &#123;remote&#125;: modifiedHit return to start merge resolution tool (opendiff): 如果不想用默认的合并工具（Git 为我默认选择了 opendiff，因为我在 Mac 上运行了该命令），你可以在上方”merge tool candidates”里找到可用的合并工具列表，输入你想用的工具名。我们将在第七章讨论怎样改变环境中的默认值。 退出合并工具以后，Git 会询问你合并是否成功。如果回答是，它会为你把相关文件暂存起来，以表明状态为已解决。 再运行一次 git status 来确认所有冲突都已解决： 1234567891011$ git status# On branch master# Changes to be committed:# (use &quot;git reset HEAD ...&quot; to unstage)## modified: index.html# 如果觉得满意了，并且确认所有冲突都已解决，也就是进入了暂存区，就可以用 git commit 来完成这次合并提交。提交的记录差不多是这样： 123456789Merge branch &apos;iss53&apos;Conflicts: index.html## It looks like you may be committing a MERGE.# If this is not correct, please remove the file# .git/MERGE_HEAD# and try again. 如果想给将来看这次合并的人一些方便，可以修改该信息，提供更多合并细节。比如你都作了哪些改动，以及这么做的原因。有时候裁决冲突的理由并不直接或明显，有必要略加注解。 分支的管理 到目前为止，你已经学会了如何创建、合并和删除分支。除此之外，我们还需要学习如何管理分支，在日后的常规工作中会经常用到下面介绍的管理命令。 git branch 命令不仅仅能创建和删除分支，如果不加任何参数，它会给出当前所有分支的清单： 1234$ git branch iss53* master testing 注意看 master 分支前的 * 字符：它表示当前所在的分支。也就是说，如果现在提交更新，master 分支将随着开发进度前移。若要查看各个分支最后一个提交对象的信息，运行git branch -v： 1234$ git branch -v iss53 93b412c fix javascript issue* master 7a98805 Merge branch &apos;iss53&apos; testing 782fd34 add scott to the author list in the readmes 要从该清单中筛选出你已经（或尚未）与当前分支合并的分支，可以用 --merge 和 --no-merged选项（Git 1.5.6 以上版本）。比如用git branch --merge 查看哪些分支已被并入当前分支（译注：也就是说哪些分支是当前分支的直接上游。）： 123$ git branch --merged iss53* master 之前我们已经合并了 iss53，所以在这里会看到它。一般来说，列表中没有 * 的分支通常都可以用 git branch -d 来删掉。原因很简单，既然已经把它们所包含的工作整合到了其他分支，删掉也不会损失什么。 另外可以用 git branch --no-merged 查看尚未合并的工作： 12$ git branch --no-merged testing 它会显示还未合并进来的分支。由于这些分支中还包含着尚未合并进来的工作成果，所以简单地用 git branch -d删除该分支会提示错误，因为那样做会丢失数据： 123$ git branch -d testingerror: The branch &apos;testing&apos; is not an ancestor of your current HEAD.If you are sure you want to delete it, run &apos;git branch -D testing&apos;. 不过，如果你确实想要删除该分支上的改动，可以用大写的删除选项 -D 强制执行，就像上面提示信息中给出的那样。 利用分支进行开发的工作流程 现在我们已经学会了新建分支和合并分支，可以（或应该）用它来做点什么呢？在本节，我们会介绍一些利用分支进行开发的工作流程。而正是由于分支管理的便捷，才衍生出了这类典型的工作模式，你可以根据项目的实际情况选择一种用用看。 长期分支 由于 Git 使用简单的三方合并，所以就算在较长一段时间内，反复多次把某个分支合并到另一分支，也不是什么难事。也就是说，你可以同时拥有多个开放的分支，每个分支用于完成特定的任务，随着开发的推进，你可以随时把某个特性分支的成果并到其他分支中。 许多使用 Git 的开发者都喜欢用这种方式来开展工作，比如仅在 master 分支中保留完全稳定的代码，即已经发布或即将发布的代码。与此同时，他们还有一个名为develop 或 next 的平行分支，专门用于后续的开发，或仅用于稳定性测试 — 当然并不是说一定要绝对稳定，不过一旦进入某种稳定状态，便可以把它合并到master 里。这样，在确保这些已完成的特性分支（短期分支，比如之前的 iss53 分支）能够通过所有测试，并且不会引入更多错误之后，就可以并到主干分支中，等待下一次的发布。 本质上我们刚才谈论的，是随着提交对象不断右移的指针。稳定分支的指针总是在提交历史中落后一大截，而前沿分支总是比较靠前 或者把它们想象成工作流水线，或许更好理解一些，经过测试的提交对象集合被遴选到更稳定的流水线 你可以用这招维护不同层次的稳定性。某些大项目还会有个 proposed（建议）或 pu（proposed updates，建议更新）分支，它包含着那些可能还没有成熟到进入next 或 master 的内容。这么做的目的是拥有不同层次的稳定性：当这些分支进入到更稳定的水平时，再把它们合并到更高层分支中去。再次说明下，使用多个长期分支的做法并非必需，不过一般来说，对于特大型项目或特复杂的项目，这么做确实更容易管理。 特性分支 在任何规模的项目中都可以使用特性（Topic）分支。一个特性分支是指一个短期的，用来实现单一特性或与其相关工作的分支。可能你在以前的版本控 制系统里从未做过类似这样的事情，因为通常创建与合并分支消耗太大。然而在 Git 中，一天之内建立、使用、合并再删除多个分支是常见的事。 我们在上节的例子里已经见过这种用法了。我们创建了 iss53 和 hotfix 这两个特性分支，在提交了若干更新后，把它们合并到主干分支，然后删除。该技术允许你迅速且完全的进行语境切换 — 因为你的工作分散在不同的流水线里，每个分支里的改变都和它的目标特性相关，浏览代码之类的事情因而变得更简单了。你可以把作出的改变保持在特性分支中几 分钟，几天甚至几个月，等它们成熟以后再合并，而不用在乎它们建立的顺序或者进度。 现在我们来看一个实际的例子。请看下图，由下往上，起先我们在 master 工作到 C1，然后开始一个新分支 iss91 尝试修复 91 号缺陷，提交到 C6 的时候，又冒出一个解决该问题的新办法，于是从之前 C4 的地方又分出一个分支iss91v2，干到 C8 的时候，又回到主干 master 中提交了 C9 和 C10，再回到 iss91v2 继续工作，提交 C11，接着，又冒出个不太确定的想法，从 master 的最新提交 C10 处开了个新的分支dumbidea 做些试验。 现在，假定两件事情：我们最终决定使用第二个解决方案，即 iss91v2 中的办法；另外，我们把 dumbidea 分支拿给同事们看了以后，发现它竟然是个天才之作。所以接下来，我们准备抛弃原来的iss91 分支（实际上会丢弃 C5 和 C6），直接在主干中并入另外两个分支。最终的提交历史将变成下图 请务必牢记这些分支全部都是本地分支，这一点很重要。当你在使用分支及合并的时候，一切都是在你自己的 Git 仓库中进行的 — 完全不涉及与服务器的交互。 远程分支 远程分支（remote branch）是对远程仓库中的分支的索引。它们是一些无法移动的本地分支；只有在 Git 进行网络交互时才会更新。远程分支就像是书签，提醒着你上次连接远程仓库时上面各分支的位置。 我们用 (远程仓库名)/(分支名) 这样的形式表示远程分支。比如我们想看看上次同 origin 仓库通讯时master的样子，就应该查看 origin/master 分支。如果你和同伴一起修复某个问题，但他们先推送了一个iss53 分支到远程仓库，虽然你可能也有一个本地的 iss53 分支，但指向服务器上最新更新的却应该是 origin/iss53 分支。 可能有点乱，我们不妨举例说明。假设你们团队有个地址为 git.ourcompany.com 的 Git 服务器。如果你从这里克隆，Git 会自动为你将此远程仓库命名为origin，并下载其中所有的数据，建立一个指向它的 master 分支的指针，在本地命名为 origin/master，但你无法在本地更改其数据。接着，Git 建立一个属于你自己的本地master 分支，始于 origin 上 master 分支相同的位置，你可以就此开始工作 一次 Git 克隆会建立你自己的本地分支 master 和远程分支 origin/master，它们都指向 origin/master 分支的最后一次提交。 如果你在本地 master 分支做了些改动，与此同时，其他人向 git.ourcompany.com 推送了他们的更新，那么服务器上的master 分支就会向前推进，而于此同时，你在本地的提交历史正朝向不同方向发展。不过只要你不和服务器通讯，你的 origin/master 指针仍然保持原位不会移动 在本地工作的同时有人向远程仓库推送内容会让提交历史开始分流。 可以运行 git fetch origin 来同步远程服务器上的数据到本地。该命令首先找到 origin 是哪个服务器（本例为git.ourcompany.com），从上面获取你尚未拥有的数据，更新你本地的数据库，然后把 origin/master 的指针移到它最新的位置上 为了演示拥有多个远程分支（在不同的远程服务器上）的项目是如何工作的，我们假设你还有另一个仅供你的敏捷开发小组使用的内部服务器 git.team1.ourcompany.com。可以用第二章中提到的git remote add 命令把它加为当前项目的远程分支之一。我们把它命名为 teamone，以便代替原始的 Git 地址 现在你可以用 git fetch teamone 来获取小组服务器上你还没有的数据了。由于当前该服务器上的内容是你 origin 服务器上的子集，Git 不会下载任何数据，而只是简单地创建一个名为teamone/master 的分支，指向 teamone 服务器上 master 分支所在的提交对象31b8e 推送本地分支 要想和其他人分享某个本地分支，你需要把它推送到一个你拥有写权限的远程仓库。你的本地分支不会被自动同步到你引入的远程服务器上，除非你明确执行推送操作。换句话说，对于无意分享的分支，你尽管保留为私人分支好了，而只推送那些协同工作要用到的特性分支。 如果你有个叫 serverfix 的分支需要和他人一起开发，可以运行 git push (远程仓库名) (分支名)： 1234567$ git push origin serverfixCounting objects: 20, done.Compressing objects: 100% (14/14), done.Writing objects: 100% (15/15), 1.74 KiB, done.Total 15 (delta 5), reused 0 (delta 0)To git@github.com:schacon/simplegit.git * [new branch] serverfix -&gt; serverfix 这其实有点像条捷径。Git 自动把 serverfix 分支名扩展为 refs/heads/serverfix:refs/heads/serverfix，意为“取出我在本地的 serverfix 分支，推送到远程仓库的 serverfix 分支中去”。我们将在第九章进一步介绍refs/heads/ 部分的细节，不过一般使用的时候都可以省略它。也可以运行 git push origin serverfix:serferfix 来实现相同的效果，它的意思是“上传我本地的 serverfix 分支到远程仓库中去，仍旧称它为 serverfix 分支”。通过此语法，你可以把本地分支推送到某个命名不同的远程分支：若想把远程分支叫作awesomebranch，可以用 git push origin serverfix:awesomebranch 来推送数据。 接下来，当你的协作者再次从服务器上获取数据时，他们将得到一个新的远程分支 origin/serverfix： 1234567$ git fetch originremote: Counting objects: 20, done.remote: Compressing objects: 100% (14/14), done.remote: Total 15 (delta 5), reused 0 (delta 0)Unpacking objects: 100% (15/15), done.From git@github.com:schacon/simplegit * [new branch] serverfix -&gt; origin/serverfix 值得注意的是，在 fetch 操作下载好新的远程分支之后，你仍然无法在本地编辑该远程仓库中的分支。换句话说，在本例中，你不会有一个新的serverfix 分支，有的只是一个你无法移动的 origin/serverfix 指针。 如果要把该内容合并到当前分支，可以运行 git merge origin/serverfix。如果想要一份自己的 serverfix来开发，可以在远程分支的基础上分化出一个新的分支来： 123$ git checkout -b serverfix origin/serverfixBranch serverfix set up to track remote branch refs/remotes/origin/serverfix.Switched to a new branch &quot;serverfix&quot; 这会切换到新建的 serverfix 本地分支，其内容同远程分支 origin/serverfix 一致，这样你就可以在里面继续开发了。 跟踪远程分支 从远程分支 checkout 出来的本地分支，称为跟踪分支(tracking branch)。跟踪分支是一种和远程分支有直接联系的本地分支。在跟踪分支里输入git push，Git 会自行推断应该向哪个服务器的哪个分支推送数据。反过来，在这些分支里运行 git pull 会获取所有远程索引，并把它们的数据都合并到本地分支中来。 在克隆仓库时，Git 通常会自动创建一个名为 master 的分支来跟踪 origin/master。这正是git push 和 git pull 一开始就能正常工作的原因。当然，你可以随心所欲地设定为其它跟踪分支，比如origin 上除了 master之外的其它分支。刚才我们已经看到了这样的一个例子：git checkout -b [分支名] [远程名]/[分支名]。如果你有 1.6.2 以上版本的 Git，还可以用--track 选项简化： 123$ git checkout --track origin/serverfixBranch serverfix set up to track remote branch refs/remotes/origin/serverfix.Switched to a new branch &quot;serverfix&quot; 要为本地分支设定不同于远程分支的名字，只需在前个版本的命令里换个名字： 123$ git checkout -b sf origin/serverfixBranch sf set up to track remote branch refs/remotes/origin/serverfix.Switched to a new branch &quot;sf&quot; 现在你的本地分支 sf 会自动向 origin/serverfix 推送和抓取数据了。 删除远程分支如果不再需要某个远程分支了，比如搞定了某个特性并把它合并进了远程的 master 分支（或任何其他存放稳定代码的地方），可以用这个非常无厘头的语法来删除它：git push [远程名] :[分支名]。如果想在服务器上删除serverfix 分支，运行下面的命令： 123$ git push origin :serverfixTo git@github.com:schacon/simplegit.git - [deleted] serverfix 咚！服务器上的分支没了。你最好特别留心这一页，因为你一定会用到那个命令，而且你很可能会忘掉它的语法。有种方便记忆这条命令的方法：记住我们不久前见过的 git push [远程名] [本地分支]:[远程分支] 语法，如果省略 [本地分支]，那就等于是在说“在这里提取空白然后把它变成[远程分支]”。 分支的衍合 把一个分支整合到另一个分支的办法有两种：merge 和 rebase（译注：rebase 的翻译暂定为“衍合”，大家知道就可以了。）。在本章我们会学习什么是衍合，如何使用衍合，为什么衍合操作如此富有魅力，以及我们应该在什么情况下使用衍合。 基本的衍合操作开发进程分叉到两个不同分支，又各自提交了更新。 之前介绍过，最容易的整合分支的方法是 merge 命令，它会把两个分支最新的快照（C3 和 C4）以及二者最新的共同祖先（C2）进行三方合并，合并的结果是产生一个新的提交对象（C5）。 其实，还有另外一个选择：你可以把在 C3 里产生的变化补丁在 C4 的基础上重新打一遍。在 Git 里，这种操作叫做衍合（rebase）。有了 rebase 命令，就可以把在一个分支里提交的改变移到另一个分支里重放一遍。 在上面这个例子中，运行： 1234$ git checkout experiment$ git rebase masterFirst, rewinding head to replay your work on top of it...Applying: added staged command 它的原理是回到两个分支最近的共同祖先，根据当前分支（也就是要进行衍合的分支 experiment）后续的历次提交对象（这里只有一个 C3），生成一系列文件补丁，然后以基底分支（也就是主干分支master）最后一个提交对象（C4）为新的出发点，逐个应用之前准备好的补丁文件，最后会生成一个新的合并提交对象（C3’），从而改写 experiment 的提交历史，使它成为 master 分支的直接下游，如图 现在回到 master 分支，进行一次快进合并 现在的 C3’ 对应的快照，其实和普通的三方合并，即上个例子中的 C5 对应的快照内容一模一样了。虽然最后整合得到的结果没有任何区别，但衍合能产生一个更为整洁的提交历史。如果视察一个衍合过的分支的历史记录，看起来会更 清楚：仿佛所有修改都是在一根线上先后进行的，尽管实际上它们原本是同时并行发生的。 一般我们使用衍合的目的，是想要得到一个能在远程分支上干净应用的补丁 — 比如某些项目你不是维护者，但想帮点忙的话，最好用衍合：先在自己的一个分支里进行开发，当准备向主项目提交补丁的时候，根据最新的origin/master 进行一次衍合操作然后再提交，这样维护者就不需要做任何整合工作（译注：实际上是把解决分支补丁同最新主干代码之间冲突的责任，化转为由提交补丁的人来解决。），只需根据你提供的仓库地址作一次快进合并，或者直接采纳你提交的补丁。 请注意，合并结果中最后一次提交所指向的快照，无论是通过衍合，还是三方合并，都会得到相同的快照内容，只不过提交历史不同罢了。衍合是按照每行的修改次序重演一遍修改，而合并是把最终结果合在一起。 有趣的衍合 衍合也可以放到其他分支进行，并不一定非得根据分化之前的分支。以图 3-31 的历史为例，我们为了给服务器端代码添加一些功能而创建了特性分支 server，然后提交 C3 和 C4。然后又从 C3 的地方再增加一个client 分支来对客户端代码进行一些相应修改，所以提交了 C8 和 C9。最后，又回到 server 分支提交了 C10。 假设在接下来的一次软件发布中，我们决定先把客户端的修改并到主线中，而暂缓并入服务端软件的修改（因为还需要进一步测试）。这个时候，我们就可以把基于 server 分支而非 master 分支的改变（即 C8 和 C9），跳过 server 直接放到master 分支中重演一遍，但这需要用 git rebase 的 --onto 选项指定新的基底分支master： 1$ git rebase --onto master server client 这好比在说：“取出 client 分支，找出 client 分支和 server 分支的共同祖先之后的变化，然后把它们在master 上重演一遍”。是不是有点复杂？不过它的结果如图 3-32 所示，非常酷（译注：虽然 client 里的 C8, C9 在 C3 之后，但这仅表明时间上的先后，而非在 C3 修改的基础上进一步改动，因为server 和 client 这两个分支对应的代码应该是两套文件，虽然这么说不是很严格，但应理解为在 C3 时间点之后，对另外的文件所做的 C8，C9 修改，放到主干重演。）： 现在可以快进 master 分支了： 12$ git checkout master$ git merge client 现在我们决定把 server 分支的变化也包含进来。我们可以直接把 server 分支衍合到 master，而不用手工切换到 server 分支后再执行衍合操作 — git rebase [主分支] [特性分支]命令会先取出特性分支server，然后在主分支 master 上重演： 1$ git rebase master server 于是，server 的进度应用到 master 的基础上， 然后就可以快进主干分支 master 了： 12$ git checkout master$ git merge server 现在 client 和 server 分支的变化都已经集成到主干分支来了，可以删掉它们了。最终我们的提交历史会变成图 3-35 的样子： 12$ git branch -d client$ git branch -d server 衍合的风险 呃，奇妙的衍合也并非完美无缺，要用它得遵守一条准则： 一旦分支中的提交对象发布到公共仓库，就千万不要对该分支进行衍合操作。 如果你遵循这条金科玉律，就不会出差错。否则，人民群众会仇恨你，你的朋友和家人也会嘲笑你，唾弃你。 在进行衍合的时候，实际上抛弃了一些现存的提交对象而创造了一些类似但不同的新的提交对象。如果你把原来分支中的提交对象发布出去，并且其他人更新下载后在其基础上开展工作，而稍后你又用git rebase 抛弃这些提交对象，把新的重演后的提交对象发布出去的话，你的合作者就不得不重新合并他们的工作，这样当你再次从他们那里获取内容时，提交历史就会变得一团糟。 下面我们用一个实际例子来说明为什么公开的衍合会带来问题。假设你从一个中央服务器克隆然后在它的基础上搞了一些开发，提交历史 现在，某人在 C1 的基础上做了些改变，并合并他自己的分支得到结果 C6，推送到中央服务器。当你抓取并合并这些数据到你本地的开发分支中后，会得到合并结果 C7，历史提交会变成 接下来，那个推送 C6 上来的人决定用衍合取代之前的合并操作；继而又用 git push --force 覆盖了服务器上的历史，得到 C4’。而之后当你再从服务器上下载最新提交后，会得到： 下载更新后需要合并，但此时衍合产生的提交对象 C4’ 的 SHA-1 校验值和之前 C4 完全不同，所以 Git 会把它们当作新的提交对象处理，而实际上此刻你的提交历史 C7 中早已经包含了 C4 的修改内容，于是合并操作会把 C7 和 C4’ 合并为 C8 C8 这一步的合并是迟早会发生的，因为只有这样你才能和其他协作者提交的内容保持同步。而在 C8 之后，你的提交历史里就会同时包含 C4 和 C4’，两者有着不同的 SHA-1 校验值，如果用git log 查看历史，会看到两个提交拥有相同的作者日期与说明，令人费解。而更糟的是，当你把这样的历史推送到服务器后，会再次把这些衍合后的提交引入到中央服务 器，进一步困扰其他人（译注：这个例子中，出问题的责任方是那个发布了 C6 后又用衍合发布 C4’ 的人，其他人会因此反馈双重历史到共享主干，从而混淆大家的视听。）。 如果把衍合当成一种在推送之前清理提交历史的手段，而且仅仅衍合那些尚未公开的提交对象，就没问题。如果衍合那些已经公开的提交对象，并且已经有人基于这些提交对象开展了后续开发工作的话，就会出现叫人沮丧的麻烦。 小结 读到这里，你应该已经学会了如何创建分支并切换到新分支，在不同分支间转换，合并本地分支，把分支推送到共享服务器上，使用共享分支与他人协作，以及在分享之前进行衍合。 转载链接Git详解三Git分支]]></content>
      <categories>
        <category>git使用及讲解</category>
      </categories>
      <tags>
        <tag>git工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络协议-最全的网络协议图]]></title>
    <url>%2F2018%2F09%2F08%2F%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E6%9C%80%E5%85%A8%E7%9A%84%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[转载自http://www.52im.net 图片较大，建议单击放大或者下载后查看]]></content>
      <categories>
        <category>网络编程协议</category>
      </categories>
      <tags>
        <tag>通信协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go语言并发讲解，虚拟内存讲解]]></title>
    <url>%2F2018%2F09%2F08%2Fgo%E8%AF%AD%E8%A8%80%E5%B9%B6%E5%8F%91%E8%AE%B2%E8%A7%A3%EF%BC%8C%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E8%AE%B2%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[并行和并发今天我们来讲一下在计算机编程中并行和并发的意思并行(parallel)：指在同一时刻，有多条指令在多个处理器上同时执行。并发(concurrency)：指在同一时刻只能有一条指令执行，但多个进程指令被快速的轮换执行，使得在宏观上具有多个进程同时执行的效果，但在微观上并不是同时执行的，只是把时间分成若干段，通过cpu时间片轮转使多个进程快速交替的执行。如果字面意思上不好理解的话那么我们可以来看一个例子就可以很轻松的理解出大师曾以咖啡机的例子来解释并行和并发的区别。 并行是两个队列同时使用两台咖啡机 （真正的多任务）并发是两个队列交替使用一台咖啡机 （ 假 的多任务）在计算机上想要实现并行该怎么办，那么我们就要像图中一样增加硬件设备，那么计算机就要增加cpu，但是计算机的cpu是有限的，所以我们就要设计并发来实现在计算机cpu不变的情况下增加运算能力，这就是并发的字面意思。 常见并发编程技术进程并发程序和进程程序，是指编译好的二进制文件，在磁盘上，不占用系统资源(内存、打开的文件、设备、锁….)进程，是一个抽象的概念，与操作系统原理联系紧密。进程是活跃的程序，占用系统资源。在内存中执行。(程序运行起来，产生一个进程)程序 → 剧本(纸) 进程 → 戏 (舞台、演员、灯光、道具…)同一个剧本可以在多个舞台同时上演。同样，同一个程序也可以加载为不同的进程(彼此之间互不影响)如：同时开两个终端。各自都有一个bash但彼此ID不同。在windows系统下，通过查看“任务管理器”，可以查看相应的进程。包括我们在基础班写的“飞机大战”等程序，运行起来后也可以在“任务管理器”中查看到。运行起来的程序就是一个进程。 进程状态进程基本的状态有5种。分别为初始态，就绪态，运行态，挂起态与终止态。其中初始态为进程准备阶段，常与就绪态结合来看。 进程并发在使用进程 实现并发时会出现什么问题呢？1：系统开销比较大，占用资源比较多，开启进程数量比较少。2：在unix/linux系统下，还会产生“孤儿进程”和“僵尸进程”。在操作系统运行过程中，可以产生很多的进程。在unix/linux系统中，正常情况下，子进程是通过父进程fork创建的，子进程再创建新的进程。并且父进程永远无法预测子进程到底什么时候结束。 当一个进程完成它的工作终止之后，它的父进程需要调用系统调用取得子进程的终止状态。孤儿进程孤儿进程: 父进程先于子进程结束，则子进程成为孤儿进程，子进程的父进程成为init进程，称为init进程领养孤儿进程。僵尸进程僵尸进程: 进程终止，父进程尚未回收，子进程残留资源（PCB）存放于内核中，变成僵尸（Zombie）进程。Windows下的进程和Linux下的进程是不一样的，它比较懒惰，从来不执行任何东西，只是为线程提供执行环境。然后由线程负责执行包含在进程的地址空间中的代码。当创建一个进程的时候，操作系统会自动创建这个进程的第一个线程，成为主线程。 线程并发什么是线程LWP：light weight process 轻量级的进程，本质仍是进程 (Linux下)进程：独立地址空间，拥有PCB 线程：有独立的PCB，但没有独立的地址空间(共享) 区别：在于是否共享地址空间。独居(进程)；合租(线程)。线程：最小的执行单位进程：最小分配资源单位，可看成是只有一个线程的进程。Windows系统下，可以直接忽略进程的概念，只谈线程。因为线程是最小的执行单位，是被系统独立调度和分派的基本单位。而进程只是给线程提供执行环境。线程同步同步即协同步调，按预定的先后次序运行。线程同步，指一个线程发出某一功能调用时，在没有得到结果之前，该调用不返回。同时其它线程为保证数据一致性，不能调用该功能。举例1： 银行存款 5000。柜台，折：取3000；提款机，卡：取 3000。剩余：2000举例2： 内存中100字节，线程T1欲填入全1， 线程T2欲填入全0。但如果T1执行了50个字节失去cpu，T2执行，会将T1写过的内容覆盖。当T1再次获得cpu继续 从失去cpu的位置向后写入1，当执行结束，内存中的100字节，既不是全1，也不是全0。产生的现象叫做“与时间有关的错误”(time related)。为了避免这种数据混乱，线程需要同步。“同步”的目的，是为了避免数据混乱，解决与时间有关的错误。实际上，不仅线程间需要同步，进程间、信号间等等都需要同步机制。因此，所有“多个控制流，共同操作一个共享资源”的情况，都需要同步。 协程并发协程：coroutine。也叫轻量级线程。与传统的系统级线程和进程相比，协程最大的优势在于“轻量级”。可以轻松创建上万个而不会导致系统资源衰竭。而线程和进程通常很难超过1万个。这也是协程别称“轻量级线程”的原因。一个线程中可以有任意多个协程，但某一时刻只能有一个协程在运行，多个协程分享该线程分配到的计算机资源。多数语言在语法层面并不直接支持协程，而是通过库的方式支持，但用库的方式支持的功能也并不完整，比如仅仅提供协程的创建、销毁与切换等能力。如果在这样的轻量级线程中调用一个同步 IO 操作，比如网络通信、本地文件读写，都会阻塞其他的并发执行轻量级线程，从而无法真正达到轻量级线程本身期望达到的目标。在协程中，调用一个任务就像调用一个函数一样，消耗的系统资源最少！但能达到进程、线程并发相同的效果。在一次并发任务中，进程、线程、协程均可以实现。从系统资源消耗的角度出发来看，进程相当多，线程次之，协程最少。 Go并发Go 在语言级别支持协程，叫goroutine。Go 语言标准库提供的所有系统调用操作（包括所有同步IO操作），都会出让CPU给其他goroutine。这让轻量级线程的切换管理不依赖于系统的线程和进程，也不需要依赖于CPU的核心数量。有人把Go比作21世纪的C语言。第一是因为Go语言设计简单，第二，21世纪最重要的就是并行程序设计，而Go从语言层面就支持并行。同时，并发程序的内存管理有时候是非常复杂的，而Go语言提供了自动垃圾回收机制。Go语言为并发编程而内置的上层API基于顺序通信进程模型CSP(communicating sequential processes)。这就意味着显式锁都是可以避免的，因为Go通过相对安全的通道发送和接受数据以实现同步，这大大地简化了并发程序的编写。Go语言中的并发程序主要使用两种手段来实现。goroutine和channel。 Goroutine什么是Goroutinegoroutine是Go语言并行设计的核心，有人称之为go程。 goroutine说到底其实就是协程，它比线程更小，十几个goroutine可能体现在底层就是五六个线程，Go语言内部帮你实现了这些goroutine之间的内存共享。执行goroutine只需极少的栈内存(大概是4~5KB)，当然会根据相应的数据伸缩。也正因为如此，可同时运行成千上万个并发任务。goroutine比thread更易用、更高效、更轻便。一般情况下，一个普通计算机跑几十个线程就有点负载过大了，但是同样的机器却可以轻松地让成百上千个goroutine进行资源竞争。 Goroutine的创建只需在函数调⽤语句前添加 go 关键字，就可创建并发执⾏单元。开发⼈员无需了解任何执⾏细节，调度器会自动将其安排到合适的系统线程上执行。在并发编程中，我们通常想将一个过程切分成几块，然后让每个goroutine各自负责一块工作，当一个程序启动时，主函数在一个单独的goroutine中运行，我们叫它main goroutine。新的goroutine会用go语句来创建。而go语言的并发设计，让我们很轻松就可以达成这一目的。示例代码： 1234567891011121314151617181920package mainimport ( &quot;fmt&quot; &quot;time&quot;)func main()&#123; go func()&#123; //加一个go关键字就创建了一个子go程 for i:=0;i&lt;5;i++&#123; fmt.Println(&quot;这里是一个匿名函数go进程&quot;) //打印一次 time.Sleep(time.Second) //延时一秒 &#125; &#125;() for i:=0;i&lt;5;i++&#123; fmt.Println(&quot;main&quot;) time.Sleep(time.Second) //延时一秒 &#125;&#125; 打印结果如下 这就是go的并发，只需要在前面加一个关键字就可以了，在这里子go程和主go程相互夺取cpu，cpu用来分配时间轮转片，轮到谁就执行，在这个程序里面因为都延时了1秒，所以运行一次就会给对方运行 一个程序要想运行，必须要有“进行地址（虚拟地址）空间”， 所有系统都一样 下面我们来看一下虚拟内存的讲解，我们先来看一张图 我们图中是拿了一个512M的物理内存来举例子，电脑假设为32位的电脑，在32位电脑上，我们运行一个程序图中左边都有两个go程序，都会分配4G的空间给程序，分别为代码区，只读数据区，数据区，未初始化数据区，堆区，栈区，内核区，但是我们的物理内存只有512M，那么两个程序占8G，那么够用吗，其实是够的，这是为什么？，这是因为在程序运行是CPU中的MMU会映射一个虚拟内存出来，你可以当作想象吧，我们平时看到的内存条什么的物理内存都会有一个物理地址，但是我们是不能直接拿物理地址来操作程序什么的，我们平时操作的地址都是CPU映射出来的虚拟内存的虚拟地址，图中我们在虚拟内存中声明了两个变量，这样CPU通过MMU来在真实的物理内存上面映射两个物理地址，类似于将物理地址和虚拟地址链接一下，然后等程序运行完毕，直接将虚拟内存释放，这样的话运行程序在32位电脑上虚拟出来的4G都是虚拟出来的。 如果想要了解更多的硬件问题推荐一下《计算机组成原理》这本书可以去了解一下]]></content>
      <categories>
        <category>GO语言</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>内存讲解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络协议]]></title>
    <url>%2F2018%2F09%2F08%2F%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[协议从应用的角度出发，协议可理解为“规则”，是数据传输和数据的解释的规则。假设，A、B双方欲传输文件。规定： 第一次，传输文件名，接收方接收到文件名，应答OK给传输方； 第二次，发送文件的尺寸，接收方接收到该数据再次应答一个OK； 第三次，传输文件内容。同样，接收方接收数据完成后应答OK表示文件内容接收成功。由此，无论A、B之间传递何种文件，都是通过三次数据传输来完成。A、B之间形成了一个最简单的数据传输规则。双方都按此规则发送、接收数据。A、B之间达成的这个相互遵守的规则即为协议。 这种仅在A、B之间被遵守的协议称之为原始协议。当此协议被更多的人采用，不断的增加、改进、维护、完善。最终形成一个稳定的、完整的文件传输协议，被广泛应用于各种文件传输过程中。该协议就成为一个标准协议。最早的ftp协议就是由此衍生而来。 典型协议 传输层 常见协议有TCP/UDP协议。 应用层 常见的协议有HTTP协议，FTP协议。 网络层 常见协议有IP协议、ICMP协议、IGMP协议。 网络接口层 常见协议有ARP协议、RARP协议。 TCP传输控制协议（Transmission Control Protocol）是一种面向连接的、可靠的、基于字节流的传输层通信协议。 UDP用户数据报协议（User Datagram Protocol）是OSI参考模型中一种无连接的传输层协议，提供面向事务的简单不可靠信息传送服务。 HTTP超文本传输协议（Hyper Text Transfer Protocol）是互联网上应用最为广泛的一种网络协议。 FTP文件传输协议（File Transfer Protocol） IP协议是因特网互联协议（Internet Protocol） ICMP协议是Internet控制报文协议（Internet Control Message Protocol）它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。 IGMP协议是 Internet 组管理协议（Internet Group Management Protocol），是因特网协议家族中的一个组播协议。该协议运行在主机和组播路由器之间。 ARP协议是正向地址解析协议（Address Resolution Protocol），通过已知的IP，寻找对应主机的MAC地址。 RARP是反向地址转换协议，通过MAC地址确定IP地址。 分层模型网络分层架构为了减少协议设计的复杂性，大多数网络模型均采用分层的方式来组织。每一层都有自己的功能，就像建筑物一样，每一层都靠下一层支持。每一层利用下一层提供的服务来为上一层提供服务，本层服务的实现细节对上层屏蔽。 越下面的层，越靠近硬件；越上面的层，越靠近用户。至于每一层叫什么名字，对应编程而言不重要，但面试的时候，面试官可能会问每一层的名字。业内普遍的分层方式有两种。OSI七层模型 和TCP/IP四层模型。可以通过背诵两个口诀来快速记忆：OSI七层模型：物、数、网、传、会、表、应TCP/IP四层模型：链、网、传、应 物理层：主要定义物理设备标准，如网线的接口类型、光纤的接口类型、各种传输介质的传输速率等。它的主要作用是传输比特流（就是由1、0转化为电流强弱来进行传输，到达目的地后再转化为1、0，也就是我们常说的数模转换与模数转换）。这一层的数据叫做比特。 数据链路层：定义了如何让格式化数据以帧为单位进行传输，以及如何让控制对物理介质的访问。这一层通常还提供错误检测和纠正，以确保数据的可靠传输。如：串口通信中使用到的115200、8、N、1 网络层：在位于不同地理位置的网络中的两个主机系统之间提供连接和路径选择。Internet的发展使得从世界各站点访问信息的用户数大大增加，而网络层正是管理这种连接的层。 传输层：定义了一些传输数据的协议和端口号（WWW端口80等），如：TCP（传输控制协议，传输效率低，可靠性强，用于传输可靠性要求高，数据量大的数据），UDP（用户数据报协议，与TCP特性恰恰相反，用于传输可靠性要求不高，数据量小的数据，如QQ聊天数据就是通过这种方式传输的）。 主要是将从下层接收的数据进行分段和传输，到达目的地址后再进行重组。常常把这一层数据叫做段。 会话层：通过传输层(端口号：传输端口与接收端口)建立数据传输的通路。主要在你的系统之间发起会话或者接受会话请求（设备之间需要互相认识可以是IP也可以是MAC或者是主机名）。 表示层：可确保一个系统的应用层所发送的信息可以被另一个系统的应用层读取。例如，PC程序与另一台计算机进行通信，其中一台计算机使用扩展二一十进制交换码(EBCDIC)，而另一台则使用美国信息交换标准码（ASCII）来表示相同的字符。如有必要，表示层会通过使用一种通格式来实现多种数据格式之间的转换。 应用层：是最靠近用户的OSI层。这一层为用户的应用程序（例如电子邮件、文件传输和终端仿真）提供网络服务。 层与协议每一层都是为了完成一种功能，为了实现这些功能，就需要大家都遵守共同的规则。大家都遵守这规则，就叫做“协议”（protocol）。网络的每一层，都定义了很多协议。这些协议的总称，叫“TCP/IP协议”。TCP/IP协议是一个大家族，不仅仅只有TCP和IP协议，它还包括其它的协议，如下图： 各层功能 链路层以太网规定，连入网络的所有设备，都必须具有“网卡”接口。数据包必须是从一块网卡，传送到另一块网卡。通过网卡能够使不同的计算机之间连接，从而完成数据通信等功能。网卡的地址——MAC 地址，就是数据包的物理发送地址和物理接收地址。 网络层网络层的作用是引进一套新的地址，使得我们能够区分不同的计算机是否属于同一个子网络。这套地址就叫做“网络地址”，就是我们平时所说的IP地址。这个IP地址好比我们的手机号码，通过手机号码可以得到用户所在的归属地。网络地址帮助我们确定计算机所在的子网络，MAC 地址则将数据包送到该子网络中的目标网卡。网络层协议包含的主要信息是源IP和目的IP。于是，“网络层”出现以后，每台计算机有了两种地址，一种是 MAC 地址，另一种是网络地址。两种地址之间没有任何联系，MAC 地址是绑定在网卡上的，网络地址则是管理员分配的，它们只是随机组合在一起。网络地址帮助我们确定计算机所在的子网络，MAC 地址则将数据包送到该子网络中的目标网卡。因此，从逻辑上可以推断，必定是先处理网络地址，然后再处理 MAC 地址。 传输层当我们一边聊QQ，一边聊微信，当一个数据包从互联网上发来的时候，我们怎么知道，它是来自QQ的内容，还是来自微信的内容？也就是说，我们还需要一个参数，表示这个数据包到底供哪个程序（进程）使用。这个参数就叫做“端口”（port），它其实是每一个使用网卡的程序的编号。每个数据包都发到主机的特定端口，所以不同的程序就能取到自己所需要的数据。端口特点： 对于同一个端口，在不同系统中对应着不同的进程 对于同一个系统，一个端口只能被一个进程拥有 应用层应用程序收到“传输层”的数据，接下来就要进行解读。由于互联网是开放架构，数据来源五花八门，必须事先规定好格式，否则根本无法解读。“应用层”的作用，就是规定应用程序的数据格式。 通信过程两台计算机通过TCP/IP协议通讯的过程如下所示：]]></content>
      <categories>
        <category>网络编程协议</category>
      </categories>
      <tags>
        <tag>通信协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git知识点详解]]></title>
    <url>%2F2018%2F09%2F07%2Fgit%E7%9F%A5%E8%AF%86%E7%82%B9%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Git知识点详解 文件状态现在我们手上已经有了一个真实项目的 Git 仓库，并从这个仓库中取出了所有文件的工作拷贝。接下来，对这些文件作些修改，在完成了一个阶段的目标之后，提交本次更新到仓库。 请记住，工作目录下面的所有文件都不外乎这两种状态：已跟踪或未跟踪。已跟踪的文件是指本来就被纳入版本控制管理的文件，在上次快照中有它们的记 录，工作一段时间后，它们的状态可能是未更新，已修改或者已放入暂存区。而所有其他文件都属于未跟踪文件。它们既没有上次更新时的快照，也不在当前的暂存 区域。初次克隆某个仓库时，工作目录中的所有文件都属于已跟踪文件，且状态为未修改。 在编辑过某些文件之后，Git 将这些文件标为已修改。我们逐步把这些修改过的文件放到暂存区域，直到最后一次性提交所有这些暂存起来的文件，如此重复。如下图： 检查当前文件状态要确定哪些文件当前处于什么状态，可以用 git status 命令。如果在克隆仓库之后立即执行此命令，会看到类似这样的输出： 123$ git status# On branch masternothing to commit (working directory clean) 这说明你现在的工作目录相当干净。换句话说，当前没有任何跟踪着的文件，也没有任何文件在上次提交后更改过。此外，上面的信息还表明，当前目录下没 有出现任何处于未跟踪的新文件，否则 Git 会在这里列出来。最后，该命令还显示了当前所在的分支是 master，这是默认的分支名称，实际是可以修改的，现在先不用考虑。下一章我们就会详细讨论分支和引用。 现在让我们用 vim 编辑一个新文件 README，保存退出后运行 git status 会看到该文件出现在未跟踪文件列表中： 12345678$ vim README$ git status# On branch master# Untracked files:# (use &quot;git add ...&quot; to include in what will be committed)## READMEnothing added to commit but untracked files present (use &quot;git add&quot; to track) 就是在“Untracked files”这行下面。Git 不会自动将之纳入跟踪范围，除非你明明白白地告诉它“我需要跟踪该文件”，因而不用担心把临时文件什么的也归入版本管理。不过现在的例子中，我们确实想要跟踪管理 README 这个文件。 跟踪新文件 使用命令 git add 开始跟踪一个新文件。所以，要跟踪 README 文件，运行： 1$ git add README 此时再运行 git status 命令，会看到 README 文件已被跟踪，并处于暂存状态： 1234567$ git status# On branch master# Changes to be committed:# (use &quot;git reset HEAD ...&quot; to unstage)## new file: README# 只要在 “Changes to be committed” 这行下面的，就说明是已暂存状态。如果此时提交，那么该文件此时此刻的版本将被留存在历史记录中。你可能会想起之前我们使用git init 后就运行了 git add 命令，开始跟踪当前目录下的文件。在 git add 后面可以指明要跟踪的文件或目录路径。如果是目录的话，就说明要递归跟踪该目录下的所有文件。（译注：其实git add 的潜台词就是把目标文件快照放入暂存区域，也就是 add file into staged area，同时未曾跟踪过的文件标记为需要跟踪。这样就好理解后续 add 操作的实际意义了。） 暂存已修改文件 现在我们修改下之前已跟踪过的文件 benchmarks.rb，然后再次运行 status 命令，会看到这样的状态报告： 123456789101112$ git status# On branch master# Changes to be committed:# (use &quot;git reset HEAD ...&quot; to unstage)## new file: README## Changed but not updated:# (use &quot;git add ...&quot; to update what will be committed)## modified: benchmarks.rb# 文件 benchmarks.rb 出现在 “Changed but not updated” 这行下面，说明已跟踪文件的内容发生了变化，但还没有放到暂存区。要暂存这次更新，需要运行git add 命令（这是个多功能命令，根据目标文件的状态不同，此命令的效果也不同：可以用它开始跟踪新文件，或者把已跟踪的文件放到暂存区，还能用于合并时把有冲突的文件标记为已解决状态等）。现在让我们运行git add 将 benchmarks.rb 放到暂存区，然后再看看 git status 的输出： 123456789$ git add benchmarks.rb$ git status# On branch master# Changes to be committed:# (use &quot;git reset HEAD ...&quot; to unstage)## new file: README# modified: benchmarks.rb# 现在两个文件都已暂存，下次提交时就会一并记录到仓库。假设此时，你想要在 benchmarks.rb 里再加条注释，重新编辑存盘后，准备好提交。不过且慢，再运行git status 看看： 1234567891011121314$ vim benchmarks.rb $ git status# On branch master# Changes to be committed:# (use &quot;git reset HEAD ...&quot; to unstage)## new file: README# modified: benchmarks.rb## Changed but not updated:# (use &quot;git add ...&quot; to update what will be committed)## modified: benchmarks.rb# 怎么回事？benchmarks.rb 文件出现了两次！一次算未暂存，一次算已暂存，这怎么可能呢？好吧，实际上 Git 只不过暂存了你运行 git add 命令时的版本，如果现在提交，那么提交的是添加注释前的版本，而非当前工作目录中的版本。所以，运行了git add 之后又作了修订的文件，需要重新运行 git add 把最新版本重新暂存起来： 123456789$ git add benchmarks.rb$ git status# On branch master# Changes to be committed:# (use &quot;git reset HEAD ...&quot; to unstage)## new file: README# modified: benchmarks.rb# 忽略某些文件一般我们总会有些文件无需纳入 Git 的管理，也不希望它们总出现在未跟踪文件列表。通常都是些自动生成的文件，比如日志文件，或者编译过程中创建的临时文件等。我们可以创建一个名为 .gitignore 的文件，列出要忽略的文件模式。来看一个实际的例子： 123$ cat .gitignore*.[oa]*~ 第一行告诉 Git 忽略所有以 .o 或 .a 结尾的文件。一般这类对象文件和存档文件都是编译过程中出现的，我们用不着跟踪它们的版本。第二行告诉 Git 忽略所有以波浪符（~）结尾的文件，许多文本编辑软件（比如 Emacs）都用这样的文件名保存副本。此外，你可能还需要忽略 log，tmp 或者 pid 目录，以及自动生成的文档等等。要养成一开始就设置好 .gitignore 文件的习惯，以免将来误提交这类无用的文件。 文件 .gitignore 的格式规范如下： 所有空行或者以注释符号 ＃ 开头的行都会被 Git 忽略。 可以使用标准的 glob 模式匹配。 匹配模式最后跟反斜杠（/）说明要忽略的是目录。 要忽略指定模式以外的文件或目录，可以在模式前加上惊叹号（!）取反。 所谓的 glob 模式是指 shell 所使用的简化了的正则表达式。星号（*）匹配零个或多个任意字符；[abc] 匹配任何一个列在方括号中的字符（这个例子要么匹配一个 a，要么匹配一个 b，要么匹配一个 c）；问号（?）只匹配一个任意字符；如果在方括号中使用短划线分隔两个字符，表示所有在这两个字符范围内的都可以匹配（比如[0-9] 表示匹配所有 0 到 9 的数字）。 我们再看一个 .gitignore 文件的例子： 123456# 此为注释 – 将被 Git 忽略*.a # 忽略所有 .a 结尾的文件!lib.a # 但 lib.a 除外/TODO # 仅仅忽略项目根目录下的 TODO 文件，不包括 subdir/TODObuild/ # 忽略 build/ 目录下的所有文件doc/*.txt # 会忽略 doc/notes.txt 但不包括 doc/server/arch.txt 查看已暂存和未暂存的更新实际上 git status 的显示比较简单，仅仅是列出了修改过的文件，如果要查看具体修改了什么地方，可以用 git diff 命令。稍后我们会详细介绍git diff，不过现在，它已经能回答我们的两个问题了：当前做的哪些更新还没有暂存？有哪些更新已经暂存起来准备好了下次提交？ git diff 会使用文件补丁的格式显示具体添加和删除的行。 假如再次修改 README 文件后暂存，然后编辑 benchmarks.rb 文件后先别暂存，运行 status命令，会看到： 123456789101112$ git status# On branch master# Changes to be committed:# (use &quot;git reset HEAD ...&quot; to unstage)## new file: README## Changed but not updated:# (use &quot;git add ...&quot; to update what will be committed)## modified: benchmarks.rb# 要查看尚未暂存的文件更新了哪些部分，不加参数直接输入 git diff： 12345678910111213141516$ git diffdiff --git a/benchmarks.rb b/benchmarks.rbindex 3cb747f..da65585 100644--- a/benchmarks.rb+++ b/benchmarks.rb@@ -36,6 +36,10 @@ def main @commit.parents[0].parents[0].parents[0] end+ run_code(x, &apos;commits 1&apos;) do+ git.commits.size+ end+ run_code(x, &apos;commits 2&apos;) do log = git.commits(&apos;master&apos;, 15) log.size 此命令比较的是工作目录中当前文件和暂存区域快照之间的差异，也就是修改之后还没有暂存起来的变化内容。 若要看已经暂存起来的文件和上次提交时的快照之间的差异，可以用 git diff --cached 命令。（Git 1.6.1 及更高版本还允许使用git diff --staged，效果是相同的，但更好记些。）来看看实际的效果： 123456789101112$ git diff --cacheddiff --git a/README b/READMEnew file mode 100644index 0000000..03902a1--- /dev/null+++ b/README2@@ -0,0 +1,5 @@+grit+ by Tom Preston-Werner, Chris Wanstrath+ http://github.com/mojombo/grit++Grit is a Ruby library for extracting information from a Git repository 请注意，单单 git diff 不过是显示还没有暂存起来的改动，而不是这次工作和上次提交之间的差异。所以有时候你一下子暂存了所有更新过的文件后，运行git diff 后却什么也没有，就是这个原因。 像之前说的，暂存 benchmarks.rb 后再编辑，运行 git status 会看到暂存前后的两个版本： 12345678910111213$ git add benchmarks.rb$ echo &apos;# test line&apos; &gt;&gt; benchmarks.rb$ git status# On branch master## Changes to be committed:## modified: benchmarks.rb## Changed but not updated:## modified: benchmarks.rb# 现在运行 git diff 看暂存前后的变化： 12345678910$ git diffdiff --git a/benchmarks.rb b/benchmarks.rbindex e445e28..86b2f7c 100644--- a/benchmarks.rb+++ b/benchmarks.rb@@ -127,3 +127,4 @@ end main() ##pp Grit::GitRuby.cache_client.stats+# test line 然后用 git diff --cached 查看已经暂存起来的变化： 12345678910111213141516$ git diff --cacheddiff --git a/benchmarks.rb b/benchmarks.rbindex 3cb747f..e445e28 100644--- a/benchmarks.rb+++ b/benchmarks.rb@@ -36,6 +36,10 @@ def main @commit.parents[0].parents[0].parents[0] end+ run_code(x, &apos;commits 1&apos;) do+ git.commits.size+ end+ run_code(x, &apos;commits 2&apos;) do log = git.commits(&apos;master&apos;, 15) log.size 提交更新现在的暂存区域已经准备妥当可以提交了。在此之前，请一定要确认还有什么修改过的或新建的文件还没有 git add过，否则提交的时候不会记录这些还没暂存起来的变化。所以，每次准备提交前，先用git status 看下，是不是都已暂存起来了，然后再运行提交命令 git commit： 1$ git commit 这种方式会启动文本编辑器以便输入本次提交的说明。（默认会启用 shell 的环境变量 $EDITOR 所指定的软件，一般都是 vim 或 emacs。当然也可以按照第一章介绍的方式，使用git config --global core.editor 命令设定你喜欢的编辑软件。） 编辑器会显示类似下面的文本信息（本例选用 Vim 的屏显方式展示）： 123456789101112# Please enter the commit message for your changes. Lines starting# with &apos;#&apos; will be ignored, and an empty message aborts the commit.# On branch master# Changes to be committed:# (use &quot;git reset HEAD ...&quot; to unstage)## new file: README# modified: benchmarks.rb~~~&quot;.git/COMMIT_EDITMSG&quot; 10L, 283C 可以看到，默认的提交消息包含最后一次运行 git status 的输出，放在注释行里，另外开头还有一空行，供你输入提交说明。你完全可以去掉这些注释行，不过留着也没关系，多少能帮你回想起这次更新的内容有哪些。（如果觉得这还不够，可以用-v 选项将修改差异的每一行都包含到注释中来。）退出编辑器时，Git 会丢掉注释行，将说明内容和本次更新提交到仓库。 另外也可以用 -m 参数后跟提交说明的方式，在一行命令中提交更新： 1234$ git commit -m &quot;Story 182: Fix benchmarks for speed&quot;[master]: created 463dc4f: &quot;Fix benchmarks for speed&quot; 2 files changed, 3 insertions(+), 0 deletions(-) create mode 100644 README 好，现在你已经创建了第一个提交！可以看到，提交后它会告诉你，当前是在哪个分支（master）提交的，本次提交的完整 SHA-1 校验和是什么（463dc4f），以及在本次提交中，有多少文件修订过，多少行添改和删改过。 记住，提交时记录的是放在暂存区域的快照，任何还未暂存的仍然保持已修改状态，可以在下次提交时纳入版本管理。每一次运行提交操作，都是对你项目作一次快照，以后可以回到这个状态，或者进行比较。 跳过使用暂存区域尽管使用暂存区域的方式可以精心准备要提交的细节，但有时候这么做略显繁琐。Git 提供了一个跳过使用暂存区域的方式，只要在提交的时候，给 git commit 加上-a 选项，Git 就会自动把所有已经跟踪过的文件暂存起来一并提交，从而跳过 git add 步骤： 看到了吗？提交之前不再需要 git add 文件 benchmarks.rb 了。 移除文件要从 Git 中移除某个文件，就必须要从已跟踪文件清单中移除（确切地说，是从暂存区域移除），然后提交。可以用 git rm 命令完成此项工作，并连带从工作目录中删除指定的文件，这样以后就不会出现在未跟踪文件清单中了。 如果只是简单地从工作目录中手工删除文件，运行 git status 12345678910$ git status# On branch master## Changed but not updated:## modified: benchmarks.rb#$ git commit -a -m &apos;added new benchmarks&apos;[master 83e38c7] added new benchmarks 1 files changed, 5 insertions(+), 0 deletions(-) 时就会在 “Changed but not updated” 部分（也就是未暂存清单）看到： 123456789$ rm grit.gemspec$ git status# On branch master## Changed but not updated:# (use &quot;git add/rm ...&quot; to update what will be committed)## deleted: grit.gemspec# 然后再运行 git rm 记录此次移除文件的操作： 12345678910$ git rm grit.gemspecrm &apos;grit.gemspec&apos;$ git status# On branch master## Changes to be committed:# (use &quot;git reset HEAD ...&quot; to unstage)## deleted: grit.gemspec# 最后提交的时候，该文件就不再纳入版本管理了。如果删除之前修改过并且已经放到暂存区域的话，则必须要用强制删除选项 -f（译注：即 force 的首字母），以防误删除文件后丢失修改的内容。 另外一种情况是，我们想把文件从 Git 仓库中删除（亦即从暂存区域移除），但仍然希望保留在当前工作目录中。换句话说，仅是从跟踪清单中删除。比如一些大型日志文件或者一堆.a 编译文件，不小心纳入仓库后，要移除跟踪但不删除文件，以便稍后在 .gitignore 文件中补上，用 --cached 选项即可： 1$ git rm --cached readme.txt 后面可以列出文件或者目录的名字，也可以使用 glob 模式。比方说： 1$ git rm log/\*.log 注意到星号 * 之前的反斜杠 \，因为 Git 有它自己的文件模式扩展匹配方式，所以我们不用 shell 来帮忙展开（译注：实际上不加反斜杠也可以运行，只不过按照 shell 扩展的话，仅仅删除指定目录下的文件而不会递归匹配。上面的例子本来就指定了目录，所以效果等同，但下面的例子就会用递归方式匹配，所以必须加反斜 杠。）。此命令删除所有log/ 目录下扩展名为 .log 的文件。类似的比如： 1$ git rm \*~ 会递归删除当前目录及其子目录中所有 ~ 结尾的文件。 移动文件不像其他的 VCS 系统，Git 并不跟踪文件移动操作。如果在 Git 中重命名了某个文件，仓库中存储的元数据并不会体现出这是一次改名操作。不过 Git 非常聪明，它会推断出究竟发生了什么，至于具体是如何做到的，我们稍后再谈。 既然如此，当你看到 Git 的 mv 命令时一定会困惑不已。要在 Git 中对文件改名，可以这么做： 1$ git mv file_from file_to 它会恰如预期般正常工作。实际上，即便此时查看状态信息，也会明白无误地看到关于重命名操作的说明： 12345678910$ git mv README.txt README$ git status# On branch master# Your branch is ahead of &apos;origin/master&apos; by 1 commit.## Changes to be committed:# (use &quot;git reset HEAD..&quot; to unstage)## renamed: README.txt -&gt; README# 其实，运行 git mv 就相当于运行了下面三条命令： 123$ mv README.txt README$ git rm README.txt$ git add README 如此分开操作，Git 也会意识到这是一次改名，所以不管何种方式都一样。当然，直接用 git mv轻便得多，不过有时候用其他工具批处理改名的话，要记得在提交前删除老的文件名，再添加新的文件名。 查看提交历史 在提交了若干更新之后，又或者克隆了某个项目，想回顾下提交历史，可以使用 git log 命令查看。 接下来的例子会用我专门用于演示的 simplegit 项目，运行下面的命令获取该项目源代码： 1git clone git://github.com/schacon/simplegit-progit.git 然后在此项目中运行 git log，应该会看到下面的输出： 123456789101112131415161718192021222324252627$ git logcommit ca82a6dff817ec66f44342007202690a93763949Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version numbercommit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Sat Mar 15 16:40:33 2008 -0700 removed unnecessary test codecommit a11bef06a3f659402fe7563abf99ad00de2209e6Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Sat Mar 15 10:31:28 2008 -0700 first commit 默认不用任何参数的话，git log 会按提交时间列出所有的更新，最近的更新排在最上面。看到了吗，每次更新都有一个 SHA-1 校验和、作者的名字和电子邮件地址、提交时间，最后缩进一个段落显示提交说明。 git log 有许多选项可以帮助你搜寻感兴趣的提交，接下来我们介绍些最常用的。 我们常用 -p 选项展开显示每次提交的内容差异，用 -2 则仅显示最近的两次更新： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687$ git log -p -2commit ca82a6dff817ec66f44342007202690a93763949Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version numberdiff --git a/Rakefile b/Rakefileindex a874b73..8f94139 100644--- a/Rakefile+++ b/Rakefile@@ -5,7 +5,7 @@ require &apos;rake/gempackagetask&apos; spec = Gem::Specification.new do |s|- s.version = &quot;0.1.0&quot;+ s.version = &quot;0.1.1&quot; s.author = &quot;Scott Chacon&quot;commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Sat Mar 15 16:40:33 2008 -0700 removed unnecessary test codediff --git a/lib/simplegit.rb b/lib/simplegit.rbindex a0a60ae..47c6340 100644--- a/lib/simplegit.rb+++ b/lib/simplegit.rb@@ -18,8 +18,3 @@ class SimpleGit end end--if $0 == __FILE__- git = SimpleGit.new- puts git.show-end\ No newline at end of file在做代码审查，或者要快速浏览其他协作者提交的更新都作了哪些改动时，就可以用这个选项。此外，还有许多摘要选项可以用，比如 --stat，仅显示简要的增改行数统计：$ git log --stat commit ca82a6dff817ec66f44342007202690a93763949Author: Scott Chacon &lt;schacon@gee-mail.com&gt;Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number Rakefile | 2 +- 1 files changed, 1 insertions(+), 1 deletions(-)commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7Author: Scott Chacon &lt;schacon@gee-mail.com&gt;Date: Sat Mar 15 16:40:33 2008 -0700 removed unnecessary test code lib/simplegit.rb | 5 ----- 1 files changed, 0 insertions(+), 5 deletions(-)commit a11bef06a3f659402fe7563abf99ad00de2209e6Author: Scott Chacon &lt;schacon@gee-mail.com&gt;Date: Sat Mar 15 10:31:28 2008 -0700 first commit README | 6 ++++++ Rakefile | 23 +++++++++++++++++++++++ lib/simplegit.rb | 25 +++++++++++++++++++++++++ 3 files changed, 54 insertions(+), 0 deletions(-) 每个提交都列出了修改过的文件，以及其中添加和移除的行数，并在最后列出所有增减行数小计。还有个常用的 --pretty 选项，可以指定使用完全不同于默认格式的方式展示提交历史。比如用oneline 将每个提交放在一行显示，这在提交数很大时非常有用。另外还有 short，full 和fuller 可以用，展示的信息或多或少有些不同，请自己动手实践一下看看效果如何。 但最有意思的是 format，可以定制要显示的记录格式，这样的输出便于后期编程提取分析，像这样： 12345678$ git log --pretty=format:&quot;%h - %an, %ar : %s&quot;$ git log --pretty=onelineca82a6dff817ec66f44342007202690a93763949 changed the version number085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 removed unnecessary test codea11bef06a3f659402fe7563abf99ad00de2209e6 first commitca82a6d - Scott Chacon, 11 months ago : changed the version number085bb3b - Scott Chacon, 11 months ago : removed unnecessary test codea11bef0 - Scott Chacon, 11 months ago : first commit 表 列出了常用的格式占位符写法及其代表的意义。 1 你一定奇怪_作者（author）_和_提交者（committer）_之间究竟有何差别，其实作者指的是实际作出修改的人，提交者指的是最后将此 工作成果提交到仓库的人。所以，当你为某个项目发布补丁，然后某个核心成员将你的补丁并入项目时，你就是作者，而那个核心成员就是提交者。我们会在第五章 再详细介绍两者之间的细微差别。 用 oneline 或 format 时结合 --graph 选项，可以看到开头多出一些 ASCII 字符串表示的简单图形，形象地展示了每个提交所在的分支及其分化衍合情况。在我们之前提到的 Grit 项目仓库中可以看到： 12345678910111213141516171819202122232425262728$ git log --pretty=format:&quot;%h %s&quot; --graph* 2d3acf9 ignore errors from SIGCHLD on trap* 5e3ee11 Merge branch &apos;master&apos; of git://github.com/dustin/grit|\| * 420eac9 Added a method for getting the current branch.* | 30e367c timeout code and tests* | 5a09431 add timeout protection to grit* | e1193f8 support for heads with slashes in them|/* d6016bc require time for xmlschema* 11d191e Merge b选项 说明%H 提交对象（commit）的完整哈希字串%h 提交对象的简短哈希字串%T 树对象（tree）的完整哈希字串%t 树对象的简短哈希字串%P 父对象（parent）的完整哈希字串%p 父对象的简短哈希字串%an 作者（author）的名字%ae 作者的电子邮件地址%ad 作者修订日期（可以用 -date= 选项定制格式）%ar 作者修订日期，按多久以前的方式显示%cn 提交者(committer)的名字%ce 提交者的电子邮件地址%cd 提交日期%cr 提交日期，按多久以前的方式显示%s 提交说明ranch &apos;defunkt&apos; into local 以上只是简单介绍了一些 git log 命令支持的选项。表 2-2 还列出了一些其他常用的选项及其释义。 123456789-p 按补丁格式显示每个更新之间的差异。--stat 显示每次更新的文件修改统计信息。--shortstat 只显示 --stat 中最后的行数修改添加移除统计。--name-only 仅在提交信息后显示已修改的文件清单。--name-status 显示新增、修改、删除的文件清单。--abbrev-commit 仅显示 SHA-1 的前几个字符，而非所有的 40 个字符。--relative-date 使用较短的相对时间显示（比如，“2 weeks ago”）。--graph 显示 ASCII 图形表示的分支合并历史。--pretty 使用其他格式显示历史提交信息。可用的选项包括 oneline，short，full，fuller 和 format（后跟指定格式） 限制输出长度除了定制输出格式的选项之外，git log 还有许多非常实用的限制输出长度的选项，也就是只输出部分提交信息。之前我们已经看到过 -2 了，它只显示最近的两条提交，实际上，这是 -选项的写法，其中的 n 可以是任何自然数，表示仅显示最近的若干条提交。不过实践中我们是不太用这个选项的，Git 在输出所有提交时会自动调用分页程序（less），要看更早的更新只需翻到下页即可。 另外还有按照时间作限制的选项，比如 --since 和 --until。下面的命令列出所有最近两周内的提交： 1$ git log --since=2.weeks 你可以给出各种时间格式，比如说具体的某一天（“2008-01-15”），或者是多久以前（“2 years 1 day 3 minutes ago”）。 还可以给出若干搜索条件，列出符合的提交。用 --author 选项显示指定作者的提交，用 --grep选项搜索提交说明中的关键字。（请注意，如果要得到同时满足这两个选项搜索条件的提交，就必须用--all-match 选项。） 如果只关心某些文件或者目录的历史提交，可以在 git log 选项的最后指定它们的路径。因为是放在最后位置上的选项，所以用两个短划线（--）隔开之前的选项和后面限定的路径名。 表 2-3 还列出了其他常用的类似选项。 123456选项 说明-(n) 仅显示最近的 n 条提交--since, --after 仅显示指定时间之后的提交。--until, --before 仅显示指定时间之前的提交。--author 仅显示指定作者相关的提交。--committer 仅显示指定提交者相关的提交。 来看一个实际的例子，如果要查看 Git 仓库中，2008 年 10 月期间，Junio Hamano 提交的但未合并的测试脚本（位于项目的 t/ 目录下的文件），可以用下面的查询命令： 12345678$ git log --pretty=&quot;%h - %s&quot; --author=gitster --since=&quot;2008-10-01&quot; \ --before=&quot;2008-11-01&quot; --no-merges -- t/5610e3b - Fix testcase failure when extended attributeacd3b9e - Enhance hold_lock_file_for_&#123;update,append&#125;()f563754 - demonstrate breakage of detached checkout wid1a43f2 - reset --hard/read-tree --reset -u: remove un51a94af - Fix &quot;checkout --track -b newbranch&quot; on detacb0ad11e - pull: allow &quot;git pull origin $something:$cur Git 项目有 20,000 多条提交，但我们给出搜索选项后，仅列出了其中满足条件的 6 条。 使用图形化工具查阅提交历史有时候图形化工具更容易展示历史提交的变化，随 Git 一同发布的 gitk 就是这样一种工具。它是用 Tcl/Tk 写成的，基本上相当于 git log 命令的可视化版本，凡是git log 可以用的选项也都能用在 gitk 上。在项目工作目录中输入 gitk 命令后，就会启动 上半个窗口显示的是历次提交的分支祖先图谱，下半个窗口显示当前点选的提交对应的具体差异。 撤销操作任何时候，你都有可能需要撤消刚才所做的某些操作。接下来，我们会介绍一些基本的撤消操作相关的命令。请注意，有些操作并不总是可以撤消的，所以请务必谨慎小心，一旦失误，就有可能丢失部分工作成果。 修改最后一次提交有时候我们提交完了才发现漏掉了几个文件没有加，或者提交信息写错了。想要撤消刚才的提交操作，可以使用 --amend 选项重新提交： 1$ git commit --amend 此命令将使用当前的暂存区域快照提交。如果刚才提交完没有作任何改动，直接运行此命令的话，相当于有机会重新编辑提交说明，但将要提交的文件快照和之前的一样。 启动文本编辑器后，会看到上次提交时的说明，编辑它确认没问题后保存退出，就会使用新的提交说明覆盖刚才失误的提交。 如果刚才提交时忘了暂存某些修改，可以先补上暂存操作，然后再运行 --amend 提交： 123$ git commit -m &apos;initial commit&apos;$ git add forgotten_file$ git commit --amend 上面的三条命令最终只是产生一个提交，第二个提交命令修正了第一个的提交内容。 取消已经暂存的文件接下来的两个小节将演示如何取消暂存区域中的文件，以及如何取消工作目录中已修改的文件。不用担心，查看文件状态的时候就提示了该如何撤消，所以不需要死记硬背。来看下面的例子，有两个修改过的文件，我们想要分开提交，但不小心用git add . 全加到了暂存区域。该如何撤消暂存其中的一个文件呢？其实，git status 的命令输出已经告诉了我们该怎么做： 123456789$ git add .$ git status# On branch master# Changes to be committed:# (use &quot;git reset HEAD ...&quot; to unstage)## modified: README.txt# modified: benchmarks.rb# 就在 “Changes to be committed” 下面，括号中有提示，可以使用 git reset HEAD ...的方式取消暂存。好吧，我们来试试取消暂存 benchmarks.rb 文件： 123456789101112131415$ git reset HEAD benchmarks.rbbenchmarks.rb: locally modified$ git status# On branch master# Changes to be committed:# (use &quot;git reset HEAD ...&quot; to unstage)## modified: README.txt## Changed but not updated:# (use &quot;git add ...&quot; to update what will be committed)# (use &quot;git checkout -- ...&quot; to discard changes in working directory)## modified: benchmarks.rb# 这条命令看起来有些古怪，先别管，能用就行。现在 benchmarks.rb 文件又回到了之前已修改未暂存的状态。 取消对文件的修改如果觉得刚才对 benchmarks.rb 的修改完全没有必要，该如何取消修改，回到之前的状态（也就是修改之前的版本）呢？git status 同样提示了具体的撤消方法，接着上面的例子，现在未暂存区域看起来像这样： 123456# Changed but not updated:# (use &quot;git add ...&quot; to update what will be committed)# (use &quot;git checkout -- ...&quot; to discard changes in working directory)## modified: benchmarks.rb# 在第二个括号中，我们看到了抛弃文件修改的命令（至少在 Git 1.6.1 以及更高版本中会这样提示，如果你还在用老版本，我们强烈建议你升级，以获取最佳的用户体验），让我们试试看： 12345678$ git checkout -- benchmarks.rb$ git status# On branch master# Changes to be committed:# (use &quot;git reset HEAD ...&quot; to unstage)## modified: README.txt# 可以看到，该文件已经恢复到修改前的版本。你可能已经意识到了，这条命令有些危险，所有对文件的修改都没有了，因为我们刚刚把之前版本的文件复制过 来重写了此文件。所以在用这条命令前，请务必确定真的不再需要保留刚才的修改。如果只是想回退版本，同时保留刚才的修改以便将来继续工作，可以用下章介绍 的 stashing 和分支来处理，应该会更好些。 记住，任何已经提交到 Git 的都可以被恢复。即便在已经删除的分支中的提交，或者用 --amend重新改写的提交，都可以被恢复（关于数据恢复的内容见第九章）。所以，你可能失去的数据，仅限于没有提交过的，对 Git 来说它们就像从未存在过一样。 远程仓库的使用 要参与任何一个 Git 项目的协作，必须要了解该如何管理远程仓库。远程仓库是指托管在网络上的项目仓库，可能会有好多个，其中有些你只能读，另外有些可以写。同他人协作开发某 个项目时，需要管理这些远程仓库，以便推送或拉取数据，分享各自的工作进展。管理远程仓库的工作，包括添加远程库，移除废弃的远程库，管理各式远程库分 支，定义是否跟踪这些分支，等等。本节我们将详细讨论远程库的管理和使用。 查看当前的远程库 要查看当前配置有哪些远程仓库，可以用 git remote 命令，它会列出每个远程库的简短名字。在克隆完某个项目后，至少可以看到一个名为 origin 的远程库，Git 默认使用这个名字来标识你所克隆的原始仓库： 12345678910$ git clone git://github.com/schacon/ticgit.gitInitialized empty Git repository in /private/tmp/ticgit/.git/remote: Counting objects: 595, done.remote: Compressing objects: 100% (269/269), done.remote: Total 595 (delta 255), reused 589 (delta 253)Receiving objects: 100% (595/595), 73.31 KiB | 1 KiB/s, done.Resolving deltas: 100% (255/255), done.$ cd ticgit$ git remoteorigin 也可以加上 -v 选项（译注：此为 --verbose 的简写，取首字母），显示对应的克隆地址： 12$ git remote -vorigin git://github.com/schacon/ticgit.git 如果有多个远程仓库，此命令将全部列出。比如在我的 Grit 项目中，可以看到： 1234567$ cd grit$ git remote -vbakkdoor git://github.com/bakkdoor/grit.gitcho45 git://github.com/cho45/grit.gitdefunkt git://github.com/defunkt/grit.gitkoke git://github.com/koke/grit.gitorigin git@github.com:mojombo/grit.git 这样一来，我就可以非常轻松地从这些用户的仓库中，拉取他们的提交到本地。请注意，上面列出的地址只有 origin 用的是 SSH URL 链接，所以也只有这个仓库我能推送数据上去（我们会在第四章解释原因）。 添加远程仓库 要添加一个新的远程仓库，可以指定一个简单的名字，以便将来引用，运行 git remote add [shortname] [url]： 123456$ git remoteorigin$ git remote add pb git://github.com/paulboone/ticgit.git$ git remote -vorigin git://github.com/schacon/ticgit.gitpb git://github.com/paulboone/ticgit.git 现在可以用字串 pb 指代对应的仓库地址了。比如说，要抓取所有 Paul 有的，但本地仓库没有的信息，可以运行 git fetch pb： 12345678$ git fetch pbremote: Counting objects: 58, done.remote: Compressing objects: 100% (41/41), done.remote: Total 44 (delta 24), reused 1 (delta 0)Unpacking objects: 100% (44/44), done.From git://github.com/paulboone/ticgit * [new branch] master -&gt; pb/master * [new branch] ticgit -&gt; pb/ticgit 现在，Paul 的主干分支（master）已经完全可以在本地访问了，对应的名字是 pb/master，你可以将它合并到自己的某个分支，或者切换到这个分支，看看有些什么有趣的更新。 从远程仓库抓取数据正如之前所看到的，可以用下面的命令从远程仓库抓取数据到本地： 1$ git fetch [remote-name] 此命令会到远程仓库中拉取所有你本地仓库中还没有的数据。运行完成后，你就可以在本地访问该远程仓库中的所有分支，将其中某个分支合并到本地，或者只是取出某个分支，一探究竟。（我们会在第三章详细讨论关于分支的概念和操作。） 如果是克隆了一个仓库，此命令会自动将远程仓库归于 origin 名下。所以，git fetch origin 会抓取从你上次克隆以来别人上传到此远程仓库中的所有更新（或是上次 fetch 以来别人提交的更新）。有一点很重要，需要记住，fetch 命令只是将远端的数据拉到本地仓库，并不自动合并到当前工作分支，只有当你确实准备好了，才能手工合并。 如果设置了某个分支用于跟踪某个远端仓库的分支（参见下节及第三章的内容），可以使用 git pull 命令自动抓取数据下来，然后将远端分支自动合并到本地仓库中当前分支。在日常工作中我们经常这么用，既快且好。实际上，默认情况下git clone 命令本质上就是自动创建了本地的 master 分支用于跟踪远程仓库中的 master 分支（假设远程仓库确实有 master 分支）。所以一般我们运行git pull，目的都是要从原始克隆的远端仓库中抓取数据后，合并到工作目录中的当前分支。 推送数据到远程仓库项目进行到一个阶段，要同别人分享目前的成果，可以将本地仓库中的数据推送到远程仓库。实现这个任务的命令很简单： git push [remote-name] [branch-name]。如果要把本地的 master 分支推送到origin 服务器上（再次说明下，克隆操作会自动使用默认的 master 和 origin 名字），可以运行下面的命令： 1$ git push origin master 只有在所克隆的服务器上有写权限，或者同一时刻没有其他人在推数据，这条命令才会如期完成任务。如果在你推数据前，已经有其他人推送了若干更新，那 你的推送操作就会被驳回。你必须先把他们的更新抓取到本地，合并到自己的项目中，然后才可以再次推送。有关推送数据到远程仓库的详细内容见第三章。 查看远程仓库信息我们可以通过命令 git remote show [remote-name] 查看某个远程仓库的详细信息，比如要看所克隆的 origin 仓库，可以运行： 12345678$ git remote show origin* remote origin URL: git://github.com/schacon/ticgit.git Remote branch merged with &apos;git pull&apos; while on branch master master Tracked remote branches master ticgit 除了对应的克隆地址外，它还给出了许多额外的信息。它友善地告诉你如果是在 master 分支，就可以用 git pull 命令抓取数据合并到本地。另外还列出了所有处于跟踪状态中的远端分支。 上面的例子非常简单，而随着使用 Git 的深入，git remote show 给出的信息可能会像这样： 123456789101112131415161718192021$ git remote show origin* remote origin URL: git@github.com:defunkt/github.git Remote branch merged with &apos;git pull&apos; while on branch issues issues Remote branch merged with &apos;git pull&apos; while on branch master master New remote branches (next fetch will store in remotes/origin) caching Stale tracking branches (use &apos;git remote prune&apos;) libwalker walker2 Tracked remote branches acl apiv2 dashboard2 issues master postgres Local branch pushed with &apos;git push&apos; master:master 它告诉我们，运行 git push 时缺省推送的分支是什么（译注：最后两行）。它还显示了有哪些远端分支还没有同步到本地（译注：第六行的caching 分支），哪些已同步到本地的远端分支在远端服务器上已被删除（译注：Stale tracking branches 下面的两个分支），以及运行git pull 时将自动合并哪些分支（译注：前四行中列出的 issues 和 master 分支）。 远程仓库的删除和重命名在新版 Git 中可以用 git remote rename 命令修改某个远程仓库在本地的简短名称，比如想把 pb改成paul，可以这么运行： 1234$ git remote rename pb paul$ git remoteoriginpaul 注意，对远程仓库的重命名，也会使对应的分支名称发生变化，原来的 pb/master 分支现在成了 paul/master。 碰到远端仓库服务器迁移，或者原来的克隆镜像不再使用，又或者某个参与者不再贡献代码，那么需要移除对应的远端仓库，可以运行 git remote rm 命令： 123$ git remote rm paul$ git remoteorigin 打标签同大多数 VCS 一样，Git 也可以对某一时间点上的版本打上标签。人们在发布某个软件版本（比如 v1.0 等等）的时候，经常这么做。本节我们一起来学习如何列出所有可用的标签，如何新建标签，以及各种不同类型标签之间的差别。 列出已有的标签 列出现有标签的命令非常简单，直接运行 git tag 即可： 123$ git tagv0.1v1.3 显示的标签按字母顺序排列，所以标签的先后并不表示重要程度的轻重。 我们可以用特定的搜索模式列出符合条件的标签。在 Git 自身项目仓库中，有着超过 240 个标签，如果你只对 1.4.2 系列的版本感兴趣，可以运行下面的命令： 12345$ git tag -l &apos;v1.4.2.*&apos;v1.4.2.1v1.4.2.2v1.4.2.3v1.4.2.4 新建标签 Git 使用的标签有两种类型：轻量级的（lightweight）和含附注的（annotated）。轻量级标签就像是个不会变化的分支，实际上它就是个指向特 定提交对象的引用。而含附注标签，实际上是存储在仓库中的一个独立对象，它有自身的校验和信息，包含着标签的名字，电子邮件地址和日期，以及标签说明，标 签本身也允许使用 GNU Privacy Guard (GPG) 来签署或验证。一般我们都建议使用含附注型的标签，以便保留相关信息；当然，如果只是临时性加注标签，或者不需要旁注额外信息，用轻量级标签也没问题。 含附注的标签创建一个含附注类型的标签非常简单，用 -a （译注：取 annotated 的首字母）指定标签名字即可： 12345$ git tag -a v1.4 -m &apos;my version 1.4&apos;$ git tagv0.1v1.3v1.4 而 -m 选项则指定了对应的标签说明，Git 会将此说明一同保存在标签对象中。如果没有给出该选项，Git 会启动文本编辑软件供你输入标签说明。 可以使用 git show 命令查看相应标签的版本信息，并连同显示打标签时的提交对象。 12345678910111213$ git show v1.4tag v1.4Tagger: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Mon Feb 9 14:45:11 2009 -0800my version 1.4commit 15027957951b64cf874c3557a0f3547bd83b3ff6Merge: 4a447f7... a6b4c97...Author: Scott Chacon &lt;schacon@gee-mail.com&gt;Date: Sun Feb 8 19:02:46 2009 -0800 Merge branch &apos;experiment&apos; 我们可以看到在提交对象信息上面，列出了此标签的提交者和提交时间，以及相应的标签说明。 轻量级标签轻量级标签实际上就是一个保存着对应提交对象的校验和信息的文件。要创建这样的标签，一个 -a，-s 或 -m 选项都不用，直接给出标签名字即可： 1234567$ git tag v1.4-lw$ git tagv0.1v1.3v1.4v1.4-lwv1.5 现在运行 git show 查看此标签信息，就只有相应的提交对象摘要： 12345678910$ git show v1.4-lwcommit 15027957951b64cf874c3557a0f3547bd83b3ff6Merge: 4a447f7... a6b4c97...Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Sun Feb 8 19:02:46 2009 -0800 Merge branch &apos;experiment&apos; 验证标签可以使用 git tag -v [tag-name] （译注：取 verify 的首字母）的方式验证已经签署的标签。此命令会调用 GPG 来验证签名，所以你需要有签署者的公钥，存放在 keyring 中，才能验证： 123456789$ git tag -v v1.4.2.1object 883653babd8ee7ea23e6a5c392bb739348b1eb61type committag v1.4.2.1tagger Junio C Hamano &lt;junkio@cox.net&gt; 1158138501 -0700 GIT 1.4.2.1Minor fixes since 1.4.2, including git-mv and git-http with alternates.gpg: Signature made Wed Sep 13 02:08:25 2006 PDT using DSA key ID F3119B9Agpg: Good signature from &quot;Junio C Hamano &lt;junkio@cox.net&gt;&quot;gpg: aka &quot;[jpeg image of size 1513]&quot;Primary key fingerprint: 3565 2A26 2040 E066 C9A7 4A7D C0C6 D9A4 F311 9B9A 分享标签默认情况下，git push 并不会把标签传送到远端服务器上，只有通过显式命令才能分享标签到远端仓库。其命令格式如同推送分支，运行git push origin [tagname] 即可： 1234567$ git push origin v1.5Counting objects: 50, done.Compressing objects: 100% (38/38), done.Writing objects: 100% (44/44), 4.56 KiB, done.Total 44 (delta 18), reused 8 (delta 1)To git@github.com:schacon/simplegit.git* [new tag] v1.5 -&gt; v1.5 如果要一次推送所有本地新增的标签上去，可以使用 --tags 选项： 1234567891011$ git push origin --tagsCounting objects: 50, done.Compressing objects: 100% (38/38), done.Writing objects: 100% (44/44), 4.56 KiB, done.Total 44 (delta 18), reused 8 (delta 1)To git@github.com:schacon/simplegit.git * [new tag] v0.1 -&gt; v0.1 * [new tag] v1.2 -&gt; v1.2 * [new tag] v1.4 -&gt; v1.4 * [new tag] v1.4-lw -&gt; v1.4-lw * [new tag] v1.5 -&gt; v1.5 现在，其他人克隆共享仓库或拉取数据同步后，也会看到这些标签。 技巧和窍门在结束本章之前，我还想和大家分享一些 Git 使用的技巧和窍门。很多使用 Git 的开发者可能根本就没用过这些技巧，我们也不是说在读过本书后非得用这些技巧不可，但至少应该有所了解吧。说实话，有了这些小窍门，我们的工作可以变得更简单，更轻松，更高效。 自动补全如果你用的是 Bash shell，可以试试看 Git 提供的自动完成脚本。下载 Git 的源代码，进入 contrib/completion 目录，会看到一个git-completion.bash 文件。将此文件复制到你自己的用户主目录中（译注：按照下面的示例，还应改名加上点：cp git-completion.bash ~/.git-completion.bash），并把下面一行内容添加到你的.bashrc文件中： 1source ~/.git-completion.bash 也可以为系统上所有用户都设置默认使用此脚本。Mac 上将此脚本复制到 /opt/local/etc/bash_completion.d 目录中，Linux 上则复制到/etc/bash_completion.d/ 目录中。这两处目录中的脚本，都会在 Bash 启动时自动加载。 如果在 Windows 上安装了 msysGit，默认使用的 Git Bash 就已经配好了这个自动完成脚本，可以直接使用。 在输入 Git 命令的时候可以敲两次跳格键（Tab），就会看到列出所有匹配的可用命令建议： 12$ git co commit config 此例中，键入 git co 然后连按两次 Tab 键，会看到两个相关的建议（命令） commit 和 config。继而输入 m会自动完成git commit 命令的输入。 命令的选项也可以用这种方式自动完成，其实这种情况更实用些。比如运行 git log 的时候忘了相关选项的名字，可以输入开头的几个字母，然后敲 Tab 键看看有哪些匹配的： 123$ git log --s --shortstat --since= --src-prefix= --stat --summary 这个技巧不错吧，可以节省很多输入和查阅文档的时间。 Git命令别名Git 并不会推断你输入的几个字符将会是哪条命令，不过如果想偷懒，少敲几个命令的字符，可以用 git config 为命令设置别名。来看看下面的例子： 1234$ git config --global alias.co checkout$ git config --global alias.br branch$ git config --global alias.ci commit$ git config --global alias.st status 现在，如果要输入 git commit 只需键入 git ci 即可。而随着 Git 使用的深入，会有很多经常要用到的命令，遇到这种情况，不妨建个别名提高效率。 使用这种技术还可以创造出新的命令，比方说取消暂存文件时的输入比较繁琐，可以自己设置一下： 1$ git config --global alias.unstage &apos;reset HEAD --&apos; 这样一来，下面的两条命令完全等同： 12$ git unstage fileA$ git reset HEAD fileA 显然，使用别名的方式看起来更清楚。另外，我们还经常设置 last 命令： 1$ git config --global alias.last &apos;log -1 HEAD&apos; 然后要看最后一次的提交信息，就变得简单多了： 1234$ git lastcommit 66938dae3329c7aebe598c2246a8e6af90d04646Author: Josh Goebel &lt;dreamer3@example.com&gt;Date: Tue Aug 26 19:48:51 2008 +0800 可以看出，实际上 Git 只是简单地在命令中替换了你设置的别名。不过有时候我们希望运行某个外部命令，而非 Git 的附属工具，这个好办，只需要在命令前加上 ! 就行。如果你自己写了些处理 Git 仓库信息的脚本的话，就可以用这种技术包装起来。作为演示，我们可以设置用 git visual启动gitk： 1$ git config --global alias.visual &quot;!gitk&quot; 到目前为止，你已经学会了最基本的 Git 操作：创建和克隆仓库，做出更新，暂存并提交这些更新，以及查看所有历史更新记录。接下来，我们将学习 Git 的必杀技特性：分支模型。 转载链接Git细节拾遗]]></content>
      <categories>
        <category>git使用及讲解</category>
      </categories>
      <tags>
        <tag>git工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git的基础使用]]></title>
    <url>%2F2018%2F09%2F07%2Fgit%E5%92%8Csvn%E7%9A%84%E8%AF%A6%E7%BB%86%E5%AF%B9%E6%AF%94%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[Git是一个分布式的版本控制工具，本篇文章从介绍Git开始，重点在于介绍Git的基本命令和使用技巧，让你尝试使用Git的同时，体验到原来一个版 本控制工具可以对开发产生如此之多的影响，文章分为两部分，第一部分介绍Git的一些常用命令，其中穿插介绍Git的基本概念和原理，第二篇重点介绍 Git的使用技巧，最后会在Git Hub上创建一个开源项目开启你的Git实战之旅。 Git是什么Git在Wikipedia上的定义：它是一个免费的、分布式的版本控制工具，或是一个强调了速度快的源代码管理工具。Git最初被Linus Torvalds开发出来用于管理Linux内核的开发。每一个Git的工作目录都是一个完全独立的代码库，并拥有完整的历史记录和版本追踪能力，不依赖 于网络和中心服务器。 Git的出现减轻了许多开发者和开源项目对于管理分支代码的压力，由于对分支的良好控制，更鼓励开发者对自己感兴趣的项目做出贡献。其实许多开源项目 包括Linux kernel, Samba, X.org Server, Ruby on Rails，都已经过渡到使用Git作为自己的版本控制工具。对于我们这些喜欢写代码的开发者嘛，有两点最大的好处，我们可以在任何地点(在上班的地铁 上)提交自己的代码和查看代码版本;我们可以开许许多多个分支来实践我们的想法，而合并这些分支的开销几乎可以忽略不计。 Git 初始化 现在进入本篇文章真正的主题，介绍一下Git的基本命令和操作，会从Git的版本库的初始化，基本操作和独有的常用命令三部分着手，让大家能够开始使用Git。 Git通常有两种方式来进行初始化: git clone: 这是较为简单的一种初始化方式，当你已经有一个远程的Git版本库，只需要在本地克隆一份，例如’git clone git://github.com/someone/some_project.git some_project’命令就是将’git://github.com/someone/some_project.git’这个URL地址的远程版 本库完全克隆到本地some_project目录下面 git init和git remote：这种方式稍微复杂一些，当你本地创建了一个工作目录，你可以进入这个目录，使用 git init 命令进行初始化，Git以后就会对该目录下的文件进行版本控制，这时候如果你需要将它放到远程服务器上，可以在远程服务器上创建一个目录，并把 可访问的URL记录下来，此时你就可以利用 git remote add 命令来增加一个远程服务器端，例如’git remote add origin git://github.com/someone/another_project.git’这条命令就会增加URL地址为’git: //github.com/someone/another_project.git’，名称为origin的远程服务器，以后提交代码的时候只需要使用 origin别名即可 Git 基本命令 现在我们有了本地和远程的版本库，让我们来试着用用Git的基本命令吧： git pull：从版本库(既可以是远程的也可以是本地的)将代码更新到本地，例如：’git pull origin master’就是将origin这个版本库的代码更新到本地的master主枝，该功能类似于SVN的update git add：将所有改动的文件（新增和有变动的）放在暂存区，由git进行管理 git rm：从当前的工作空间中和索引中删除文件，例如’git rm app/model/user.rb’，移除暂存区 git commit：提交当前工作空间的修改内容，类似于SVN的commit命令，例如’git commit -m “story #3, add user model”‘，提交的时候必须用-m来输入一条提交信息 git push：将本地commit的代码更新到远程版本库中，例如’git push origin branchname’就会将本地的代码更新到名为orgin的远程版本库中 git log：查看历史日志 git revert：还原一个版本的修改，必须提供一个具体的Git版本号，例如’git revert bbaf6fb5060b4875b18ff9ff637ce118256d6f20’，Git的版本号都是生成的一个哈希值、 上面的命令几乎都是每个版本控制工具所公有的，下面就开始尝试一下Git独有的一些命令： Git 独有命令 git branch：对分支的增、删、查等操作，例如 git branch new_branch 会从当前的工作版本创建一个叫做new_branch的新分支，git branch -D new_branch 就会强制删除叫做new_branch的分支，git branch 就会列出本地所有的分支 git checkout：Git的checkout有两个作用，其一是在 不同的branch之间进行切换，例如 ‘git checkout new_branch’就会切换到new_branch的分支上去;另一个功能是 还原代码的作用，例如git checkout app/model/user.rb 就会将user.rb文件从上一个已提交的版本中更新回来，未提交的内容全部会回滚 git rebase：用下面两幅图解释会比较清楚一些，rebase命令执行后，实际上是将分支点从C移到了G，这样分支也就具有了从C到G的功能 （使历史更加简洁明了） git reset：回滚到指定的版本号，我们有A-G提交的版本，其中C 的版本号是 bbaf6fb，我们执行了’git reset bbaf6fb’那么结果就只剩下了A-C三个提交的版本 git stash：将当前未提交的工作存入Git工作栈中，时机成熟的时候再应用回来，这里暂时提一下这个命令的用法，后面在技巧篇会重点讲解 git config：新增、更改Git的各种设置，例如：git config branch.master.remote origin 就将master的远程版本库设置为别名叫做origin版本库 git tag：将某个版本打上一个标签，例如：git tag revert_version bbaf6fb50 来标记这个被你还原的版本，那么以后你想查看该版本时，就可以使用 revert_version标签名，而不是哈希值了 Git其他命令add #添加文件内容至索引 branch #列出、创建或删除分支 checkout #检出一个分支或路径到工作区 clone #克隆一个版本库到一个新目录 commit #最近一次的提交，–amend修改最近一次提交说明 diff #显示提交之间、提交和工作区之间等的差异 fetch #从另外一个版本库下载对象和引用 init #创建一个空的 Git 版本库或重新初始化一个已存在的版本库 log #显示提交日志 –stat 具体文件的改动 reflog #记录丢失的历史 merge #合并两个或更多开发历史，–squash 把分支所有提交合并成一个提交 mv #移动或重命名一个文件、目录或符号链接 pull #获取并合并另外的版本库或一个本地分支（相当于git fetch和git merge） push #更新远程引用和相关的对象 rebase #本地提交转移至更新后的上游分支中 reset #重置当前HEAD到指定状态 rm #从工作区和索引中删除文件 show #显示各种类型的对象 status #显示工作区状态 tag #创建、列出、删除或校验一个GPG签名的 tag 对象 cherry-pick #从其他分支复制指定的提交，然后导入到现在的分支 git分支命令创建分支： git branch linux #创建分支 git checkout linux #切换分支 git branch #查看当前分支情况,当前分支前有*号 git add readme.txt #提交到暂存区 git commit -m “new branch” #提交到git版本仓库 git checkout master #我们在提交文件后再切回master分支 分支合并：（合并前必须保证在master主干上） git branch #查看在哪个位置 git merge Linux #合并创建的Linux分支（–no–ff默认情况下，Git执行”快进式合并”（fast-farward merge），会直接将Master分支指向Develop分支。使用–no–ff参数后，会执行正常合并，在Master分支上生成一个新节点。） git branch -d linux #确认合并后删除分支 如果有冲突： git merge linux #合并Linux分支(冲突) Auto-merging readme.txt CONFLICT (content): Merge conflict in readme.txt Automatic merge failed; fix conflicts and then commit the result. 那么此时，我们在master与linux分支上都分别对中readme文件进行了修改并提交了，那这种情况下Git就没法再为我们自动的快速合并了，它只能告诉我们readme文件的内容有冲突，需要手工处理冲突的内容后才能继续合并 自己修改完readme.txt文件后再次提交 git全局配置1234567891011yum install git #安装Gitgit config –global user.name “xubusi” #配置git使用用户git config –global user.email “xubusi@mail.com” #配置git使用邮箱git config –global color.ui true #加颜色 git config –list #所有配置的信息（上面的结果）user.name=xubusiuser.email=xubusi@mail.comcolor.ui=true .git目录结构Git之所以能够提供方便的本地分支等特性，是与它的文件存储机制有关的。Git存储版本控制信息时使用它自己定义的一套文件系统存储机制，在代码根目录下有一个.git文件夹，会有如下这样的目录结构： 123456789HEADbranches/configdescriptionhooks/indexinfo/objects/refs/ 有几个比较重要的文件和目录需要解释一下： HEAD：文件存放根节点的信息，其实目录结构就表示一个树型结构，Git采用这种树形结构来存储版本信息， 那么HEAD就表示根; refs：目录存储了你在当前版本控制目录下的各种不同引用(引用指的是你本地和远程所用到的各个树分支的信息)，它有heads、 remotes、stash、tags四个子目录，分别存储对不同的根、远程版本库、Git栈和标签的四种引用，你可以通过命令’git show-ref’更清晰地查看引用信息; logs：目录根据不同的引用存储了日志信息。因此，Git只需要代码根目录下的这一个.git目录就可以记录完 整的版本控制信息，而不是像SVN那样根目录和子目录下都有.svn目录。那么下面就来看一下Git与SVN的区别吧 .gitigmore: 放一些不需要git管理的文件（例：IDE的工作目录 .idea，） git与svn的不同VN(Subversion)是当前使用最多的版本控制工具。与它相比较，Git最大的优势在于两点：易于本地增加分支和分布式的特性。 下面两幅图可以形象的展示Git与SVN的不同之处 GIT对于易于本地增加分支，图中Git本地和服务器端结构都很灵活，所有版本都存储在一个目录中，你只需要进行分支的切换即可达到在某个分支工作的效果。 SVN则完全不同，如果你需要在本地试验一些自己的代码，只能本地维护多个不同的拷贝，每个拷贝对应一个SVN服务器地址。 分布式对于Git而言，你可以本地提交代码，所以在上面的图中，Git有利于将一个大任务分解，进行本地的多次提交，而SVN只能在本地进行大量的一 次性更改，导致将来合并到主干上造成巨大的风险。Git的代码日志是在本地的，可以随时查看。SVN的日志在服务器上的，每次查看日志需要先从服务器上下 载下来。我工作的小组，代码服务器在美国，每次查看小组几年前所做的工作时，日志下载就需要十分钟，这不能不说是一个痛苦。后来我们迁移到Git上，利用 Git日志在本地的特性，我用Ruby编写了一个Rake脚本，可以查看某个具体任务的所有代码历史，每次只需要几秒钟，大大方便我的工作。当然分布式并 不是说用了Git就不需要一个代码中心服务器，如果你工作在一个团队里，还是需要一个服务器来保存所有的代码的。 实际的例子： 以前我所 在的小组使用SVN作为版本控制工具，当我正在试图增强一个模块，工作做到一半，由于会改变原模块的行为导致代码服务器上许多测试的失败，所以并没有提交 代码。这时候上级对我说，现在有一个很紧急的Bug需要处理， 必须在两个小时内完成。我只好将本地的所有修改diff，并输出成为一个patch文件，然后回滚有关当前任务的所有代码，再开始修改Bug的任务，等到 修改好后，在将patch应用回来。前前后后要完成多个繁琐的步骤，这还不计中间代码发生冲突所要进行的工作量。 可是如果使用Git， 我们只需要开一个分支或者转回到主分支上，就可以随时开始Bug修改的任务，完成之后，只要切换到原来的分支就可以优雅的继续以前的任务。只要你愿意，每 一个新的任务都可以开一个分支，完成后，再将它合并到主分支上，轻松而优雅。 gitlab介绍安装服务相关命令安装有可能的依赖： yum install openssh-server yum install postfix yum install cronie 安装gitlab： curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh #下载数据源 yum install gitlab-ce 安装完成后： gitlab-ctl reconfigure #使配置文件生效 但是会初始化除了gitlab.rb之外的所有文件 gitlab-ctl status #查看状态 gitlab-ctl stop #停服务 gitlab-ctl start #起服务 gitlab-ctl tail #查看日志的命令（Gitlab 默认的日志文件存放在/var/log/gitlab 目录下） 如下表示启动成功：（全是run，有down表示有的服务没启动成功） 然后打开浏览器输入ip或者域名 相关目录.git/config #版本库特定的配置设置，可用–file修改 ~/.gitconfig #用户特定的配置设置，可用–global修改 /var/opt/gitlab/git-data/repositories/root #库默认存储目录 /opt/gitlab #是gitlab的应用代码和相应的依赖程序 /var/opt/gitlab #此目录下是运行gitlab-ctl reconfigure命令编译后的应用数据和配置文件，不需要人为修改配置/etc/gitlab #此目录下存放了以omnibus-gitlab包安装方式时的配置文件，这里的配置文件才需要管理员手动编译配置/var/log/gitlab #此目录下存放了gitlab各个组件产生的日志 /var/opt/gitlab/backups/ #备份文件生成的目录 相关文件/opt/gitlab/embedded/service/gitlab-rails/config #配置文件（修改clone的ip地址） /etc/gitlab/gitlab.rb #设置相关选项进行配置（gitlab地址就在这） /var/opt/gitlab/git-data #Git存储库数据（默认) 转载链接Git使用基础篇]]></content>
      <categories>
        <category>git使用及讲解</category>
      </categories>
      <tags>
        <tag>git工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git和svn的详细对比表]]></title>
    <url>%2F2018%2F09%2F07%2Fgit%E7%9A%84%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[刚开始工作那会，工作做版本控制的选型，几个tl最后选的git，当时不是很懂，只知道git性能多一些，现在回头看了一下这个表格，更加明白他们之间的差异了，git完胜！ 版本工具差异 svn git 系统特点 1.集中式版本控制系统（文档管理很方便）2.企业内部并行集中开发3.windows系统上开发推荐使用4.克隆一个拥有将近一万个提交(commit),五个分支,每个分支有大约1500个文件，用时将近一个小时 1.分布式系统（代码管理很方便）2.开源项目开发3.mac,Linux系统上开发推荐使用4.克隆一个拥有将近一万个提交(commit),五个分支,每个分支有大约1500个文件，用时1分钟 灵活性 1.搭载svn的服务器出现故障，无法与之交互2.所有的svn操作都需要中央仓库交互（例：拉分支，看日志等） 1.可以单机操作，git服务器故障也可以在本地git仓库工作2.除了push和pull（或fetch）操作，其他都可以在本地操作3.根据自己开发任务任意在本地创建分支4.日志都是在本地查看，效率较高 安全性 较差，定期备份，并且是整个svn都得备份 较高，每个开发者的本地就是一套完整版本库，记录着版本库的所有信息（gitlab集成了备份功能） 分支方面 1.拉分支更像是copy一个路径2.可针对任何子目录进行branch3.拉分支的时间较慢，因为拉分支相当于copy4.创建完分支后，影响全部成员，每个人都会拥有这个分支5.多分支并行开发较重（工作较多而且繁琐） 1.我可以在Git的任意一个提交点（commit point）开启分支！（git checkout -b newbranch HashId）2.拉分支时间较快，因为拉分支只是创建文件的指针和HEAD3.自己本地创建的分支不会影响其他人4.比较适合多分支并行开发5.git checkout hash值(切回之前的版本，无需版本回退)6.强大的cherry-pick 版本控制 1.保存前后变化的差异数据，作为版本控制2.版本号进行控制，每次操作都会产生一个高版本号（svn的全局版本号，这是svn一个较大的特点，git是hash值） 1.git只关心文件数据的整体发生变化，更像是把文件做快照，文件没有改变时，分支只想这个文件的指针不会改变，文件发生改变，指针指向新版本2. 40 位长的哈希值作为版本号，没有先后之分3.git rebase操作可以更好的保持提交记录的整洁 工作流程 1.每次更改文件之前都得update操作，有的时候修改过程中这个文件有更新，commit不会成功2.有冲突，会打断提交动作（冲突解决是一个提交速度的竞赛：手快者，先提交，平安无事；手慢者，后提交，可能遇到麻烦的冲突解决。） 1.开始工作前进行fetch操作，完成开发工作后push操作，有冲突解决冲突2.git的提交过程不会被打断，有冲突会标记冲突文件3.gitflow流程（经典） 内容管理 svn对中文支持好，操作简单，适用于大众 对程序的源代码管理方便，代码库占用的空间少，易于分支化管理 学习成本 使用起来更方便，svn对中文支持好，操作简单，适用于大众 更在乎效率而不是易用性，成本较高（有很多独有的命令，rebase，远程仓库交互的命令，等等） 权限管理 svn的权限管理相当严格，可以按组、个人针对某个子目录的权限控制（每个目录下都会有个.svn的隐藏文件） git没有严格的权限管理控制，只有账号角色划分（在项目的home文件下有且只有一个.svn目录） 管理平台 有吧（这个“吧”字，肯定有，但本人没有接触过） gitlab（建议使用，集成的功能较多，API开发），gerrit，github等 转载链接： git和svn的详细对比]]></content>
      <categories>
        <category>git使用及讲解</category>
      </categories>
      <tags>
        <tag>git工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github向导]]></title>
    <url>%2F2018%2F09%2F07%2Fgithub%E5%90%91%E5%AF%BC%2F</url>
    <content type="text"><![CDATA[Hello World项目是计算机编程的悠久传统。这是一个简单的练习，让你开始学习新的东西。让我们开始使用GitHub！ 你将学到如下内容： 1: 创建和使用一个仓库。 2: 开始和管理一个分支。 3: 更改一个文件，然后推送到仓库，并且附带一些注释。 4: 打开和合并一个推送请求。 创建一个仓库仓库用来组织一个单一的项目，可以包含目录和文件，图片，视频，表格和数据集等所有项目所需要的内容。建议增加一个README文件用来描述项目相关信息。github可以直接生成一个空的README文件。 1: 进入github，在右上角找到+号，然后选择新建项目。 2: 输入项目名称，比如wuman-Small-projects。 3: 写一些简短的描述。 4: 选择可见等级； 5: 单击创建项目，即可完成创建。 创建完成后，如果是空的项目，会显示一个命令列表，以帮助用户通过git进行操作： 命令行指令 Git 全局设置 12git config --global user.name &quot;wumansgy&quot;git config --global user.email &quot;wumansgy@wumansgy.com&quot; 创建新版本库 123456git clone https://github.com/wumansgy/wuman-Small-projects.gitcd hello-worldtouch README.mdgit add README.mdgit commit -m &quot;add README&quot;git push -u origin master 已存在的文件夹 123456cd existing_foldergit initgit remote add origin https://github.com/wumansgy/wuman-Small-projects.gitgit add .git commitgit push -u origin master 已存在的 Git 版本库 1234cd existing_repogit remote add origin https://github.com/wumansgy/wuman-Small-projects.gitgit push -u origin --allgit push -u origin --tags 创建一个分支github上默认分支为master。并且还提供了将分支合并的功能。 1: 打开hello-world仓库首页。 2: 在项目名称之后单击+号，弹出菜单，并选择新分支，赚到分支创建页。 3：输入分支名称，单击绿色创建分支按钮，即可创建成功。 4: 创建成功后，回到hello-world项目首页，可以看到新创建的分支。 更改和提交更新1: 在hello-world项目首页，在对应项目名称的后面单击+号，弹出菜单，并选择新文件（也可以选择上传文件以上传一个新的本地文件，或者单击新目录以创建一个新目录）。 或者如果有文件存在，打开对应的文件，然后单击编辑按钮，以开始编辑一个存在的文件。 2: 我们以新文件为例，如下图，输入文件名称，文件内容，并且在下方输入注释，然后单击提交修改即可完成新文件或者修改文件的功能： 开启一个推送请求如果将某个分支的更改情况推送到另外一个分支，或者master，需要提交一个推送请求。 1: 打开hello-world项目首页，单击最上头的合并请求。 2: 单击绿色的新建合并请求。 3: 选择来源分支（即当前分支newbranch）与目标分支（比如master），单击比较分支后继续。 4: 填写标题和描述，确定来源分支和目标分支，以及确定最下方的提交和变更内容，最后单击绿色的提交新的合并请求。 合并一个推送请求经过步骤3之后，项目的所有者或者在上述步骤中指定了指派人，会收到一个合并请求的通知。 当确认后，会进行具体的合并过程。 此过程，也可以通过命令行来完成，具体过程如下 检出，在本地审查和合并 Step 1. 获取并检出此合并请求的分支 12git fetch origingit checkout -b newbranch origin/newbranch Step 2. 本地审查变更 Step 3. 合并分支并修复出现的任何冲突 Step 4. 推送合并的结果到 GitLab 1git push origin master 常用的命令行功能1: 更新 12$ git fetch origin 更新主分支的更新$ git fetch 更新所有内容 2: 克隆 1$ git clone https://github.com/wumansgy/wuman-Small-projects.git 3: 在某个分支上克隆 1$ git clone -b newbranch https://github.com/wumansgy/wuman-Small-projects.git 4: 合并 1$ git merge origin/master 5: 更新，然后合并 1$ git pull 6: 添加文件 1$ git add [file.name](http://file.name) 7: 删除文件 1$ git rm [file.name](http://file.name) 8: 添加注释 1$ git commit -m ‘add a new file’ 9: 推送更改 1$ git push -u origin/master]]></content>
      <categories>
        <category>git使用及讲解</category>
      </categories>
      <tags>
        <tag>git工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP通信三次握手四次挥手]]></title>
    <url>%2F2018%2F09%2F06%2FTcp%E9%80%9A%E4%BF%A1%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%2F</url>
    <content type="text"><![CDATA[TCP通信过程下图是一次TCP通讯的时序图。TCP连接建立断开。包含大家熟知的三次握手和四次握手 在这个例子中，首先客户端主动发起连接、发送请求，然后服务器端响应请求，然后客户端主动关闭连接。两条竖线表示通讯的两端，从上到下表示时间的先后顺序。注意，数据从一端传到网络的另一端也需要时间，所以图中的箭头都是斜的。 三次握手：所谓三次握手（Three-Way Handshake）即建立TCP连接，就是指建立一个TCP连接时，需要客户端和服务端总共发送3个包以确认连接的建立。好比两个人在打电话：Client:“喂，你听得到吗？”Server:“我听得到，你听得到我吗？”Client:“我能听到你，今天balabala…” 建立连接（三次握手）的过程：1.客户端发送一个带SYN标志的TCP报文到服务器。这是上图中三次握手过程中的段1。客户端发出SYN位表示连接请求。序号是1000，这个序号在网络通讯中用作临时的地址，每发一个数据字节，这个序号要加1，这样在接收端可以根据序号排出数据包的正确顺序，也可以发现丢包的情况。另外，规定SYN位和FIN位也要占一个序号，这次虽然没发数据，但是由于发了SYN位，因此下次再发送应该用序号1001。mss表示最大段尺寸，如果一个段太大，封装成帧后超过了链路层的最大长度，就必须在IP层分片，为了避免这种情况，客户端声明自己的最大段尺寸，建议服务器端发来的段不要超过这个长度。2.服务器端回应客户端，是三次握手中的第2个报文段，同时带ACK标志和SYN标志。表示对刚才客户端SYN的回应；同时又发送SYN给客户端，询问客户端是否准备好进行数据通讯。服务器发出段2，也带有SYN位，同时置ACK位表示确认，确认序号是1001，表示“我接收到序号1000及其以前所有的段，请你下次发送序号为1001的段”，也就是应答了客户端的连接请求，同时也给客户端发出一个连接请求，同时声明最大尺寸为1024。3.客户必须再次回应服务器端一个ACK报文，这是报文段3。客户端发出段3，对服务器的连接请求进行应答，确认序号是8001。在这个过程中，客户端和服务器分别给对方发了连接请求，也应答了对方的连接请求，其中服务器的请求和应答在一个段中发出。因此一共有三个段用于建立连接，称为“三方握手”。在建立连接的同时，双方协商了一些信息，例如，双方发送序号的初始值、最大段尺寸等。数据传输的过程：1.客户端发出段4，包含从序号1001开始的20个字节数据。2.服务器发出段5，确认序号为1021，对序号为1001-1020的数据表示确认收到，同时请求发送序号1021开始的数据，服务器在应答的同时也向客户端发送从序号8001开始的10个字节数据。3.客户端发出段6，对服务器发来的序号为8001-8010的数据表示确认收到，请求发送序号8011开始的数据。在数据传输过程中，ACK和确认序号是非常重要的，应用程序交给TCP协议发送的数据会暂存在TCP层的发送缓冲区中，发出数据包给对方之后，只有收到对方应答的ACK段才知道该数据包确实发到了对方，可以从发送缓冲区中释放掉了，如果因为网络故障丢失了数据包或者丢失了对方发回的ACK段，经过等待超时后TCP协议自动将发送缓冲区中的数据包重发。 四次挥手：所谓四次挥手（Four-Way-Wavehand）即终止TCP连接，就是指断开一个TCP连接时，需要客户端和服务端总共发送4个包以确认连接的断开。在socket编程中，这一过程由客户端或服务器任一方执行close来触发。好比两个人打完电话要挂断：Client:“我要说的事情都说完了，我没事了。挂啦？”Server:“等下，我还有一个事儿。Balabala…”Server:“好了，我没事儿了。挂了啊。”Client:“ok！拜拜”关闭连接（四次握手）的过程：由于TCP连接是全双工的，因此每个方向都必须单独进行关闭。这原则是当一方完成它的数据发送任务后就能发送一个FIN来终止这个方向的连接。收到一个 FIN只意味着这一方向上没有数据流动，一个TCP连接在收到一个FIN后仍能发送数据。首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。1.客户端发出段7，FIN位表示关闭连接的请求。2.服务器发出段8，应答客户端的关闭连接请求。3.服务器发出段9，其中也包含FIN位，向客户端发送关闭连接请求。4.客户端发出段10，应答服务器的关闭连接请求。建立连接的过程是三次握手，而关闭连接通常需要4个段，服务器的应答和关闭连接请求通常不合并在一个段中，因为有连接半关闭的情况，这种情况下客户端关闭连接之后就不能再发送数据给服务器了，但是服务器还可以发送数据给客户端，直到服务器也关闭连接为止。 这就是简单的3次握手和四次挥手的讲解，如果可以理解记住如下状态那就更好 总结过程：TCP状态转换： 1. 主动端：CLOSE –&gt; SYN –&gt; SYN_SEND状态 –&gt; ESTABLISHED状态（数据通信期间处于的状态） —&gt; FIN –&gt; FIN_WAIT_1状态。—&gt; 接收 ACK —&gt; FIN_WAIT_2状态 (半关闭—— 只出现在主动端) —&gt; 接收FIN、回ACK ——&gt; TIME_WAIT (等2MSL)—&gt; 确保最后一个ACK能被对端收到。(只出现在主动端)2. 被动端：CLOSE –&gt; LISTEN —&gt; ESTABLISHED状态（数据通信期间处于的状态） —&gt; 接收 FIN、回复ACK –&gt; CLOSE_WAIT(对应 对端处于 半关闭) –&gt; 发送FIN –&gt; LAST_ACK —&gt; 接收ACK —&gt; CLOSE]]></content>
      <categories>
        <category>网络编程协议</category>
      </categories>
      <tags>
        <tag>TCP/IP</tag>
        <tag>通信协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通信Socket编程]]></title>
    <url>%2F2018%2F09%2F06%2F%E9%80%9A%E4%BF%A1Socket%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Socket编程什么是Socket：Socket，英文含义是【插座、插孔】，一般称之为套接字，用于描述IP地址和端口。可以实现不同程序间的数据通信。Socket起源于Unix，而Unix基本哲学之一就是“一切皆文件”，都可以用“打开open –&gt; 读写write/read –&gt; 关闭close”模式来操作。Socket就是该模式的一个实现，网络的Socket数据传输是一种特殊的I/O，Socket也是一种文件描述符。Socket也具有一个类似于打开文件的函数调用：Socket()，该函数返回一个整型的Socket描述符，随后的连接建立、数据传输等操作都是通过该Socket实现的。套接字的内核实现较为复杂，不宜在学习初期深入学习，了解到如下结构足矣。 套接字通讯原理示意在TCP/IP协议中，“IP地址+TCP或UDP端口号”唯一标识网络通讯中的一个进程。“IP地址+端口号”就对应一个socket。欲建立连接的两个进程各自有一个socket来标识，那么这两个socket组成的socket pair就唯一标识一个连接。因此可以用Socket来描述网络连接的一对一关系。常用的Socket类型有两种：流式Socket（SOCK_STREAM）和数据报式Socket（SOCK_DGRAM）。流式是一种面向连接的Socket，针对于面向连接的TCP服务应用；数据报式Socket是一种无连接的Socket，对应于无连接的UDP服务应用。 网络应用程序设计模式C/S模式传统的网络应用设计模式，客户机(client)/服务器(server)模式。需要在通讯两端各自部署客户机和服务器来完成数据通信。B/S模式浏览器(Browser)/服务器(Server)模式。只需在一端部署服务器，而另外一端使用每台PC都默认配置的浏览器即可完成数据的传输。优缺点对于C/S模式来说，其优点明显。客户端位于目标主机上可以保证性能，将数据缓存至客户端本地，从而提高数据传输效率。且，一般来说客户端和服务器程序由一个开发团队创作，所以他们之间所采用的协议相对灵活。可以在标准协议的基础上根据需求裁剪及定制。例如，腾讯所采用的通信协议，即为ftp协议的修改剪裁版。因此，传统的网络应用程序及较大型的网络应用程序都首选C/S模式进行开发。如，知名的网络游戏魔兽世界。3D画面，数据量庞大，使用C/S模式可以提前在本地进行大量数据的缓存处理，从而提高观感。C/S模式的缺点也较突出。由于客户端和服务器都需要有一个开发团队来完成开发。工作量将成倍提升，开发周期较长。另外，从用户角度出发，需要将客户端安插至用户主机上，对用户主机的安全性构成威胁。这也是很多用户不愿使用C/S模式应用程序的重要原因。B/S模式相比C/S模式而言，由于它没有独立的客户端，使用标准浏览器作为客户端，其工作开发量较小。只需开发服务器端即可。另外由于其采用浏览器显示数据，因此移植性非常好，不受平台限制。如早期的偷菜游戏，在各个平台上都可以完美运行。B/S模式的缺点也较明显。由于使用第三方浏览器，因此网络应用支持受限。另外，没有客户端放到对方主机上，缓存数据不尽如人意，从而传输数据量受到限制。应用的观感大打折扣。第三，必须与浏览器一样，采用标准http协议进行通信，协议选择不灵活。因此在开发过程中，模式的选择由上述各自的特点决定。根据实际需求选择应用程序设计模式。TCP的C/S架构 简单的C/S模型通信 Server端： 12345678910Listen函数： func Listen(network, address string) (Listener, error) network：选用的协议：TCP、UDP， 如：“tcp”或 “udp” address：IP地址+端口号, 如：“127.0.0.1:8000”或 “:8000”Listener 接口：type Listener interface &#123; Accept() (Conn, error) Close() error Addr() Addr&#125; Conn 接口： 12345678910type Conn interface &#123; Read(b []byte) (n int, err error) Write(b []byte) (n int, err error) Close() error LocalAddr() Addr RemoteAddr() Addr SetDeadline(t time.Time) error SetReadDeadline(t time.Time) error SetWriteDeadline(t time.Time) error&#125; 参看 https://studygolang.com/pkgdoc 中文帮助文档中的demo： 示例代码： TCP服务器.go 1234567891011121314151617181920212223242526272829303132333435package mainimport ( &quot;net&quot; &quot;fmt&quot;)func main() &#123; // 创建监听 listener, err:= net.Listen(&quot;tcp&quot;, &quot;:8000&quot;) if err != nil &#123; fmt.Println(&quot;listen err:&quot;, err) return &#125; defer listener.Close() // 主协程结束时，关闭listener fmt.Println(&quot;服务器等待客户端建立连接...&quot;) // 等待客户端连接请求 conn, err := listener.Accept() if err != nil &#123; fmt.Println(&quot;accept err:&quot;, err) return &#125; defer conn.Close() // 使用结束，断开与客户端链接 fmt.Println(&quot;客户端与服务器连接建立成功...&quot;) // 接收客户端数据 buf := make([]byte, 1024) // 创建1024大小的缓冲区，用于read n, err := conn.Read(buf) if err != nil &#123; fmt.Println(&quot;read err:&quot;, err) return &#125; fmt.Println(&quot;服务器读到:&quot;, string(buf[:n])) // 读多少，打印多少。&#125; 如图，在整个通信过程中，服务器端有两个socket参与进来，但用于通信的只有 conn 这个socket。它是由 listener创建的。隶属于服务器端。 Client 端： 123func Dial(network, address string) (Conn, error) network：选用的协议：TCP、UDP，如：“tcp”或 “udp” address：服务器IP地址+端口号, 如：“121.36.108.11:8000”或 “www.itcast.cn:8000” Conn 接口： 12345678910type Conn interface &#123; Read(b []byte) (n int, err error) Write(b []byte) (n int, err error) Close() error LocalAddr() Addr RemoteAddr() Addr SetDeadline(t time.Time) error SetReadDeadline(t time.Time) error SetWriteDeadline(t time.Time) error&#125; 客户端实现 1234567891011121314151617181920212223package mainimport ( "net" "fmt")func main() &#123; // 主动发起连接请求 conn, err := net.Dial("tcp", "127.0.0.1:8000") if err != nil &#123; fmt.Println("Dial err:", err) return &#125; defer conn.Close() // 结束时，关闭连接 // 发送数据 _, err = conn.Write([]byte("Are u ready?")) if err != nil &#123; fmt.Println("Write err:", err) return &#125;&#125; 下一章节将讲解一下并发模型的服务器，以及TCP通信过程，还有UDP服务器的讲解；]]></content>
      <categories>
        <category>网络编程协议</category>
      </categories>
      <tags>
        <tag>通信协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构--散列表（哈希表）2]]></title>
    <url>%2F2018%2F09%2F06%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%95%A3%E5%88%97%E8%A1%A8%E5%93%88%E5%B8%8C%E8%A1%A82%2F</url>
    <content type="text"><![CDATA[本文主要采用： 构造方法：除留余数法： f(key)=key%p (P&lt;=m m:散列表的长度) 处理散列冲突方法：链地址法（单链表） 代码实例：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125package main import &quot;fmt&quot; /* 除留余数发定址 线性探测发解决冲突*/type keyType int //key值的类型type valueType int //value值的类型const maxSize = 12 //hastable的最大长度//除留余数发： f(key)=key%p (P&lt;=m m:散列表的长度)var p = 11var nullKey = keyType(-65535)var nullValue = valueType(-65535) //无效的数据 type hashData struct &#123; key keyType //key值 value valueType //value值 next *hashData&#125; var hashTable [maxSize]hashData //定义哈希表，大小为maxSize，类型为：hashData//初始化哈希表func initHashTable() &#123; for i := 0; i &lt; len(hashTable); i++ &#123; // 头结点 p := new(hashData) p.key = nullKey //空值 p.value = nullValue //空值 p.next = nil dataNode := hashData&#123;keyType(nullKey), valueType(nullValue), p&#125; hashTable[i] = dataNode &#125;&#125; //向哈希表添加数据元素func insertHashTable(ht *[maxSize]hashData, key keyType, value valueType) bool &#123; //先查找，如果key值已经存在，则替换成key新对应的value data:=searchHashTable(ht,key) if data!=nil&#123; //已经存在 data.value=value return true &#125; addr := int(key) % p //开辟空间 新建节点 q := new(hashData) q.key = key //赋 key值 q.value = value //赋value值 r := ht[addr].next //找到最末尾元素 for r.next != nil &#123; r = r.next &#125; q.next = r.next r.next = q return true&#125; //查找数据func searchHashTable(ht *[maxSize]hashData, key keyType) (data *hashData) &#123; //按照添加的位置 找对应的数据（链表），而不是对数组遍历 addr := int(key) % p //fmt.Println(&quot;------------&quot;,addr) data = nil q := ht[addr].next for q != nil &#123; if q.key == key &#123; return q //如果找个，返回对应的节点（指针指向此节点） &#125; q = q.next //移动到下一个位置继续 &#125; return&#125; //删除数据func deleteHashTable(ht *[maxSize]hashData, key keyType) bool &#123; addr := int(key) % p q := ht[addr].next r := q.next for r != nil &#123; //删除节点 if r.key == key &#123; q.next = r.next return true &#125; q = r r = q.next &#125; return false&#125;func main() &#123; //初始化哈希表 initHashTable() //添加数据 // 元素0对应的数据 insertHashTable(&amp;hashTable, 0, 48) m := searchHashTable(&amp;hashTable, 0) if m != nil &#123; fmt.Printf(&quot;【%d】：%d\n&quot;, m.key, m.value) &#125; else &#123; fmt.Println(&quot;没有查找到数据！&quot;) &#125; //添加key已经存在的数据 insertHashTable(&amp;hashTable,0,666) m = searchHashTable(&amp;hashTable, 0) if m != nil &#123; fmt.Printf(&quot;【%d】：%d\n&quot;, m.key, m.value) &#125; else &#123; fmt.Println(&quot;没有查找到数据！&quot;) &#125; //删除数据元素 deleteHashTable(&amp;hashTable, 0) //删除之后 再次查找 m = searchHashTable(&amp;hashTable, 0) if m != nil &#123; fmt.Printf(&quot;【%d】：%d\n&quot;, m.key, m.value) &#125; else &#123; fmt.Println(&quot;没有查找到数据！&quot;) &#125; &#125;]]></content>
      <categories>
        <category>数据结构和算法</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构--散列表（哈希表）1]]></title>
    <url>%2F2018%2F09%2F06%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%95%A3%E5%88%97%E8%A1%A8%E5%93%88%E5%B8%8C%E8%A1%A81%2F</url>
    <content type="text"><![CDATA[本文主要采用： 构造方法：除留余数法： f(key)=key%p (P&lt;=m m:散列表的长度) 处理散列冲突方法：线性探测法 代码实例：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112package main import &quot;fmt&quot; /* 除留余数发定址 线性探测发解决冲突*/type keyType int //key值的类型type valueType int //value值的类型 const maxSize = 12 //hastable的最大长度//除留余数发： f(key)=key%p (P&lt;=m m:散列表的长度)var p = 11var nullValue = keyType(-65535) //无效的数据 type hashData struct &#123; key keyType //key值 value valueType //value值 //count int //探查次数&#125; var hashTable [maxSize]hashData //定义哈希表，大小为maxSize，类型为：hashData//初始化哈希表func initHashTable() &#123; for i:=0;i&lt;len(hashTable);i++&#123; dataNode:=hashData&#123;nullValue,0,&#125; hashTable[i]=dataNode &#125;&#125;//向哈希表添加数据元素func insertHashTable(ht *[maxSize]hashData, key keyType, value valueType) bool&#123; count := 0 //添加时 查找次数 addr := int(key) % p //线性探测发： f(key)=( f(key)+d)%m (d=1,d=2,d=3...) d := 0 for count &lt; maxSize &#123; addr := (addr + d) % p if ht[addr].key ==nullValue &#123; dataNode := hashData&#123;key, value, &#125; ht[addr] = dataNode return true &#125; d++ count++ &#125; return false&#125;//查找数据func searchHashTable( ht *[maxSize]hashData,key keyType) (positon int) &#123; //addr:=int(key)%p positon=-1 //没有找到，返回值为：-1 for index,data:=range ht&#123; if data.key==key &#123; positon=index return //返回对应于数组的下标 &#125; &#125; return&#125;//删除数据func deleteHashTable(ht *[maxSize]hashData,key keyType) bool &#123; for index,data:=range ht&#123; if data.key==key &#123; /* 特别注意;这种方法不能更改数据 data.key=nullValue //重置key data.value=0 //清空数据 */ dataNode:=hashData&#123;nullValue,0&#125; ht[index]=dataNode return true &#125; &#125; return false &#125;func main() &#123; //初始化哈希表 initHashTable() //向哈希表中添加10个数据 for i:=0;i&lt;10;i++&#123; insertHashTable(&amp;hashTable,keyType(i),valueType(i*100)) &#125; fmt.Println(hashTable) //打印，是否添加成功 //查找 index:=searchHashTable(&amp;hashTable,keyType(3)) if index==-1 &#123; fmt.Println(&quot;没有查询到对应的数据&quot;) &#125;else &#123; value:=hashTable[index].value fmt.Printf(&quot;key：%d对应的value：%d\n&quot;,index,value) &#125; //删除数据元素 deleteState:=deleteHashTable(&amp;hashTable,keyType(3)) if deleteState &#123; fmt.Println(&quot;找到对应的元素，删除成功！&quot;) &#125;else &#123; fmt.Println(&quot;没有找到元素，删除失败！&quot;) &#125; //再次查找，看是否真正删除 index1:=searchHashTable(&amp;hashTable,keyType(3)) if index1==-1 &#123; fmt.Println(&quot;没有查询到对应的数据&quot;) &#125;else &#123; value:=hashTable[index1].value fmt.Printf(&quot;key：%d对应的value：%d&quot;,index1,value) &#125; //fmt.Println(hashTable)&#125;]]></content>
      <categories>
        <category>数据结构和算法</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬取豆瓣评分Demo]]></title>
    <url>%2F2018%2F09%2F05%2F%E7%88%AC%E5%8F%96%E8%B1%86%E7%93%A3%E8%AF%84%E5%88%86Demo%2F</url>
    <content type="text"><![CDATA[爬虫爬虫简介： 是一个程序，用来获取指定网站数据信息。 明确 url 。确定爬取对象 发送请求。获取服务器响应数据。 解析数据，提取有用数据内容。 保存、分析数据结果。 今天我们用go并发来简单写一个小Demo来爬取一下豆瓣评分网站的数据 首先来思路分析一下该怎么做： 明确 url。找出url之间的一些小规律，比如豆瓣的url规律如下 1234567https://movie.douban.com/top250?start=0&amp;filter= 1https://movie.douban.com/top250?start=25&amp;filter= 2 https://movie.douban.com/top250?start=50&amp;filter= 3https://movie.douban.com/top250?start=75&amp;filter= 4 之间的规律很好找 待提取字符特性： 提示用户指定爬取起始、终止页 封装 doWork 函数， 按起始、终止页面循环爬取网页数据 组织每个网页的 url。 下一页 = +25 封装函数 HttpGetDB（url）result，err { http.Get(url), resp.Body.Read(buf), n==0 break, result+= string(buf[:n}) } 爬取网页的所有数据 通过result 返回给调用者。 解析、编译正则表达式 —— 提取 “电影名称”fileNames 传出的是[][]string ， 下标为【1】是不带匹配参考项。 解析、编译正则表达式 —— 提取 “评分”传出的是[][]string ， 下标为【1】是不带匹配参考项。 解析、编译正则表达式 —— 提取 “评价人数”传出的是[][]string ， 下标为【1】是不带匹配参考项。 封装函数，将上述内容写入文件。save2File（ [][]string） 创建并发go程 提取所有网页数据。 创建阻止主go程提取退出的 channel ， SpiderPageDB() 末尾处，写channel doWork 中，添加新 for ，读channel 代码实现：首先可以封装一个函数来爬取多少页到多少页，并且每一页构造一个go程 123456789101112func doWork(start, end int) &#123; page := make(chan int) // 循环创建多个goroutine，提高爬取效率 for i:=start; i&lt;=end; i++ &#123; go SpiderPageDB(i, page) &#125; // 循环读取 channel， 协调主、子go程调用顺序 for i:=start; i&lt;=end; i++ &#123; fmt.Printf(&quot;第%d页爬取完成\n&quot;, &lt;-page) &#125;&#125; 获取每一页的数据函数 123456789101112131415161718192021func HttpGetDB(url string) (result string, err error) &#123; resp, err1 := http.Get(url) if err1 != nil &#123; err = err1 return &#125; defer resp.Body.Close() buf := make([]byte, 4096) for &#123; n, err2 := resp.Body.Read(buf) if n == 0 &#123; break &#125; if err2 != nil &amp;&amp; err2 != io.EOF &#123; err = err2 return &#125; result += string(buf[:n]) &#125; return&#125; 得到每一个数据然后分析数据解析数据 123456789101112131415161718192021222324252627282930func SpiderPageDB(i int, page chan&lt;- int) &#123; url := &quot;https://movie.douban.com/top250?start=&quot; + strconv.Itoa((i-1)*25) + &quot;&amp;filter=&quot; result, err := HttpGetDB(url) if err != nil &#123; fmt.Println(&quot;HttpGetDB err:&quot;, err) return &#125; // 编译、解析正则表达式 —— 电影名 ret1 := regexp.MustCompile(`&lt;img width=&quot;100&quot; alt=&quot;(?s:(.*?))&quot; src=&quot;` ) // 提取有效信息 fileNames := ret1.FindAllStringSubmatch(result, -1) // 编译、解析正则表达式 —— 分数 pattern := `&lt;span class=&quot;rating_num&quot; property=&quot;v:average&quot;&gt;(.*?)&lt;/span&gt;` ret2 := regexp.MustCompile(pattern ) // 提取有效信息 fileScore := ret2.FindAllStringSubmatch(result, -1)/* for _, one := range fileScore &#123; fmt.Println(&quot;fileName:&quot;, one[1]) &#125;*/ // 编译、解析正则表达式 —— 评分人数 ret3 := regexp.MustCompile(`&lt;span&gt;(\d*?)人评价&lt;/span&gt;`) // 提取有效信息 peopleNum := ret3.FindAllStringSubmatch(result, -1) // 写入到一个文件中 save2file(i, fileNames, fileScore, peopleNum) page &lt;- i // 写入channel ，协调主go程与子go程调用顺序。&#125; 最后保存数据到文件中 123456789101112131415161718192021func save2file(idx int, fileNames, fileScore, peopleNum [][]string) &#123; // 组织保存文件路径及名程 path := &quot;D:/ecec/第&quot; + strconv.Itoa(idx) + &quot;页.txt&quot; f, err := os.Create(path) if err != nil &#123; fmt.Println(&quot;Create err:&quot;, err) return &#125; defer f.Close() // 获取 一个网页中的条目数 —— 25 n := len(fileNames) // 写一行标题 f.WriteString(&quot;电影名称&quot; + &quot;\t&quot; + &quot;评分&quot; + &quot;\t&quot; + &quot;评价人数&quot; + &quot;\n&quot;) // 依次按序写入电影相关条目。 for i:=0; i&lt;n; i++ &#123; f.WriteString(fileNames[i][1] + &quot;\t&quot; + fileScore[i][1] + &quot;\t&quot; + peopleNum[i][1] + &quot;\n&quot;) &#125;&#125; 最后直接在main里面就可以调用 完整代码如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109package mainimport ( "fmt" "strconv" "net/http" "io" "regexp" "os")func HttpGetDB(url string) (result string, err error) &#123; resp, err1 := http.Get(url) if err1 != nil &#123; err = err1 return &#125; defer resp.Body.Close() buf := make([]byte, 4096) for &#123; n, err2 := resp.Body.Read(buf) if n == 0 &#123; break &#125; if err2 != nil &amp;&amp; err2 != io.EOF &#123; err = err2 return &#125; result += string(buf[:n]) &#125; return&#125;func SpiderPageDB(i int, page chan&lt;- int) &#123; url := "https://movie.douban.com/top250?start=" + strconv.Itoa((i-1)*25) + "&amp;filter=" result, err := HttpGetDB(url) if err != nil &#123; fmt.Println("HttpGetDB err:", err) return &#125; // 编译、解析正则表达式 —— 电影名 ret1 := regexp.MustCompile(`&lt;img width="100" alt="(?s:(.*?))" src="` ) // 提取有效信息 fileNames := ret1.FindAllStringSubmatch(result, -1) // 编译、解析正则表达式 —— 分数 pattern := `&lt;span class="rating_num" property="v:average"&gt;(.*?)&lt;/span&gt;` ret2 := regexp.MustCompile(pattern ) // 提取有效信息 fileScore := ret2.FindAllStringSubmatch(result, -1)/* for _, one := range fileScore &#123; fmt.Println("fileName:", one[1]) &#125;*/ // 编译、解析正则表达式 —— 评分人数 ret3 := regexp.MustCompile(`&lt;span&gt;(\d*?)人评价&lt;/span&gt;`) // 提取有效信息 peopleNum := ret3.FindAllStringSubmatch(result, -1) // 写入到一个文件中 save2file(i, fileNames, fileScore, peopleNum) page &lt;- i // 写入channel ，协调主go程与子go程调用顺序。&#125;func save2file(idx int, fileNames, fileScore, peopleNum [][]string) &#123; // 组织保存文件路径及名程 path := "C:/exec/第" + strconv.Itoa(idx) + "页.txt" f, err := os.Create(path) if err != nil &#123; fmt.Println("Create err:", err) return &#125; defer f.Close() // 获取 一个网页中的条目数 —— 25 n := len(fileNames) // 写一行标题 f.WriteString("电影名称" + "\t" + "评分" + "\t" + "评价人数" + "\n") // 依次按序写入电影相关条目。 for i:=0; i&lt;n; i++ &#123; f.WriteString(fileNames[i][1] + "\t" + fileScore[i][1] + "\t" + peopleNum[i][1] + "\n") &#125;&#125;func doWork(start, end int) &#123; page := make(chan int) // 循环创建多个goroutine，提高爬取效率 for i:=start; i&lt;=end; i++ &#123; go SpiderPageDB(i, page) &#125; // 循环读取 channel， 协调主、子go程调用顺序 for i:=start; i&lt;=end; i++ &#123; fmt.Printf("第%d页爬取完成\n", &lt;-page) &#125;&#125;func main() &#123; var start, end int fmt.Print("请输入爬取起始页面（&gt;=1）:") fmt.Scan(&amp;start) fmt.Print("请输入爬取终止页面（&gt;=start）:") fmt.Scan(&amp;end) doWork(start, end)&#125;]]></content>
      <categories>
        <category>GO语言</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>go并发简单爬虫Demo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符二进制转换]]></title>
    <url>%2F2018%2F09%2F05%2F%E5%AD%97%E7%AC%A6%E4%BA%8C%E8%BF%9B%E5%88%B6%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[字符二进制转换运用位操作左移和右移来实现字符二进制转换的一个源码（自己也可以去实现） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112package Btosimport ( "errors" "regexp")const ( zero = byte('0') one = byte('1') lsb = byte('[') // left square brackets rsb = byte(']') // right square brackets space = byte(' '))var uint8arr [8]uint8// ErrBadStringFormat represents a error of input string's format is illegal .var ErrBadStringFormat = errors.New("bad string format")// ErrEmptyString represents a error of empty input string.var ErrEmptyString = errors.New("empty string")func init() &#123; uint8arr[0] = 128 uint8arr[1] = 64 uint8arr[2] = 32 uint8arr[3] = 16 uint8arr[4] = 8 uint8arr[5] = 4 uint8arr[6] = 2 uint8arr[7] = 1&#125;// append bytes of string in binary format.func appendBinaryString(bs []byte, b byte) []byte &#123; var a byte for i := 0; i &lt; 8; i++ &#123; a = b b &lt;&lt;= 1 b &gt;&gt;= 1 switch a &#123; case b: bs = append(bs, zero) default: bs = append(bs, one) &#125; b &lt;&lt;= 1 &#125; return bs&#125;// ByteToBinaryString get the string in binary format of a byte or uint8.func ByteToBinaryString(b byte) string &#123; buf := make([]byte, 0, 8) buf = appendBinaryString(buf, b) return string(buf)&#125;// BytesToBinaryString get the string in binary format of a []byte or []int8.func BytesToBinaryString(bs []byte) string &#123; l := len(bs) bl := l*8 + l + 1 buf := make([]byte, 0, bl) buf = append(buf, lsb) for _, b := range bs &#123; buf = appendBinaryString(buf, b) buf = append(buf, space) &#125; buf[bl-1] = rsb return string(buf)&#125;// regex for delete useless string which is going to be in binary format.var rbDel = regexp.MustCompile(`[^01]`)// BinaryStringToBytes get the binary bytes according to the// input string which is in binary format.func BinaryStringToBytes(s string) (bs []byte) &#123; if len(s) == 0 &#123; panic(ErrEmptyString) &#125; s = rbDel.ReplaceAllString(s, "") l := len(s) if l == 0 &#123; panic(ErrBadStringFormat) &#125; mo := l % 8 l /= 8 if mo != 0 &#123; l++ &#125; bs = make([]byte, 0, l) mo = 8 - mo var n uint8 for i, b := range []byte(s) &#123; m := (i + mo) % 8 switch b &#123; case one: n += uint8arr[m] &#125; if m == 7 &#123; bs = append(bs, n) n = 0 &#125; &#125; return&#125;]]></content>
      <categories>
        <category>GO语言</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>二进制转换</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go语言贪食蛇和c语言区别]]></title>
    <url>%2F2018%2F09%2F05%2Fgo%E8%AF%AD%E8%A8%80%E8%B4%AA%E9%A3%9F%E8%9B%87%E5%92%8Cc%E8%AF%AD%E8%A8%80%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[CSDN博客链接 GO贪食蛇小Demo利用go语言写贪食蛇游戏那么就会利用面向对象的思想来写一下，创造蛇身体对象，然后写出来，go语言写的时候我们需要调用一个c语言写的一个包，go语言可以直接调用调用c语言的函数，很方便简洁，我们先来看一下我自己写的C语言的一个包 1234567891011121314151617181920212223242526272829303132333435363738394041424344package Clib/*#include &lt;windows.h&gt;#include &lt;conio.h&gt;// 使用了WinAPI来移动控制台的光标void gotoxy(int x,int y)&#123; COORD c; c.X=x,c.Y=y; SetConsoleCursorPosition(GetStdHandle(STD_OUTPUT_HANDLE),c);&#125;// 从键盘获取一次按键，但不显示到控制台int direct()&#123; return _getch();&#125;//去掉控制台光标void hideCursor()&#123; CONSOLE_CURSOR_INFO cci; cci.bVisible = FALSE; cci.dwSize = sizeof(cci); SetConsoleCursorInfo(GetStdHandle(STD_OUTPUT_HANDLE), &amp;cci);&#125;*/import "C" // go中可以嵌入C语言的函数//设置控制台光标位置func GotoPostion(X int, Y int) &#123; //调用C语言函数 C.gotoxy(C.int(X), C.int(Y))&#125;//无显获取键盘输入的字符func Direction() (key int) &#123; key = int(C.direct()) return&#125;//设置控制台光标隐藏func HideCursor() &#123; C.hideCursor()&#125; 这个包把一些需要用到c语言的函数写进来，调用c语言的函数需要用到c语言的环境，别忘记自己电脑上要装c语言的环境奥，我们来看一下这个目录结构 首先我们的代码是放在GoCode里面下面的src目录下面，Clib里面是自己写的C语言的一个包，贪食蛇和Clib是同级别目录，在这里我们用的是goland编译器，编译器这里可以自己选择，我们编译的时候就不能单个文件编译了，因为需要调用自己的包，所以要选择多文件编译如图 我自己用的goland编译的时候需要改一下改成Directory 然后目录选到所在目录的src目录，然后设置好后就可以直接编译运行啦，当然也可以直接命令行编译运行 如图，我们可以在所在目录下面直接go build ./这样就是生成可执行文件.exe的，也可以直接使用go run命令直接编译运行， 感兴趣的小伙伴可以自己去试试啦 下面来看一下go语言写的代码，（可以自己去完善一下奥，比如加入等级，加入障碍物，蛇的速度都是自己可以调节的奥） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284package mainimport ( "Clib" "fmt" "os" "math/rand" "time")const wide int = 20const high int = 20var key int64 = 1 //关卡var food1 food //定义一个全局食物结构体//var size int = 2 //定义一个全局蛇的长度var score int = 0 //定义一个全局分数var dx int = 0var dy int = 0 //蛇的偏移量var barr1 barrier //障碍物结构体var c cake //定义一个蛋糕var FLAG bool=truetype postion struct &#123; x int y int //父类坐标&#125;type cake struct&#123; ca [5]postion&#125; //定义一个蛋糕type snake struct &#123; p [wide * high]postion size int dir byte&#125;type barrier struct &#123; barr [6]postion&#125; //障碍物结构体func (c *cake)setcake()&#123; x:=rand.Intn(wide-6)+3 y:=rand.Intn(high-6)+3 c.ca[0].x,c.ca[0].y=x,y c.ca[1].x,c.ca[1].y=x-1,y c.ca[2].x,c.ca[2].y= x-2,y c.ca[3].x,c.ca[3].y=x-1,y-1 c.ca[4].x,c.ca[4].y=x-1,y+1&#125;func (b *barrier)setbarrier()&#123; //定义一些随机障碍物 b.barr[0].x,b.barr[0].y=rand.Intn(wide-1)+1,rand.Intn(high-3)+1 b.barr[1].x,b.barr[1].y=rand.Intn(wide-1)+1,rand.Intn(high-3)+1 b.barr[2].x,b.barr[2].y=rand.Intn(wide-1)+1,rand.Intn(high-3)+1 //b.barr[3].x,b.barr[3].y=rand.Intn(wide-1)+1,rand.Intn(high-3)+1 //b.barr[4].x,b.barr[4].y=rand.Intn(wide-1)+1,rand.Intn(high-3)+1 //b.barr[5].x,b.barr[5].y=rand.Intn(wide-1)+1,rand.Intn(high-3)+1&#125;type food struct &#123; postion&#125; //食物func drawui(p postion, ch byte) &#123; Clib.GotoPostion(p.x*2+4, p.y+2+2) fmt.Fprintf(os.Stderr, "%c", ch)&#125;func (s *snake) initsnake() &#123; //蛇初始化 s.p[0].x = wide / 2 s.p[0].y = high / 2 s.p[1].x = wide/2 - 1 s.p[1].y = high / 2 //蛇头和第一个蛇结点初始化 s.dir = 'R' s.size=2 fmt.Fprintln(os.Stderr, ` #-----------------------------------------# | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | #-----------------------------------------#`) food1 = food&#123;postion&#123;rand.Intn(wide), rand.Intn(high) - 2&#125;&#125; //食物初始化 drawui(food1.postion, 'o') //画出食物 //go func()&#123; Clib.GotoPostion(46,19) fmt.Printf("正在进行第%d关，小心障碍物",key) //&#125;() go func()&#123; for&#123; time.Sleep(time.Second) num:=rand.Intn(10) if num==6&#123; c.setcake() break &#125; &#125; for i:=0;i&lt;len(c.ca);i++&#123; drawui(c.ca[i],'#') &#125; &#125;() //吃蛋糕的作用 go func()&#123; for i:=0;i&lt;len(barr1.barr);i++&#123; Clib.GotoPostion(barr1.barr[i].x,barr1.barr[i].y) drawui(barr1.barr[i],'!') &#125; &#125;() //打印出障碍物 go func() &#123; for &#123; switch Clib.Direction() &#123; case 72, 87, 119: if s.dir == 'D' &#123; break &#125; s.dir = 'U' case 65, 97, 75: if s.dir == 'R' &#123; break &#125; s.dir = 'L' case 100, 68, 77: if s.dir == 'L' &#123; break &#125; s.dir = 'R' case 83, 115, 80: if s.dir == 'U' &#123; break &#125; s.dir = 'D' case 32: s.dir = 'P' &#125; &#125; &#125;() //获取蛇跑的方向&#125;func (s *snake) playgame() &#123; //barr:=barrier&#123;postion&#123;rand.Intn(wide-5)+5,rand.Intn(high-5)+3&#125; //drawui(barr.postion,'p') for &#123; switch key &#123; case 1: time.Sleep(time.Second / 3) case 2:time.Sleep(time.Second / 5) case 3:time.Sleep(time.Second / 6) case 4:time.Sleep(time.Second / 7) case 5:time.Sleep(time.Second / 8) case 6:time.Sleep(time.Second / 9) //用来每增加一关蛇的速度加快 &#125; if s.dir == 'P' &#123; continue &#125; if s.p[0].x &lt; 0 || s.p[0].x &gt;= wide || s.p[0].y+2 &lt; 0 || s.p[0].y &gt;= high-2 &#123; Clib.GotoPostion(wide*3, high-3) FLAG=false return //如果蛇头碰墙就死亡 &#125; //if s.p[0].x==barr.postion.x&amp;&amp;s.p[0].y==barr.postion.y&#123; // Clib.GotoPostion(wide*3, high-3) // return //如果蛇头碰障碍物就死亡 //&#125; for i := 1; i &lt;s.size; i++ &#123; if s.p[0].x == s.p[i].x &amp;&amp; s.p[0].y == s.p[i].y &#123; Clib.GotoPostion(wide*3, high-3) FLAG=false return &#125; &#125; for j:=0;j&lt;len(barr1.barr);j++&#123; if s.p[0].x==barr1.barr[j].x&amp;&amp;s.p[0].y==barr1.barr[j].y&#123; Clib.GotoPostion(wide*3, high-3) FLAG=false return &#125; //碰到障碍物死亡 &#125; for m:=0;m&lt;len(c.ca);m++&#123; if s.p[0].x==c.ca[m].x&amp;&amp;s.p[0].y==c.ca[m].y&#123; s.size++ score++ &#125; if score &gt;= int(6+key*2) &#123; key++ return &#125; &#125; if s.p[0].x == food1.x &amp;&amp; s.p[0].y == food1.y &#123; s.size++ score++ if score &gt;= int(6+key*2) &#123; key++ return &#125; //画蛇 //food1 = food&#123;postion&#123;rand.Intn(wide), rand.Intn(high) - 2&#125;&#125; for &#123; flag := true temp := food&#123;postion&#123;rand.Intn(wide), rand.Intn(high) - 2&#125;&#125; for i := 1; i &lt; s.size; i++ &#123; if (temp.postion.x == s.p[i].x &amp;&amp; temp.postion.y == s.p[i].y) &#123; flag = false break &#125; &#125; for i:=0;i&lt;len(barr1.barr);i++&#123; if temp.postion.x==barr1.barr[i].x&amp;&amp;temp.postion.y==barr1.barr[i].y&#123; flag=false break &#125; &#125; if flag == true &#123; food1 = temp break &#125; &#125; drawui(food1.postion, 'o') &#125; switch s.dir &#123; case 'U': dx = 0 dy = -1 case 'D': dx = 0 dy = 1 case 'L': dx = -1 dy = 0 case 'R': dx = 1 dy = 0 &#125; lp := s.p[s.size-1] //蛇尾位置 for i := s.size - 1; i &gt; 0; i-- &#123; s.p[i] = s.p[i-1] drawui(s.p[i], '*') &#125; drawui(lp, ' ') //蛇尾画空格 s.p[0].x += dx s.p[0].y += dy //更新蛇头 drawui(s.p[0], 'O') //画蛇头 &#125;&#125;func main() &#123; rand.Seed(time.Now().UnixNano()) var s snake for k:=1;k&lt;=6;k++&#123; //用来循环6次代表6个关卡，这里可以自己设置多少关卡 s.initsnake() //初始化 barr1.setbarrier() //障碍物 s.playgame() //玩游戏开始 if FLAG==false&#123; //这个代表蛇死亡返回的，所以这样就退出了 Clib.GotoPostion(46,21) fmt.Printf("你已死亡，第%d关总分：%d分",k, score) break &#125; Clib.GotoPostion(46,21) fmt.Printf("第%d关总分：%d分,稍等进入下一关",k, score) //key++ time.Sleep(time.Second * 5) //延时5秒 Clib.Cls() //每一关清屏一下 //size=2 score=0 //每一关分数置为0 &#125; time.Sleep(time.Second * 5) //延时5秒&#125;]]></content>
      <categories>
        <category>GO语言</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>小Demo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C语言贪食蛇实现]]></title>
    <url>%2F2018%2F09%2F05%2FC%E8%AF%AD%E8%A8%80%E8%B4%AA%E9%A3%9F%E8%9B%87%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[CSDN博客 贪食蛇小Demo我们先来看一下C语言的贪食蛇代码，相对于面向对象的的语言，C语言是一门面向过程的语言，C语言写出来的代码都是顺着平常的思路来一步一步实现的，我们先来看C语言的代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;windows.h&gt;#include&lt;time.h&gt;//函数声明区void Pos(int x, int y);//光标位置设定void muban();//打印模板void initSnake();//蛇身的初始化void creatFood();//创建食物char reDirection();//识别方向int snakeMove();//蛇移动int crossWall();//不能穿墙int eatSelf();//不能吃自己typedef struct Snake//相当于蛇一个节点&#123; int x;//横坐标 int y;//纵坐标 struct Snake *next;&#125;snake;snake *head;//头指针snake *p;//用来遍历snake *food1;//用来标记的char status='L';//初始方向的状态，解决开始会动的问题int score=0;//分数int add=10;//一个食物的分int leap=0;//用来标志是否结束，0没有，1代表蛇死了代表结束了int endleap=0;//结束标志 1就是结束int sleepTime=500;void initSnake()//蛇身初始化，给定一个长度，用结构体表示是蛇的骨架，真正要显示出来是打印▇&#123; int i; snake *tail;//尾指针 tail=(snake*)malloc(sizeof(snake));//第一个节点/头结点 tail-&gt;x=30;//2的倍数，因为方块的长是两个单位 tail-&gt;y=10;//1个单位 tail-&gt;next=NULL; for(i=1;i&lt;=4;i++)//尾插法 &#123; head=(snake*)malloc(sizeof(snake));//申请一个节点 head-&gt;next=tail;//连接成链 head-&gt;x=30-2*i;//下一个节点的位置 head-&gt;y=10; tail=head; &#125; //遍历打印出来 while(tail!=NULL) &#123; Pos(tail-&gt;x,tail-&gt;y); printf("▇"); tail=tail-&gt;next; &#125;&#125;char reDirection()//识别用户按下的键值 保留方向值&#123; if(GetAsyncKeyState(VK_F7))//热键 &#123; if(sleepTime&gt;300)//最多减到300 &#123; sleepTime-=50;//每次减50 add++;//每次食物加1分 &#125; &#125; if(GetAsyncKeyState(VK_F8)) &#123; if(sleepTime&lt;800)//最多加到800 &#123; sleepTime+=50;//每次加50 add--;//每次食物减1分 &#125; &#125; if(GetAsyncKeyState(VK_UP)&amp;&amp;status!='D') status='U'; if(GetAsyncKeyState(VK_DOWN)&amp;&amp;status!='U') status='D'; if(GetAsyncKeyState(VK_LEFT)&amp;&amp;status!='R') status='L'; if(GetAsyncKeyState(VK_RIGHT)&amp;&amp;status!='L') status='R'; return status;&#125;void Pos(int x, int y)//设置光标位置，从哪里开始输出&#123; COORD pos;//表示一个字符在控制台屏幕上的坐标，左上角(0,0) HANDLE hOutput; pos.X = x; pos.Y = y; hOutput = GetStdHandle(STD_OUTPUT_HANDLE);//返回标准的输入、输出或错误的设备的句柄，也就是获得输入、输出/错误的屏幕缓冲区的句柄 SetConsoleCursorPosition(hOutput, pos);&#125;void creatFood()//创建食物&#123; snake *food;//创造一个食物 food=(snake*)malloc(sizeof(snake)); srand((unsigned int)time(NULL));//随着时间变化，产生不一样种子，就会得到没规律的食物 while(food-&gt;x%2!=0) &#123; food-&gt;x=rand()%56+2; &#125; food-&gt;y=rand()%23+1; //上面虽然解决了食物不会出现在城墙里，没有考虑食物出现在蛇本身里面 p=head;//用p来遍历 while(p!=NULL)//解决食物出现在蛇本身 &#123; if(food-&gt;x==p-&gt;x&amp;&amp;food-&gt;y==p-&gt;y) &#123; free(food); creatFood(); &#125; p=p-&gt;next; &#125; Pos(food-&gt;x,food-&gt;y); food1=food;//food1用来标记的作用 printf("▇"); Pos(70,20);//解决有光标闪烁的办法 printf("您的分数是:%d",score);&#125;void muban()&#123; int i; for(i=0;i&lt;=60;i+=2)//方块水平方向占两个单位 &#123; Pos(i,0); printf("▇");//上行 Pos(i,26); printf("▇");//下行 &#125; for(i=0;i&lt;=25;i+=1)//方块垂直方向占1个单位 &#123; Pos(0,i);//左列 printf("▇"); Pos(60,i);//右列 printf("▇"); &#125;&#125;int snakeMove()&#123; snake *nexthead; nexthead=(snake*)malloc(sizeof(snake)); if(status=='R')//向右走 &#123; nexthead-&gt;x=head-&gt;x+2; nexthead-&gt;y=head-&gt;y; if(nexthead-&gt;x==food1-&gt;x&amp;&amp;nexthead-&gt;y==food1-&gt;y)//吃掉了食物 &#123; nexthead-&gt;next=head; head=nexthead; p=head;//p用来从头遍历，打印方块 while(p!=NULL) &#123; Pos(p-&gt;x,p-&gt;y); printf("▇"); p=p-&gt;next; &#125;//吃掉了食物得创造 score=score+add; creatFood(); &#125; else//没有食物 &#123; nexthead-&gt;next=head; head=nexthead; p=head;//p用来从头遍历，打印方块 while(p-&gt;next-&gt;next!=NULL) &#123; Pos(p-&gt;x,p-&gt;y); printf("▇"); p=p-&gt;next; &#125; Pos(p-&gt;next-&gt;x,p-&gt;next-&gt;y); printf(" ");//会带来一个光标闪烁 Pos(70,20);//解决办法 printf("您的分数是:%d",score); free(p-&gt;next); p-&gt;next=NULL; &#125; &#125; if(status=='L')//向左走 &#123; nexthead-&gt;x=head-&gt;x-2; nexthead-&gt;y=head-&gt;y; if(nexthead-&gt;x==food1-&gt;x&amp;&amp;nexthead-&gt;y==food1-&gt;y)//吃掉了食物 &#123; nexthead-&gt;next=head; head=nexthead; p=head;//p用来从头遍历，打印方块 while(p!=NULL) &#123; Pos(p-&gt;x,p-&gt;y); printf("▇"); p=p-&gt;next; &#125;//吃掉了食物得创造 score=score+add; creatFood(); &#125; else//没有食物 &#123; nexthead-&gt;next=head; head=nexthead; p=head;//p用来从头遍历，打印方块 while(p-&gt;next-&gt;next!=NULL) &#123; Pos(p-&gt;x,p-&gt;y); printf("▇"); p=p-&gt;next; &#125; Pos(p-&gt;next-&gt;x,p-&gt;next-&gt;y); printf(" "); Pos(70,20);//解决办法 printf("您的分数是:%d",score); free(p-&gt;next); p-&gt;next=NULL; &#125; &#125; if(status=='U')//向上走 &#123; nexthead-&gt;x=head-&gt;x; nexthead-&gt;y=head-&gt;y-1; if(nexthead-&gt;x==food1-&gt;x&amp;&amp;nexthead-&gt;y==food1-&gt;y)//吃掉了食物 &#123; nexthead-&gt;next=head; head=nexthead; p=head;//p用来从头遍历，打印方块 while(p!=NULL) &#123; Pos(p-&gt;x,p-&gt;y); printf("▇"); p=p-&gt;next; &#125;//吃掉了食物得创造 score=score+add; creatFood(); &#125; else//没有食物 &#123; nexthead-&gt;next=head; head=nexthead; p=head;//p用来从头遍历，打印方块 while(p-&gt;next-&gt;next!=NULL) &#123; Pos(p-&gt;x,p-&gt;y); printf("▇"); p=p-&gt;next; &#125; Pos(p-&gt;next-&gt;x,p-&gt;next-&gt;y); printf(" "); Pos(70,20);//解决办法 printf("您的分数是:%d",score); free(p-&gt;next); p-&gt;next=NULL; &#125; &#125; if(status=='D')//向下走 &#123; nexthead-&gt;x=head-&gt;x; nexthead-&gt;y=head-&gt;y+1; if(nexthead-&gt;x==food1-&gt;x&amp;&amp;nexthead-&gt;y==food1-&gt;y)//吃掉了食物 &#123; nexthead-&gt;next=head; head=nexthead; p=head;//p用来从头遍历，打印方块 while(p!=NULL) &#123; Pos(p-&gt;x,p-&gt;y); printf("▇"); p=p-&gt;next; &#125;//吃掉了食物得创造 score=score+add; creatFood(); &#125; else//没有食物 &#123; nexthead-&gt;next=head; head=nexthead; p=head;//p用来从头遍历，打印方块 while(p-&gt;next-&gt;next!=NULL) &#123; Pos(p-&gt;x,p-&gt;y); printf("▇"); p=p-&gt;next; &#125; Pos(p-&gt;next-&gt;x,p-&gt;next-&gt;y); printf(" "); Pos(70,20);//解决办法 printf("您的分数是:%d",score); free(p-&gt;next); p-&gt;next=NULL; &#125; &#125; Sleep(sleepTime);//蛇移动的速度，里面是毫秒，越大速度越慢 status=reDirection();//判别下方向先 if(crossWall()==1||eatSelf()==1) //exit(0);//直接把程序关闭了 endleap=1; return endleap;&#125;int crossWall()//判断蛇有没穿透墙&#123; if(head-&gt;x==0||head-&gt;y==0||head-&gt;x==60||head-&gt;y==25) leap=1; return leap;&#125;int eatSelf()//判断是否咬到了自己&#123; snake *q;//遍历的 q=head-&gt;next; while(q!=NULL) &#123; if(q-&gt;x==head-&gt;x&amp;&amp;head-&gt;y==q-&gt;y) leap=1; q=q-&gt;next; &#125; return leap;&#125;//打印食物的时候会出现光标，解决办法就是引开它int main()&#123; muban();//打印模板 initSnake();//初始化蛇 creatFood();//创建食物 while(1)//死循环，让蛇一直动起来，直到蛇死了 &#123; if(snakeMove()==1)//判断是否结束 &#123; Pos(70,23); printf("蛇死了"); system("pause");//用来暂停 Pos(70,24);//解决press any key to continue 在该地点打印 大家试下 break; &#125; &#125; printf("是否继续游戏，y or n：");//y 继续 if(getch()=='y')//重新游戏 &#123; //蛇一开始就死了，因为全局变量没有恢复原值，仍然保留上一局的值 status='L';//初始方向的状态，解决开始会动的问题 score=0;//分数 add=10;//一个食物的分 leap=0;//用来标志是否结束，0没有，1代表蛇死了代表结束了 endleap=0;//结束标志 1就是结束 sleepTime=500; system("cls");//清理屏幕 main();//自己调用自己 看不一样的编译器，vc6.0允许调用自己 &#125; if(getch()=='n') &#123; Pos(70,25);//定一个位置，再打印press exit(0);//退出程序 &#125; return 0;&#125;//蛇的速度变化，每个食物的分数增加//是否继续游戏//按键的作用 在C语言中，我们利用定义一个一个函数模块来实现蛇的基础实现，然后定义蛇的一个结构体，利用链表的知识来串联蛇身体，来让蛇身连接起来并走动起来。 /*go语言实现的贪食蛇请见博下一章/]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>小Demo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C和Go相互调用]]></title>
    <url>%2F2018%2F09%2F05%2FC%E5%92%8CGo%E7%9B%B8%E4%BA%92%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[转载处：https://colobu.com/2018/08/28/c-and-go-calling-interaction/ C和Go相互调用C可以调用Go，并且Go可以调用C， 如果更进一步呢， C--&gt;Go--&gt;C 或者 Go--&gt;C--&gt;Go的调用如何实现？ 本文通过两个简单的例子帮助你了解这两种复杂的调用关系。本文不涉及两者之间的复杂的数据转换，官方文章C? Go? Cgo!、wiki/cgo和cmd/cgo有一些介绍。 Go–&gt;C–&gt;GoGo程序调用C实现的函数，然后C实现的函数又调用Go实现的函数。 1、首先，我们新建一个hello.go的文件： hello.go 1`package mainimport "C"import "fmt"//export HelloFromGofunc HelloFromGo() &#123; fmt.Printf("Hello from Go!\n")&#125;` 它定义了一个HelloFromGo函数，注意这个函数是一个纯的Go函数，我们定义它的输出符号为HelloFromGo。 2、接着我们新建一个hello.c的文件： 12345678#include &lt;stdio.h&gt;#include &quot;_cgo_export.h&quot;int helloFromC() &#123; printf(&quot;Hi from C\n&quot;); //call Go function HelloFromGo(); return 0;&#125; 这个c文件定义了一个C函数helloFromC,内部它会调用我们刚才定义的HelloFromGo函数。 这样，我们实现了C调用Go: C--&gt;Go,下面我们再实现Go调用C。 3、最后新建一个main.go文件： 123456789package main/*extern int helloFromC();*/import &quot;C&quot;func main() &#123; //call c function C.helloFromC()&#125; 它调用第二步实现的C函数helloFromC。 运行测试一下： 123$ go run .Hi from CHello from Go! 可以看到，期望的函数调用正常的运行。第一行是C函数的输出，第二行是Go函数的输出。 C–&gt;Go–&gt;C第二个例子演示了C程序调用Go实现的函数，然后Go实现的函数又调用C实现的函数。 1、首先新建一个hello.c文件： 12345#include &lt;stdio.h&gt;int helloFromC() &#123; printf(&quot;Hi from C\n&quot;); return 0;&#125; 它定义了一个纯C实现的函数。 2、接着新建一个hello.go文件： 1234567891011121314// go build -o hello.so -buildmode=c-shared .package main/*extern int helloFromC();*/import &quot;C&quot;import &quot;fmt&quot;//export HelloFromGofunc HelloFromGo() &#123; fmt.Printf(&quot;Hello from Go!\n&quot;) C.helloFromC()&#125;func main() &#123;&#125; 它实现了一个Go函数HelloFromGo,内部实现调用了C实现的函数helloFromC,这样我们就实现了Go--&gt;C。 注意包名设置为package main，并且增加一个空的main函数。 运行go build -o hello.so -buildmode=c-shared .生成一个C可以调用的库，这调命令执行完后会生成hello.so文件和hello.h文件。 3、最后新建一个文件夹，随便起个名字，比如main 将刚才生成的hello.so文件和hello.h文件复制到main文件夹，并在main文件夹中新建一个文件main.c: 123456789#include &lt;stdio.h&gt;#include &quot;hello.h&quot;int main() &#123; printf(&quot;use hello lib from C:\n&quot;); HelloFromGo(); return 0;&#125; 运行gcc -o main main.c hello.so生成可执行文件main, 运行main: 1234$ ./mainuse hello lib from C:Hello from Go!Hi from C 第一行输出来自main.c,第二行来自Go函数，第三行来自hello.c中的C函数，这样我们就实现了C--&gt;Go--C的复杂调用。 C--&gt;Go--&gt;C的状态变量我们来分析第二步中的一个特殊的场景， 为了下面我们好区分，我们给程序标记一下， 记为C1--&gt;Go--&gt;C2, C2的程序修改一下，加入一个状态变量a,并且函数helloFromC中会打印a的地址和值，也会将a加一。 123456#include &lt;stdio.h&gt;int a = 1;int helloFromC() &#123; printf(&quot;Hi from C: %p, %d\n&quot;, &amp;a, a++); return 0;&#125; 然后修改main.c程序,让它既通过Go嗲用C1.helloFromC,又直接调用C1.helloFromC,看看多次调用的时候a的指针是否一致，并且a的值是否有变化。 1234567891011121314#include &lt;stdio.h&gt;#include &quot;hello.h&quot;int main() &#123; printf(&quot;use hello lib from C:\n&quot;); // 1. 直接调用C函数 helloFromC(); // 2. 调用Go函数 HelloFromGo(); // 3. 直接调用C函数 helloFromC(); return 0;&#125; 激动人心的时候到了。我们不同的编译方式会产生不同的结果。 1、gcc -o main main.c hello.so 和第二步相同的编译方式，编译出main并执行， 因为hello.so中包含C1.helloFromC实现，所以可以正常执行。 123456./mainuse hello lib from C:Hi from C: 0x10092a370, 1Hello from Go!Hi from C: 0x10092a370, 2Hi from C: 0x10092a370, 3 可以看到a的指针是同一个值，无论通过Go函数改变还是通过C函数改变都是更改的同一个变量。 nm可以查看生成的main的符号： 1234567nm main U _HelloFromGo0000000100000000 T __mh_execute_header U _helloFromC0000000100000f10 T _main U _printf U dyld_stub_binder U代表这个符号是未定义的符号，通过动态库链接进来。 2、 gcc -o main main.c hello.so ../hello.c 我们编译的时候直接链接hello.c的实现，然后运行main: 123456./mainuse hello lib from C:Hi from C: 0x104888020, 1Hello from Go!Hi from C: 0x1049f7370, 1Hi from C: 0x104888020, 2 可以看到a是不同的两个变量。 nm可以查看生成的main的符号： 12345678nm main U _HelloFromGo0000000100000000 T __mh_execute_header0000000100001020 D _a0000000100000f10 T _helloFromC0000000100000ec0 T _main U _printf U dyld_stub_binder 可以看到_a是初始化的环境变量，_helloFromC的类型是T而不是U,代表它是一个全局的Text符号,这和上一步是不一样的]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>go语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链以太坊相关资料]]></title>
    <url>%2F2018%2F09%2F04%2F%E5%8C%BA%E5%9D%97%E9%93%BE%E4%BB%A5%E5%A4%AA%E5%9D%8A%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99%2F</url>
    <content type="text"><![CDATA[收集整理了一些免费区块链、以太坊技术开发相关的文件，有需要的可以下载，文件链接： web3.js API官方文档中文版：https://pan.baidu.com/s/1hOV9hEzi7hFxJCL4LTvC6g 以太坊官方文档中文版 ：https://pan.baidu.com/s/1ktODJKLMBmkOsi8MPrpIJA 以太坊白皮书中文版 ：https://pan.baidu.com/s/1bzAFnzJ35hlQxJ2J4Oj-Ow Solidity的官方文档中文版 ：https://pan.baidu.com/s/18yp9XjEqAHpiFm2ZSCygHw Truffle的官方文档中文版 ：https://pan.baidu.com/s/1y6SVd7lSLUHK21YF5FzIUQ C#区块链编程指南 ：https://pan.baidu.com/s/1sJPLqp1eQqkG7jmxqwn3EA 区块链技术指南： ：https://pan.baidu.com/s/13cJxAa80I6iMCczA04CZhg 精通比特币中文版： ：https://pan.baidu.com/s/1lz6te3wcQuNJm28rFvBfxg Node.js区块链开发 ：https://pan.baidu.com/s/1Ldpn0DvJ5LgLqwix6eWgyg geth使用指南文档中文版 ：https://pan.baidu.com/s/1M0WxhmumF_fRqzt_cegnag 以太坊DApp开发环境搭建-Ubuntu : https://pan.baidu.com/s/10qL4q-uKooMehv9X2R1qSA 以太坊DApp开发环境搭建-windows ：https://pan.baidu.com/s/1cyYkhIJIFuI2oyxM9Ut0eA 以太坊DApp开发私链搭建-Ubuntu : https://pan.baidu.com/s/1aBOFZT2bCjD2o0EILBWs-g 以太坊DApp开发私链搭建-windows ：https://pan.baidu.com/s/10Y6F1cqUltZNN99aJv9kAA 以太坊ganache CLI命令行参数详解：https://pan.baidu.com/s/1lnknFkwenacaeM4asOcBdg 使用truflle和infura部署以太坊合约：https://pan.baidu.com/s/1PTxSVff2vHSVUihYczRRqw IPFS安装部署与开发环境搭建-windows：https://pan.baidu.com/s/1bnhDvqCoOgAqEBZXMtVbRg EOS.IO教程： EOS智能合约与DApp开发入门：http://t.cn/RealN1W 以太坊教程： 以太坊DApp开发实战入门：http://t.cn/RmeEwxJ 以太坊node.js电商实战：http://t.cn/RnmDmaD C#开发以太坊区块链的教程：http://t.cn/ReYjplC java开发以太坊区块链的教程，web3j开发详解：http://t.cn/RrpULLJ PHP开发以太坊区块链的教程：http://t.cn/RrRAlAO python用web3.py开发以太坊区块链应用的教程：http://t.cn/RdXcpVD]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>以太坊</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链中的双花问题]]></title>
    <url>%2F2018%2F09%2F04%2F%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%AD%E7%9A%84%E5%8F%8C%E8%8A%B1%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[区块链中的“双花”问题我们举个简单的例子，比如你在商场刷卡买东西。这个行为面临三种危险： 首先，刷卡这个行为，验证的是你的信用卡信息，也就是说只要给刷卡机提供同样的信息，就能从你的账户里把钱刷走。没错，很多朋友都听说过，有犯罪组织专门从事复制卡信息的勾当，然后“盗刷”你的卡。在一些不发达国家的小店里刷卡就特别容易中招。 其次，负责记账和结算的卡组织和银行的服务器可能被黑客攻破，造成数据泄露和伪造交易。回想这些年一波又一波某某大公司数据库被黑客攻入的新闻，这危险并非危言耸听。（好吧，认真的geek会说这里用词应该是cracker骇客而非hacker黑客，不过这年头认真的人越来越少了） 最后，还有一种可能，就是用卡人自己可能利用系统网络延迟，在进行第一笔交易、用完所有额度后，趁系统还没记账把额度扣完，立刻进行第二笔交易，形成诈骗。当然目前的结算系统延迟极小，这情况不太可能，不过像在优惠券或者抢购资格这种另外搭建的相对脆弱的系统上还是有可能的。 网上支付也一样，犯罪分子可以用特殊手段（例如木马，伪造WIFI等）截获你跟服务器之间的传递数据，如果商家加密技术太弱的话信息就可能被破解——嗯，某国很多时候数据干脆是不加密的。所以大家才一直被警告不要乱装程序、不要连可疑的WiFi。 区块链是怎么处理这些问题的呢？我们以比特币交易为例，逐条分析。 首先，比特币拥有者想要完成某项交易，比如买手机吧，他会向全网广播：我小A向小B支付1个比特币（嗯，这金额现在大致可以买个5个iPhone 8）。 与这条信息一起的，还有一条加密信息，这条信息是用Hash函数对上一条信息加密生成一个摘要后，再用A的私钥进行加密的（称为私钥“签名”）。 接收到这条信息的B和其他用户先用同样的Hash函数对明文信息生成摘要，再用A的公钥对加密信息进行解密，如果解密得到的摘要与明文生成的摘要相同，便认为信息确实是A发出的，且没有经过篡改。 A的公钥和Hash是公开的，私钥则无法算出，只有A知道，这样就既保证了交易的达成，又保证了A的信息无法被窃取。 其次，由在POW（运算力证明）中胜出的矿工负责这段时间的记账，事先完全无法知道究竟哪个矿工来记账，黑客也就无从黑起，除非碰运气。 最后，在传统系统中因为结算速度极快而不太可能的情况，在比特币网络中反而可能性比较大。因为没有中心化的管理者，交易确认的时间要长很多，使得这种诈骗有可能实现，这就是比特币的double spending双重花费问题，简称“双花”。 对于双花问题，比特币网络，或者说区块链网络，是这么应对的： -每笔交易都需要先确认对应比特币之前的状态，如果它之前已经被标记为花掉，那么新的交易会被拒绝。 -如果先发起一笔交易，在它被确认前，也就是这个时间段的交易还未被记账成区块block时，进行矛盾的第二笔交易，那么在记账时，这些交易会被拒绝。 -上面只是小伎俩，现在tricky的部分开始了。如果诈骗者刻意把第一笔交易向一半网络进行广播，把第二笔交易向另一半网络广播——这个诈骗者智商还挺高——然后两边正好有两个矿工几乎同时取得记账权，把各自记的block发布给大家的话（这个概率很低），网络是不是会混乱呢，区块链的规则是这样的：先选择任意一个账本都可以，这时候原来统一的账本出现了分叉： 但是在两个账本中各只有一笔交易，诈骗者不会有好处。接下来，下一个矿工选择在A基础上继续记账的话，A分支就会比B分支更长，根据区块链的规则，最长的分支会被认可，短的分支会被放弃，账本还是会回归为一个，交易也只有一笔有效： -那么如果这个诈骗犯真的智商非常高，他会这么做：如果是A分支被认可（B也一样），相应交易确认，拿到商品之后，立刻自己变身矿工，争取到连续两次记账权，然后在B分支上连加两个block，就像这样： 于是B分支成为认可的分支，A被舍弃，A分支中的交易不再成立，但他已经拿到商品，诈骗成功。 在B分支落后的情况下要强行让它超过A分支，其实是挺难的，假设诈骗者掌握了全网1%的计算能力，那么他争取到记账权的概率就是1%，两次就是10的负4次方。但这个概率还没有太低。 应对办法呢？建议大家在一笔交易确认后，也就是一个block被记下来之后，再等5个block，也就是等6个block被确认后再把交易对应的商品交付。这样，诈骗者还能追上的概率就几乎为0了。除非…… 如果诈骗者掌握了全网50%以上的计算力，那么，即使落后很多，他追上也只是时间问题，这就是比特币的“51%攻击”。 这就是区块链需要警惕的问题。虽然在比特币网络中，用户已经极多，全网算力总和非常大，如果真掌握50%以上，也不用靠这个诈骗了，挖矿的收益都更高。但是在小的区块链网络中呢？况且，没有50%以上的算力，还是有机会成功的，只是概率低而已。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>双花问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[什么是区块链]]></title>
    <url>%2F2018%2F09%2F04%2F%E4%BB%80%E4%B9%88%E6%98%AF%E5%8C%BA%E5%9D%97%E9%93%BE%2F</url>
    <content type="text"><![CDATA[【定义】区块链（Blockchain）是指通过去中心化和去信任的方式集体维护一个可靠数据库的技术方案。该技术方案让参与系统中的任意多个节点，把一段时间系统内全部信息交流的数据，通过密码学算法计算和记录到一个数据块（block），并且生成该数据块的指纹用于链接（chain）下个数据块和校验，系统所有参与节点来共同认定记录是否为真。 区块链是一种类似于NoSQL（非关系型数据库）这样的技术解决方案统称，并不是某种特定技术，能够通过很多编程语言和架构来实现区块链技术。并且实现区块链的方式种类也有很多，目前常见的包括POW（Proof of Work，工作量证明），POS（Proof of Stake，权益证明），DPOS（Delegate Proof of Stake，股份授权证明机制）等。 区块链的概念首次在论文《比特币：一种点对点的电子现金系统（Bitcoin: A Peer-to-Peer Electronic Cash System）》中提出，作者为自称中本聪（Satoshi Nakamoto）的个人（或团体）。因此可以把比特币看成区块链的首个在金融支付领域中的应用。 【通俗解释】无论多大的系统或者多小的网站，一般在它背后都有数据库。那么这个数据库由谁来维护？在一般情况下，谁负责运营这个网络或者系统，那么就由谁来进行维护。如果是微信数据库肯定是腾讯团队维护，淘宝的数据库就是阿里的团队在维护。大家一定认为这种方式是天经地义的，但是区块链技术却不是这样。 如果我们把数据库想象成是一个账本：比如支付宝就是很典型的账本，任何数据的改变就是记账型的。数据库的维护我们可以认为是很简单的记账方式。在区块链的世界也是这样，区块链系统中的每一个人都有机会参与记账。系统会在一段时间内，可能选择十秒钟内，也可能十分钟，选出这段时间记账最快最好的人，由这个人来记账，他会把这段时间数据库的变化和账本的变化记在一个区块（block）中，我们可以把这个区块想象成一页纸上，系统在确认记录正确后，会把过去账本的数据指纹链接（chain）这张纸上，然后把这张纸发给整个系统里面其他的所有人。然后周而复始，系统会寻找下一个记账又快又好的人，而系统中的其他所有人都会获得整个账本的副本。这也就意味着这个系统每一个人都有一模一样的账本，这种技术，我们就称之为区块链技术（Blockchain），也称为分布式账本技术。 由于每个人（计算机）都有一模一样的账本，并且每个人（计算机）都有着完全相等的权利，因此不会由于单个人（计算机）失去联系或宕机，而导致整个系统崩溃。既然有一模一样的账本，就意味着所有的数据都是公开透明的，每一个人可以看到每一个账户上到底有什么数字变化。它非常有趣的特性就是，其中的数据无法篡改。因为系统会自动比较，会认为相同数量最多的账本是真的账本，少部分和别人数量不一样的账本是虚假的账本。在这种情况下，任何人篡改自己的账本是没有任何意义的，因为除非你能够篡改整个系统里面大部分节点。如果整个系统节点只有五个、十个节点也许还容易做到，但是如果有上万个甚至上十万个，并且还分布在互联网上的任何角落，除非某个人能控制世界上大多数的电脑，否则不太可能篡改这样大型的区块链。 【要素】结合区块链的定义，我们认为必须具有如下四点要素才能被称为公开区块链技术，如果只具有前3点要素，我们将认为其为私有区块链技术（私有链）。 1、点对点的对等网络（权力对等、物理点对点连接） 2、可验证的数据结构（可验证的PKC体系，不可篡改数据库） 3、分布式的共识机制（解决拜占庭将军问题，解决双重支付） 4、纳什均衡的博弈设计（合作是演化稳定的策略） 【特性】结合定义区块链的定义，区块链会现实出四个主要的特性：去中心化（Decentralized）、去信任（Trustless）、集体维护（Collectively maintain）、可靠数据库（Reliable Database）。并且由四个特征会引申出另外2个特征：开源（Open Source）、隐私保护（Anonymity）。如果一个系统不具备这些特征，将不能视其为基于区块链技术的应用。 去中心化（Decentralized）：整个网络没有中心化的硬件或者管理机构，任意节点之间的权利和义务都是均等的，且任一节点的损坏或者失去都会不影响整个系统的运作。因此也可以认为区块链系统具有极好的健壮性。 去信任（Trustless）：参与整个系统中的每个节点之间进行数据交换是无需互相信任的，整个系统的运作规则是公开透明的，所有的数据内容也是公开的，因此在系统指定的规则范围和时间范围内，节点之间是不能也无法欺骗其它节点。 集体维护（Collectively maintain）：系统中的数据块由整个系统中所有具有维护功能的节点来共同维护的，而这些具有维护功能的节点是任何人都可以参与的。 可靠数据库（Reliable Database）：整个系统将通过分数据库的形式，让每个参与节点都能获得一份完整数据库的拷贝。除非能够同时控制整个系统中超过51%的节点，否则单个节点上对数据库的修改是无效的，也无法影响其他节点上的数据内容。因此参与系统中的节点越多和计算能力越强，该系统中的数据安全性越高。 开源（Open Source）：由于整个系统的运作规则必须是公开透明的，所以对于程序而言，整个系统必定会是开源的。 隐私保护（Anonymity）：由于节点和节点之间是无需互相信任的，因此节点和节点之间无需公开身份，在系统中的每个参与的节点的隐私都是受到保护。 【区块链意义之一 ：解决拜占庭将军问题】区块链解决的核心问题不是“数字货币”，而是在信息不对称、不确定的环境下，如何建立满足经济活动赖以发生、发展的“信任”生态体系。而这个问题称之为“拜占庭将军问题”，也可称为“拜占庭容错”或者“两军问题”，这是一个分布式系统中进行信息机交互时面临的难题，即在整个网络中的任意节点都无法信任与之通信的对方时，如何能创建出共识基础来进行安全的信息交互而无需担心数据被篡改。区块链使用算法证明机制来保证整个网络的安全，借助它，整个系统中的所有节点能够在去信任的环境下自动安全的交换数据。更多介绍请参见《比特币与拜占庭将军问题》。 【区块链意义之二：实现跨国价值转移】互联网诞生最初，最早核心解决的问题是信息制造和传输，我们可以通过互联网将信息快速生成并且复制到全世界每一个有着网络的角落，但是它尚始终不能解决价值转移和信用转移。这里所谓的价值转移是指，在网络中每个人都能够认可和确认的方式，将某一部分价值精确的从某一个地址转移到另一个地址，而且必须确保当价值转移后，原来的地址减少了被转移的部分，而新的地址增加了所转移的价值。这里说的价值可以是货币资产，也可以是某种实体资产或者虚拟资产（包括有价证券、金融衍生品等）。而这操作的结果必须获得所有参与方的认可，且其结果不能受到任何某一方的操纵。 在目前的互联网中也有各种各样的金融体系，也有许多政府银行提供或者第三方提供的支付系统，但是它还是依靠中心化的方案来解决。所谓中心化的方案，就是通过某个公司或者政府信用作为背书，将所有的价值转移计算放在一个中心服务器（集群）中，尽管所有的计算也是由程序自动完成，但是却必须信任这个中心化的人或者机构。事实上通过中心化的信用背书来解决，也只能将信用局限在一定的机构、地区或者国家的范围之内。由此可以看出，必须要解决的这个根本问题，那就是信用。所以价值转移的核心问题是跨国信用共识。 在如此纷繁复杂的全球体系中，要凭空建立一个全球性的信用共识体系是很难的，由于每个国家的政治、经济和文化情况不同，对于两个国家的企业和政府完全互信是几乎做不到的，这也就意味着无论是以个人抑或企业政府的信用进行背书，对于跨国之间的价值交换即使可以完成，也有着巨大的时间和经济成本。但是在漫长的人类历史中，无论每个国家的宗教、政治和文化是如何的不同，唯一能取得共识的是数学（基础科学）。因此，可以毫不夸张的说，数学（算法）是全球文明的最大公约数，也是全球人类获得最多共识的基础。如果我们以数学算法（程序）作为背书，所有的规则都建立一个公开透明的数学算法（程序）之上，能够让所有不同政治文化背景的人群获得共识。 【未来的发展】互联网将使得全球之间的互动越来越紧密，伴随而来的就是巨大的信任鸿沟。目前现有的主流数据库技术架构都是私密且中心化的，在这个架构上是永远无法解决价值转移和互信问题。所以区块链技术有可能将成为下一代数据库架构。通过去中心化技术，将能够在大数据的基础上完成数学（算法）背书、全球互信这个巨大的进步。 区块链技术作为一种特定分布式存取数据技术，它通过网络中多个参与计算的节点开共同参与数据的计算和记录，并且互相验证其信息的有效性（防伪）。从这一点来，区块链技术也是一种特定的数据库技术。互联网刚刚进入大数据时代，但是从目前来看，大数据还处于非常基础的阶段。但是当进入到区块链数据库阶段，将进入到真正的强信任背书的大数据时代。这里面的所有数据都获得坚不可摧的质量，任何人都没有能力也没有必要去质疑。 也许我们现在正处在一个重大的转折点之上——和工业革命所带来的深刻变革几乎相同的重大转折的早期阶段。不仅仅是新技术指数级、数字化和组合式的进步与变革，更多的惊喜也许还会在我们前面。在未来的24个月里，这个星球所增长的计算机算力和记录的数据将会超过所有历史阶段的总和。在过去的24个月里，这个增值可能已经超过了1000倍。这些数字化的数据信息还在以比摩尔定律更快的速度增长。区块链技术将不仅仅应用在金融支付领域，而是将会扩展到目前所有应用范围，诸如去中心化的微博、微信、搜索、租房，甚至是打车软件都有可能会出现。因为区块链将可以让人类无地域限制的、去信任的方式来进行大规模协作。 我们这一代人将很可能会幸运地经历人类历史上两个最让人吃惊的事件，地球上的所有人和所有机器通过区块链技术以前所未有的互信展开了空前的大规模协作，其次就是基于此真正的人工智能将被创造出来。这两个时间将会深深地改变这个世界的经济发展模式。创业者、企业家、科学家以及各种各样的极客将利用这个充裕的世界去创造能让我们震惊和快乐。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[拜占庭将军问题]]></title>
    <url>%2F2018%2F09%2F04%2F%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%B0%86%E5%86%9B%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[拜占庭将军问题（Byzantine failures）是由莱斯利·兰伯特提出的点对点通信中的基本问题。含义是在存在消息丢失的不可靠信道上试图通过消息传递的方式达到一致性是不可能的。因此对一致性的研究一般假设信道是可靠的，或不存在本问题。这个难题也被称为“拜占庭容错”、“拜占庭将军问题”、或者“两军问题”。 拜占庭将军问题是一个协议问题，拜占庭帝国军队的将军们必须全体一致的决定是否攻击某一支敌军。问题是这些将军在地理上是分隔开来的，并且将军中存在叛徒。叛徒可以任意行动以达到以下目标：欺骗某些将军采取进攻行动；促成一个不是所有将军都同意的决定，如当将军们不希望进攻时促成进攻行动；或者迷惑某些将军，使他们无法做出决定。如果叛徒达到了这些目的之一，则任何攻击行动的结果都是注定要失败的，只有完全达成一致的努力才能获得胜利。 拜占庭假设是对现实世界的模型化，由于硬件错误、网络拥塞或断开以及遭到恶意攻击，计算机和网络可能出现不可预料的行为。拜占庭容错协议必须处理这些失效，并且这些协议还要满足所要解决的问题要求的规范。 首先，不要把比特币当成一种货币，而是一个总账。它是个电子账本，网络上的每一个参与者的电脑都会有一份账本的备份，并且所有的备份都是在实时的持续的更新、对账、以及同步着。每一个参与者都能在这本账本里记上一笔，这一笔记录着一定数量的币从一个参与者那里被发送到另一个参与者那里，并且每一条这样的记录都接着就实时的广播到网络了，所以在每一台电脑上的每一分份拷贝都是几乎同时更新的，并且所有的账本拷贝都保持着同步。这本公开的分布式的账本就可以称为“区块链（blockchain）”，并且它使用了BT技术以保证所有的拷贝都是同步的。 可以把比特币当作一个对于在分布式系统领域的一个复杂的算法难题的通用解决方法。 这一问题的趣味非正式表述如下：想象一下，在拜占庭时代有一个墙高壁厚的城邦，拜占庭，高墙之内是它的邻居想象不到之多的财富。它被其他10个城邦所环绕，这10个城邦也很富饶，但和拜占庭相比就微不足道了。它的十个邻居都觊觎拜占庭的财富，并希望侵略并占领它。 但是，拜占庭的防御是如此的强大，没有一个相邻的城邦能够成功入侵。任何单个城邦的入侵行动都会失败，而入侵者的军队也会被歼灭，使得其自身容易遭到其他九个城邦的入侵和劫掠。这十个城邦之间也互相觊觎对方的财富并持续互相对抗着。而且，拜占庭的防御如此之强，十个邻居的一半以上同时进攻才能攻破它。 也就是说，如果六个或者更多的相邻敌军一起进攻，他们就会成功并获得拜占庭的财富。然而，如果其中有一个或者更多背叛了其他人，答应一起入侵但在其他人进攻的时候又不干了，也就导致只有五支或者更少的军队在同时进攻，那么所有的进攻军队都会被歼灭，并随后被其他的（包括背叛他们的那（几）个）邻居所劫掠。这是一个由不互相信任的各方构成的网络，但他们又必须一起努力以完成共同的使命。 而且，是个邻居之间通讯和协调统计时间的唯一途径是通过骑马在他们之间传递信息。他们不能聚在一个地方开个会（所有的王都不互相信任他们的安全在自己的城堡或者军队范围之外能够得到保障）。然而，他们可以在任意时间以任意频率派出任意数量的信使到任意的对方。每条信息都包含类似如下的内容：“我将在第四天的6点钟进攻，你愿意加入吗？”。 如果收信人同意了，他们就会在原信上附上一份签名了的/认证了的/盖了图章的/验证了的回应，然后把新合并了的信息的拷贝再次发送给九个邻居，要求他们也如此这样做。最后的目标是，通过在原始信息链上盖上他们所有十个人的图章，让他们在时间上达成共识。最后的结果是，会有一个盖有十个同意同一时间的图章信息链，可能还会有一些被抛弃了的包含部分但不是全部图章的信息链。 但是，问题在于如果每个城邦向其他九个城邦派出一名信使，那么就是十个城邦每个派出了九名信使，也就是在任何一个时间又总计90次的传输，并且每个城市分别收到九个信息，可能每一封都写着不同的进攻时间。除此以外，部分城邦会答应超过一个的攻击时间，故意背叛发起人，所以他们将重新广播超过一条的信息链。这个系统迅速变质成不可信的信息和攻击时间相互矛盾的纠结体。 比特币通过对这个系统做出一个简单的（事后看是简单的）修改解决了这个问题，它为发送信息加入了成本，这降低了信息传递的速率，并加入了一个随机元素以保证在一个时间只有一个城邦可以进行广播。它加入的成本是“工作量证明”，并且它是基于计算一个随机哈希算法的。哈希是一种算法，它唯一做的事情就是获得一些输入然后进行计算，并得到一串64位的随机数字和字母的字符串，就像这个： 1d70298566aa2f1a66d892dc31fedce6147b5bf509e28d29627078d9a01a8f86b 在比特币的世界中，输入数据包括了到当前时间点的整个总账（区块链）。并且尽管单个哈希值用现在的计算机可以几乎即时的计算出来，但只有一个前13个字符是0的哈希值结果可以被比特币系统接受成为“工作量证明”。这样一个13个0的哈希值是极其不可能与罕见的，并且在当前需要花费整个比特币网络大约10分钟的时间来找到一个。在一台网络中的机器随机的找到一个有效哈希值之前，上十亿个的无效值会被计算出来，这就是减慢信息传递速率并使得整个系统可用的“工作量证明”。下面是一个例子： 123f51d0199c4a6d9f6da230b579d850698dff6f695b47d868cc1165c0ce74df5e1d70298566aa2f1a66d892dc31fedce6147b5bf509e28d29627078d9a01a8f86b119c506ceaa18a973a5dbcfbf23253bc970114edd1063bd1288fbba468dcb7f8 在找到一个有效值之前，成百万上亿个更多的类似上面这样的字符串被计算出来…… 1000000000000084b6550604bf21ad8a955b945a0f78c3408c5002af3cdcc14f5 那台发现下一个有效哈希值的机器（或者说在我们类比中的城邦），把所有的之前的信息放到一起，附上它自己的，以及它的签名/印章/诸如此类，并向网络中的其他机器广播出去。只要其他网络中的机器接收到并验证通过了这个13个0的哈希值和附着在上面的信息，他们就会停止他们当下的计算，使用新的信息更新他们的总账拷贝，然后把新更新的总账/区块链作为哈希算法的输入，再次开始计算哈希值。哈希计算竞赛从一个新的开始点重新开始。如此这般，网络持续同步着，所有网络上的电脑都使用着同一版本的总账。 与此同时，每一次成功找到有效哈希值以及区块链更新的间隔大概是10分钟（这是故意的，算法难度每两周调整一次以保证网络一直需要花费10分钟来找到一个有效的哈希值）。在那10分钟以内，网络上的参与者发送信息并完成交易，并且因为网络上的每一条机器都是使用同一个总账，所有的这些交易和信息都会进入遍布全网的每一份总账拷贝。当区块链更新并在全网同步之后，所有的在之前的10分钟内进入区块链的交易也被更新并同步了。因此分散的交易记录是在所有的参与者之间进行对账和同步的。 最后，在个人向网络输入一笔交易的时候，他们使用内嵌在比特币客户端的标准公钥加密工具来同时他们的私钥以及接收者的公钥来为这笔交易签名。这对应于拜占庭将军问题中他们用来签名和验证消息时使用的“印章”。因此，哈希计算速率的限制，加上公钥加密，使得一个不可信网络变成了一个可信的网络，使得所有参与者可以在某些事情上达成一致（比如说攻击时间、或者一系列的交易、域名记录、政治投票系统、或者任何其他的需要分布式协议的地方）。 这里是比特币为何如此特别的关键：它代表了一个对于一个困难的算法上的难题的解决方案，这一解决方案在一系列的历史事件发生之前是不可能的，这些事件有： 互联网的创造 公钥加密算法的发明 点对点Bitorrent(BT)协议的发明。BT协议最开始是开发来用于在网络上的相对小的用户子集之间共享许多文件的，但比特币用它来在所有用户之间共享单个文件。 人们意识到，在系统中添加一个简单的时间延迟，同时使用公钥加密算法以验证每笔交易，可以解决这个问题。 如果说一些最棒的想法在事后看来是很简单的，那么上述的第四点就完全符合条件，尽管整个项目是站在了巨人的肩膀上的。 最后，这一对于拜占庭将军问题的解决方案，可以推广到任何核心问题是在分布式网络上缺乏信任的领域。如我们已经提到乐的，人们正在为互联网建设一个分布式的域名系统，以及为政治选举建设分布式的投票系统（还没有网站）。如果人们认为单纯的文件分享搅乱了这个世界，那么比特币解决方案和协议才刚刚打开洪水的闸门。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>拜占庭将军问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[队列的链式存储结构]]></title>
    <url>%2F2018%2F09%2F04%2F%E9%98%9F%E5%88%97%E7%9A%84%E9%93%BE%E5%BC%8F%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[队列的链式存储结构，其实就是线性表的单链表，只不过它只能尾进头出而已，我们把它简称为链队列。 为了操作上的方便，我们将队头指针指向链队列的头结点，而队尾指针指向终端结点。链队列示意图： 当队列为空时，front和rear都指向头结点 实例代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package mainimport ( "errors" "fmt")type qelemType int//数据节点(链表形式)type QNode struct &#123; data qelemType next *QNode&#125;type queuePtr *QNode//定义队列type LinkQueue struct &#123; front, rear queuePtr&#125;//创建头结点func createHeadNode(q *LinkQueue) &#123; s := queuePtr(new(QNode)) s.next = nil q.front = s q.rear = s&#125;//如队列操作func enQueue(q *LinkQueue, e qelemType) &#123; s := queuePtr(new(QNode)) s.data = e s.next = nil //队尾为空 q.rear.next = s q.rear = s //rear指向新添加的数据（保证指向最后一个元素）&#125;//出队列func deQueue(q *LinkQueue) (err error, res qelemType) &#123; if q.front == q.rear &#123; err = errors.New("队列为空，没有数据出队列") return &#125; s := q.front.next res = s.data q.front.next = s.next if q.rear == s &#123; q.rear = q.front &#125; return&#125;func main() &#123; var p LinkQueue /* 注意 需要创建头结点，不然头结点为空，操作它的.next 会发生异常,异常信息如下： panic: runtime error: invalid memory address or nil pointer dereference [signal 0xc0000005 code=0x0 addr=0x0 pc=0x48b5c9] */ createHeadNode(&amp;p) enQueue(&amp;p, qelemType(123)) enQueue(&amp;p, qelemType(345)) enQueue(&amp;p, qelemType(567)) _, res := deQueue(&amp;p) fmt.Println(res) _, res = deQueue(&amp;p) fmt.Println(res) _, res = deQueue(&amp;p) fmt.Println(res) err, res := deQueue(&amp;p) fmt.Println(err, res)&#125; 运行效果：]]></content>
      <categories>
        <category>数据结构和算法</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>单链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go语言之陷阱for range]]></title>
    <url>%2F2018%2F09%2F04%2Fgo%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%99%B7%E9%98%B1for-range%2F</url>
    <content type="text"><![CDATA[在go语言中，遍历有两种方法，一种就是for的普通方法，还有一种就是for range的遍历，但是在使用for range时，如果使用不当，就会出现一些问题比如我们下面先来看一个例题 123456789101112131415161718192021package mainimport "fmt"type Student struct&#123; Name string Age int&#125; //一个学生结构体func main()&#123; m:=make(map[string]*Student) //声明一个映射 stus:=[]Student&#123; &#123;"宋",22&#125;, &#123;"高",23&#125;, &#123;"徐",24&#125;, &#123;"李",25&#125;, &#125; //一个学生类切片 for _,stu:=range stus&#123; m[stu.Name]=&amp;stu //遍历赋值给映射 &#125; for _,value:=range m&#123; fmt.Println(*value) //遍历打印出来 &#125;&#125; 我们的代码是把stus这个结构体切片里面的内容用for range赋值给m映射，看起来代码好像没什么问题，一次循环赋值一次循环打印，那我们来看一下打印结果是什么 打印结果竟然是这样，为什么都是一样的呢，而且是结构体切片最后的一个元素，看下面这张图 这是因为我们第一次使用for range遍历的时候 我们是使用零时变量stu的地址来传给m的，而且零时变量stu每次的地址都是不会变的，所以一直到遍历最后一次就会把最后一个值的地址传给m，这就导致了m里面的值都是一样，我们可以试着来打印一下地址来看看 我们先来打印一下m看看 看到没，这四个地址竟然都是一样的，这就是因为用stu零时变量去地址去传的话地址都是一样的，那样传值就达不到预期的效果，所以一定要小心这个陷阱，那我们上面应该怎样改就可以完整的传值呢 看到没，我们可以在for range里面弄一个stu1来接受零时变量stu的值，然后取stu1的地址传值，这样就不会出错啦，我们来看看打印结果 这样我们每次的地址也不一样了，打印出来的结果也就正确达到预期的结果了，因为map是无序的所以打印出来也是无序的，切忌用for range的时候小心陷阱]]></content>
      <categories>
        <category>GO语言</category>
      </categories>
      <tags>
        <tag>go语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go语言错误捕获和panic异常]]></title>
    <url>%2F2018%2F09%2F04%2Fgo%E8%AF%AD%E8%A8%80%E9%94%99%E8%AF%AF%E6%8D%95%E8%8E%B7%E5%92%8Cpanic%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[在Go语言中我们首先来看一下err错误信息，我们先来看一段代码 123456789101112131415161718192021222324252627package mainimport ( "fmt" "errors")func calc(a int, b int) (v int, err error) &#123; //捕获错误信息 if b == 0 &#123; //如果代码中出现错误 可以使用errors.New()创建错误信息 err = errors.New("除数不能为0") return &#125; v = a / b return&#125;func main() &#123; a := 10 b := 0 v, err := calc(a, b) //根据错误信息进行处理 if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Println(v) &#125; //fmt.Println(v)&#125; 在这里我们可以接收到错误信息并打印出来，我们先看一下会报错吗？结果显示部会报错的，因为我们接收到了错误并打印出来了 我们看这里并没有报错，而是打印出了错误 信息， 在Go中我们还可以直接调用panic函数来终止程序， 我们来看这张图，这张图里面我们给数组定义为10个长度，然后下面直接调用下标为10的数组，这样会出什么错误呢，这样就是数组下标超出范围，因为数组下标是从0开始到长度减一，我们来看一下编译器运行的结果报什么错， 编译提示panic异常，然后提示数组下标越界，这是因为当我们写程序时，比如遇到一些错误比如：数组下标越界，空指针异常，野指针这些错误的时候，系统就会调用自己本身的panic函数，那么我们自己在写程序的时候也是可以调用panic函数的，下面来看这段代码 12345678910111213package mainimport "fmt"func main() &#123; fmt.Println("hello world1") fmt.Println("hello world2") fmt.Println("hello world3") //程序可以运行 但是遇到panic停止 //当程序遇到panic时 会自动崩溃 panic("终止程序") fmt.Println("hello world4") fmt.Println("hello world5") fmt.Println("hello world6")&#125; 我们来看一下运行结果 在这里我们看到，只打印了上面的三句话，当遇到panic函数的时候就会程序崩溃，然后下面的程序停止执行，我们不仅仅可以使用panic来终止程序，我们还可以捕获错误后继续执行程序，我们来看下一段代码 12345678910111213141516171819202122package mainimport "fmt"func test(i int) &#123; var arr [10]int //优先使用错误拦截 在错误出现之前进行拦截 在错误出现后进行错误捕获 //错误拦截必须配合defer使用 通过匿名函数使用 defer func() &#123; //恢复程序的控制权 err := recover() if err != nil &#123; fmt.Println(err) &#125; &#125;() arr[i] = 123 //err panic fmt.Println(arr)&#125;func main() &#123; i := 10 test(i) fmt.Println("hello world")&#125; 看这段代码，然后我们来看一下运行结果 第一句话直接打印出了错误：运行时错误，数组下标越界，但是程序并没有终止而是继续运行下去了这是为什么了， 如图所示，这里我们延迟调用了一下，因为recover必须和defer配合使用，并且调用一定要在错误出现之前调用才有效果，这样捕获到了错误并且恢复了程序的控制权。]]></content>
      <categories>
        <category>GO语言</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>错误捕获</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go语言切片深入讲解]]></title>
    <url>%2F2018%2F09%2F03%2Fgo%E8%AF%AD%E8%A8%80%E5%88%87%E7%89%87%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[我们在上一篇的切片讲解中，我们讲解到在go语言中 map和切片都是传引用（地址），也就是在调用函数的时候都是可以直接修改变量的值，关于切片，在某种程度上表面上来说也是可以这样说的，我们先来看一下一个小小的例题 1234567891011package mainimport &quot;fmt&quot;func Change(s []int)&#123; s[0]=11 s[1]=22&#125;func main()&#123; slice:=[]int&#123;1,2,3,4,5&#125; Change(slice) fmt.Println(slice)&#125; 我们先来看一下结果 我们可以看到切片当作函数参数的时候调用之后值确实改变了，这也间接的可以认为切片是地址传递，但是我们想要了解的更深入的话可以继续了解下去 我们继续来看一个小例子 123456789101112package mainimport "fmt"func Add(s []int)&#123; s=append(s,6,7,8)&#125;func main()&#123; slice:=[]int&#123;1,2,3,4,5&#125; Add(slice) fmt.Println(slice)&#125; 在这里函数调用了append这个函数来增加切片的个数， 我们可以清晰的看到打印的结果并没有变，我们在之前讲到过这里是因为append扩容使得地址发生了变化，所以不是指向原来的切片也就导致了并不是在原来的切片上面增加了，这就说到了切片的本质，在这里详细说一下，切片的本质不是指向数组的指针，而是一种新定义的一种数据结构，这个数据结构里面包含一个指针，len，还有cap， 12345type slice struct &#123; *Pointer len cap &#125; 看到没，切片的本质是这样一个数据结构，而且在函数调用的时候切片做的其实是一个值的传递！！！只不过这个值是一个包含指针，长度，容量的一个结构体的值，这样我们一想就可以一目了然的知道了为什么前面我们所说的切片是地址传递了吧，那是因为他传的那个值里面包含一个指针，所以函数调用的时候就可以用这个值里面的指针来操作原来的切片，我们看如下的一张图片， 我们看上面的图就可以更加的明白了，在函数调用的时候首先，在栈区里面main函数会得到一块内存（栈帧），然后调用testFunc函数的时候testFunc也会得到一块内存（栈帧），然后调用的时候把切片的值传递给形参，注意这里的值是包含一个指针，长度，容量的结构体值，我们在使用一般操作的时候不会改变那个地址，所以会正常操作main函数里面的切片，当我们使用append函数的时候就会导致保存的指针值发生变化，那样就会保存一个新的地址，操作也会在新的地方操作，这样的话原来的切片就不会发生变化，当testFunc函数调用完毕后，我们的testFunc函数就会释放，而原来的切片也没有得到改变，这就是我们所看到的，这才是切片的本质 所以最后得到的总结就是：切片当作参数传递的时候是值传递，但是这个值不是一个普通的值，而是一个包含指针，长度，容量的值，如果有不懂的也可以尝试着去看一看源码。 附图：（内存的微讲解）]]></content>
      <categories>
        <category>GO语言</category>
      </categories>
      <tags>
        <tag>go语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go语言切片微讲解]]></title>
    <url>%2F2018%2F09%2F03%2Fgo%E8%AF%AD%E8%A8%80%E5%88%87%E7%89%87%E5%BE%AE%E8%AE%B2%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[传递参数时分为值传递和地址传递，go语言中切片和map是地址传递，但是切片传递要有一个注意事项 例如： 123456789package mainfunc test(a []int)&#123; a=append(a,1,2,3)&#125;func main()&#123; var s []int=[]int&#123;89,4,5,6&#125; test(s) fmt.Println(s)&#125; 在这里里面为什么调用函数后切片没有变化呢，切片不是地址传递吗？这是因为在test函数里面用了append()函数,在调用函数时，在栈区里面把1 2 3 添加到a里面然后重新分配了地址，而原来的s切片还是指向原来地址，根本没有变，所以在main函数里面打印出s还是原来的，不会改变，那么如何做到用了append后改变原来切片的值呢 如下 1234567891011package mainimport "fmt"func test(a []int)(b []int)&#123; b=append(a,1,2,3,7) return&#125;func main()&#123; var s []int=[]int&#123;9,10&#125; s=test(s) fmt.Println(s)&#125; 我们可以用return 把改变后的地址传回去这样就可以了 切片用append函数的时候一定要注意，因为如果容量不足的时候会自动扩充，如果原来的地址后面没有足够的空间那么就会重新找一个足够大的空间来储存，所以切片利用append的时候地址是有可能变化的。]]></content>
      <categories>
        <category>GO语言</category>
      </categories>
      <tags>
        <tag>go语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[插入排序]]></title>
    <url>%2F2018%2F09%2F02%2F%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[插入排序在上一章中我们讲了算法排序中的最简单的冒泡排序，今天我们来讲解一下插入排序，后续将讲解快速排序，归并排序，希尔排序，二叉排序，这些等等，后续的排序都是在时间复杂度和空间复杂度上面优于这两种的，所以我们今天先来讲解一下插入排序 我们先来看以下的一张图 为了方便排序，我们一般将数据的第一个元素作为有序组，其他视为待插入组，图中以升序为例子进行讲解。 我们将第一个元素作为有序的数组，然后将后面的元素视为无序的，将后面的无序组第一个元素和有序组最后一个元素比较，如果符合要求就插入进去然后有序组就多一个，无序组就少一个 第二次排序的时候有序组就为两个元素，有序组的最后一个元素拿出来继续和无序组的第一个相比，然后再插入一个，这样有序组就又多了一个，无序组少一个 这样一直循环到某个条件，这样无序组就没有了，剩下的都是有序组，这样排序就完成了。 我们来看一下代码怎样实现，在这里我们就用GO语言来实现，在某些方面个人觉得go写的代码比C/C++要少很多，更加方便一点 12345678910111213141516package mainimport "fmt"func main() &#123; var arr [10]int = [10]int&#123;9, 1, 3, 4, 7, 5, 2, 10, 11, 8&#125; //插入排序 var temp ,j int //临时变量temp for i := 1; i &lt; len(arr); i++ &#123; //遍历无序数组,下标1开始 if arr[i] &lt; arr[i-1] &#123; //无序组第一个小于有序组最后一个才进入否则直接下一个元素 temp=arr[i] //用变量temp取出arr[i]的元素值 for j=i-1;j&gt;=0&amp;&amp;arr[j]&gt;temp;j--&#123; //这里面temp不能写成arr[i]是因为下面 arr[j+1]=arr[j] // 有一个arr[j+1]=arr[j]那样会导致arr[i]会变 &#125; arr[j+1]=temp //因为上面经过了j--所以这里需要arr[j+1]，for循环后就找到位置填充temp，也就是之前取出来的arr[i] &#125; &#125; fmt.Println(arr)&#125; 下面你可以自己去实现一下了，后续将讲解更难的排序方法。]]></content>
      <categories>
        <category>数据结构和算法</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>排序问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode|无重复字符的最长子串]]></title>
    <url>%2F2018%2F09%2F02%2F%E6%AF%8F%E6%97%A5%E4%B8%80%E9%81%93%E7%BC%96%E7%A8%8B%E7%AE%97%E6%B3%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[今天的题目为： 给定一个字符串，找出不含有重复字符的最长子串的长度。 示例 1: 123输入: &quot;abcabcbb&quot;输出: 3 解释: 无重复字符的最长子串是 &quot;abc&quot;，其长度为 3。 示例 2: 123输入: &quot;bbbbb&quot;输出: 1解释: 无重复字符的最长子串是 &quot;b&quot;，其长度为 1。 示例 3: 1234输入: "pwwkew"输出: 3解释: 无重复字符的最长子串是 "wke"，其长度为 3。 请注意，答案必须是一个子串，"pwke" 是一个子序列 而不是子串。 首先来思路分析：我们可以先第一次把所有不重复的字符串分割一下保存下来，这样就可以找到这一次的不重复的子字符串最长的 然后在一次一次往后面移动，这样就可以找出所有不重复的子字符串，最后再求出最大值。 比如： abcd ahjiklo字符串 我们第一次从头开始寻找，找到不重复的子字符串，那就有两个，一个为abcd另外一个为ahjiklo,如果单单重上面看那么最长的不重复子字符串就是ahjiklo，但是我们需要的不是这个，那么我们就需要再循环一次，每次把第一个字符去掉然后再寻找，比如这一次把a去掉那么找出的最长子字符串就是bcdahjiklo，这个是最长的，然后再把本次的第一个字符去掉一直循环，这样到最后找出最长的子字符串， 复杂度分析：当然，这种方法可以算是一种暴力解决的方法，没有什么技巧性，时间复杂度也是最复杂的，O（n3）的复杂度，当然如果想要优化的话可以自己去研究一下奥。 代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344package mainimport "fmt"func lengthOfLongestSubstring(str string) int &#123; //每次求出的最大值返回 s:=[]byte(str) //先把字符串转为byte类型的切片 slice:=make([]string,0)//ased//aerfch//risdud //定义一个字符串切片，可以把无重复的字符串字段保存进去flag: for i:=0;i&lt;len(s);i++&#123; for j:=i-1;j&gt;=0;j--&#123; if s[i]==s[j]&#123; //这里遍历用来找出无重复字符串段 slice=append(slice,string(s[:i])) //把无重复字符段放切片里面去 s=s[i:] //切片往后移 goto flag; //在新切片里面再次循环直到找出无重复字符段放进字符串切片里面 &#125; &#125; &#125; slice=append(slice,string(s)) //把最后一个放进切片，如果整个字符串都没有重复那么就这一个 //fmt.Println(slice) max:=len(slice[0]) for k:=0;k&lt;len(slice);k++&#123; //循环找出这一次的最大值 if len(slice[k])&gt;max&#123; max=len(slice[k]) &#125; &#125; return max //返回本次最大值&#125;func main()&#123; var str string fmt.Printf("请输入一个字符串\n") fmt.Scanf("%s",&amp;str) var max int for i:=len(str);i&gt;0;i--&#123; tmp:=lengthOfLongestSubstring(str) //每求一次最大值往后退一次，确保能得到真正的最大值 if tmp&gt;max&#123; max=tmp &#125; str=str[1:] //每次用切片割掉第一个元素 &#125; fmt.Println(max) //输出最大值，这里也可以输出最长的子字符串&#125; 这样就可以求出来了，如果想要优化的伙伴可以自己去稍加研究。]]></content>
      <categories>
        <category>数据结构和算法</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>编程题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一条简单区块链的实现]]></title>
    <url>%2F2018%2F09%2F02%2F%E4%B8%80%E6%9D%A1%E7%AE%80%E5%8D%95%E5%8C%BA%E5%9D%97%E9%93%BE%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[在上一章中我们讲解了一个简单的区块创建，那么我们今天来讲解一下一条简单区块链的实现 思路分析： 创建一个创世块，就是区块链的头 //上一章节中讲解了如果实现一个区块的简单实现 定义一个结构体，用来保存区块链中的区块，结构体里面的元素可以就是那条链 用方法来实现区块的添加，每次调用方法都加进相应的区块 第一步实现 1234567type Block struct &#123; //创建一个区块的结构体 Time int64 //时间戳 Data []byte //数据信息 PreviousHash []byte //前一个哈希值 Hash []byte //当前的哈希&#125; 第二步实现 123type Blockchain struct&#123; //创建一个区块链类型 blocks []*Block //一系列区块储存，这里用切片来保存&#125; 第三步实现 123456789101112func (blockchain *Blockchain)Addblock(data string)&#123; //添加区块的方法 newblock:=Block&#123;&#125; //一个新区块 newblock.Data=[]byte(data) //初始化数据 newblock.PreviousHash=blockchain.blocks[len(blockchain.blocks)-1].Hash //得到前一个区块的哈希 newblock.Sethash() //得到哈希 blockchain.blocks=append(blockchain.blocks,&amp;newblock) //新区块添加到这条链当中&#125;func Newblockchain()*Blockchain&#123; // 创建一条新的区块链 blos:=Blockchain&#123;[]*Block&#123;Firstblock()&#125;&#125; //初始化 return &amp;blos&#125; 这样新的区块链就完成的差不多了，加上上一章的简单实现区块链的代码就已经实现了，下面我们整理一下将得到如下的代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package mainimport ( "time" "strconv" "bytes" "crypto/sha256" "fmt")/*一个简单的区块链创建*/type Block struct &#123; //创建一个区块的结构体 Time int64 //时间戳 Data []byte //数据信息 PreviousHash []byte //前一个哈希值 Hash []byte //当前的哈希&#125;type Blockchain struct&#123; //创建一个区块链类型 blocks []*Block //一系列区块储存，这里用切片来保存&#125;func (blockchain *Blockchain)Addblock(data string)&#123; //添加区块的方法 newblock:=Block&#123;&#125; //一个新区块 newblock.Data=[]byte(data) //初始化数据 newblock.PreviousHash=blockchain.blocks[len(blockchain.blocks)-1].Hash //得到前一个区块的哈希 newblock.Sethash() //得到哈希 blockchain.blocks=append(blockchain.blocks,&amp;newblock) //新区块添加到这条链当中&#125;func Newblockchain()*Blockchain&#123; // 创建一条新的区块链 blos:=Blockchain&#123;[]*Block&#123;Firstblock()&#125;&#125; //初始化 return &amp;blos&#125;func Firstblock()*Block&#123; firstblock:=Newblock("firstblock",[]byte&#123;&#125;) return firstblock&#125;func (block *Block)Sethash()&#123; timer:=[]byte(strconv.FormatInt(block.Time,10)) herds:=bytes.Join([][]byte&#123;timer,[]byte(block.Data),block.PreviousHash&#125;,[]byte&#123;&#125;) hash:=sha256.Sum256(herds) block.Hash=hash[:]&#125;func Newblock(data string,prevhash []byte)*Block&#123; block:=Block&#123;&#125; block.Time=time.Now().Unix() block.Data=[]byte(data) block.PreviousHash=prevhash block.Sethash() return &amp;block&#125;func main() &#123; //创建一个区块链 blocks:=Newblockchain() blocks.Addblock("seng one BTC to sary") //信息（数据）为seng one BTC to sary 添加到区块链中 blocks.Addblock("send two ETH to wuman")//信息（数据）为send two ETH to wuman 添加到区块链中 blocks.Addblock("send one ADA to zijian")//信息（数据）为send one ADA to zijian 添加到区块链中 for _,v:=range blocks.blocks&#123; //循环遍历打印一下看结果 fmt.Println("=======================================") fmt.Printf("data=:%s\n",v.Data) fmt.Printf("prevhash:=%x\n",v.PreviousHash) fmt.Printf("hash:=%x\n",v.Hash) &#125;&#125; 我们来看一下结果：]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个简单区块的实现]]></title>
    <url>%2F2018%2F09%2F01%2F%E5%8C%BA%E5%9D%97%E9%93%BE%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B01%2F</url>
    <content type="text"><![CDATA[简单区块实现区块链技术如今已经越来越成熟，但是我们怎么深入到本质用技术的眼光来看待区块链技术，见名知意，区块链的意思就是用链条把区块链接起来，那我们先用代码来看一下，今天我们用go语言来简单的实现一个区块并打印。 我们可以先来理一下思路，我们想要实现一个区块该怎么办，思路理好然后再来代码一步一步实现 创建一个结构体来保存一个区块的信息 //大概包括时间戳，数据，前哈希，本哈希这几个数据 创建第一个区块并给其中的数据赋值，也就相当于一个创世块，注意这里创世块的前哈希传一个空值就可以 给这个区块的数据处理一下然后加密得到本区块的哈希 主函数里面打印看一下本区块的哈希 //哈希用16进制打印 大概这样思路就可以理顺了，然后我们就可以一步一步实现了 1：第一步创建一个区块结构体 1234567type Block struct &#123; //创建一个区块结构体 Timer int64 //时间戳 Data []byte //数据 prevHash []byte //前一个区块的哈希值 Hash []byte //本区块的哈希值&#125; 区块结构体创建完成，继续下一步 2：创建第一个区块 1234func Firstblosk() *Block &#123; //创建第一个区块信息，相当于一个创始块 firstblock := NewBlock("This is firstblock", []byte&#123;&#125;) //传入参数，返回结构体指针类型 return firstblock //返回的是结构体指针类型&#125; 123456789func NewBlock(data string, prevhash []byte) *Block &#123; //创建区块的函数 block1 := Block&#123;&#125; //创建一个区块结构体 block1.Timer = time.Now().Unix() //得到时间 block1.Data = []byte(data) //传入数据参数 block1.prevHash = prevhash //前一个哈希值为传入的数据 block1.setHash() //setHash 方法加密得到自己的hash return &amp;block1 //返回区块指针&#125; 用来创建第一个区块 3：给区块信息数据处理 123456func (block *Block) setHash() &#123; time := []byte(strconv.FormatInt(block.Timer, 10)) //将区块的时间转为字符切片类型，方便加密 heards := bytes.Join([][]byte&#123;time, block.Data, block.prevHash&#125;, []byte&#123;&#125;) //将时间，数据，前一个哈希拼接一下 hash := sha256.Sum256(heards) //用sha256包的Sum256函数加密 block.Hash = hash[:] //加密后的直接赋值给本哈希&#125; 4:主函数里面打印看一下本区块的哈希 //哈希用16进制打印 12345func main() &#123; firstblock := Firstblosk() fmt.Printf("%x",string(firstblock.Hash)) //16进制打印&#125; 这样一个简单的区块就创建成功了，我们把所有代码连接起来然后来看一下打印结果 123456789101112131415161718192021222324252627282930313233343536373839404142package main/*一个简单的区块创建实现*/import ( "time" "strconv" "bytes" "crypto/sha256" "fmt")type Block struct &#123; //创建一个区块结构体 Timer int64 //时间戳 Data []byte //数据 prevHash []byte //前一个区块的哈希值 Hash []byte //本区块的哈希值&#125;func (block *Block) setHash() &#123; time := []byte(strconv.FormatInt(block.Timer, 10)) //将区块的时间转为字符切片类型，方便加密 heards := bytes.Join([][]byte&#123;time, block.Data, block.prevHash&#125;, []byte&#123;&#125;) //将时间，数据，前一个哈希拼接一下 hash := sha256.Sum256(heards) //用sha256包的Sum256函数加密 block.Hash = hash[:] //加密后的直接赋值给本哈希&#125;func Firstblosk() *Block &#123; //创建第一个区块信息，相当于一个创始块 firstblock := NewBlock("This is firstblock", []byte&#123;&#125;) //传入参数，返回结构体指针类型 return firstblock //返回的是结构体指针类型&#125;func NewBlock(data string, prevhash []byte) *Block &#123; //创建区块的函数 block1 := Block&#123;&#125; //创建一个区块结构体 block1.Timer = time.Now().Unix() //得到时间 block1.Data = []byte(data) //传入数据参数 block1.prevHash = prevhash //前一个哈希值为传入的数据 block1.setHash() //setHash 方法加密得到自己的hash return &amp;block1 //返回区块指针&#125;func main() &#123; firstblock := Firstblosk() fmt.Printf("%x",string(firstblock.Hash)) //16进制打印&#125; 我们来看一下哈希打印结果 这样一个简单的区块就实现了，那么如果要实现一个简单的区块链呢？其实也按照这样的思路写下去也很容易实现，记住：区块链的本区块的哈希是下一个区块的前哈希，这样链接，下一章我们将讲解一个简单的区块链实现。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo+github博客搭建]]></title>
    <url>%2F2018%2F09%2F01%2F%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA1%2F</url>
    <content type="text"><![CDATA[技术小白搭建个人博客 github+hexo本文主要讲解博客的搭建过程，next主题优化，next配置文件详解等。 不做过多介绍了，快速开始 准备安装软件依次安装 1、Node.js 2、Git 注册github访问https://github.com/ 右上角signup uername 最好都用小写，因为最后建立的博客地址是：http://username.github.io；邮箱十分重要，GitHub 上很多通知都是通过邮箱的。 创建Repository Repository 名字应该是http://username.github.io。比如我的username 就是wumansgy 其他的可以选择添加一些描述也可以选择默认什么也不添加 ，点击creat repository 配置和使用Github开始–所有应用–找到git bash 配置SSH keysssh keys就是用来使本地git 项目与github联系 1. 检查SSH keys的设置首先要检查自己电脑上现有的 SSH key： 1$ cd ~/. ssh 如果显示“No such file or directory”，说明这是你第一次使用 git 2、生成新的 SSH Key：123$ ssh-keygen -t rsa -C &quot;邮件地址@youremail.com&quot;Generating public/private rsa key pair.Enter file in which to save the key (/Users/your_user_directory/.ssh/id_rsa):&lt;回车就好&gt; 【提示1】这里的邮箱地址，输入注册 Github 的邮箱地址； 【提示2】「-C」的是大写的「C」 然后系统会要你输入密码： 12Enter passphrase (empty for no passphrase):&lt;设置密码&gt;Enter same passphrase again:&lt;再次输入密码&gt; 在回车中会提示你输入一个密码，这个密码会在你提交项目时使用，如果为空的话提交项目时则不用输入。这个设置是防止别人往你的项目里提交内容。 注意：输入密码的时候没有输入痕迹的，不要以为什么也没有输入。 最后看到这样的界面，就成功设置ssh key了： 3、添加SSH Key到GitHub在本地文件夹找到id_rsa.pub文件，看上面的图片第四行的位置告诉你存在哪里了 没找到的勾选一下文件扩展名 隐藏的项目 .ssh文件夹里记事本打开这个文件复制全部内容到 github相应位置。不要着急…（记得期末考试复习概率论看汤家凤老师的视频时老师的口头禅…） 你的github主页 点击头像后边的箭头（为什么我每次想要上传头像都没反应呢？希望有知道的小伙伴能看到告诉我一下） Title最好写，随便写。网上有说不写title也有可能后期出现乱七八糟的错误 Key部分就是放刚才复制的内容啦 点击Add SSH key 测试git bash 里 输入以下代码 不要改任何一个字 我就是自作聪明以为代表的是自己注册时候的邮箱然后… 1$ ssh -T git@github.com 如果得到以下反馈 123The authenticity of host &apos;GitHub.com (207.97.227.239)&apos; can&apos;t be established.RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.Are you sure you want to continue connecting (yes/no) 输入yes回车 1Enter passphrase for key &apos;/c/Users/lenovo/.ssh/id_rsa&apos;: 输入刚才设置的密码回车 设置用户信息现在已经可以通过 SSH 链接到 GitHub 啦!当然还需要完善一些个人信息: 12$ git config --global user.name &quot;wuyalan&quot;//输入注册时的username$ git config --global user.email &quot;alan.wyl@foxmail.com&quot;//填写注册邮箱 GitHub 也是用这些信息来做权限的处理，输入下面的代码进行个人信息的设置，把名称和邮箱替换成你自己的，名字必须是你的真名，而不是GitHub的昵称。 SSH Key配置成功本机已成功连接到 github。 如有问题，请重新设置。常见错误请参考： 错误1 错误2 搭建hexo博客利用npm命令安装hexo 12$ cd$ npm install -g hexo 1. 创建独立博客项目文件夹 安装完成后，关掉前面那个 Git Bash 窗口。在本地创建一个与 Repository 中博客项目同名的文件夹（如E:[http://username.github.io]）在文件夹上点击鼠标右键，选择 Git bash here； 【提示】在进行博客搭建工作时，每次使用命令都要在 H:[http://username.github.io] 目录下。 执行下面的指令，Hexo 就会自动在 H:[http://username.github.io]文件夹建立独立博客所需要的所有文件啦！ 1$ hexo init 2. 安装依赖包 1$ npm install 3. 确保git部署 1$ npm install hexo-deployer-git --save 4.本地查看 现在已经搭建好本地的 Hexo 博客了，执行完下面的命令就可以到浏览器输入 localhost:4000 查看到啦 12$ hexo g$ hexo s hexo g 每次进行相应改动都要hexo g 生成一下 hexo s 启动服务预览 5. 用Hexo克隆主题 执行完 hexo init 命令后会给一个默认的主题：landscape 你可以到官网找你喜欢的主题进行下载 hexo themes 知乎：有哪些好看的 Hexo 主题？ 找到它所在的 Github Repository （怎么找，我喜欢的那个，恰好博主放了他的github地址，emmm） 找到之后通过git命令下载 在主题的repository点击clone 复制一下那个地址 1$ git clone +复制的地址+themes/archer 后面就是clone之后放到你本地的博客文件夹themes文件夹下 名字纹archer的文件 我下载的是archer主题~（有喜欢同样的小伙伴在个性化自己主题的时候欢迎来交流一下呀~真的是技术小白~还没研究清楚要怎么改，不过主题作者也会在readme说明的，细心看就是） 6. 修改整站配置文件 自己把 http://blog.io 中文件都点开看一遍，主要配置文件是 _config.yml ，可以用记事本打开，推荐使用 sublime 或者nodepad++打开。 修订清单如下，文档内有详细注释，可按注释逐个修订 博客名字及作者信息：_config.yml 个人介绍页面：about.md 代表作页面：milestone.md 博客参考 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889这里贴一份网上看到的 可以复制替换原来的 但是替换之前最好备份 可能会出错那要么你就对照着看一下改就好# Hexo Configuration## Docs: http://zespia.tw/hexo/docs/configure.html## Source: https://github.com/tommy351/hexo/# Site 这里的配置，哪项配置反映在哪里，可以参考我的博客title: My Blog #博客名subtitle: to be continued... #副标题description: My blog #给搜索引擎看的，对网站的描述，可以自定义author: Yourname #作者，在博客底部可以看到email: yourname@yourmail.com #你的联系邮箱language: zh-CN #中文。如果不填则默认英文# URL #这项暂不配置，绑定域名后，欲创建sitemap.xml需要配置该项## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and root as &apos;/child/&apos;url: http://yoursite.comroot: /permalink: :year/:month/:day/:title/tag_dir: tagsarchive_dir: archivescategory_dir: categories# Writing 文章布局、写作格式的定义，不修改new_post_name: :title.md # File name of new postsdefault_layout: postauto_spacing: false # Add spaces between asian characters and western characterstitlecase: false # Transform title into titlecasemax_open_file: 100filename_case: 0highlight: enable: true backtick_code_block: true line_number: true tab_replace:# Category &amp; Tagdefault_category: uncategorizedcategory_map:tag_map:# Archives 默认值为2，这里都修改为1，相应页面就只会列出标题，而非全文## 2: Enable pagination## 1: Disable pagination## 0: Fully Disablearchive: 1category: 1tag: 1# Server 不修改## Hexo uses Connect as a server## You can customize the logger format as defined in## http://www.senchalabs.org/connect/logger.htmlport: 4000logger: falselogger_format:# Date / Time format 日期格式，可以修改成自己喜欢的格式## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-M-Dtime_format: H:mm:ss# Pagination 每页显示文章数，可以自定义，贴主设置的是10## Set per_page to 0 to disable paginationper_page: 10pagination_dir: page# Disqus Disqus插件，我们会替换成“多说”，不修改disqus_shortname:# Extensions 这里配置站点所用主题和插件，暂时默认## Plugins: https://github.com/tommy351/hexo/wiki/Plugins## Themes: https://github.com/tommy351/hexo/wiki/Themestheme: landscapeexclude_generator:plugins:- hexo-generator-feed- hexo-generator-sitemap# Deployment 站点部署到github要配置## Docs: http://zespia.tw/hexo/docs/deploy.htmldeploy: type: git repository: branch: master 7. 启用新下载的主题 在刚打开的的_config.yml 文件中，找到“# Extensions”，把默认主题 landscape 修改为刚刚下载下来的主题名： 【提示】http://username.github.io 里有两个 config.yml 文件，一个在根目录，一个在 theme 下，现在修改的是在根目录下的。 8. 更新主题 git bash 里执行 12$ cd themes/主题名$ git pull 9. 本地查看调试 每次修改都要hexo g 生成一下 12$ hexo g #生成$ hexo s #启动本地服务，进行文章预览调试，退出服务用Ctrl+c 浏览器输入 localhost：4000 预览效果 将博客部署到http://username.github.io1. 复制SSH码进入 Github 个人主页中的 Repository，复制新建的独立博客项目:http://username.github.io 的 SSH 码 2. 编辑整站配置文件打开 H:\username.github.io_config.yml,把刚刚复制的 SSH 码粘贴到“repository：”后面，别忘了冒号后要空一格。 1234deploy: type: git repository: git@github.com:username/username.github.io.git branch: master 3. 执行下列指令即可完成部署。【提示】每次修改本地文件后，需要 hexo g 才能保存。每次使用命令时，都要在你的博客文件夹目录下 12$ hexo g$ hexo d （ps：我在第一次hexo d 的时候出现了错误，具体错误提示忘了，原因是我没有deploy 的权限 在repository的setting （这里我有一点小疑惑 为什么delete不了这个公钥呢，我想要delete是因为第一次设置时没有勾选 ..如下 emm里面的内容就是重复配置SSH key的步骤，记得勾选这个小框框，我就是没有勾选设置之后还是没有deploy成功 ） 因为我看到的教程里大多数没有讲这一部分，所以我也不确定这一步是否必须，如果有遇到相同问题的小伙伴可以参考 ） 【提示】如果在配置 SSH key 时设置了密码，执行 hexo d 命令上传文件时需要输入密码进行确认，会出现一个小框框。 输入密码之后在浏览器输入： username.github.io 如果得到你想要的效果，那么恭喜你，博客已经搭建好啦！ 允许你偷偷激动一下…哈哈哈 之后就是写博文了，我还没开始…要好好写博客好好写博客 你看技术大神们哪个没有自己的优秀博客。 不懂技术的小伙伴也可以在自己的小天地写文，很爽又很有逼格是不是~ 我的博客地址：进入 next主题使用及优化启用主题与所有 Hexo 主题启用的模式一样。 当 克隆/下载 完成后，打开 站点配置文件， 找到 theme 字段，并将其值更改为 next。 启用 NexT 主题 1theme: next 到此，NexT 主题安装完成。下一步我们将验证主题是否正确启用。在切换主题之后、验证之前， 我们最好使用 hexo clean 来清除 Hexo 的缓存。 选择 SchemeScheme 是 NexT 提供的一种特性，借助于 Scheme，NexT 为你提供多种不同的外观。同时，几乎所有的配置都可以 在 Scheme 之间共用。目前 NexT 支持三种 Scheme，他们是： Muse - 默认 Scheme，这是 NexT 最初的版本，黑白主调，大量留白 Mist - Muse 的紧凑版本，整洁有序的单栏外观 Pisces - 双栏 Scheme，小家碧玉似的清新 Scheme 的切换通过更改 主题配置文件，搜索 scheme 关键字。 你会看到有三行 scheme 的配置，将你需用启用的 scheme 前面注释 # 去除即可。 选择 Pisces Scheme 123#scheme: Muse#scheme: Mistscheme: Pisces 设置 语言编辑 站点配置文件， 将 language 设置成你所需要的语言。建议明确设置你所需要的语言，例如选用简体中文，配置如下： 1language: zh-CN Local Search添加百度/谷歌/本地 自定义站点内容搜索 安装 hexo-generator-searchdb，在站点的根目录下执行以下命令： 1$ npm install hexo-generator-searchdb --save 编辑 站点配置文件，新增以下内容到任意位置： 12345search: path: search.xml field: post format: html limit: 10000 编辑 主题配置文件，启用本地搜索功能： 123# Local searchlocal_search: enable: true 文章模块的美化文章内代码美化 行内代码在主题目录下，将source/css/_custom/custom.styl文件修改如下： 123456789//行内代码样式code &#123; color: #ff7600; background: #fbf7f8; border: 1px solid #d6d6d6; padding:1px 4px; word-break: break-all; border-radius:4px;&#125; 区块代码在主题目录下，修改config.yml文件： 12# 样式可选： normal | night | night eighties | night blue | night brighthighlight_theme: night 文章结束语 添加模块文件 在主题目录下layout/_macro中新建 passage-end-tag.swig文件,并添加以下内容： 1234567&lt;div&gt; &#123;% if not is_index %&#125; &lt;div style=&quot;text-align:center;color: #ccc;font-size:14px;&quot;&gt; -------------本文结束&lt;i class=&quot;fa fa-paw&quot;&gt;&lt;/i&gt;感谢您的阅读------------- &lt;/div&gt; &#123;% endif %&#125;&lt;/div&gt; 导入模板文件 在layout/_macro/post.swig文件中，找到： 123&#123;#####################&#125;&#123;### END POST BODY ###&#125;&#123;#####################&#125; 在上面代码之前添加： 12345&lt;div&gt; &#123;% if not is_index %&#125; &#123;% include &apos;passage-end-tag.swig&apos; %&#125; &#123;% endif %&#125;&lt;/div&gt; 配置在主题配置文件中添加： 123# 文章末尾添加“本文结束”标记passage_end_tag: enabled: true 增强文章底部版权信息 增加文章md文件的头部信息中添加copyright: true时，添加版权声明 增加文章标题、发布时间、更新时间等信息 在目录 next/layout/_macro/下添加 my-copyright.swig： 123456789101112131415161718192021222324252627282930&#123;% if page.copyright %&#125;&lt;div class=&quot;my_post_copyright&quot;&gt; &lt;script src=&quot;//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js&quot;&gt;&lt;/script&gt; &lt;!-- JS库 sweetalert 可修改路径 --&gt; &lt;script src=&quot;https://cdn.bootcss.com/jquery/2.0.0/jquery.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;https://unpkg.com/sweetalert/dist/sweetalert.min.js&quot;&gt;&lt;/script&gt; &lt;p&gt;&lt;span&gt;本文标题:&lt;/span&gt;&lt;a href=&quot;&#123;&#123; url_for(page.path) &#125;&#125;&quot;&gt;&#123;&#123; page.title &#125;&#125;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;文章作者:&lt;/span&gt;&lt;a href=&quot;/&quot; title=&quot;访问 &#123;&#123; theme.author &#125;&#125; 的个人博客&quot;&gt;&#123;&#123; theme.author &#125;&#125;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;发布时间:&lt;/span&gt;&#123;&#123; page.date.format(&quot;YYYY年MM月DD日 - HH:MM&quot;) &#125;&#125;&lt;/p&gt; &lt;p&gt;&lt;span&gt;最后更新:&lt;/span&gt;&#123;&#123; page.updated.format(&quot;YYYY年MM月DD日 - HH:MM&quot;) &#125;&#125;&lt;/p&gt; &lt;p&gt;&lt;span&gt;原始链接:&lt;/span&gt;&lt;a href=&quot;&#123;&#123; url_for(page.path) &#125;&#125;&quot; title=&quot;&#123;&#123; page.title &#125;&#125;&quot;&gt;&#123;&#123; page.permalink &#125;&#125;&lt;/a&gt; &lt;span class=&quot;copy-path&quot; title=&quot;点击复制文章链接&quot;&gt;&lt;i class=&quot;fa fa-clipboard&quot; data-clipboard-text=&quot;&#123;&#123; page.permalink &#125;&#125;&quot; aria-label=&quot;复制成功！&quot;&gt;&lt;/i&gt;&lt;/span&gt; &lt;/p&gt; &lt;p&gt;&lt;span&gt;许可协议:&lt;/span&gt;&lt;i class=&quot;fa fa-creative-commons&quot;&gt;&lt;/i&gt; &lt;a rel=&quot;license&quot; href=&quot;https://creativecommons.org/licenses/by-nc-nd/4.0/&quot; target=&quot;_blank&quot; title=&quot;Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)&quot;&gt;署名-非商业性使用-禁止演绎 4.0 国际&lt;/a&gt; 转载请保留原文链接及作者。&lt;/p&gt; &lt;/div&gt;&lt;script&gt; var clipboard = new Clipboard(&apos;.fa-clipboard&apos;); $(&quot;.fa-clipboard&quot;).click(function()&#123; clipboard.on(&apos;success&apos;, function()&#123; swal(&#123; title: &quot;&quot;, text: &apos;复制成功&apos;, icon: &quot;success&quot;, showConfirmButton: true &#125;); &#125;); &#125;); &lt;/script&gt;&#123;% endif %&#125; 在目录next/source/css/_common/components/post/下添加my-post-copyright.styl： 123456789101112131415161718192021222324252627282930313233343536373839404142434445.my_post_copyright &#123; width: 85%; max-width: 45em; margin: 2.8em auto 0; padding: 0.5em 1.0em; border: 1px solid #d3d3d3; font-size: 0.93rem; line-height: 1.6em; word-break: break-all; background: rgba(255,255,255,0.4);&#125;.my_post_copyright p&#123;margin:0;&#125;.my_post_copyright span &#123; display: inline-block; width: 5.2em; color: #b5b5b5; font-weight: bold;&#125;.my_post_copyright .raw &#123; margin-left: 1em; width: 5em;&#125;.my_post_copyright a &#123; color: #808080; border-bottom:0;&#125;.my_post_copyright a:hover &#123; color: #a3d2a3; text-decoration: underline;&#125;.my_post_copyright:hover .fa-clipboard &#123; color: #000;&#125;.my_post_copyright .post-url:hover &#123; font-weight: normal;&#125;.my_post_copyright .copy-path &#123; margin-left: 1em; width: 1em; +mobile()&#123;display:none;&#125;&#125;.my_post_copyright .copy-path:hover &#123; color: #808080; cursor: pointer;&#125; 修改next/layout/_macro/post.swig，在代码 123&#123;#####################&#125;&#123;### END POST BODY ###&#125;&#123;#####################&#125; 之前添加增加如下代码： 12345&lt;div&gt; &#123;% if not is_index %&#125; &#123;% include &apos;my-copyright.swig&apos; %&#125; &#123;% endif %&#125;&lt;/div&gt; 修改next/source/css/_common/components/post/post.styl文件，在最后一行增加代码： 1@import &quot;my-post-copyright&quot; 保存重新生成即可。 微信：sgsgy5 qq:869087033 欢迎交流，搭建走了很多坑。 友情链接 参考： 技术小白搭建hexo+github博客 next最新版主题下载使用 next主题官方文档 next主题个性化教程 next主题配置文件详解 NexT v6.0+ 背景动画Canvas_nest设置无效的解决方案 给Hexo搭建的博客增加百度谷歌搜索引擎验证 添加文章字数和读取文章的时间 hexo + next主题高级配置 关于博客图片上传方法]]></content>
      <categories>
        <category>博客</category>
      </categories>
      <tags>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go语言中的面向对象，接口类型，工厂设计模式解读]]></title>
    <url>%2F2018%2F09%2F01%2Fgo%E8%AF%AD%E8%A8%80%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[工厂模式： 定义一个用于创建对象的接口，让子类决定实例化哪一个类抽象工厂模式：为创建一组相关或相互依赖的对象提供一个接口，而且无需指定他们的具体类个人觉得这个区别在于产品，如果产品单一，最合适用工厂模式，但是如果有多个业务品种、业务分类时，通过抽象工厂模式产生需要的对象是一种非常好的解决方式。再通俗深化理解下：工厂模式针对的是一个产品等级结构 ，抽象工厂模式针对的是面向多个产品等级结构的。工厂方法模式 抽象工厂模式针对的是一个产品等级结构 针对的是面向多个产品等级结构一个抽象产品类 多个抽象产品类可以派生出多个具体产品类 每个抽象产品类可以派生出多个具体产品类一个抽象工厂类，可以派生出多个具体工厂类 一个抽象工厂类，可以派生出多个具体工厂类每个具体工厂类只能创建一个具体产品类的实例 每个具体工厂类可以创建多个具体产品类的实例加减乘除四则运算器工厂模式举例子 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677package mainimport "fmt"type operation struct&#123; //定义一个父类两个数据 num1 float64 num2 float64&#125;type operationAdd struct&#123; //加法子类 operation&#125;func (op *operationAdd)getresult()float64&#123; //加法类的方法 return op.num1+op.num2&#125;type operationSub struct&#123; //减法子类 operation&#125;func (sub *operationSub)getresult()float64&#123; //减法类的方法 return sub.num1-sub.num2&#125;type operationMult struct&#123; //乘法子类 operation&#125;func (mult *operationMult)getresult()float64&#123; return mult.num1*mult.num2&#125;type operationDivi struct&#123; operation&#125; //除法子类func (divi *operationDivi)getresult()float64&#123; return divi.num1/divi.num2&#125;type operationer interface&#123; //定义接口 getresult() float64 //加法的方法&#125;type operationfactor struct &#123; //operation //用于创建对象的类，工厂模式&#125;func (op *operationfactor)creatoperation(ope string,num1 float64,num2 float64)float64&#123; //用于构件对象类 var result float64 switch ope &#123; case "+": add:=&amp;operationAdd&#123;operation&#123;num1,num2&#125;&#125; //按照传过来的符号来创建相应的对象 result=operationwho(add) //传递给多态的函数，直接调用 case "-": sub:=&amp;operationSub&#123;operation&#123;num1,num2&#125;&#125; result=operationwho(sub) case "*": mult:=&amp;operationMult&#123;operation&#123;num1,num2&#125;&#125; result=operationwho(mult) case "/": divi:=&amp;operationDivi&#123;operation&#123;num1,num2&#125;&#125; result=operationwho(divi) &#125; return result&#125;func operationwho(i operationer)float64&#123; return i.getresult() //此处为创建一个多态的函数&#125;func main()&#123; //m:=&amp;operationAdd&#123;operation&#123;3,4&#125;&#125; //var iop operationer //iop=m //sum:=iop.getresult() //fmt.Println(sum) var op1 operationfactor //直接创建工厂类对象 sum:=op1.creatoperation("+",9,6) //直接调用工厂类的方法 fmt.Println(sum) var op2 operationfactor sub:=op2.creatoperation("-",9,8) fmt.Println(sub) var op3 operationfactor mult:=op3.creatoperation("*",3,4) fmt.Println(mult) var op4 operationfactor div:=op4.creatoperation("/",9,10) fmt.Println(div)&#125; 在上面的例子当中，如果对面向对象没有接触的话可能会有一些不好理解，在go语言当中面向对象可能和别的语言有一些不同，go语言是利用匿名字段来实现继承，在上面的例子中多态函数的实现可以让函数调用更加方便，比如每个结构体类都有10几个甚至更多的函数，那么直接都把这些函数封装在多态的函数里面，那么每次调用直接传递一个结构体类给多态函数就直接全部调用了，这样就是很方便的]]></content>
      <categories>
        <category>GO语言</category>
      </categories>
      <tags>
        <tag>go语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go语言简单排序之冒泡和插入排序]]></title>
    <url>%2F2018%2F09%2F01%2Fgo%E8%AF%AD%E8%A8%80%E5%86%92%E6%B3%A1%E5%92%8C%E6%8F%92%E5%8F%991%2F</url>
    <content type="text"><![CDATA[编程即数学，在编程中也会遇到很多的数学问题的集合，今天我们来讲解一下编程中最常见的冒泡排序，以及冒泡排序之后的插入排序 1：冒泡排序：见名知意，冒泡在我们生活当中可以有哪些常见的事物呢，比如在生活当中，大家都见到过烧开水的状态，那么水中的气泡就会不断的往上面漂浮，应用物理学上的知识来讲就是气泡的质量比较轻，在水中有浮力，就会不断的上浮，那么我们应该怎样应用到编程中的冒泡排序呢，我们先来看一段代码，然后慢慢分析 12345678910111213141516171819package mainimport "fmt"//func main() &#123; arr := [10]int&#123;9, 1, 5, 6, 3, 7, 10, 8, 2, 4&#125; //先定义一个乱序数组 //冒泡排序 for i := 0; i &lt; 10-1; i++ &#123; //外面的循环用来循环次数 for j := 0; j &lt; 10-1-i; j++ &#123; //里面的循环用来循环 每次对比到哪里 if arr[j] &gt; arr[j+1] &#123; //数据交换 arr[j], arr[j+1] = arr[j+1], arr[j] //go语言的多个数据交换格式 //temp := arr[j] //普通数据交换格式 //arr[j] = arr[j+1] //arr[j+1] = temp &#125; &#125; &#125; fmt.Println(arr)&#125; 我们看到这个代码和这张图片，在图片中我们只写了前面几次，先来看第一次，第一个元素和第二个相比4比2大，如果第一个元素比第二个大那么就交换一下，然后第二个元素和第三个相比，如果大就交换，然后第三第四相比，第四第五相比，一直比到最后一个和倒数第一个，有没有发现这样比一次就能确定一个最大的数，而且最大的数是放在最后一个元素里面的，这样一次就是外面的外循环 1for i := 0; i &lt; 10-1; i++ &#123; //这句话就是外面的循环 然后确定第一个最大的放最后一个，那么我们然后怎么办呢 ，然后我们当然继续下一次对比然后再确定一个第二大的放在倒数第二的位置啊，最大的确定下来后，我们继续从第一个开始遍历，但是这次遍历要注意了，不需要遍历到最后一个元素，而只需遍历到倒数第二个就行了，这是为什么呢，因为最后一个元素已经确定下来是最大的了，所以就不需要对比了，我们来看内循环 12for j := 0; j &lt; 10-1-i; j++ &#123; //里面的循环用来循环 每次对比到哪里//这里的判断条件是 小于10-1-i，i是什么呢，就是外循环的次数，所以只需要对比到10-1-i就行 然后内循环每次对比相邻的两个元素，如果前面大于后面的那么就交换， 12345//数据交换 arr[j], arr[j+1] = arr[j+1], arr[j] //go语言的多个数据交换格式 //temp := arr[j] //普通数据交换格式 //arr[j] = arr[j+1] //arr[j+1] = temp 这里面数据交换 有两种格式，第一种就是GO语言里面的简单交换格式，第二种是常见的交换数据格式，需要定义一个临时变量 然后可以打印出来数组，就变成从小到大的升序数组了， 那么如果要变成降序排序怎么改呢？ 来看这句话 1if arr[j] &gt; arr[j+1] &#123; 我们只需要把这里的大于号改成小于号就行啦 不喜勿喷，谢谢哈哈插入排序后续]]></content>
      <categories>
        <category>数据结构和算法</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>排序问题</tag>
      </tags>
  </entry>
</search>
