<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[高并发下map和chan实现的链接池的线程安全及效率]]></title>
    <url>%2F2018%2F10%2F05%2F%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%8Bmap%E5%92%8Cchan%E5%AE%9E%E7%8E%B0%E7%9A%84%E9%93%BE%E6%8E%A5%E6%B1%A0%E7%9A%84%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E5%8F%8A%E6%95%88%E7%8E%87%2F</url>
    <content type="text"><![CDATA[1.背景上一次blog写着写着崩掉了，这次一定写完一节保存一节。 目前从事go语言的后台开发，在集群通信时需要用到thrift的rpc。由于集群间通信非常频繁且并发需求很高，所以只能采用连接池的形式。由于集群规模是有限的，每个节点都需要保存平行节点的连接，所以链接池的实现方式应该是map[host]chan conn。在go语言中，我们知道channel是线程安全的，但map却不是线程安全的。所以我们需要适当的加锁来保证其线程安全同时兼顾效率。 2. 链接池的一般设计 新建链接时，需要给定目标地址 获取链接时，需要给定目标地址，若链接池存在链接，则从链接池返回，若不存在链接，则新建链接返回 链接池中存放的链接总是空闲链接 连接使用完后需放回链接池 放回链接池需要给定目标地址 放回链接池时若链接池已满，则关闭该链接并将其交给gc 3.链接池的一般定义123456789type factory func(host string) conntype conn interface &#123; Close() error&#125;type pool struct &#123; m map[string]chan conn mu sync.RWMutex fact factory&#125; 以上是一个通用链接池的实现，用了channel和读写锁，暂时不考虑链接超时等问题。我们的目的是探索这个链接池在高并发情况下的线程安全和get，put效率问题。所以下来我们给出实验主程序。 4.测试主程序测试主程序如下所示 pt是记录的get，put次数，采用原子操作进行累加，其耗时忽略不计。 hosts为集群规模，也是map的大小，一般来说不会太大。 threadnum为并发的协程数 为了方便，此处直接使用net.dial作为工厂方法实现 每一个协程是一个死循环，不断地进行get，put操作。每次操作会使pts加1。 12345678910111213141516171819202122232425262728293031323334353637383940414243func main()&#123; var pts uint64 p := &amp;pool&#123; m :make(map[string]chan conn), mu:sync.RWMutex&#123;&#125;, fact:func(target string)conn&#123; c,_ :=net.Dial("","8080") return c &#125;, &#125; //打印线程，打印get，put效率 be := time.Now() go func ()&#123; for true&#123; //此处先休眠一秒是为了避免第一次时差计算为0导致的除法错误 time.Sleep(1 *time.Second) cost := time.Since(be) / time.Second println(atomic.LoadUint64(&amp;pts)/uint64(cost),"pt/s") &#125; &#125;() time.Sleep(1*time.Second) //打印线程完，此处等待一秒是为对应打印线程第一次休眠，尽量减少误差 //集群规模 hosts := []string&#123;"192.168.0.1","192.168.0.2","192.168.0.3","192.168.0.4"&#125; //并发线程数量 threadnum := 1 for i:=0;i&lt;threadnum;i++&#123; go func()&#123; for true&#123; target := hosts[rand.Int() % len(hosts)] conn := p.Get(target) //------------------使用连接开始 //time.Sleep(1*time.Nanosecond) //------------------使用连接完毕 p.Put(target,conn) atomic.AddUint64(&amp;pts,1) &#125; &#125;() &#125; time.Sleep(100 * time.Second)&#125; 5.单协程情况下的效率5.1 单协程get &amp; put实现单协程模式下，我们不必考虑线程安全的问题，也就不必加锁。此时的get，put实现如下 1234567891011121314151617181920212223func (p *pool)Get(host string) (c conn)&#123; if _,ok := p.m[host];!ok&#123; p.m[host] = make(chan conn,100) &#125; select &#123; case c = &lt;- p.m[host]: &#123;&#125; default: c = p.New(host) &#125; return&#125;func (p *pool)Put(host string,c conn)&#123; select &#123; case p.m[host] &lt;- c: &#123;&#125; default: c.Close() &#125;&#125;func (p *pool)New(host string)conn&#123; return p.fact(host)&#125; 5.2 测试结果我们设置threadnum为1，测试结果如下。其速度大概在5,000,000 次/秒 6.并发情况下效率-全写锁6.1 全写锁的get &amp; put 实现为了保证并发情况下的线程安全，我们需要使用读写锁，那么对get和put操作究竟该如何加锁呢，最安全的形式当然是全写锁的形式，单其效率肯定是最低的，因为这样同一时刻总是只有一个协程在进行写或者读。 123456789101112131415161718192021222324func (p *pool)Get1(host string) (c conn)&#123; p.mu.Lock() defer p.mu.RLock() if _,ok := p.m[host];!ok&#123; p.m[host] = make(chan conn,100) &#125; select &#123; case c = &lt;- p.m[host]: &#123;&#125; default: c = p.New(host) &#125; return&#125;func (p *pool)Put1(host string,c conn)&#123; p.mu.Lock() defer p.mu.Unlock() select &#123; case p.m[host] &lt;- c: &#123;&#125; default: c.Close() &#125;&#125; 6.2 测试结果6.2.1 全写锁下 的多协程测试结果我们设置threadnum为4，测试结果如下，其速度大概在1,000,000次/秒 6.2.2 全写锁下单协程测试结果如果我们将threadnum设置为1，再次测试，其速度为2,800,00次/秒。可以看到，多协程会降低效率，因为协程间切换也会有时间消耗。但我们经常听说多协程会提高运行速度，这也是对的，那么什么时候多协程会提高运速度呢，这就是我说的链接使用时间的问题，当连接使用时间大于锁竞争和协程切换时间的时候，我们用多协程会提高效率。而实际使用中，连接的使用时间总是存在的且一般都大于锁竞争时间和协程切换时间。 6.2.3 单协程下存在链接使用时间的的测试结果在主程序中，我们在get和put间加上休眠时间，此处设置休眠时间为1毫秒即链接使用1毫秒后放链接池。同时协程数设置为1。单协程情况下，其速度大概如下500次/秒。可以看到实际的效率大幅度降低。 6.2.4 多协程下存在链接使用时间的测试结果同样保持链接使用时间为1毫秒，协程数量设置为4，测试结果如下。其速度大概为2,000次/秒，刚好是单协程的4倍。所以实际情况下多协程的使用需要慎重考虑，并不是多协程一定能提高程序的处理速度，相反在某些情况下会降低程序的执行速度。由于本次测试的是链接池的性能和安全，接下来的测试不再添加链接使用时间，只单纯的测试读写锁和效率的问题。本小节算是一个附加测试。 7.并发情况下效率-读写锁1由于全写锁没有实际的使用意义，所以我们需要使用读写锁来提高效率，那么如何保证线程安全添加读写锁呢。首先对于我们的map结构来说，当有写操作的时候，我们的读操作应该是不可靠的，所以不能进行，当读操作时，我们不希望有写操作但其他协程也能同时读取，这桥恰符合读写锁的作用原理。 当加写锁时，所有的读写均不可用 当加读锁时，所有的写操作不可用，读操作可用 7.1 读写锁1 get &amp; put实现考察我们的put程序，只有对map的读，所以只需要加读锁，而在get中，包含了两部分，第一次写操作和第二次的读操作，所以我们很简单的我们想到，需要使用两次锁，第一次写锁，第二次读锁。 123456789101112131415161718192021222324252627func (p *pool)Get2(host string) (c conn)&#123; p.mu.Lock() if _,ok := p.m[host];!ok&#123; p.m[host] = make(chan conn,100) &#125; p.mu.Unlock() p.mu.RLock() defer p.mu.RUnlock() select &#123; case c = &lt;- p.m[host]: &#123;&#125; default: c = p.New(host) &#125; return&#125;func (p *pool)Put1(host string,c conn)&#123; p.mu.RLock() defer p.mu.RUnlock() select &#123; case p.m[host] &lt;- c: &#123;&#125; default: c.Close() &#125;&#125; 7.2 测试结果我们本来期望的是效率应该比全写锁要高一些，但实际情况是低一些，只有800,000次/秒。那问题出在哪里呢。从程序上来看，get多了一次加锁，所以导致锁竞争次数比全写锁要高一些，但我们并不能减少锁次数直接使用读锁，这样是不安全的，程序也会报错。所以我们给出另一种安全的读写锁形式。 8.并发情况下效率-读写锁8.1 读写锁2 get &amp; put实我们从实际的使用来看一下get程序，由于我们给定了hosts，所以其实对map的写入操作只会进行四次，但后来每次进行get时都会加一次写锁，这是没有必要的。仔细看一下第一次写锁，我们加的有些草率，因为首先会读取一次map来判断是否应该进行写入操作，所以我们可以通过增加一次读锁，来减少后来的加写锁。当然有人会说为什么不直接初始化map，这样就没有写操作，这我也考虑过，但是集群规模有可能会扩张并且会动态变化，直接初始化map会显得有些刻意，并且通用性也不强，与其他模块会产生耦合。所以这种做法并没有多少设计上的美感，相反会显得比较low。我们给出第二种读写锁如下。123456789101112131415161718192021222324252627282930func (p *pool)Get3(host string) (c conn)&#123; p.mu.RLock() if _,ok := p.m[host];!ok&#123; p.mu.RUnlock() p.mu.Lock() p.m[host] = make(chan conn,100) p.mu.Unlock() &#125;else&#123; p.mu.RUnlock() &#125; p.mu.RLock() defer p.mu.RUnlock() select &#123; case c = &lt;- p.m[host]: &#123;&#125; default: c = p.New(host) &#125; return&#125;func Put3(host string,c conn)&#123; p.mu.RLock() defer p.mu.RUnlock() select &#123; case p.m[host] &lt;- c: &#123;&#125; default: c.Close() &#125;&#125; 8.2 测试结测试结果如下，其速度大概在3,400,000次/秒。是全写锁性能的4倍左右。 9.defer对锁的性能影响我们经常听说defer的执行效率低，其实是因为defer在函数返回时才执行，这对普通的函数并没有影响，但对所来说，如果我们可以提前释放锁，那么肯定能减少很多锁的无效占用。顺便我们测试一下defer函数对锁的性能影响，对8.1的get &amp; put实现，我们将其中的defer全部替换为函数结束之前手动释放锁。其实只在put中有defer 9.1 无defer的 get &amp; put实现12345678910111213141516171819202122232425262728func (p *pool)Get4(host string) (c conn)&#123; p.mu.RLock() if _,ok := p.m[host];!ok&#123; p.mu.RUnlock() p.mu.Lock() p.m[host] = make(chan conn,100) p.mu.Unlock() &#125;else&#123; p.mu.RUnlock() &#125; select &#123; case c = &lt;- p.m[host]: &#123;&#125; default: c = p.New(host) &#125; return&#125;func (p *pool)Put4(host string,c conn)&#123; p.mu.RLock() select &#123; case p.m[host] &lt;- c: &#123;&#125; default: c.Close() &#125; p.mu.RUnlock()&#125; 9.2 测试结果测试结果如下，仅仅修改了一处defer，速度达到接近4,000,000次/秒，性能提高了15%。还是非常可观的。 10.总结 这篇bolg真不容易，写了我好久 多协程提高程序执行速度是有前提的，并不能无脑提高程序速度 map是非线程安全的，需要谨慎使用 读写锁性能比单纯的写锁(互斥锁)要高很多，尽量使用读写锁 读写锁的使用可以针对具体情况进行优化，还可以使用go race detector来检测是否安全 锁尽量手动释放，当然defer是一种非常优雅的写法，对效率要求不高的程序中我还是喜欢用defer]]></content>
      <categories>
        <category>GO语言</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>高并发线程安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-wc命令]]></title>
    <url>%2F2018%2F10%2F04%2FLinux%E5%91%BD%E4%BB%A4-wc%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux系统中的wc(Word Count)命令的功能为统计指定文件中的字节数、字数、行数，并将统计结果显示输出。 语法wc(选项)(参数) 选项1234567-c 统计字节数。-l 统计行数。-m 统计字符数。这个标志不能与 -c 标志一起使用。-w 统计字数。一个字被定义为由空白、跳格或换行字符分隔的字符串。-L 打印最长行的长度。-help 显示帮助信息--version 显示版本信息 参数文件：需要统计的文件列表。 功能统计指定文件中的字节数、字数、行数，并将统计结果显示输出。该命令统计指定文件中的字节数、字数、行数。如果没有给出文件名，则从标准输入读取。wc同时也给出所指定文件的总统计数。 常用实例1）查看文件的字节数、字数、行数 1234567891011121314151617181920# cat test.txt hnlinuxpeida.cnblogs.comubuntuubuntu linuxredhatRedhatlinuxmint# wc test.txt 7 8 70 test.txt# wc -l test.txt 7 test.txt# wc -c test.txt 70 test.txt# wc -w test.txt 8 test.txt# wc -m test.txt 70 test.txt# wc -L test.txt 17 test.txt 说明： 7 8 70 test.txt 行数 单词数 字节数 文件名 2）用wc命令怎么做到只打印统计数字不打印文件名 1234# wc -l test.txt 7 test.txt# cat test.txt |wc -l7 说明： 使用管道线，这在编写shell脚本时特别有用。 3）用来统计当前目录下的文件数 123456789101112#cd test6# ll总计 604---xr--r-- 1 root mail 302108 11-30 08:39 linklog.log---xr--r-- 1 mail users 302108 11-30 08:39 log2012.log-rw-r--r-- 1 mail users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2014.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2015.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2016.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2017.log# ls -l | wc -l8 说明： 数量中包含当前目录 转载链接： http://www.cnblogs.com/peida/archive/2012/12/18/2822758.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-grep命令]]></title>
    <url>%2F2018%2F10%2F04%2FLinux%E5%91%BD%E4%BB%A4-grep%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[grep（global search regular expression(RE) and print out the line，全面搜索正则表达式并把行打印出来）是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。 grep可用于shell脚本，因为grep通过返回一个状态值来说明搜索的状态，如果模板搜索成功，则返回0，如果搜索不成功，则返回1，如果搜索的文件不存在，则返回2。我们利用这些返回值就可进行一些自动化的文本处理工作。 选项12345678910111213141516171819202122232425-a 不要忽略二进制数据。-A&lt;显示列数&gt; 除了显示符合范本样式的那一行之外，并显示该行之后的内容。-b 在显示符合范本样式的那一行之外，并显示该行之前的内容。-c 计算符合范本样式的列数。-C&lt;显示列数&gt;或-&lt;显示列数&gt; 除了显示符合范本样式的那一列之外，并显示该列之前后的内容。-d&lt;进行动作&gt; 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep命令将回报信息并停止动作。-e&lt;范本样式&gt; 指定字符串作为查找文件内容的范本样式。-E 将范本样式为延伸的普通表示法来使用，意味着使用能使用扩展正则表达式。-f&lt;范本文件&gt; 指定范本文件，其内容有一个或多个范本样式，让grep查找符合范本条件的文件内容，格式为每一列的范本样式。-F 将范本样式视为固定字符串的列表。-G 将范本样式视为普通的表示法来使用。-h 在显示符合范本样式的那一列之前，不标示该列所属的文件名称。-H 在显示符合范本样式的那一列之前，标示该列的文件名称。-i 忽略字符大小写的差别。-l 列出文件内容符合指定的范本样式的文件名称。-L 列出文件内容不符合指定的范本样式的文件名称。-n 在显示符合范本样式的那一列之前，标示出该列的编号。-q 不显示任何信息。-R/-r 此参数的效果和指定“-d recurse”参数相同。-s 不显示错误信息。-v 反转查找。-w 只显示全字符合的列。-x 只显示全列符合的列。-y 此参数效果跟“-i”相同。-o 只输出文件中匹配到的部分。 规则表达式grep的规则表达式: ^ #锚定行的开始 如：’^grep’匹配所有以grep开头的行。 \$ #锚定行的结束 如：’grep$’匹配所有以grep结尾的行。 . #匹配一个非换行符的字符 如：’gr.p’匹配gr后接一个任意字符，然后是p。 #匹配零个或多个先前字符 如：’*grep’匹配所有一个或多个空格后紧跟grep的行。 .* #一起用代表任意字符。 [] #匹配一个指定范围内的字符，如’[Gg]rep’匹配Grep和grep。 [^] #匹配一个不在指定范围内的字符，如：’[^A-FH-Z]rep’匹配不包含A-F和H-Z的一个字母开头，紧跟rep的行。 (..) #标记匹配字符，如’(love)‘，love被标记为1。 \&lt; #锚定单词的开始，如:’\&lt;grep’匹配包含以grep开头的单词的行。 > #锚定单词的结束，如’grep&gt;‘匹配包含以grep结尾的单词的行。 x{m} #重复字符x，m次，如：’0{5}‘匹配包含5个o的行。 x{m,} #重复字符x,至少m次，如：’o{5,}‘匹配至少有5个o的行。 x{m,n} #重复字符x，至少m次，不多于n次，如：’o{5,10}‘匹配5–10个o的行。 \w #匹配文字和数字字符，也就是[A-Za-z0-9]，如：’G\w*p’匹配以G后跟零个或多个文字或数字字符，然后是p。 \W #\w的反置形式，匹配一个或多个非单词字符，如点号句号等。 \b #单词锁定符，如: ‘\bgrep\b’只匹配grep。 POSIX字符: 为了在不同国家的字符编码中保持一至，POSIX(The Portable Operating System Interface)增加了特殊的字符类，如[:alnum:]是[A-Za-z0-9]的另一个写法。要把它们放到[]号内才能成为正则表达式，如[A- Za-z0-9]或[[:alnum:]]。在linux下的grep除fgrep外，都支持POSIX的字符类。 [:alnum:] #文字数字字符 [:alpha:] #文字字符 [:digit:] #数字字符 [:graph:] #非空字符（非空格、控制字符） [:lower:] #小写字符 [:cntrl:] #控制字符 [:print:] #非空字符（包括空格） [:punct:] #标点符号 [:space:] #所有空白字符（新行，空格，制表符） [:upper:] #大写字符 [:xdigit:] #十六进制数字（0-9，a-f，A-F） 常用实例1）查找指定进程 123 ps -ef|grep svnroot 4943 1 0 Dec05 ? 00:00:00 svnserve -d -r /opt/svndata/grape/root 16867 16838 0 19:53 pts/0 00:00:00 grep svn 2）查找指定进程个数 12# ps -ef|grep -c svn 2 3）从文件中读取关键词进行搜索 12345678910111213141516# cat test.txt hnlinuxpeida.cnblogs.comubuntuubuntu linuxredhatRedhatlinuxmint# cat test2.txt linuxRedhat# cat test.txt | grep -f test2.txthnlinuxubuntu linuxRedhatlinuxmint 说明： 输出test.txt文件中含有从test2.txt文件中读取出的关键词的内容行 4）从文件中读取关键词进行搜索且显示行号 12345678910111213141516# cat test.txt hnlinuxpeida.cnblogs.comubuntuubuntu linuxredhatRedhatlinuxmint# cat test2.txt linuxRedhat# cat test.txt | grep -nf test2.txt1:hnlinux4:ubuntu linux6:Redhat7:linuxmint 说明： 输出test.txt文件中含有从test2.txt文件中读取出的关键词的内容行，并显示每一行的行号 5）从文件中查找关键词 12345678# grep &apos;linux&apos; test.txt hnlinuxubuntu linuxlinuxmint# grep -n &apos;linux&apos; test.txt 1:hnlinux4:ubuntu linux7:linuxmint 6）从多个文件中查找关键词 12345678910# grep -n &apos;linux&apos; test.txt test2.txt test.txt:1:hnlinuxtest.txt:4:ubuntu linuxtest.txt:7:linuxminttest2.txt:1:linux# grep &apos;linux&apos; test.txt test2.txt test.txt:hnlinuxtest.txt:ubuntu linuxtest.txt:linuxminttest2.txt:linux 说明： 多文件时，输出查询到的信息内容行时，会把文件的命名在行最前面输出并且加上”:”作为标示符 7）grep不显示本身进程 12345678910# ps aux|grep sshroot 2720 0.0 0.0 62656 1212 ? Ss Nov02 0:00 /usr/sbin/sshdroot 16834 0.0 0.0 88088 3288 ? Ss 19:53 0:00 sshd: root@pts/0 root 16901 0.0 0.0 61180 764 pts/0 S+ 20:31 0:00 grep ssh# ps aux|grep [s]shroot 2720 0.0 0.0 62656 1212 ? Ss Nov02 0:00 /usr/sbin/sshdroot 16834 0.0 0.0 88088 3288 ? Ss 19:53 0:00 sshd: root@pts/0 # ps aux | grep ssh | grep -v &quot;grep&quot;root 2720 0.0 0.0 62656 1212 ? Ss Nov02 0:00 /usr/sbin/sshdroot 16834 0.0 0.0 88088 3288 ? Ss 19:53 0:00 sshd: root@pts/0 8）找出已u开头的行内容 123# cat test.txt |grep ^uubuntuubuntu linux 9）输出非u开头的行内容 123456# cat test.txt |grep ^[^u]hnlinuxpeida.cnblogs.comredhatRedhatlinuxmint 10）输出以hat结尾的行内容 123# cat test.txt |grep hat$redhatRedhat 11）查服务器ip地址所在行 1234# ifconfig eth0|grep &quot;[0-9]\&#123;1,3\&#125;\.[0-9]\&#123;1,3\&#125;\.[0-9]\&#123;1,3\&#125;\.[0-9]\&#123;1,3\&#125;&quot; inet addr:192.168.120.204 Bcast:192.168.120.255 Mask:255.255.255.0# ifconfig eth0|grep -E &quot;([0-9]&#123;1,3&#125;\.)&#123;3&#125;[0-9]&quot; inet addr:192.168.120.204 Bcast:192.168.120.255 Mask:255.255.255.0 12）显示包含ed或者at字符的内容行 12345# cat test.txt |grep -E &quot;peida|com&quot;peida.cnblogs.com# cat test.txt |grep -E &quot;ed|at&quot;redhatRedhat 13）显示当前目录下面以.txt 结尾的文件中的所有包含每个字符串至少有7个连续小写字符的字符串的行 1234# grep &apos;[a-z]\&#123;7\&#125;&apos; *.txttest.txt:hnlinuxtest.txt:peida.cnblogs.comtest.txt:linuxmint 14）在多级目录中对文本进行递归搜索 1#grep &quot;text&quot; . -r -n # .表示当前目录。 15）显示过滤注释( # ; 开头) 和空行后的配置信息 1# grep -Ev &quot;^$|^[#;]&quot; server.conf 参考链接： http://man.linuxde.net/grep http://www.cnblogs.com/peida/archive/2012/12/17/2821195.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-kill命令]]></title>
    <url>%2F2018%2F10%2F04%2FLinux%E5%91%BD%E4%BB%A4-kill%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux中的kill命令用来终止指定的进程（terminate a process）的运行，是Linux下进程管理的常用命令。通常，终止一个前台进程可以使用Ctrl+C键，但是，对于一个后台进程就须用kill命令来终止，我们就需要先使用ps/pidof/pstree/top等工具获取进程PID，然后使用kill命令来杀掉该进程。kill命令是通过向进程发送指定的信号来结束相应进程的。在默认情况下，采用编号为15的TERM信号。TERM信号将终止所有不能捕获该信号的进程。对于那些可以捕获该信号的进程就要用编号为9的kill信号，强行“杀掉”该进程。 语法kill(选项)(参数) 选项12345-a：当处理当前进程时，不限制命令名和进程号的对应关系；-l &lt;信息编号&gt;：若不加&lt;信息编号&gt;选项，则-l参数会列出全部的信息名称；-p：指定kill 命令只打印相关进程的进程号，而不发送任何信号；-s &lt;信息名称或编号&gt;：指定要送出的信息；-u：指定用户。 参数进程或作业识别号：指定要删除的进程或作业。 功能发送指定的信号到相应进程。不指定型号将发送SIGTERM（15）终止指定进程。如果无法终止该程序可用“-KILL”参数，其发送的信号为SIGKILL（9），将强制结束进程，使用ps命令或者jobs命令可以查看进程号。root用户将影响用户的进程，非root用户只能影响自己的进程。 常用实例1234567891011121314151617# kill -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR1 11) SIGSEGV 12) SIGUSR213) SIGPIPE 14) SIGALRM 15) SIGTERM 16) SIGSTKFLT17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU25) SIGXFSZ 26) SIGVTALRM 27) SIGPROF 28) SIGWINCH29) SIGIO 30) SIGPWR 31) SIGSYS 34) SIGRTMIN35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+3 38) SIGRTMIN+439) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+843) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+1247) SIGRTMIN+13 48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-1451) SIGRTMAX-13 52) SIGRTMAX-12 53) SIGRTMAX-11 54) SIGRTMAX-1055) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-7 58) SIGRTMAX-659) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-263) SIGRTMAX-1 64) SIGRTMAX 说明： 只有第9种信号(SIGKILL)才可以无条件终止进程，其他信号进程都有权利忽略。 下面是常用的信号： HUP 1 终端断线 INT 2 中断（同 Ctrl + C） QUIT 3 退出（同 Ctrl + \） TERM 15 终止 KILL 9 强制终止 CONT 18 继续（与STOP相反， fg/bg命令） STOP 19 暂停（同 Ctrl + Z） 2）得到指定信号的数值 12345678# kill -l KILL9# kill -l SIGKILL9# kill -l TERM15# kill -l SIGTERM15 3）先用ps查找进程，然后用kill杀掉 123456#ps -ef|grep vim root 3268 2884 0 16:21 pts/1 00:00:00 vim install.logroot 3370 2822 0 16:21 pts/0 00:00:00 grep vim# kill 3268 # kill 3268 -bash: kill: (3268) - 没有那个进程 4）彻底杀死进程 123456# ps -ef|grep vim root 3268 2884 0 16:21 pts/1 00:00:00 vim install.logroot 3370 2822 0 16:21 pts/0 00:00:00 grep vim# kill –9 3268 # kill 3268 -bash: kill: (3268) - 没有那个进程 5）杀死指定用户所有进程 12# kill -9 $(ps -ef | grep peidalinux) # kill -u peidalinux 6）init进程是不可杀的 123456789101112# ps -ef|grep initroot 1 0 0 Nov02 ? 00:00:00 init [3] root 17563 17534 0 17:37 pts/1 00:00:00 grep init# kill -9 1# kill -HUP 1# ps -ef|grep initroot 1 0 0 Nov02 ? 00:00:00 init [3] root 17565 17534 0 17:38 pts/1 00:00:00 grep init# kill -KILL 1# ps -ef|grep initroot 1 0 0 Nov02 ? 00:00:00 init [3] root 17567 17534 0 17:38 pts/1 00:00:00 grep init 说明： init是Linux系统操作中不可缺少的程序之一。所谓的init进程，它是一个由内核启动的用户级进程。内核自行启动（已经被载入内存，开始运行，并已初始化所有的设备驱动程序和数据结构等）之后，就通过启动一个用户级程序init的方式，完成引导进程。所以,init始终是第一个进程（其进程编号始终为1）。 其它所有进程都是init进程的子孙。init进程是不可杀的！ 参考链接： http://www.cnblogs.com/peida/archive/2012/12/20/2825837.html http://man.linuxde.net/kill]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-ps命令]]></title>
    <url>%2F2018%2F10%2F04%2FLinux%E5%91%BD%E4%BB%A4-ps%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[ps命令用于报告当前系统的进程状态。可以搭配kill指令随时中断、删除不必要的程序。ps命令是最基本同时也是非常强大的进程查看命令，使用该命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵死、哪些进程占用了过多的资源等等，总之大部分信息都是可以通过执行该命令得到的。 linux上进程有5种状态: 运行(正在运行或在运行队列中等待) 中断(休眠中, 受阻, 在等待某个条件的形成或接受到信号) 不可中断(收到信号不唤醒和不可运行, 进程必须等待直到有中断发生) 僵死(进程已终止, 但进程描述符存在, 直到父进程调用wait4()系统调用后释放) 停止(进程收到SIGSTOP, SIGSTP, SIGTIN, SIGTOU信号后停止运行运行) ps工具标识进程的5种状态码: D 不可中断 uninterruptible sleep （usually IO） R 运行 runnable （on run queue） S 中断 sleeping T 停止 traced or stopped Z 僵死 a defunct （“zombie”） process 语法ps(选项) 选项1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162-a：显示所有终端机下执行的程序，除了阶段作业领导者之外。a：显示现行终端机下的所有程序，包括其他用户的程序。-A：显示所有程序。-c：显示CLS和PRI栏位。c：列出程序时，显示每个程序真正的指令名称，而不包含路径，选项或常驻服务的标示。-C&lt;指令名称&gt;：指定执行指令的名称，并列出该指令的程序的状况。-d：显示所有程序，但不包括阶段作业领导者的程序。-e：此选项的效果和指定&quot;A&quot;选项相同。e：列出程序时，显示每个程序所使用的环境变量。-f：显示UID,PPIP,C与STIME栏位。f：用ASCII字符显示树状结构，表达程序间的相互关系。-g&lt;群组名称&gt;：此选项的效果和指定&quot;-G&quot;选项相同，当亦能使用阶段作业领导者的名称来指定。g：显示现行终端机下的所有程序，包括群组领导者的程序。-G&lt;群组识别码&gt;：列出属于该群组的程序的状况，也可使用群组名称来指定。h：不显示标题列。-H：显示树状结构，表示程序间的相互关系。-j或j：采用工作控制的格式显示程序状况。-l或l：采用详细的格式来显示程序状况。L：列出栏位的相关信息。-m或m：显示所有的执行绪。n：以数字来表示USER和WCHAN栏位。-N：显示所有的程序，除了执行ps指令终端机下的程序之外。-p&lt;程序识别码&gt;：指定程序识别码，并列出该程序的状况。p&lt;程序识别码&gt;：此选项的效果和指定&quot;-p&quot;选项相同，只在列表格式方面稍有差异。r：只列出现行终端机正在执行中的程序。-s&lt;阶段作业&gt;：指定阶段作业的程序识别码，并列出隶属该阶段作业的程序的状况。s：采用程序信号的格式显示程序状况。S：列出程序时，包括已中断的子程序资料。-t&lt;终端机编号&gt;：指定终端机编号，并列出属于该终端机的程序的状况。t&lt;终端机编号&gt;：此选项的效果和指定&quot;-t&quot;选项相同，只在列表格式方面稍有差异。-T：显示现行终端机下的所有程序。-u&lt;用户识别码&gt;：此选项的效果和指定&quot;-U&quot;选项相同。u：以用户为主的格式来显示程序状况。-U&lt;用户识别码&gt;：列出属于该用户的程序的状况，也可使用用户名称来指定。U&lt;用户名称&gt;：列出属于该用户的程序的状况。v：采用虚拟内存的格式显示程序状况。-V或V：显示版本信息。-w或w：采用宽阔的格式来显示程序状况。 x：显示所有程序，不以终端机来区分。X：采用旧式的Linux i386登陆格式显示程序状况。-y：配合选项&quot;-l&quot;使用时，不显示F(flag)栏位，并以RSS栏位取代ADDR栏位 。-&lt;程序识别码&gt;：此选项的效果和指定&quot;p&quot;选项相同。--cols&lt;每列字符数&gt;：设置每列的最大字符数。--columns&lt;每列字符数&gt;：此选项的效果和指定&quot;--cols&quot;选项相同。--cumulative：此选项的效果和指定&quot;S&quot;选项相同。--deselect：此选项的效果和指定&quot;-N&quot;选项相同。--forest：此选项的效果和指定&quot;f&quot;选项相同。--headers：重复显示标题列。--help：在线帮助。--info：显示排错信息。--lines&lt;显示列数&gt;：设置显示画面的列数。--no-headers：此选项的效果和指定&quot;h&quot;选项相同，只在列表格式方面稍有差异。--group&lt;群组名称&gt;：此选项的效果和指定&quot;-G&quot;选项相同。--Group&lt;群组识别码&gt;：此选项的效果和指定&quot;-G&quot;选项相同。--pid&lt;程序识别码&gt;：此选项的效果和指定&quot;-p&quot;选项相同。--rows&lt;显示列数&gt;：此选项的效果和指定&quot;--lines&quot;选项相同。--sid&lt;阶段作业&gt;：此选项的效果和指定&quot;-s&quot;选项相同。--tty&lt;终端机编号&gt;：此选项的效果和指定&quot;-t&quot;选项相同。--user&lt;用户名称&gt;：此选项的效果和指定&quot;-U&quot;选项相同。--User&lt;用户识别码&gt;：此选项的效果和指定&quot;-U&quot;选项相同。--version：此选项的效果和指定&quot;-V&quot;选项相同。--widty&lt;每列字符数&gt;：此选项的效果和指定&quot;-cols&quot;选项相同。 常用范例1）显示所有进程信息 123456# ps -A PID TTY TIME CMD 1 ? 00:00:00 init 2 ? 00:00:01 migration/0 3 ? 00:00:00 ksoftirqd/0 4 ? 00:00:01 migration/1 2）显示指定用户信息 123456# ps -u root PID TTY TIME CMD 1 ? 00:00:00 init 2 ? 00:00:01 migration/0 3 ? 00:00:00 ksoftirqd/0 4 ? 00:00:01 migration/1 3）显示所有进程信息，连同命令行 1234567ps -efUID PID PPID C STIME TTY TIME CMDroot 1 0 0 Nov02 ? 00:00:00 init [3] root 2 1 0 Nov02 ? 00:00:01 [migration/0]root 3 1 0 Nov02 ? 00:00:00 [ksoftirqd/0]root 4 1 0 Nov02 ? 00:00:01 [migration/1]root 5 1 0 Nov02 ? 00:00:00 [ksoftirqd/1] 4） ps 与grep 常用组合用法，查找特定进程 1234# ps -ef|grep sshroot 2720 1 0 Nov02 ? 00:00:00 /usr/sbin/sshdroot 17394 2720 0 14:58 ? 00:00:00 sshd: root@pts/0 root 17465 17398 0 15:57 pts/0 00:00:00 grep ssh 5）将目前属于您自己这次登入的 PID 与相关信息列示出来 1234# ps -lF S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD4 S 0 17398 17394 0 75 0 - 16543 wait pts/0 00:00:00 bash4 R 0 17469 17398 0 77 0 - 15877 - pts/0 00:00:00 ps 说明： 各相关信息的意义： F 代表这个程序的旗标 (flag)， 4 代表使用者为 super user S 代表这个程序的状态 (STAT)，关于各 STAT 的意义将在内文介绍 UID 程序被该 UID 所拥有 PID 就是这个程序的 ID ！ PPID 则是其上级父程序的ID C CPU 使用的资源百分比 PRI 这个是 Priority (优先执行序) 的缩写，详细后面介绍 NI 这个是 Nice 值，在下一小节我们会持续介绍 ADDR 这个是 kernel function，指出该程序在内存的那个部分。如果是个 running的程序，一般就是 “-“ SZ 使用掉的内存大小 WCHAN 目前这个程序是否正在运作当中，若为 - 表示正在运作 TTY 登入者的终端机位置 TIME 使用掉的 CPU 时间。 CMD 所下达的指令为何 在预设的情况下， ps 仅会列出与目前所在的 bash shell 有关的 PID 而已，所以， 当我使用 ps -l 的时候，只有三个 PID。 6）列出目前所有的正在内存当中的程序 1234567# ps auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.0 10368 676 ? Ss Nov02 0:00 init [3] root 2 0.0 0.0 0 0 ? S&lt; Nov02 0:01 [migration/0]root 3 0.0 0.0 0 0 ? SN Nov02 0:00 [ksoftirqd/0]root 4 0.0 0.0 0 0 ? S&lt; Nov02 0:01 [migration/1]root 5 0.0 0.0 0 0 ? SN Nov02 0:00 [ksoftirqd/1] 说明： USER：该 process 属于那个使用者账号的 PID ：该 process 的号码 %CPU：该 process 使用掉的 CPU 资源百分比 %MEM：该 process 所占用的物理内存百分比 VSZ ：该 process 使用掉的虚拟内存量 (Kbytes) RSS ：该 process 占用的固定的内存量 (Kbytes) TTY ：该 process 是在那个终端机上面运作，若与终端机无关，则显示 ?，另外， tty1-tty6 是本机上面的登入者程序，若为 pts/0 等等的，则表示为由网络连接进主机的程序。 STAT：该程序目前的状态，主要的状态有 R ：该程序目前正在运作，或者是可被运作 S ：该程序目前正在睡眠当中 (可说是 idle 状态)，但可被某些讯号 (signal) 唤醒。 T ：该程序目前正在侦测或者是停止了 Z ：该程序应该已经终止，但是其父程序却无法正常的终止他，造成 zombie (疆尸) 程序的状态 START：该 process 被触发启动的时间 TIME ：该 process 实际使用 CPU 运作的时间 COMMAND：该程序的实际指令 7）列出类似程序树的程序显示 12345678 ps -axjfWarning: bad syntax, perhaps a bogus &apos;-&apos;? See /usr/share/doc/procps-3.2.7/FAQ PPID PID PGID SID TTY TPGID STAT UID TIME COMMAND 0 1 1 1 ? -1 Ss 0 0:00 init [3] 1 2 1 1 ? -1 S&lt; 0 0:01 [migration/0] 1 3 1 1 ? -1 SN 0 0:00 [ksoftirqd/0] 1 4 1 1 ? -1 S&lt; 0 0:01 [migration/1] 1 5 1 1 ? -1 SN 0 0:00 [ksoftirqd/1] 8）找出与 cron 与 syslog 这两个服务有关的 PID 号码 1234# ps aux | egrep &apos;(cron|syslog)&apos;root 2682 0.0 0.0 83384 2000 ? Sl Nov02 0:00 /sbin/rsyslogd -i /var/run/syslogd.pid -c 5root 2735 0.0 0.0 74812 1140 ? Ss Nov02 0:00 crondroot 17475 0.0 0.0 61180 832 pts/0 S+ 16:27 0:00 egrep (cron|syslog) 说明： 其他实例： 可以用 | 管道和 more 连接起来分页查看 1ps -aux |more 把所有进程显示出来，并输出到ps001.txt文件 1ps -aux &gt; ps001.txt 输出指定的字段 1234# ps -o pid,ppid,pgrp,session,tpgid,comm PID PPID PGRP SESS TPGID COMMAND17398 17394 17398 17398 17478 bash17478 17398 17478 17398 17478 ps 参考链接： http://www.cnblogs.com/peida/archive/2012/12/19/2824418.html http://man.linuxde.net/ps]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-killall命令]]></title>
    <url>%2F2018%2F10%2F04%2FLinux%E5%91%BD%E4%BB%A4-killall%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux系统中的killall命令用于杀死指定名字的进程（kill processes by name）。我们可以使用kill命令杀死指定进程PID的进程，如果要找到我们需要杀死的进程，我们还需要在之前使用ps等命令再配合grep来查找进程，而killall把这两个过程合二为一，是一个很好用的命令。 语法killall(选项)(参数) 选项123456789101112-Z 只杀死拥有scontext 的进程-e 要求匹配进程名称-I 忽略小写-g 杀死进程组而不是进程-i 交互模式，杀死进程前先询问用户-l 列出所有的已知信号名称-q 不输出警告信息-s 发送指定的信号-v 报告信号是否成功发送-w 等待进程死亡--help 显示帮助信息--version 显示版本显示 参数进程名称：指定要杀死的进程名称 常用实例1）杀死所有同名进程 1234567# ps -ef|grep viroot 17581 17398 0 17:51 pts/0 00:00:00 vi test.txtroot 17640 17612 0 17:51 pts/2 00:00:00 vi test.logroot 17642 17582 0 17:51 pts/1 00:00:00 grep vi# killall vi# ps -ef|grep viroot 17645 17582 0 17:52 pts/1 00:00:00 grep vi 2）向进程发送指定信号 1234567891011121314151617181920# vi &amp; [1] 17646[root@localhost ~]# killall -TERM vi[1]+ Stopped vi# vi &amp; [2] 17648# ps -ef|grep viroot 17646 17582 0 17:54 pts/1 00:00:00 viroot 17648 17582 0 17:54 pts/1 00:00:00 viroot 17650 17582 0 17:55 pts/1 00:00:00 grep vi[2]+ Stopped vi# killall -TERM vi# ps -ef|grep viroot 17646 17582 0 17:54 pts/1 00:00:00 viroot 17648 17582 0 17:54 pts/1 00:00:00 viroot 17653 17582 0 17:55 pts/1 00:00:00 grep vi# killall -KILL vi[1]- 已杀死 vi[2]+ 已杀死 vi# ps -ef|grep viroot 17656 17582 0 17:56 pts/1 00:00:00 grep vi 3）把所有的登录后的shell给杀掉 123456789# w 18:01:03 up 41 days, 18:53, 3 users, load average: 0.00, 0.00, 0.00USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot pts/0 10.2.0.68 14:58 9:52 0.10s 0.10s -bashroot pts/1 10.2.0.68 17:51 0.00s 0.02s 0.00s wroot pts/2 10.2.0.68 17:51 9:24 0.01s 0.01s -bash# killall -9 bash# w 18:01:48 up 41 days, 18:54, 1 user, load average: 0.07, 0.02, 0.00USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot pts/0 10.2.0.68 18:01 0.00s 0.01s 0.00s w 说明： 运行命令：killall -9 bash 后，所有bash都会被卡掉了，所以当前所有连接丢失了。需要重新连接并登录。 参考链接： http://www.cnblogs.com/peida/archive/2012/12/21/2827366.html http://man.linuxde.net/killall]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-ln命令]]></title>
    <url>%2F2018%2F10%2F01%2FLinux%E5%91%BD%E4%BB%A4-ln%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[ln是linux中又一个非常重要命令，它的功能是为某一个文件在另外一个位置建立一个同步的链接.当我们需要在不同的目录，用到相同的文件时，我们不需要在每一个需要的目录下都放一个必须相同的文件，我们只要在某个固定的目录，放上该文件，然后在 其它的目录下用ln命令链接（link）它就可以，不必重复的占用磁盘空间。 语法ln(选项)(参数) 选项1234567891011-b或--backup：删除，覆盖目标文件之前的备份；-d或-F或——directory：建立目录的硬连接；-f或——force：强行建立文件或目录的连接，不论文件或目录是否存在；-i或——interactive：覆盖既有文件之前先询问用户；-n或--no-dereference：把符号连接的目的目录视为一般文件；-s或——symbolic：对源文件建立符号连接，而非硬连接；-S&lt;字尾备份字符串&gt;或--suffix=&lt;字尾备份字符串&gt;：用&quot;-b&quot;参数备份目标文件后，备份文件的字尾会被加上一个备份字符串，预设的备份字符串是符号“~”，用户可通过“-S”参数来改变它；-v或——verbose：显示指令执行过程；-V&lt;备份方式&gt;或--version-control=&lt;备份方式&gt;：用“-b”参数备份目标文件后，备份文件的字尾会被加上一个备份字符串，这个字符串不仅可用“-S”参数变更，当使用“-V”参数&lt;备份方式&gt;指定不同备份方式时，也会产生不同字尾的备份字符串；--help：在线帮助；--version：显示版本信息。 参数 源文件：指定连接的源文件。如果使用-s选项创建符号连接，则“源文件”可以是文件或者目录。创建硬连接时，则“源文件”参数只能是文件； 目标文件：指定源文件的目标连接文件。 功能linux文件系统中，有所谓的链接（link），我们可以将其视为档案的别名，而链接又可分为两种：硬链接（hard link）与软链接（symbolic link），硬链接的意思是一个档案可以有多个名称，而软链接的方式则是产生一个特殊的档案，该档案的内容是指向另一个档案的位置。硬链接是存在同一个系统中，而软链接却可以跨越不同的文件系统。 软链接： 1.软链接，以路径的形式存在。类似于Windows操作系统中的快捷方式 2.软链接可以 跨文件系统 ，硬链接不可以 3.软链接可以对一个不存在的文件名进行链接 4.软链接可以对目录进行链接 硬链接: 1.硬链接，以文件副本的形式存在。但不占用实际空间。 2.不允许给目录创建硬链接 3.硬链接只有在同一个文件系统中才能创建 这里有两点要注意： 第一，ln命令会保持每一处链接文件的同步性，也就是说，不论你改动了哪一处，其它的文件都会发生相同的变化； 第二，ln的链接又分软链接和硬链接两种，软链接就是ln –s 源文件 目标文件，它只会在你选定的位置上生成一个文件的镜像，不会占用磁盘空间，硬链接 ln 源文件 目标文件，没有参数-s， 它会在你选定的位置上生成一个和源文件大小相同的文件，无论是软链接还是硬链接，文件都保持同步变化。 ln指令用在链接文件或目录，如同时指定两个以上的文件或目录，且最后的目的地是一个已经存在的目录，则会把前面指定的所有文件或目录复制到该目录中。若同时指定多个文件或目录，且最后的目的地并非是一个已存在的目录，则会出现错误信息。 常用范例1）给文件创建软链接 123456# ll-rw-r--r-- 1 root bin 61 11-13 06:03 log2013.log# ln -s log2013.log link2013# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 1 root bin 61 11-13 06:03 log2013.log 说明： 为log2013.log文件创建软链接link2013，如果log2013.log丢失，link2013将失效 2）给文件创建硬链接 12345678# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 1 root bin 61 11-13 06:03 log2013.log# ln log2013.log ln2013# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 2 root bin 61 11-13 06:03 ln2013-rw-r--r-- 2 root bin 61 11-13 06:03 log2013.log 说明： 为log2013.log创建硬链接ln2013，log2013.log与ln2013的各项属性相同 3）接上面两实例，链接完毕后，删除和重建链接原文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 2 root bin 61 11-13 06:03 ln2013-rw-r--r-- 2 root bin 61 11-13 06:03 log2013.log# rm -rf log2013.log # lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 1 root bin 61 11-13 06:03 ln2013# touch log2013.log# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 1 root bin 61 11-13 06:03 ln2013---xrw-r-- 1 root bin 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root root 0 12-07 16:19 log2013.log# vi log2013.log 2013-012013-022013-032013-042013-052013-062013-072013-082013-092013-102013-112013-12# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 1 root bin 61 11-13 06:03 ln2013-rw-r--r-- 1 root root 96 12-07 16:21 log2013.log# cat link2013 2013-012013-022013-032013-042013-052013-062013-072013-082013-092013-102013-112013-12# cat ln2013 hostnamebaidu=baidu.comhostnamesina=sina.comhostnames=true 说明： 1.源文件被删除后，并没有影响硬链接文件；软链接文件在centos系统下不断的闪烁，提示源文件已经不存在 2.重建源文件后，软链接不在闪烁提示，说明已经链接成功，找到了链接文件系统；重建后，硬链接文件并没有受到源文件影响，硬链接文件的内容还是保留了删除前源文件的内容，说明硬链接已经失效 4）将文件链接为另一个目录中的相同名字 1234567891011121314151617181920212223242526# ln log2013.log test3# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 1 root bin 61 11-13 06:03 ln2013-rw-r--r-- 2 root root 96 12-07 16:21 log2013.log# cd test3# ll-rw-r--r-- 2 root root 96 12-07 16:21 log2013.log# vi log2013.log 2013-012013-022013-032013-042013-052013-062013-072013-082013-092013-10# ll-rw-r--r-- 2 root root 80 12-07 16:36 log2013.log# cd ..# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 1 root bin 61 11-13 06:03 ln2013-rw-r--r-- 2 root root 80 12-07 16:36 log2013.log 说明： 在test3目录中创建了log2013.log的硬链接，修改test3目录中的log2013.log文件，同时也会同步到源文件 5）给目录创建软链接 123456789101112131415161718192021222324252627# lldrwxr-xr-x 2 root root 4096 12-07 16:36 test3drwxr-xr-x 2 root root 4096 12-07 16:57 test5# cd test5# lllrwxrwxrwx 1 root root 5 12-07 16:57 test3 -&gt; test3# cd test3-bash: cd: test3: 符号连接的层数过多# lllrwxrwxrwx 1 root root 5 12-07 16:57 test3 -&gt; test3# rm -rf test3# ll# ln -sv /opt/soft/test/test3 /opt/soft/test/test5创建指向“/opt/soft/test/test3”的符号链接“/opt/soft/test/test5/test3”# lllrwxrwxrwx 1 root root 20 12-07 16:59 test3 -&gt; /opt/soft/test/test3# # cd test3# ll总计 4-rw-r--r-- 2 root root 80 12-07 16:36 log2013.log# touch log2014.log# ll总计 4-rw-r--r-- 2 root root 80 12-07 16:36 log2013.log-rw-r--r-- 1 root root 0 12-07 17:05 log2014.log 说明： 1.目录只能创建软链接 2.目录创建链接必须用绝对路径，相对路径创建会不成功，会提示：符号连接的层数过多 这样的错误 3.在链接目标目录中修改文件都会在源文件目录中同步变化 参考链接： http://www.cnblogs.com/peida/archive/2012/12/11/2812294.html http://man.linuxde.net/ln]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-cal命令]]></title>
    <url>%2F2018%2F10%2F01%2FLinux%E5%91%BD%E4%BB%A4-cal%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[cal命令用于显示当前日历，或者指定日期的日历。 语法cal(选项)(参数) 选项123456-l：显示单月输出；-3：显示临近三个月的日历；-s：将星期日作为月的第一天；-m：将星期一作为月的第一天；-j：显示“julian”日期；-y：显示当前年的日历。 参数12月：指定月份；年：指定年份。 常用实例1）显示当前月份日历 12345678# cal March 2018 Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 8 9 1011 12 13 14 15 16 1718 19 20 21 22 23 2425 26 27 28 29 30 31 2）显示指定月份的日历 1234567891011121314151617# cal 9 2012 九月 2012 日 一 二 三 四 五 六 1 2 3 4 5 6 7 8 9 10 11 12 13 14 1516 17 18 19 20 21 2223 24 25 26 27 28 2930 3）显示2013年日历 12345678910111213141516171819202122232425262728293031323334# cal -y 2013 2013 January February March Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa 1 2 3 4 5 1 2 1 2 6 7 8 9 10 11 12 3 4 5 6 7 8 9 3 4 5 6 7 8 913 14 15 16 17 18 19 10 11 12 13 14 15 16 10 11 12 13 14 15 1620 21 22 23 24 25 26 17 18 19 20 21 22 23 17 18 19 20 21 22 2327 28 29 30 31 24 25 26 27 28 24 25 26 27 28 29 30 31 April May June Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 1 2 3 4 1 7 8 9 10 11 12 13 5 6 7 8 9 10 11 2 3 4 5 6 7 814 15 16 17 18 19 20 12 13 14 15 16 17 18 9 10 11 12 13 14 1521 22 23 24 25 26 27 19 20 21 22 23 24 25 16 17 18 19 20 21 2228 29 30 26 27 28 29 30 31 23 24 25 26 27 28 29 30 July August September Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 1 2 3 1 2 3 4 5 6 7 7 8 9 10 11 12 13 4 5 6 7 8 9 10 8 9 10 11 12 13 1414 15 16 17 18 19 20 11 12 13 14 15 16 17 15 16 17 18 19 20 2121 22 23 24 25 26 27 18 19 20 21 22 23 24 22 23 24 25 26 27 2828 29 30 31 25 26 27 28 29 30 31 29 30 October November December Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa 1 2 3 4 5 1 2 1 2 3 4 5 6 7 6 7 8 9 10 11 12 3 4 5 6 7 8 9 8 9 10 11 12 13 1413 14 15 16 17 18 19 10 11 12 13 14 15 16 15 16 17 18 19 20 2120 21 22 23 24 25 26 17 18 19 20 21 22 23 22 23 24 25 26 27 2827 28 29 30 31 24 25 26 27 28 29 30 29 30 31 4）显示自1月1日的天数 12345678# cal -j March 2018 Sun Mon Tue Wed Thu Fri Sat 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 5）星期一显示在第一列 12345678# cal -m March 2018 Mo Tu We Th Fr Sa Su 1 2 3 4 5 6 7 8 9 10 1112 13 14 15 16 17 1819 20 21 22 23 24 2526 27 28 29 30 31 参考链接： http://man.linuxde.net/cal http://www.cnblogs.com/peida/archive/2012/12/14/2817473.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-date命令]]></title>
    <url>%2F2018%2F10%2F01%2FLinux%E5%91%BD%E4%BB%A4-date%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[在linux环境中，不管是编程还是其他维护，时间是必不可少的，也经常会用到时间的运算，熟练运用date命令来表示自己想要表示的时间，肯定可以给自己的工作带来诸多方便。 语法date(选项)(参数) 选项12345-d&lt;字符串&gt;：显示字符串所指的日期与时间。字符串前后必须加上双引号；-s&lt;字符串&gt;：根据字符串来设置日期与时间。字符串前后必须加上双引号；-u：显示GMT；--help：在线帮助；--version：显示版本信息。 参数&lt;+时间日期格式&gt;：指定显示时使用的日期时间格式。 日期格式字符串列表123456789101112131415161718192021222324%H 小时，24小时制（00~23）%I 小时，12小时制（01~12）%k 小时，24小时制（0~23）%l 小时，12小时制（1~12）%M 分钟（00~59）%p 显示出AM或PM%r 显示时间，12小时制（hh:mm:ss %p）%s 从1970年1月1日00:00:00到目前经历的秒数%S 显示秒（00~59）%T 显示时间，24小时制（hh:mm:ss）%X 显示时间的格式（%H:%M:%S）%Z 显示时区，日期域（CST）%a 星期的简称（Sun~Sat）%A 星期的全称（Sunday~Saturday）%h,%b 月的简称（Jan~Dec）%B 月的全称（January~December）%c 日期和时间（Tue Nov 20 14:12:58 2012）%d 一个月的第几天（01~31）%x,%D 日期（mm/dd/yy）%j 一年的第几天（001~366）%m 月份（01~12）%w 一个星期的第几天（0代表星期天）%W 一年的第几个星期（00~53，星期一为第一天）%y 年的最后两个数字（1999则是99） 常用实例1）格式化输出： 12#date +&quot;%Y-%m-%d&quot;2018-03-29 2）输出昨天日期： 12#date -d &quot;1 day ago&quot; +&quot;%Y-%m-%d&quot;2018-03-28 3）2秒后输出： 12#date -d &quot;2 second&quot; +&quot;%Y-%m-%d %H:%M:%S&quot; 2018-03-29 10:08:37 4）apache格式转换： 12date -d &quot;Dec 5, 2009 12:00:37 AM&quot; +&quot;%Y-%m-%d %H:%M.%S&quot;2009-12-05 00:00.37 5）格式转换后时间游走： 12date -d &quot;Dec 5, 2009 12:00:37 AM 2 year ago&quot; +&quot;%Y-%m-%d %H:%M.%S&quot;2007-12-05 00:00.37 6）加减操作： 1234567date +%Y%m%d //显示前天年月日date -d &quot;+1 day&quot; +%Y%m%d //显示前一天的日期date -d &quot;-1 day&quot; +%Y%m%d //显示后一天的日期date -d &quot;-1 month&quot; +%Y%m%d //显示上一月的日期date -d &quot;+1 month&quot; +%Y%m%d //显示下一月的日期date -d &quot;-1 year&quot; +%Y%m%d //显示前一年的日期date -d &quot;+1 year&quot; +%Y%m%d //显示下一年的日期 7）设定时间 1234567date -s //设置当前时间，只有root权限才能设置，其他只能查看date -s 20120523 //设置成20120523，这样会把具体时间设置成空00:00:00date -s 01:01:01 //设置具体时间，不会对日期做更改date -s &quot;01:01:01 2012-05-23&quot; //这样可以设置全部时间date -s &quot;01:01:01 20120523&quot; //这样可以设置全部时间date -s &quot;2012-05-23 01:01:01&quot; //这样可以设置全部时间date -s &quot;20120523 01:01:01&quot; //这样可以设置全部时间 8）有时需要检查一组命令花费的时间，举例： 12345678#!/bin/bashstart=$(date +%s)nmap man.linuxde.net &amp;&gt; /dev/nullend=$(date +%s)difference=$(( end - start ))echo $difference seconds. 参考链接： http://man.linuxde.net/date http://www.cnblogs.com/peida/archive/2012/12/13/2815687.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-diff命令]]></title>
    <url>%2F2018%2F10%2F01%2FLinux%E5%91%BD%E4%BB%A4-diff%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[diff 命令是 linux上非常重要的工具，用于比较文件的内容，特别是比较两个版本不同的文件以找到改动的地方。diff在命令行中打印每一个行的改动。最新版本的diff还支持二进制文件。diff程序的输出被称为补丁 (patch)，因为Linux系统中还有一个patch程序，可以根据diff的输出将a.c的文件内容更新为b.c。diff是svn、cvs、git等版本控制工具不可或缺的一部分。 语法diff(选项)(参数) 选项12345678910111213141516171819202122232425262728293031323334-&lt;行数&gt;：指定要显示多少行的文本。此参数必须与-c或-u参数一并使用；-a或——text：diff预设只会逐行比较文本文件；-b或--ignore-space-change：不检查空格字符的不同；-B或--ignore-blank-lines：不检查空白行；-c：显示全部内容，并标出不同之处；-C&lt;行数&gt;或--context&lt;行数&gt;：与执行“-c-&lt;行数&gt;”指令相同；-d或——minimal：使用不同的演算法，以小的单位来做比较；-D&lt;巨集名称&gt;或ifdef&lt;巨集名称&gt;：此参数的输出格式可用于前置处理器巨集；-e或——ed：此参数的输出格式可用于ed的script文件；-f或-forward-ed：输出的格式类似ed的script文件，但按照原来文件的顺序来显示不同处；-H或--speed-large-files：比较大文件时，可加快速度；-l&lt;字符或字符串&gt;或--ignore-matching-lines&lt;字符或字符串&gt;：若两个文件在某几行有所不同，而之际航同时都包含了选项中指定的字符或字符串，则不显示这两个文件的差异；-i或--ignore-case：不检查大小写的不同；-l或——paginate：将结果交由pr程序来分页；-n或——rcs：将比较结果以RCS的格式来显示；-N或--new-file：在比较目录时，若文件A仅出现在某个目录中，预设会显示：Only in目录，文件A 若使用-N参数，则diff会将文件A 与一个空白的文件比较；-p：若比较的文件为C语言的程序码文件时，显示差异所在的函数名称；-P或--unidirectional-new-file：与-N类似，但只有当第二个目录包含了第一个目录所没有的文件时，才会将这个文件与空白的文件做比较；-q或--brief：仅显示有无差异，不显示详细的信息；-r或——recursive：比较子目录中的文件；-s或--report-identical-files：若没有发现任何差异，仍然显示信息；-S&lt;文件&gt;或--starting-file&lt;文件&gt;：在比较目录时，从指定的文件开始比较；-t或--expand-tabs：在输出时，将tab字符展开；-T或--initial-tab：在每行前面加上tab字符以便对齐；-u，-U&lt;列数&gt;或--unified=&lt;列数&gt;：以合并的方式来显示文件内容的不同；-v或——version：显示版本信息；-w或--ignore-all-space：忽略全部的空格字符；-W&lt;宽度&gt;或--width&lt;宽度&gt;：在使用-y参数时，指定栏宽；-x&lt;文件名或目录&gt;或--exclude&lt;文件名或目录&gt;：不比较选项中所指定的文件或目录；-X&lt;文件&gt;或--exclude-from&lt;文件&gt;；您可以将文件或目录类型存成文本文件，然后在=&lt;文件&gt;中指定此文本文件；-y或--side-by-side：以并列的方式显示文件的异同之处；--help：显示帮助；--left-column：在使用-y参数时，若两个文件某一行内容相同，则仅在左侧的栏位显示该行内容；--suppress-common-lines：在使用-y参数时，仅显示不同之处。 参数 文件1：指定要比较的第一个文件； 文件2：指定要比较的第二个文件。 功能diff命令能比较单个文件或者目录内容。如果指定比较的是文件，则只有当输入为文本文件时才有效。以逐行的方式，比较文本文件的异同处。如果指定比较的是目录的时候，diff命令会比较两个目录下名字相同的文本文件。列出不同的二进制文件、公共子目录和只在一个目录出现的文件。 常用实例1）比较两个文件 123456789101112# diff log2014.log log2013.log 3c3&lt; 2014-03---&gt; 2013-038c8&lt; 2013-07---&gt; 2013-0811,12d10&lt; 2013-11&lt; 2013-12 说明： 上面的“3c3”和“8c8”表示log2014.log和log20143log文件在3行和第8行内容有所不同；”11,12d10”表示第一个文件比第二个文件多了第11和12行。 diff 的normal 显示格式有三种提示: a - add c - change d - delete 2）并排格式输出 12345678910111213141516171819202122232425# diff log2014.log log2013.log -y -W 502013-01 2013-012013-02 2013-022014-03 | 2013-032013-04 2013-042013-05 2013-052013-06 2013-062013-07 2013-072013-07 | 2013-082013-09 2013-092013-10 2013-102013-11 &lt;2013-12 &lt;# diff log2013.log log2014.log -y -W 502013-01 2013-012013-02 2013-022013-03 | 2014-032013-04 2013-042013-05 2013-052013-06 2013-062013-07 2013-072013-08 | 2013-072013-09 2013-09 &gt; 2013-11 &gt; 2013-12 说明： “|”表示前后2个文件内容有不同 “&lt;”表示后面文件比前面文件少了1行内容 “&gt;”表示后面文件比前面文件多了1行内容 3）上下文输出格式 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# diff log2013.log log2014.log -c*** log2013.log 2012-12-07 16:36:26.000000000 +0800--- log2014.log 2012-12-07 18:01:54.000000000 +0800****************** 1,10 **** 2013-01 2013-02! 2013-03 2013-04 2013-05 2013-06 2013-07! 2013-08 2013-09 2013-10--- 1,12 ---- 2013-01 2013-02! 2014-03 2013-04 2013-05 2013-06 2013-07! 2013-07 2013-09 2013-10+ 2013-11+ 2013-12# diff log2014.log log2013.log -c*** log2014.log 2012-12-07 18:01:54.000000000 +0800--- log2013.log 2012-12-07 16:36:26.000000000 +0800****************** 1,12 **** 2013-01 2013-02! 2014-03 2013-04 2013-05 2013-06 2013-07! 2013-07 2013-09 2013-10- 2013-11- 2013-12--- 1,10 ---- 2013-01 2013-02! 2013-03 2013-04 2013-05 2013-06 2013-07! 2013-08 2013-09 2013-10 说明： 这种方式在开头两行作了比较文件的说明，这里有三中特殊字符： “＋” 比较的文件的后者比前着多一行 “－” 比较的文件的后者比前着少一行 “！” 比较的文件两者有差别的行 4）统一格式输出 123456789101112131415161718# diff log2014.log log2013.log -u--- log2014.log 2012-12-07 18:01:54.000000000 +0800+++ log2013.log 2012-12-07 16:36:26.000000000 +0800@@ -1,12 +1,10 @@ 2013-01 2013-02-2014-03+2013-03 2013-04 2013-05 2013-06 2013-07-2013-07+2013-08 2013-09 2013-10-2013-11-2013-12 说明： 它的第一部分，也是文件的基本信息： — log2014.log 2012-12-07 18:01:54.000000000 +0800 +++ log2013.log 2012-12-07 16:36:26.000000000 +0800 “—“表示变动前的文件，”+++”表示变动后的文件。 第二部分，变动的位置用两个@作为起首和结束。 @@ -1,12 +1,10 @@ 前面的”-1,12”分成三个部分：减号表示第一个文件（即log2014.log），”1”表示第1行，”12”表示连续12行。合在一起，就表示下面是第一个文件从第1行开始的连续12行。同样的，”+1,10”表示变动后，成为第二个文件从第1行开始的连续10行。 5）比较文件夹不同 123456789101112131415161718192021222324252627282930313233343536# diff test3 test6Only in test6: linklog.logOnly in test6: log2012.logdiff test3/log2013.log test6/log2013.log1,10c1,3&lt; 2013-01&lt; 2013-02&lt; 2013-03&lt; 2013-04&lt; 2013-05&lt; 2013-06&lt; 2013-07&lt; 2013-08&lt; 2013-09&lt; 2013-10---&gt; hostnamebaidu=baidu.com&gt; hostnamesina=sina.com&gt; hostnames=truediff test3/log2014.log test6/log2014.log1,12d0&lt; 2013-01&lt; 2013-02&lt; 2014-03&lt; 2013-04&lt; 2013-05&lt; 2013-06&lt; 2013-07&lt; 2013-07&lt; 2013-09&lt; 2013-10&lt; 2013-11&lt; 2013-12Only in test6: log2015.logOnly in test6: log2016.logOnly in test6: log2017.log 6）比较两个文件不同，并生产补丁 123456789101112131415161718192021222324# diff -ruN log2013.log log2014.log &gt;patch.log# ll总计 12-rw-r--r-- 2 root root 80 12-07 16:36 log2013.log-rw-r--r-- 1 root root 96 12-07 18:01 log2014.log-rw-r--r-- 1 root root 248 12-07 21:33 patch.log# cat patch.log --- log2013.log 2012-12-07 16:36:26.000000000 +0800+++ log2014.log 2012-12-07 18:01:54.000000000 +0800@@ -1,10 +1,12 @@ 2013-01 2013-02-2013-03+2014-03 2013-04 2013-05 2013-06 2013-07-2013-08+2013-07 2013-09 2013-10+2013-11+2013-12 7）打补丁 1234567891011121314151617181920212223242526# cat log2013.log2013-012013-022013-032013-042013-052013-062013-072013-082013-092013-10# patch log2013.log patch.log patching file log2013.log# cat log2013.log 2013-012013-022014-032013-042013-052013-062013-072013-072013-092013-102013-112013-12 参考链接： http://www.cnblogs.com/peida/archive/2012/12/12/2814048.html http://man.linuxde.net/diff]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-df命令]]></title>
    <url>%2F2018%2F09%2F29%2FLinux%E5%91%BD%E4%BB%A4-df%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[df命令用于显示磁盘分区上的可使用的磁盘空间。默认显示单位为KB。可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。 语法df(选项)(参数) 选项12345678910111213141516-a或--all：包含全部的文件系统；--block-size=&lt;区块大小&gt;：以指定的区块大小来显示区块数目；-h或--human-readable：以可读性较高的方式来显示信息；-H或--si：与-h参数相同，但在计算时是以1000 Bytes为换算单位而非1024 Bytes；-i或--inodes：显示inode的信息；-k或--kilobytes：指定区块大小为1024字节；-l或--local：仅显示本地端的文件系统；-m或--megabytes：指定区块大小为1048576字节；--no-sync：在取得磁盘使用信息前，不要执行sync指令，此为预设值；-P或--portability：使用POSIX的输出格式；--sync：在取得磁盘使用信息前，先执行sync指令；-t&lt;文件系统类型&gt;或--type=&lt;文件系统类型&gt;：仅显示指定文件系统类型的磁盘信息；-T或--print-type：显示文件系统的类型；-x&lt;文件系统类型&gt;或--exclude-type=&lt;文件系统类型&gt;：不要显示指定文件系统类型的磁盘信息；--help：显示帮助；--version：显示版本信息。 参数文件： 指定文件系统上的文件 常用实例1）查看系统磁盘设备，默认是KB为单位： 123456# df文件系统 1K-块 已用 可用 已用% 挂载点/dev/sda2 146294492 28244432 110498708 21% //dev/sda1 1019208 62360 904240 7% /boottmpfs 1032204 0 1032204 0% /dev/shm/dev/sdb1 2884284108 218826068 2518944764 8% /data1 2）使用-h选项以KB以上的单位来显示，可读性高： 123456# df -h文件系统 容量 已用 可用 已用% 挂载点/dev/sda2 140G 27G 106G 21% //dev/sda1 996M 61M 884M 7% /boottmpfs 1009M 0 1009M 0% /dev/shm/dev/sdb1 2.7T 209G 2.4T 8% /data1 3）查看全部文件系统： 12345678910# df -a文件系统 1K-块 已用 可用 已用% 挂载点/dev/sda2 146294492 28244432 110498708 21% /proc 0 0 0 - /procsysfs 0 0 0 - /sysdevpts 0 0 0 - /dev/pts/dev/sda1 1019208 62360 904240 7% /boottmpfs 1032204 0 1032204 0% /dev/shm/dev/sdb1 2884284108 218826068 2518944764 8% /data1none 0 0 0 - /proc/sys/fs/binfmt_misc 转载链接： http://man.linuxde.net/df]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-du命令]]></title>
    <url>%2F2018%2F09%2F29%2FLinux%E5%91%BD%E4%BB%A4-du%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[du命令也是查看使用空间的，但是与df命令不同的是Linux du命令是对文件和目录磁盘使用的空间的查看，还是和df命令有一些区别的。 语法du [选项][文件] 选项123456789101112131415-a或-all 显示目录中个别文件的大小。-b或-bytes 显示目录或文件大小时，以byte为单位。-c或--total 除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和。-k或--kilobytes 以KB(1024bytes)为单位输出。-m或--megabytes 以MB为单位输出。-s或--summarize 仅显示总计，只列出最后加总的值。-h或--human-readable 以K，M，G为单位，提高信息的可读性。-x或--one-file-xystem 以一开始处理时的文件系统为准，若遇上其它不同的文件系统目录则略过。-L&lt;符号链接&gt;或--dereference&lt;符号链接&gt; 显示选项中所指定符号链接的源文件大小。-S或--separate-dirs 显示个别目录的大小时，并不含其子目录的大小。-X&lt;文件&gt;或--exclude-from=&lt;文件&gt; 在&lt;文件&gt;指定目录或文件。--exclude=&lt;目录或文件&gt; 略过指定的目录或文件。-D或--dereference-args 显示指定符号链接的源文件大小。-H或--si 与-h参数相同，但是K，M，G是以1000为换算单位。-l或--count-links 重复计算硬件链接的文件。 常用实例1）显示目录或者文件所占空间 12345678910111213# du608 ./test6308 ./test44 ./scf/lib4 ./scf/service/deploy/product4 ./scf/service/deploy/info12 ./scf/service/deploy16 ./scf/service4 ./scf/doc4 ./scf/bin32 ./scf8 ./test31288 . 说明： 只显示当前目录下面的子目录的目录大小和当前目录的总的大小，最下面的1288为当前目录的总大小 2）显示指定文件所占空间 12# du log2012.log 300 log2012.log 3）查看指定目录的所占空间 123456789# du scf4 scf/lib4 scf/service/deploy/product4 scf/service/deploy/info12 scf/service/deploy16 scf/service4 scf/doc4 scf/bin32 scf 4）显示多个文件所占空间 123# du log30.tar.gz log31.tar.gz 4 log30.tar.gz4 log31.tar.gz 5）只显示总和的大小 1234567# du -s1288 .# du -s scf32 scf# cd ..# du -s test1288 test 6）方便阅读的格式显示 123456# du -h test608K test/test6308K test/test44.0K test/scf/lib4.0K test/scf/service/deploy/product4.0K test/scf/service/deploy/info 7）文件和目录都显示 123456789101112# du -ah test4.0K test/log31.tar.gz4.0K test/test13.tar.gz0 test/linklog.log0 test/test6/log2014.log300K test/test6/linklog.log0 test/test6/log2015.log4.0K test/test6/log2013.log300K test/test6/log2012.log0 test/test6/log2017.log0 test/test6/log2016.log608K test/test6 8）显示几个文件或目录各自占用磁盘空间的大小，还统计它们的总和 1234# du -c log30.tar.gz log31.tar.gz 4 log30.tar.gz4 log31.tar.gz8 总计 说明： 加上-c选项后，du不仅显示两个目录各自占用磁盘空间的大小，还在最后一行统计它们的总和。 9）按照空间大小排序 1234567# du|sort -nr|more1288 .608 ./test6308 ./test432 ./scf16 ./scf/service12 ./scf/service/deploy 10）输出当前目录下各个子目录所使用的空间 123456# du -h --max-depth=1608K ./test6308K ./test432K ./scf8.0K ./test31.3M . 参考链接： http://www.cnblogs.com/peida/archive/2012/12/10/2810755.html http://man.linuxde.net/du]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-gzip命令]]></title>
    <url>%2F2018%2F09%2F29%2FLinux%E5%91%BD%E4%BB%A4-gzip%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[gzip命令用来压缩文件。gzip是个使用广泛的压缩程序，文件经它压缩过后，其名称后面会多处“.gz”扩展名。 gzip是在Linux系统中经常使用的一个对文件进行压缩和解压缩的命令，既方便又好用。gzip不仅可以用来压缩大的、较少使用的文件以节省磁盘空间，还可以和tar命令一起构成Linux操作系统中比较流行的压缩文件格式。据统计，gzip命令对文本文件有60%～70%的压缩率。减少文件大小有两个明显的好处，一是可以减少存储空间，二是通过网络传输文件时，可以减少传输的时间。 语法gzip(选项)(参数) 选项1234567891011121314151617-a或——ascii：使用ASCII文字模式；-d或--decompress或----uncompress：解开压缩文件；-f或——force：强行压缩文件。不理会文件名称或硬连接是否存在以及该文件是否为符号连接；-h或——help：在线帮助；-l或——list：列出压缩文件的相关信息；-L或——license：显示版本与版权信息；-n或--no-name：压缩文件时，不保存原来的文件名称及时间戳记；-N或——name：压缩文件时，保存原来的文件名称及时间戳记；-q或——quiet：不显示警告信息；-r或——recursive：递归处理，将指定目录下的所有文件及子目录一并处理；-S或&lt;压缩字尾字符串&gt;或----suffix&lt;压缩字尾字符串&gt;：更改压缩字尾字符串；-t或——test：测试压缩文件是否正确无误；-v或——verbose：显示指令执行过程；-V或——version：显示版本信息；-&lt;压缩效率&gt;：压缩效率是一个介于1~9的数值，预设值为“6”，指定愈大的数值，压缩效率就会愈高；--best：此参数的效果和指定“-9”参数相同；--fast：此参数的效果和指定“-1”参数相同。 参数文件列表：指定要压缩的文件列表。 常用范例1）把test6目录下的每个文件压缩成.gz文件 1234567891011# ll总计 604---xr--r-- 1 root mail 302108 11-30 08:39 linklog.log---xr--r-- 1 mail users 302108 11-30 08:39 log2012.log-rw-r--r-- 1 mail users 61 11-30 08:39 log2013.log# gzip *# ll总计 28---xr--r-- 1 root mail 1341 11-30 08:39 linklog.log.gz---xr--r-- 1 mail users 1341 11-30 08:39 log2012.log.gz-rw-r--r-- 1 mail users 70 11-30 08:39 log2013.log.gz 2）把例1中每个压缩的文件解压，并列出详细的信息 1234567891011121314# ll总计 28---xr--r-- 1 root mail 1341 11-30 08:39 linklog.log.gz---xr--r-- 1 mail users 1341 11-30 08:39 log2012.log.gz-rw-r--r-- 1 mail users 70 11-30 08:39 log2013.log.gz# gzip -dv *linklog.log.gz: 99.6% -- replaced with linklog.loglog2012.log.gz: 99.6% -- replaced with log2012.loglog2013.log.gz: 47.5% -- replaced with log2013.log# ll总计 604---xr--r-- 1 root mail 302108 11-30 08:39 linklog.log---xr--r-- 1 mail users 302108 11-30 08:39 log2012.log-rw-r--r-- 1 mail users 61 11-30 08:39 log2013.log 3）详细显示例1中每个压缩的文件的信息，并不解压 12345# gzip -l * compressed uncompressed ratio uncompressed_name 1341 302108 99.6% linklog.log 1341 302108 99.6% log2012.log 70 61 47.5% log2013.log 4）压缩一个tar备份文件，此时压缩文件的扩展名为.tar.gz 12345#ls -al log.tar-rw-r--r-- 1 root root 307200 11-29 17:54 log.tar# gzip -r log.tar# ls -al log.tar.gz -rw-r--r-- 1 root root 1421 11-29 17:54 log.tar.gz 5）递归的压缩目录 12345678910111213141516# ll总计 604---xr--r-- 1 root mail 302108 11-30 08:39 linklog.log---xr--r-- 1 mail users 302108 11-30 08:39 log2012.log-rw-r--r-- 1 mail users 61 11-30 08:39 log2013.log# cd ..# gzip -rv test6test6/linklog.log: 99.6% -- replaced with test6/linklog.log.gztest6/log2013.log: 47.5% -- replaced with test6/log2013.log.gztest6/log2012.log: 99.6% -- replaced with test6/log2012.log.gz# cd test6# ll总计 28---xr--r-- 1 root mail 1341 11-30 08:39 linklog.log.gz---xr--r-- 1 mail users 1341 11-30 08:39 log2012.log.gz-rw-r--r-- 1 mail users 70 11-30 08:39 log2013.log.gz 说明： 这样，所有test下面的文件都变成了.gz，目录依然存在只是目录里面的文件相应变成了.gz.这就是压缩，和打包不同。因为是对目录操作，所以需要加上-r选项，这样也可以对子目录进行递归了。 6）递归地解压目录 12345678910111213# ll总计 28---xr--r-- 1 root mail 1341 11-30 08:39 linklog.log.gz---xr--r-- 1 mail users 1341 11-30 08:39 log2012.log.gz-rw-r--r-- 1 mail users 70 11-30 08:39 log2013.log.gz# cd ..# gzip -dr test6# cd test6# ll总计 604---xr--r-- 1 root mail 302108 11-30 08:39 linklog.log---xr--r-- 1 mail users 302108 11-30 08:39 log2012.log-rw-r--r-- 1 mail users 61 11-30 08:39 log2013.log 参考链接： http://www.cnblogs.com/peida/archive/2012/12/06/2804323.html http://man.linuxde.net/gzip]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-/etc/group文件详解]]></title>
    <url>%2F2018%2F09%2F28%2FLinux%E5%91%BD%E4%BB%A4-etc-group%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Linux /etc/group文件与/etc/passwd和/etc/shadow文件都是有关于系统管理员对用户和用户组管理时相关的文件。linux /etc/group文件是有关于系统管理员对用户和用户组管理的文件,linux用户组的所有信息都存放在/etc/group文件中。具有某种共同特征的用户集合起来就是用户组（Group）。用户组（Group）配置文件主要有 /etc/group和/etc/gshadow，其中/etc/gshadow是/etc/group的加密信息文件。 将用户分组是Linux系统中对用户进行管理及控制访问权限的一种手段。每个用户都属于某个用户组；一个组中可以有多个用户，一个用户也可以属于不同的组。当一个用户同时是多个组中的成员时，在/etc/passwd文件中记录的是用户所属的主组，也就是登录时所属的默认组，而其他组称为附加组。 用户组的所有信息都存放在/etc/group文件中。此文件的格式是由冒号(:)隔开若干个字段，这些字段具体如下： 组名:口令:组标识号:组内用户列表 具体解释 组名：组名是用户组的名称，由字母或数字构成。与/etc/passwd中的登录名一样，组名不应重复。 口令：口令字段存放的是用户组加密后的口令字。一般Linux系统的用户组都没有口令，即这个字段一般为空，或者是*。 组标识号：组标识号与用户标识号类似，也是一个整数，被系统内部用来标识组。别称GID. 组内用户列表：属于这个组的所有用户的列表，不同用户之间用逗号(,)分隔。这个用户组可能是用户的主组，也可能是附加组。 使用实例12345# cat /etc/grouproot:x:0:root,linuxsirbin:x:1:root,bin,daemondaemon:x:2:root,bin,daemonsys:x:3:root,bin 说明： 我们以root:\x:0:root,linuxsir 为例： 用户组root，x是密码段，表示没有设置密码，GID是0,root用户组下包括root、linuxsir以及GID为0的其它用户。 转载链接： http://www.cnblogs.com/peida/archive/2012/12/05/2802419.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-chown命令]]></title>
    <url>%2F2018%2F09%2F28%2FLinux%E5%91%BD%E4%BB%A4-chown%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[chown将指定文件的拥有者改为指定的用户或组，用户可以是用户名或者用户ID；组可以是组名或者组ID；文件是以空格分开的要改变权限的文件列表，支持通配符。系统管理员经常使用chown命令，在将文件拷贝到另一个用户的名录下之后，让用户拥有使用该文件的权限。 语法chown(选项)(参数) 选项123456789-c或——changes：效果类似“-v”参数，但仅回报更改的部分；-f或--quite或——silent：不显示错误信息；-h或--no-dereference：只对符号连接的文件作修改，而不更改其他任何相关文件；-R或——recursive：递归处理，将指定目录下的所有文件及子目录一并处理；-v或——version：显示指令执行过程；--dereference：效果和“-h”参数相同；--help：在线帮助；--reference=&lt;参考文件或目录&gt;：把指定文件或目录的拥有者与所属群组全部设成和参考文件或目录的拥有者与所属群组相同；--version：显示版本信息。 参数用户：组：指定所有者和所属工作组。当省略“：组”，仅改变文件所有者；文件：指定要改变所有者和工作组的文件列表。支持多个文件和目标，支持shell通配符。 功能通过chown改变文件的拥有者和群组。在更改文件的所有者或所属群组时，可以使用用户名称和用户识别码设置。普通用户不能将自己的文件改变成其他的拥有者。其操作权限一般为管理员。 常用实例1）改变拥有者和群组 1234567# ll---xr--r-- 1 root users 302108 11-30 08:39 linklog.log---xr--r-- 1 root users 302108 11-30 08:39 log2012.log# chown mail:mail log2012.log # ll---xr--r-- 1 root users 302108 11-30 08:39 linklog.log---xr--r-- 1 mail mail 302108 11-30 08:39 log2012.log 2）改变文件拥有者 123456789ll总计 604---xr--r-- 1 root users 302108 11-30 08:39 linklog.log---xr--r-- 1 mail mail 302108 11-30 08:39 log2012.log# chown root: log2012.log # ll总计 604---xr--r-- 1 root users 302108 11-30 08:39 linklog.log---xr--r-- 1 root mail 302108 11-30 08:39 log2012.log 3）改变文件群组 123456789# ll总计 604---xr--r-- 1 root users 302108 11-30 08:39 linklog.log---xr--r-- 1 root root 302108 11-30 08:39 log2012.log# chown :mail log2012.log # ll总计 604---xr--r-- 1 root users 302108 11-30 08:39 linklog.log---xr--r-- 1 root mail 302108 11-30 08:39 log2012.log 4）改变指定目录以及其子目录下的所有文件的拥有者和群组 1234567891011121314151617181920212223# lldrwxr-xr-x 2 root users 4096 11-30 08:39 test6# chown -R -v root:mail test6“test6/log2014.log” 的所有者已更改为 root:mail“test6/linklog.log” 的所有者已更改为 root:mail“test6/log2015.log” 的所有者已更改为 root:mail“test6/log2013.log” 的所有者已更改为 root:mail“test6/log2012.log” 的所有者已保留为 root:mail“test6/log2017.log” 的所有者已更改为 root:mail“test6/log2016.log” 的所有者已更改为 root:mail“test6” 的所有者已更改为 root:mail# lldrwxr-xr-x 2 root mail 4096 11-30 08:39 test6# cd test6# ll总计 604---xr--r-- 1 root mail 302108 11-30 08:39 linklog.log---xr--r-- 1 root mail 302108 11-30 08:39 log2012.log-rw-r--r-- 1 root mail 61 11-30 08:39 log2013.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2014.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2015.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2016.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2017.log 参考链接： http://www.cnblogs.com/peida/archive/2012/12/04/2800684.html http://man.linuxde.net/chown]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-chgrp命令]]></title>
    <url>%2F2018%2F09%2F28%2FLinux%E5%91%BD%E4%BB%A4-chgrp%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[chgrp命令用来改变文件或目录所属的用户组。该命令用来改变指定文件所属的用户组。其中，组名可以是用户组的id，也可以是用户组的组名。文件名可以 是由空格分开的要改变属组的文件列表，也可以是由通配符描述的文件集合。如果用户不是该文件的文件主或超级用户(root)，则不能改变该文件的组。 在UNIX系统家族里，文件或目录权限的掌控以拥有者及所属群组来管理。您可以使用chgrp指令去变更文件与目录的所属群组，设置方式采用群组名称或群组识别码皆可。 语法chgrp(选项)(参数) 选项123456-c或——changes：效果类似“-v”参数，但仅回报更改的部分；-f或--quiet或——silent：不显示错误信息；-h或--no-dereference：只对符号连接的文件作修改，而不是该其他任何相关文件；-R或——recursive：递归处理，将指令目录下的所有文件及子目录一并处理；-v或——verbose：显示指令执行过程；--reference=&lt;参考文件或目录&gt;：把指定文件或目录的所属群组全部设成和参考文件或目录的所属群组相同； 参数组：指定新工作名称 文件： 指定要改变所属组的文件 常用实例将/usr/meng及其子目录下的所有文件的用户组改为mengxin 1chgrp -R mengxin /usr/meng 转载地址： http://man.linuxde.net/chgrp]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-tar命令]]></title>
    <url>%2F2018%2F09%2F26%2FLinux%E5%91%BD%E4%BB%A4-tar%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[tar命令可以为linux的文件和目录创建档案。利用tar，可以为某一特定文件创建档案（备份文件），也可以在档案中改变文件，或者向档案中加入新的文件。tar最初被用来在磁带上创建档案，现在，用户可以在任何设备上创建档案。利用tar命令，可以把一大堆的文件和目录全部打包成一个文件，这对于备份文件或将几个文件组合成为一个文件以便于网络传输是非常有用的。 首先要弄清两个概念：打包和压缩。打包时指将一大堆文件或目录变成为一个总的文件；压缩则是将一个大的文件通过一些压缩算法变成一个小文件。 为什么要区分这两个概念呢？这源于Linux中很多压缩程序只能针对一个文件进行压缩，这样当你想要压缩一大堆文件时，你得先将这一大堆文件先打成一个包（tar命令），然后再用压缩程序进行压缩（gzip bzip2命令）。 语法tar(选项)(参数) 选项1234567891011121314151617181920212223-A或--catenate：新增文件到以存在的备份文件；-B：设置区块大小；-c或--create：建立新的备份文件；-C &lt;目录&gt;：这个选项用在解压缩，若要在特定目录解压缩，可以使用这个选项。-d：记录文件的差别；-x或--extract或--get：从备份文件中还原文件；-t或--list：列出备份文件的内容；-z或--gzip或--ungzip：通过gzip指令处理备份文件；-Z或--compress或--uncompress：通过compress指令处理备份文件；-f&lt;备份文件&gt;或--file=&lt;备份文件&gt;：指定备份文件；-v或--verbose：显示指令执行过程；-r：添加文件到已经压缩的文件；-u：添加改变了和现有的文件到已经存在的压缩文件；-j：支持bzip2解压文件；-v：显示操作过程；-l：文件系统边界设置；-k：保留原有文件不覆盖；-m：保留文件不被覆盖；-w：确认压缩文件的正确性；-p或--same-permissions：用原来的文件权限还原文件；-P或--absolute-names：文件名使用绝对名称，不移除文件名称前的“/”号；-N &lt;日期格式&gt; 或 --newer=&lt;日期时间&gt;：只将较指定日期更新的文件保存到备份文件里；--exclude=&lt;范本样式&gt;：排除符合范本样式的文件。 参数文件或目录：指定要打包的文件或目录列表。 常用实例1）将文件全部打包成tar包： 123tar -cvf log.tar log2012.log 仅打包，不压缩！ tar -zcvf log.tar.gz log2012.log 打包后，以 gzip 压缩 tar -jcvf log.tar.bz2 log2012.log 打包后，以 bzip2 压缩 在选项f之后的文件档名是自己取的，我们习惯上都用 .tar 来作为辨识。 如果加z选项，则以.tar.gz或.tgz来代表gzip压缩过的tar包；如果加j选项，则以.tar.bz2来作为tar包名。 2）查阅上述tar包内有哪些文件： 1tar -ztvf log.tar.gz 由于我们使用 gzip 压缩的log.tar.gz，所以要查阅log.tar.gz包内的文件时，就得要加上z这个选项了。 3）将tar包解压缩： 1tar -zxvf /opt/soft/test/log.tar.gz 在预设的情况下，我们可以将压缩档在任何地方解开的 4）只将tar内的部分文件解压出来： 1tar -zxvf /opt/soft/test/log30.tar.gz log2013.log 5）文件备份下来，并且保存其权限： 1tar -zcvpf log31.tar.gz log2014.log log2015.log log2016.log 这个-p的属性是很重要的，尤其是当您要保留原本文件的属性时。 6）在文件夹当中，比某个日期新的文件才备份： 1tar -N &quot;2012/11/13&quot; -zcvf log17.tar.gz test 7）备份文件夹内容是排除部分文件： 1tar --exclude scf/service -zcvf scf.tar.gz scf/* 8）其实最简单的使用 tar 就只要记忆底下的方式即可： 123压 缩：tar -jcv -f filename.tar.bz2 要被压缩的文件或目录名称查 询：tar -jtv -f filename.tar.bz2解压缩：tar -jxv -f filename.tar.bz2 -C 欲解压缩的目录 转载链接： http://man.linuxde.net/tar]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-chmod命令]]></title>
    <url>%2F2018%2F09%2F26%2FLinux%E5%91%BD%E4%BB%A4-chmod%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[chmod命令用于改变linux系统文件或目录的访问权限。用它控制文件或目录的访问权限。该命令有两种用法。一种是包含字母和操作符表达式的文字设定法；另一种是包含数字的数字设定法。 权限范围的表示法如下： u User，即文件或目录的拥有者；g Group，即文件或目录的所属群组；o Other，除了文件或目录拥有者或所属群组之外，其他用户皆属于这个范围；a All，即全部的用户，包含拥有者，所属群组以及其他用户；r 读取权限，数字代号为“4”;w 写入权限，数字代号为“2”；x 执行或切换权限，数字代号为“1”；- 不具任何权限，数字代号为“0”；s 特殊功能说明：变更文件或目录的权限。 语法chmod(选项)(参数) 选项1234-c或——changes：效果类似“-v”参数，但仅回报更改的部分；-f或--quiet或——silent：不显示错误信息；-R或——recursive：递归处理，将指令目录下的所有文件及子目录一并处理；-v或——verbose：显示指令执行过程； 参数权限模式：指定文件的权限模式；文件：要改变权限的文件。 知识扩展和实例Linux用 户分为：拥有者、组群(Group)、其他（other），Linux系统中，预设的情況下，系统中所有的帐号与一般身份使用者，以及root的相关信 息， 都是记录在/etc/passwd文件中。每个人的密码则是记录在/etc/shadow文件下。 此外，所有的组群名称记录在/etc/group內！ linux文件的用户权限的分析图 例：rwx rw- r– r=读取属性 //值＝4w=写入属性 //值＝2x=执行属性 //值＝1 1234chmod u+x,g+w f01 //为文件f01设置自己可以执行，组员可以写入的权限chmod u=rwx,g=rw,o=r f01chmod 764 f01chmod a+x f01 //对文件f01的u,g,o都设置可执行属性 文件的属主和属组属性设置 12chown user:market f01 //把文件f01给uesr，添加到market组ll -d f1 查看目录f1的属性 参考链接： http://man.linuxde.net/chmod http://www.cnblogs.com/peida/archive/2012/11/29/2794010.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux文件属性详解]]></title>
    <url>%2F2018%2F09%2F26%2FLinux%E6%96%87%E4%BB%B6%E5%B1%9E%E6%80%A7%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Linux 文件或目录的属性主要包括：文件或目录的节点、种类、权限模式、链接数量、所归属的用户和用户组、最近访问或修改的时间等内容。具体情况如下： 123456789101112# ls -lih总计 316K2095120 lrwxrwxrwx 1 root root 11 11-22 06:58 linklog.log -&gt; log2012.log2095112 -rw-r--r-- 1 root root 296K 11-13 06:03 log2012.log2095110 -rw-r--r-- 1 root root 61 11-13 06:03 log2013.log2095107 -rw-r--r-- 1 root root 0 11-13 06:03 log2014.log2095117 -rw-r--r-- 1 root root 0 11-13 06:06 log2015.log2095118 -rw-r--r-- 1 root root 0 11-16 14:41 log2016.log2095119 -rw-r--r-- 1 root root 0 11-16 14:43 log2017.log2095113 drwxr-xr-x 6 root root 4.0K 10-27 01:58 scf2095109 drwxrwxr-x 2 root root 4.0K 11-13 06:08 test32095131 drwxrwxr-x 2 root root 4.0K 11-13 05:50 test4 说明： 第一列：inode 第二列：文件种类和权限； 第三列： 硬链接个数； 第四列： 属主； 第五列：所归属的组； 第六列：文件或目录的大小； 第七列和第八列：最后访问或修改时间； 第九列：文件名或目录名 我们以log2012.log为例： 2095112 -rw-r–r– 1 root root 296K 11-13 06:03 log2012.log inode 的值是：2095112 文件类型：文件类型是-，表示这是一个普通文件； 关于文件的类型，请参考：每天一个linux命令(24)：Linux文件类型与扩展名 文件权限：文件权限是rw-r–r– ，表示文件属主可读、可写、不可执行，文件所归属的用户组不可写，可读，不可执行，其它用户不可写，可读，不可执行； 硬链接个数： log2012.log这个文件没有硬链接；因为数值是1，就是他本身； 文件属主：也就是这个文件归哪于哪个用户 ，它归于root，也就是第一个root； 文件属组：也就是说，对于这个文件，它归属于哪个用户组，在这里是root用户组； 文件大小：文件大小是296k个字节； 访问可修改时间 ：这里的时间是最后访问的时间，最后访问和文件被修改或创建的时间，有时并不是一致的； 当然文档的属性不仅仅包括这些，这些是我们最常用的一些属性。 关于inode： inode 译成中文就是索引节点。每个存储设备或存储设备的分区（存储设备是硬盘、软盘、U盘等等）被格式化为文件系统后，应该有两部份，一部份是inode，另一部份是Block，Block是用来存储数据用的。而inode呢，就是用来存储这些数 据的信息，这些信息包括文件大小、属主、归属的用户组、读写权限等。inode为每个文件进行信息索引，所以就有了inode的数值。操作系统根据指令， 能通过inode值最快的找到相对应的文件。 做个比喻，比如一本书，存储设备或分区就相当于这本书，Block相当于书中的每一页，inode 就相当于这本书前面的目录，一本书有很多的内容，如果想查找某部份的内容，我们可以先查目录，通过目录能最快的找到我们想要看的内容。虽然不太恰当，但还是比较形象。 当我们用ls 查看某个目录或文件时，如果加上-i 参数，就可以看到inode节点了；比如我们前面所说的例子： 12ls -li log2012.log# ls -li log2012.log 2095112 -rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log log2012.log 的inode值是 2095112 ； 查看一个文件或目录的inode，要通过ls 命令的的 -i参数。 转载链接： http://www.cnblogs.com/peida/archive/2012/11/23/2783762.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux文件类型与拓展名]]></title>
    <url>%2F2018%2F09%2F26%2FLinux%E6%96%87%E4%BB%B6%E7%B1%BB%E5%9E%8B%E4%B8%8E%E6%8B%93%E5%B1%95%E5%90%8D%2F</url>
    <content type="text"><![CDATA[Linux文件类型和Linux文件的文件名所代表的意义是两个不同的概念。我们通过一般应用程序而创建的比如file.txt、file.tar.gz ，这些文件虽然要用不同的程序来打开，但放在Linux文件类型中衡量的话，大多是常规文件（也被称为普通文件）。 文件类型Linux文件类型常见的有：普通文件、目录文件、字符设备文件和块设备文件、符号链接文件等，现在我们进行一个简要的说明。 普通文件我们用 ls -lh 来查看某个文件的属性，可以看到有类似-rwxrwxrwx，值得注意的是第一个符号是 - ，这样的文件在Linux中就是普通文件。这些文件一般是用一些相关的应用程序创建，比如图像工具、文档工具、归档工具… …. 或 cp工具等。这类文件的删除方式是用rm 命令。 另外，依照文件的内容，又大略可以分为： 1）纯文本档（ASCII）： 这是linux系统中最多的一种文件类型，称为纯文本档是因为人类可以直接读到的数据，例如数字、字母等等。几乎只要我们可以用来做为设定的文件都属于这一种文件类型。举例来说，你可以用命令： cat ~/.bashrc 来看到该文件内容。（cat是将一个文件内容读出来的指令）。 2） 二进制文件(binary)： Linux系统其实仅认识且可以执行二进制文件(binary file)。Linux当中的可执行文件(scripts, 文字型批处理文件不算)就是这种格式的文件。 刚刚使用的命令cat就是一个binary file。 3）数据格式文件(data)： 有些程序在运作的过程当中会读取某些特定格式的文件，那些特定格式的文件可以被称为数据文件 (data file)。举例来说，我们的Linux在使用者登录时，都会将登录的数据记录在 /var/log/wtmp那个文件内，该文件是一个data file，他能够透过last这个指令读出来！ 但是使用cat时，会读出乱码～因为他是属于一种特殊格式的文件？ 目录文件当我们在某个目录下执行，看到有类似 drwxr-xr-x ，这样的文件就是目录，目录在Linux是一个比较特殊的文件。注意它的第一个字符是d。创建目录的命令可以用 mkdir 命令，或cp命令，cp可以把一个目录复制为另一个目录。删除用rm 或rmdir命令。 字符设备或块设备文件当您进入/dev目录，列一下文件，会看到类似如下的: 1234# ls -al /dev/ttycrw-rw-rw- 1 root tty 5, 0 11-03 15:11 /dev/tty# ls -la /dev/sda1brw-r----- 1 root disk 8, 1 11-03 07:11 /dev/sda1 我们看到/dev/tty的属性是 crw-rw-rw- ，注意前面第一个字符是 c ，这表示字符设备文件。比如猫等串口设备。我们看到 /dev/sda1 的属性是 brw-r—– ，注意前面的第一个字符是b，这表示块设备，比如硬盘，光驱等设备。 这个种类的文件，是用mknode来创建，用rm来删除。目前在最新的Linux发行版本中，我们一般不用自己来创建设备文件。因为这些文件是和内核相关联的。 与系统周边及储存等相关的一些文件， 通常都集中在/dev这个目录之下！通常又分为两种： 区块(block)设备档 ： 就是一些储存数据， 以提供系统随机存取的接口设备，举例来说，硬盘与软盘等就是啦！ 你可以随机的在硬盘的不同区块读写，这种装置就是成组设备！你可以自行查一下/dev/sda看看， 会发现第一个属性为[ b ]！ 字符(character)设备文件： 亦即是一些串行端口的接口设备， 例如键盘、鼠标等等！这些设备的特色就是一次性读取的，不能够截断输出。 举例来说，你不可能让鼠标跳到另一个画面，而是滑动到另一个地方！第一个属性为 [ c ]。 数据接口文件(sockets)：数据接口文件（或者：套接口文件），这种类型的文件通常被用在网络上的数据承接了。我们可以启动一个程序来监听客户端的要求， 而客户端就可以透过这个socket来进行数据的沟通了。第一个属性为 [ s ]， 最常在/var/run这个目录中看到这种文件类型了。 例如：当我们启动MySQL服务器时，会产生一个mysql.sock的文件。 12# ls -lh /var/lib/mysql/mysql.sock srwxrwxrwx 1 mysql mysql 0 04-19 11:12 /var/lib/mysql/mysql.sock 注意这个文件的属性的第一个字符是 s。 符号链接文件：当我们查看文件属性时，会看到有类似 lrwxrwxrwx,注意第一个字符是l，这类文件是链接文件。是通过ln -s 源文件名 新文件名 。上面是一个例子，表示setup.log是install.log的软链接文件。怎么理解呢？这和Windows操作系统中的快捷方式有点相似。 符号链接文件的创建方法举例: 123456# ls -lh log2012.log-rw-r--r-- 1 root root 296K 11-13 06:03 log2012.log# ln -s log2012.log linklog.log# ls -lh *.loglrwxrwxrwx 1 root root 11 11-22 06:58 linklog.log -&gt; log2012.log-rw-r--r-- 1 root root 296K 11-13 06:03 log2012.log 数据输送文件（FIFO,pipe）:FIFO也是一种特殊的文件类型，他主要的目的在解决多个程序同时存取一个文件所造成的错误问题。 FIFO是first-in-first-out的缩写。第一个属性为[p] 。 Linux文件扩展名扩展名类型基本上，Linux的文件是没有所谓的扩展名的，一个Linux文件能不能被执行，与他的第一栏的十个属性有关， 与档名根本一点关系也没有。这个观念跟Windows的情况不相同喔！在Windows底下， 能被执行的文件扩展名通常是 .com .exe .bat等等，而在Linux底下，只要你的权限当中具有x的话，例如[ -rwx-r-xr-x ] 即代表这个文件可以被执行。 不过，可以被执行跟可以执行成功是不一样的～举例来说，在root家目录下的install.log 是一个纯文本档，如果经由修改权限成为 -rwxrwxrwx 后，这个文件能够真的执行成功吗？ 当然不行～因为他的内容根本就没有可以执行的数据。所以说，这个x代表这个文件具有可执行的能力， 但是能不能执行成功，当然就得要看该文件的内容. 虽然如此，不过我们仍然希望可以藉由扩展名来了解该文件是什么东西，所以，通常我们还是会以适当的扩展名来表示该文件是什么种类的。底下有数种常用的扩展名： *.sh ： 脚本或批处理文件 (scripts)，因为批处理文件为使用shell写成的，所以扩展名就编成 .sh Z, .tar, .tar.gz, .zip, *.tgz： 经过打包的压缩文件。这是因为压缩软件分别为 gunzip, tar 等等的，由于不同的压缩软件，而取其相关的扩展名！ .html, .php：网页相关文件，分别代表 HTML 语法与 PHP 语法的网页文件。 .html 的文件可使用网页浏览器来直接开启，至于 .php 的文件， 则可以透过 client 端的浏览器来 server 端浏览，以得到运算后的网页结果。 基本上，Linux系统上的文件名真的只是让你了解该文件可能的用途而已，真正的执行与否仍然需要权限的规范才行。例如虽然有一个文件为可执行文件，如常见的/bin/ls这个显示文件属性的指令，不过，如果这个文件的权限被修改成无法执行时，那么ls就变成不能执行。 上述的这种问题最常发生在文件传送的过程中。例如你在网络上下载一个可执行文件，但是偏偏在你的 Linux系统中就是无法执行！呵呵！那么就是可能文件的属性被改变了。不要怀疑，从网络上传送到你的 Linux系统中，文件的属性与权限确实是会被改变的。 Linux文件名长度限制：在Linux底下，使用预设的Ext2/Ext3文件系统时，针对文件名长度限制为： 单一文件或目录的最大容许文件名为 255 个字符 包含完整路径名称及目录 (/) 之完整档名为 4096 个字符 是相当长的档名！我们希望Linux的文件名可以一看就知道该文件在干嘛的， 所以档名通常是很长很长。 Linux文件名的字符的限制：由于Linux在文字接口下的一些指令操作关系，一般来说，你在设定Linux底下的文件名时， 最好可以避免一些特殊字符比较好！例如底下这些： ? &gt; &lt; ; &amp; ! [ ] | \ ‘ “ ` ( ) { } 因为这些符号在文字接口下，是有特殊意义的。另外，文件名的开头为小数点“.”时， 代表这个文件为隐藏文件！同时，由于指令下达当中，常常会使用到 -option 之类的选项， 所以你最好也避免将文件档名的开头以 - 或 + 来命名。 转载链接： http://www.cnblogs.com/peida/archive/2012/11/22/2781912.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux目录结构]]></title>
    <url>%2F2018%2F09%2F26%2FLinux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[对于每一个Linux学习者来说，了解Linux文件系统的目录结构，是学好Linux的至关重要的一步.，深入了解linux文件目录结构的标准和每个目录的详细功能，对于我们用好linux系统只管重要，下面我们就开始了解一下linux目录结构的相关知识。 当在使用Linux的时候，如果您通过ls –l / 就会发现，在/下包涵很多的目录，比如etc、usr、var、bin … … 等目录，而在这些目录中，我们进去看看，发现也有很多的目录或文件。文件系统在Linux下看上去就象树形结构，所以我们可以把文件系统的结构形象的称为 树形结构。 文件系统的是用来组织和排列文件存取的，所以它是可见的，在Linux中，我们可以通过ls等工具来查看其结构，在Linux系统中，我们见到的都是树形结构；比如操作系统安装在一个文件系统中，他表现为由/ 起始的树形结构。linux文件系统的最顶端是/，我们称/为Linux的root，也就是 Linux操作系统的文件系统。Linux的文件系统的入口就是/，所有的目录、文件、设备都在/之下，/就是Linux文件系统的组织者，也是最上级的领导者。 由于linux是开放源代码，各大公司和团体根据linux的核心代码做各自的操作，编程。这样就造成在根下的目录的不同。这样就造成个人不能使用他人的linux系统的PC。因为你根本不知道一些基本的配置，文件在哪里。。。这就造成了混乱。这就是FHS（Filesystem Hierarchy Standard ）机构诞生的原因。该机构是linux爱好者自发的组成的一个团体，主要是是对linux做一些基本的要求，不至于是操作者换一台主机就成了linux的‘文盲’。 根据FHS(http://www.pathname.com/fhs/)的官方文件指出，) 他们的主要目的是希望让使用者可以了解到已安装软件通常放置于那个目录下， 所以他们希望独立的软件开发商、操作系统制作者、以及想要维护系统的用户，都能够遵循FHS的标准。 也就是说，FHS的重点在于规范每个特定的目录下应该要放置什么样子的数据而已。 这样做好处非常多，因为Linux操作系统就能够在既有的面貌下(目录架构不变)发展出开发者想要的独特风格。 事实上，FHS是根据过去的经验一直再持续的改版的，FHS依据文件系统使用的频繁与否与是否允许使用者随意更动， 而将目录定义成为四种交互作用的形态，用表格来说有点像底下这样： 可分享的(shareable) 不可分享的(unshareable) 不变的(static) /usr (软件放置处) /etc (配置文件) /opt (第三方协力软件) /boot (开机与核心档) 可变动的(variable) /var/mail (使用者邮件信箱) /var/run (程序相关) /var/spool/news (新闻组) /var/lock (程序相关) 四中类型: 可分享的： 可以分享给其他系统挂载使用的目录，所以包括执行文件与用户的邮件等数据， 是能够分享给网络上其他主机挂载用的目录； 不可分享的： 自己机器上面运作的装置文件或者是与程序有关的socket文件等， 由于仅与自身机器有关，所以当然就不适合分享给其他主机了。 不变的： 有些数据是不会经常变动的，跟随着distribution而不变动。 例如函式库、文件说明文件、系统管理员所管理的主机服务配置文件等等； 可变动的： 经常改变的数据，例如登录文件、一般用户可自行收受的新闻组等。 事实上，FHS针对目录树架构仅定义出三层目录底下应该放置什么数据而已，分别是底下这三个目录的定义： / (root, 根目录)：与开机系统有关； /usr (unix software resource)：与软件安装/执行有关； /var (variable)：与系统运作过程有关。 根目录 (/) 的意义与内容：根目录是整个系统最重要的一个目录，因为不但所有的目录都是由根目录衍生出来的， 同时根目录也与开机/还原/系统修复等动作有关。 由于系统开机时需要特定的开机软件、核心文件、开机所需程序、 函式库等等文件数据，若系统出现错误时，根目录也必须要包含有能够修复文件系统的程序才行。 因为根目录是这么的重要，所以在FHS的要求方面，他希望根目录不要放在非常大的分区， 因为越大的分区内你会放入越多的数据，如此一来根目录所在分区就可能会有较多发生错误的机会。 因此FHS标准建议：根目录(/)所在分区应该越小越好， 且应用程序所安装的软件最好不要与根目录放在同一个分区内，保持根目录越小越好。 如此不但效能较佳，根目录所在的文件系统也较不容易发生问题。说白了，就是根目录和Windows的C盘一个样。 根据以上原因，FHS认为根目录(/)下应该包含如下子目录： 目录 应放置档案内容 /bin 系统有很多放置执行档的目录，但/bin比较特殊。因为/bin放置的是在单人维护模式下还能够被操作的指令。在/bin底下的指令可以被root与一般帐号所使用，主要有：cat,chmod(修改权限), chown, date, mv, mkdir, cp, bash等等常用的指令。 /boot 主要放置开机会使用到的档案，包括Linux核心档案以及开机选单与开机所需设定档等等。Linux kernel常用的档名为：vmlinuz ，如果使用的是grub这个开机管理程式，则还会存在/boot/grub/这个目录。 /dev 在Linux系统上，任何装置与周边设备都是以档案的型态存在于这个目录当中。 只要通过存取这个目录下的某个档案，就等于存取某个装置。比要重要的档案有/dev/null, /dev/zero, /dev/tty , /dev/lp, / dev/hd, /dev/sd*等等 /etc 系统主要的设定档几乎都放置在这个目录内，例如人员的帐号密码档、各种服务的启始档等等。 一般来说，这个目录下的各档案属性是可以让一般使用者查阅的，但是只有root有权力修改。 FHS建议不要放置可执行档(binary)在这个目录中。 比较重要的档案有：/etc/inittab, /etc/init.d/, /etc/modprobe.conf, /etc/X11/, /etc/fstab, /etc/sysconfig/等等。 另外，其下重要的目录有：/etc/init.d/ ：所有服务的预设启动script都是放在这里的，例如要启动或者关闭iptables的话： /etc/init.d/iptables start、/etc/init.d/ iptables stop/etc/xinetd.d/ ：这就是所谓的super daemon管理的各项服务的设定档目录。/etc/X11/ ：与X Window有关的各种设定档都在这里，尤其是xorg.conf或XF86Config这两个X Server的设定档。 /home 这是系统预设的使用者家目录(home directory)。 在你新增一个一般使用者帐号时，预设的使用者家目录都会规范到这里来。比较重要的是，家目录有两种代号： ~ ：代表当前使用者的家目录，而 ~guest：则代表用户名为guest的家目录。 /lib 系统的函式库非常的多，而/lib放置的则是在开机时会用到的函式库，以及在/bin或/sbin底下的指令会呼叫的函式库而已 。 什么是函式库呢？妳可以将他想成是外挂，某些指令必须要有这些外挂才能够顺利完成程式的执行之意。 尤其重要的是/lib/modules/这个目录，因为该目录会放置核心相关的模组(驱动程式)。 /media media是媒体的英文，顾名思义，这个/media底下放置的就是可移除的装置。 包括软碟、光碟、DVD等等装置都暂时挂载于此。 常见的档名有：/media/floppy, /media/cdrom等等。 /mnt 如果妳想要暂时挂载某些额外的装置，一般建议妳可以放置到这个目录中。在古早时候，这个目录的用途与/media相同啦。 只是有了/media之后，这个目录就用来暂时挂载用了。 /opt 这个是给第三方协力软体放置的目录 。 什么是第三方协力软体啊？举例来说，KDE这个桌面管理系统是一个独立的计画，不过他可以安装到Linux系统中，因此KDE的软体就建议放置到此目录下了。 另外，如果妳想要自行安装额外的软体(非原本的distribution提供的)，那么也能够将你的软体安装到这里来。 不过，以前的Linux系统中，我们还是习惯放置在/usr/local目录下。 /root 系统管理员(root)的家目录。 之所以放在这里，是因为如果进入单人维护模式而仅挂载根目录时，该目录就能够拥有root的家目录，所以我们会希望root的家目录与根目录放置在同一个分区中。 /sbin Linux有非常多指令是用来设定系统环境的，这些指令只有root才能够利用来设定系统，其他使用者最多只能用来查询而已。放在/sbin底下的为开机过程中所需要的，里面包括了开机、修复、还原系统所需要的指令。至于某些伺服器软体程式，一般则放置到/usr/sbin/当中。至于本机自行安装的软体所产生的系统执行档(system binary)，则放置到/usr/local/sbin/当中了。常见的指令包括：fdisk, fsck, ifconfig, init, mkfs等等。 /srv srv可以视为service的缩写，是一些网路服务启动之后，这些服务所需要取用的资料目录。 常见的服务例如WWW, FTP等等。 举例来说，WWW伺服器需要的网页资料就可以放置在/srv/www/里面。呵呵，看来平时我们编写的代码应该放到这里了。 /tmp 这是让一般使用者或者是正在执行的程序暂时放置档案的地方。这个目录是任何人都能够存取的，所以你需要定期的清理一下。当然，重要资料不可放置在此目录啊。 因为FHS甚至建议在开机时，应该要将/tmp下的资料都删除。 事实上FHS针对根目录所定义的标准就仅限于上表，不过仍旧有些目录也需要我们了解一下，具体如下： 目录 应放置文件内容 /lost+found 这个目录是使用标准的ext2/ext3档案系统格式才会产生的一个目录，目的在于当档案系统发生错误时，将一些遗失的片段放置到这个目录下。 这个目录通常会在分割槽的最顶层存在，例如你加装一个硬盘于/disk中，那在这个系统下就会自动产生一个这样的目录/disk/lost+found /proc 这个目录本身是一个虚拟文件系统(virtual filesystem)喔。 他放置的资料都是在内存当中，例如系统核心、行程资讯(process)（是进程吗?）、周边装置的状态及网络状态等等。因为这个目录下的资料都是在记忆体（内存）当中，所以本身不占任何硬盘空间。比较重要的档案（目录）例如： /proc/cpuinfo, /proc/dma, /proc/interrupts, /proc/ioports, /proc/net/*等等。呵呵，是虚拟内存吗[guest]？ /sys 这个目录其实跟/proc非常类似，也是一个虚拟的档案系统，主要也是记录与核心相关的资讯。 包括目前已载入的核心模组与核心侦测到的硬体装置资讯等等。 这个目录同样不占硬盘容量。 除了这些目录的内容之外，另外要注意的是，因为根目录与开机有关，开机过程中仅有根目录会被挂载， 其他分区则是在开机完成之后才会持续的进行挂载的行为。就是因为如此，因此根目录下与开机过程有关的目录， 就不能够与根目录放到不同的分区去。那哪些目录不可与根目录分开呢？有底下这些： /etc：配置文件 /bin：重要执行档 /dev：所需要的装置文件 /lib：执行档所需的函式库与核心所需的模块 /sbin：重要的系统执行文件 这五个目录千万不可与根目录分开在不同的分区。请背下来啊。 /usr 的意义与内容：依据FHS的基本定义，/usr里面放置的数据属于可分享的与不可变动的(shareable, static)， 如果你知道如何透过网络进行分区的挂载(例如在服务器篇会谈到的NFS服务器)，那么/usr确实可以分享给局域网络内的其他主机来使用喔。 /usr不是user的缩写，其实usr是Unix Software Resource的缩写， 也就是Unix操作系统软件资源所放置的目录，而不是用户的数据啦。这点要注意。 FHS建议所有软件开发者，应该将他们的数据合理的分别放置到这个目录下的次目录，而不要自行建立该软件自己独立的目录。 因为是所有系统默认的软件(distribution发布者提供的软件)都会放置到/usr底下，因此这个目录有点类似Windows 系统的C:\Windows\ + C:\Program files\这两个目录的综合体，系统刚安装完毕时，这个目录会占用最多的硬盘容量。 一般来说，/usr的次目录建议有底下这些： 目录 应放置文件内容 /usr/X11R6/ 为X Window System重要数据所放置的目录，之所以取名为X11R6是因为最后的X版本为第11版，且该版的第6次释出之意。 /usr/bin/ 绝大部分的用户可使用指令都放在这里。请注意到他与/bin的不同之处。(是否与开机过程有关) /usr/include/ c/c++等程序语言的档头(header)与包含档(include)放置处，当我们以tarball方式 (*.tar.gz 的方式安装软件)安装某些数据时，会使用到里头的许多包含档。 /usr/lib/ 包含各应用软件的函式库、目标文件(object file)，以及不被一般使用者惯用的执行档或脚本(script)。 某些软件会提供一些特殊的指令来进行服务器的设定，这些指令也不会经常被系统管理员操作， 那就会被摆放到这个目录下啦。要注意的是，如果你使用的是X86_64的Linux系统， 那可能会有/usr/lib64/目录产生 /usr/local/ 统管理员在本机自行安装自己下载的软件(非distribution默认提供者)，建议安装到此目录， 这样会比较便于管理。举例来说，你的distribution提供的软件较旧，你想安装较新的软件但又不想移除旧版， 此时你可以将新版软件安装于/usr/local/目录下，可与原先的旧版软件有分别啦。 你可以自行到/usr/local去看看，该目录下也是具有bin, etc, include, lib…的次目录 /usr/sbin/ 非系统正常运作所需要的系统指令。最常见的就是某些网络服务器软件的服务指令(daemon) /usr/share/ 放置共享文件的地方，在这个目录下放置的数据几乎是不分硬件架构均可读取的数据， 因为几乎都是文本文件嘛。在此目录下常见的还有这些次目录：/usr/share/man：联机帮助文件/usr/share/doc：软件杂项的文件说明/usr/share/zoneinfo：与时区有关的时区文件 /usr/src/ 一般原始码建议放置到这里，src有source的意思。至于核心原始码则建议放置到/usr/src/linux/目录下。 /var 的意义与内容：如果/usr是安装时会占用较大硬盘容量的目录，那么/var就是在系统运作后才会渐渐占用硬盘容量的目录。 因为/var目录主要针对常态性变动的文件，包括缓存(cache)、登录档(log file)以及某些软件运作所产生的文件， 包括程序文件(lock file, run file)，或者例如MySQL数据库的文件等等。常见的次目录有： 目录 应放置文件内容 /var/cache/ 应用程序本身运作过程中会产生的一些暂存档 /var/lib/ 程序本身执行的过程中，需要使用到的数据文件放置的目录。在此目录下各自的软件应该要有各自的目录。 举例来说，MySQL的数据库放置到/var/lib/mysql/而rpm的数据库则放到/var/lib/rpm去 /var/lock/ 某些装置或者是文件资源一次只能被一个应用程序所使用，如果同时有两个程序使用该装置时， 就可能产生一些错误的状况，因此就得要将该装置上锁(lock)，以确保该装置只会给单一软件所使用。 举例来说，刻录机正在刻录一块光盘，你想一下，会不会有两个人同时在使用一个刻录机烧片？ 如果两个人同时刻录，那片子写入的是谁的数据？所以当第一个人在刻录时该刻录机就会被上锁， 第二个人就得要该装置被解除锁定(就是前一个人用完了)才能够继续使用 /var/log/ 非常重要。这是登录文件放置的目录。里面比较重要的文件如/var/log/messages, /var/log/wtmp(记录登入者的信息)等。 /var/mail/ 放置个人电子邮件信箱的目录，不过这个目录也被放置到/var/spool/mail/目录中，通常这两个目录是互为链接文件。 /var/run/ 某些程序或者是服务启动后，会将他们的PID放置在这个目录下 /var/spool/ 这个目录通常放置一些队列数据，所谓的“队列”就是排队等待其他程序使用的数据。 这些数据被使用后通常都会被删除。举例来说，系统收到新信会放置到/var/spool/mail/中， 但使用者收下该信件后该封信原则上就会被删除。信件如果暂时寄不出去会被放到/var/spool/mqueue/中， 等到被送出后就被删除。如果是工作排程数据(crontab)，就会被放置到/var/spool/cron/目录中。 由于FHS仅是定义出最上层(/)及次层(/usr, /var)的目录内容应该要放置的文件或目录数据， 因此，在其他次目录层级内，就可以随开发者自行来配置了。 目录树(directory tree) :在Linux底下，所有的文件与目录都是由根目录开始的。那是所有目录与文件的源头, 然后再一个一个的分支下来，因此，我们也称这种目录配置方式为：目录树(directory tree), 这个目录树的主要特性有： 目录树的启始点为根目录 (/, root)； 每一个目录不止能使用本地端的 partition 的文件系统，也可以使用网络上的 filesystem 。举例来说， 可以利用 Network File System (NFS) 服务器挂载某特定目录等。 每一个文件在此目录树中的文件名(包含完整路径)都是独一无二的。 如果我们将整个目录树以图的方法来显示，并且将较为重要的文件数据列出来的话，那么目录树架构就如下图所示： 绝对路径与相对路径除了需要特别注意的FHS目录配置外，在文件名部分我们也要特别注意。因为根据档名写法的不同，也可将所谓的路径(path)定义为绝对路径(absolute)与相对路径(relative)。 这两种文件名/路径的写法依据是这样的： 绝对路径： 由根目录(/)开始写起的文件名或目录名称， 例如 /home/dmtsai/.bashrc； 相对路径： 相对于目前路径的文件名写法。 例如 ./home/dmtsai 或 http://www.cnblogs.com/home/dmtsai/ 等等。反正开头不是 / 就属于相对路径的写法 而你必须要了解，相对路径是以你当前所在路径的相对位置来表示的。举例来说，你目前在 /home 这个目录下， 如果想要进入 /var/log 这个目录时，可以怎么写呢？ cd /var/log (absolute) cd ../var/log (relative) 因为你在 /home 底下，所以要回到上一层 (../) 之后，才能继续往 /var 来移动的，特别注意这两个特殊的目录： . ：代表当前的目录，也可以使用 ./ 来表示； .. ：代表上一层目录，也可以 ../ 来代表。 这个 . 与 .. 目录概念是很重要的，你常常会看到 cd .. 或 ./command 之类的指令下达方式， 就是代表上一层与目前所在目录的工作状态。 实例1：如何先进入/var/spool/mail/目录，再进入到/var/spool/cron/目录内？ 命令： cd /var/spool/mail cd ../cron 说明： 由于/var/spool/mail与/var/spool/cron是同样在/var/spool/目录中。如此就不需要在由根目录开始写起了。这个相对路径是非常有帮助的，尤其对于某些软件开发商来说。 一般来说，软件开发商会将数据放置到/usr/local/里面的各相对目录。 但如果用户想要安装到不同目录呢？就得要使用相对路径。 实例2：网络文件常常提到类似./run.sh之类的数据，这个指令的意义为何？ 说明： 由于指令的执行需要变量的支持，若你的执行文件放置在本目录，并且本目录并非正规的执行文件目录(/bin, /usr/bin等为正规)，此时要执行指令就得要严格指定该执行档。./代表本目录的意思，所以./run.sh代表执行本目录下， 名为run.sh的文件。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-find参数详解]]></title>
    <url>%2F2018%2F09%2F23%2FLinux%E5%91%BD%E4%BB%A4-find%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[find一些常用参数的一些常用实例和一些具体用法和注意事项。 使用name选项：文件名选项是find命令最常用的选项，要么单独使用该选项，要么和其他选项一起使用。 可以使用某种文件名模式来匹配文件，记住要用引号将文件名模式引起来。 不管当前路径是什么，如果想要在自己的根目录$HOME中查找文件名符合*.log的文件，使用~作为 ‘pathname’参数，波浪号~代表了你的$HOME目录。 find ~ -name &quot;*.log&quot; -print 想要在当前目录及子目录中查找所有的‘ *.log‘文件，可以用： find . -name &quot;*.log&quot; -print 想要的当前目录及子目录中查找文件名以一个大写字母开头的文件，可以用： find . -name &quot;[A-Z]*&quot; -print 想要在/etc目录中查找文件名以host开头的文件，可以用： find /etc -name &quot;host*&quot; -print 想要查找$HOME目录中的文件，可以用： find ~ -name &quot;*&quot; -print 或find . -print 要想让系统高负荷运行，就从根目录开始查找所有的文件。 find / -name &quot;*&quot; -print 如果想在当前目录查找文件名以一个个小写字母开头，最后是4到9加上.log结束的文件： find . -name &quot;[a-z]*[4-9].log&quot; -print 用perm选项：按照文件权限模式用-perm选项,按文件权限模式来查找文件的话。最好使用八进制的权限表示法。 如在当前目录下查找文件权限位为755的文件，即文件属主可以读、写、执行，其他用户可以读、执行的文件，可以用： 12345# find . -perm 755 -print../scf./scf/lib./scf/service 还有一种表达方法：在八进制数字前面要加一个横杠-，表示都匹配，如-007就相当于777，-005相当于555, 忽略某个目录：如果在查找文件时希望忽略某个目录，因为你知道那个目录中没有你所要查找的文件，那么可以使用-prune选项来指出需要忽略的目录。在使用-prune选项时要当心，因为如果你同时使用了-depth选项，那么-prune选项就会被find命令忽略。如果希望在test目录下查找文件，但不希望在test/test3目录下查找，可以用： 12345# find test -path &quot;test/test3&quot; -prune -o -printtesttest/log2014.logtest/log2015.logtest/test4 说明： find [-path ..][expression] 在路径列表的后面的是表达式 -path “test” -prune -o -print 是 -path “test” -a -prune -o -print 的简写表达式按顺序求值, -a 和 -o 都是短路求值，与 shell 的 &amp;&amp; 和 || 类似如果 -path “test” 为真，则求值 -prune , -prune 返回真，与逻辑表达式为真；否则不求值 -prune，与逻辑表达式为假。如果 -path “test” -a -prune 为假，则求值 -print ，-print返回真，或逻辑表达式为真；否则不求值 -print，或逻辑表达式为真。 这个表达式组合特例可以用伪码写为: if -path “test” then -prune else -print 避开多个文件夹:123456# find test \( -path test/test4 -o -path test/test3 \) -prune -o -printtesttest/log2014.logtest/log2015.logtest/scftest/scf/lib 说明： 圆括号表示表达式的结合。 \ 表示引用，即指示 shell 不对后面的字符作特殊解释，而留给 find 命令去解释其意义。 使用user和nouser选项：按文件属主查找文件： 实例1：在$HOME目录中查找文件属主为peida的文件 1find ~ -user peida -print 实例2：在/etc目录下查找文件属主为peida的文件: 1find /etc -user peida -print 实例3：为了查找属主帐户已经被删除的文件，可以使用-nouser选项。在/home目录下查找所有的这类文件 1find/home -nouser -print 说明： 这样就能够找到那些属主在/etc/passwd文件中没有有效帐户的文件。在使用-nouser选项时，不必给出用户名； find命令能够为你完成相应的工作。 使用group和nogroup选项：就像user和nouser选项一样，针对文件所属于的用户组， find命令也具有同样的选项，为了在/apps目录下查找属于gem用户组的文件，可以用： 1find /apps -group gem -print 要查找没有有效所属用户组的所有文件，可以使用nogroup选项。下面的find命令从文件系统的根目录处查找这样的文件: 1find / -nogroup -print 按照更改时间或访问时间等查找文件：如果希望按照更改时间来查找文件，可以使用mtime,atime或ctime选项。如果系统突然没有可用空间了，很有可能某一个文件的长度在此期间增长迅速，这时就可以用mtime选项来查找这样的文件。 用减号-来限定更改时间在距今n日以内的文件，而用加号+来限定更改时间在距今n日以前的文件。 希望在系统根目录下查找更改时间在5日以内的文件，可以用： 1find / -mtime -5 -print 为了在/var/adm目录下查找更改时间在3日以前的文件，可以用: 1find /var/adm -mtime +3 -print 查找比某个文件新或旧的文件：如果希望查找更改时间比某个文件新但比另一个文件旧的所有文件，可以使用-newer选项。 它的一般形式为： newest_file_name ! oldest_file_name 其中，！是逻辑非符号。 1）查找更改时间比文件log2012.log新但比文件log2017.log旧的文件 1234567891011121314151617# ll总计 316-rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root root 61 11-13 06:03 log2013.log-rw-r--r-- 1 root root 0 11-13 06:03 log2014.log-rw-r--r-- 1 root root 0 11-13 06:06 log2015.log-rw-r--r-- 1 root root 0 11-16 14:41 log2016.log-rw-r--r-- 1 root root 0 11-16 14:43 log2017.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-13 06:08 test3drwxrwxr-x 2 root root 4096 11-13 05:50 test4# find -newer log2012.log ! -newer log2017.log../log2015.log./log2017.log./log2016.log./test3 2）查找更改时间在比log2012.log文件新的文件 123456 find -newer log2012.log../log2015.log./log2017.log./log2016.log./test3 使用type选项： 2）：在/etc目录下查找所有的目录 1find /etc -type d -print 2）：在当前目录下查找除目录以外的所有类型的文件 1find . ! -type d -print 3）：在/etc目录下查找所有的符号链接文件 1find /etc -type l -print 使用size选项：可以按照文件长度来查找文件，这里所指的文件长度既可以用块（block）来计量，也可以用字节来计量。以字节计量文件长度的表达形式为N c；以块计量文件长度只用数字表示即可。 在按照文件长度查找文件时，一般使用这种以字节表示的文件长度，在查看文件系统的大小，因为这时使用块来计量更容易转换。 1）：在当前目录下查找文件长度大于1 M字节的文件 1find . -size +1000000c -print 2）：在/home/apache目录下查找文件长度恰好为100字节的文件: 1find /home/apache -size 100c -print 3）：在当前目录下查找长度超过10块的文件（一块等于512字节） 1find . -size +10 -print 使用depth选项：在使用find命令时，可能希望先匹配所有的文件，再在子目录中查找。使用depth选项就可以使find命令这样做。这样做的一个原因就是，当在使用find命令向磁带上备份文件系统时，希望首先备份所有的文件，其次再备份子目录中的文件。 1)：find命令从文件系统的根目录开始，查找一个名为CON.FILE的文件。 1find / -name &quot;CON.FILE&quot; -depth -print 说明： 它将首先匹配所有的文件然后再进入子目录中查找 使用mount选项：在当前的文件系统中查找文件（不进入其他文件系统），可以使用find命令的mount选项。 1）：从当前目录开始查找位于本文件系统中文件名以XC结尾的文件 1find . -name &quot;*.XC&quot; -mount -print 转载链接： http://www.cnblogs.com/peida/archive/2012/11/16/2773289.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-find之xargs]]></title>
    <url>%2F2018%2F09%2F23%2FLinux%E5%91%BD%E4%BB%A4-find%E4%B9%8Bxargs%2F</url>
    <content type="text"><![CDATA[在使用 find命令的-exec选项处理匹配到的文件时， find命令将所有匹配到的文件一起传递给exec执行。但有些系统对能够传递给exec的命令长度有限制，这样在find命令运行几分钟之后，就会出现溢出错误。错误信息通常是“参数列太长”或“参数列溢出”。这就是xargs命令的用处所在，特别是与find命令一起使用。 find命令把匹配到的文件传递给xargs命令，而xargs命令每次只获取一部分文件而不是全部，不像-exec选项那样。这样它可以先处理最先获取的一部分文件，然后是下一批，并如此继续下去。 在有些系统中，使用-exec选项会为处理每一个匹配到的文件而发起一个相应的进程，并非将匹配到的文件全部作为参数一次执行；这样在有些情况下就会出现进程过多，系统性能下降的问题，因而效率不高； 而使用xargs命令则只有一个进程。另外，在使用xargs命令时，究竟是一次获取所有的参数，还是分批取得参数，以及每一次获取参数的数目都会根据该命令的选项及系统内核中相应的可调参数来确定。 使用实例： 1） 查找系统中的每一个普通文件，然后使用xargs命令来测试它们分别属于哪类文件 123456789101112#ll总计 312-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.log-rw-r--r-- 1 root root 0 11-12 22:25 log2013.log-rw-r--r-- 1 root root 0 11-12 22:25 log2014.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 11-12 19:32 test3drwxrwxrwx 2 root root 4096 11-12 19:32 test4# find . -type f -print | xargs file./log2014.log: empty./log2013.log: empty./log2012.log: ASCII text 2）在整个系统中查找内存信息转储文件(core dump) ，然后把结果保存到/tmp/core.log 文件中 12345678# find / -name &quot;core&quot; -print | xargs echo &quot;&quot; &gt;/tmp/core.log# cd /tmp# ll总计 16-rw-r--r-- 1 root root 1524 11-12 22:29 core.logdrwx------ 2 root root 4096 11-12 22:24 ssh-TzcZDx1766drwx------ 2 root root 4096 11-12 22:28 ssh-ykiRPk1815drwx------ 2 root root 4096 11-03 07:11 vmware-root 3）在当前目录下查找所有用户具有读、写和执行权限的文件，并收回相应的写权限 1234567891011121314151617# ll总计 312-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.log-rw-r--r-- 1 root root 0 11-12 22:25 log2013.log-rw-r--r-- 1 root root 0 11-12 22:25 log2014.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 11-12 19:32 test3drwxrwxrwx 2 root root 4096 11-12 19:32 test4# find . -perm -7 -print | xargs chmod o-w# ll总计 312-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.log-rw-r--r-- 1 root root 0 11-12 22:25 log2013.log-rw-r--r-- 1 root root 0 11-12 22:25 log2014.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-12 19:32 test3drwxrwxr-x 2 root root 4096 11-12 19:32 test4 说明： 执行命令后，文件夹scf、test3和test4的权限都发生改变 4）用grep命令在所有的普通文件中搜索hostname这个词 1234# find . -type f -print | xargs grep &quot;hostname&quot;./log2013.log:hostnamebaidu=baidu.com./log2013.log:hostnamesina=sina.com./log2013.log:hostnames=true 5）用grep命令在当前目录下的所有普通文件中搜索hostnames这个词 123# find . -name \* -type f -print | xargs grep &quot;hostnames&quot;./log2013.log:hostnamesina=sina.com./log2013.log:hostnames=true 说明： 注意，在上面的例子中， \用来取消find命令中的*在shell中的特殊含义。 6）使用xargs执行mv 12345678910111213141516171819202122# ll总计 316-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.log-rw-r--r-- 1 root root 61 11-12 22:44 log2013.log-rw-r--r-- 1 root root 0 11-12 22:25 log2014.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-12 22:54 test3drwxrwxr-x 2 root root 4096 11-12 19:32 test4# cd test4/# ll总计 0[root@localhost test4]# cd ..# find . -name &quot;*.log&quot; | xargs -i mv &#123;&#125; test4# ll总计 12drwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-13 05:50 test3drwxrwxr-x 2 root root 4096 11-13 05:50 test4# cd test4/# ll总计 304-rw-r--r-- 1 root root 302108 11-12 22:54 log2012.log-rw-r--r-- 1 root root 61 11-12 22:54 log2013.log-rw-r--r-- 1 root root 0 11-12 22:54 log2014.log 7）find后执行xargs提示xargs: argument line too long解决方法： 12#find . -type f -atime +0 -print0 | xargs -0 -l1 -t rm -frm -f 说明： -l1是一次处理一个；-t是处理之前打印出命令 8）使用-i参数默认的前面输出用{}代替，-I参数可以指定其他代替字符，如例子中的[] 1234567891011121314151617181920# ll总计 12drwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-13 05:50 test3drwxrwxr-x 2 root root 4096 11-13 05:50 test4# cd test4# find . -name &quot;file&quot; | xargs -I [] cp [] ..# ll总计 304-rw-r--r-- 1 root root 302108 11-12 22:54 log2012.log-rw-r--r-- 1 root root 61 11-12 22:54 log2013.log-rw-r--r-- 1 root root 0 11-12 22:54 log2014.log# cd ..# ll总计 316-rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root root 61 11-13 06:03 log2013.log-rw-r--r-- 1 root root 0 11-13 06:03 log2014.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-13 05:50 test3drwxrwxr-x 2 root root 4096 11-13 05:50 test4 说明： 使用-i参数默认的前面输出用{}代替，-I参数可以指定其他代替字符，如例子中的[] 9）xargs的-p参数的使用 123456789101112131415161718192021222324252627# ll总计 0-rw-r--r-- 1 root root 0 11-13 06:06 log2015.log# cd ..# ll总计 316-rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root root 61 11-13 06:03 log2013.log-rw-r--r-- 1 root root 0 11-13 06:03 log2014.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-13 06:06 test3drwxrwxr-x 2 root root 4096 11-13 05:50 test4# cd test3# find . -name &quot;*.log&quot; | xargs -p -i mv &#123;&#125; ..mv ./log2015.log .. ?...y# ll总计 0# cd ..# ll总计 316-rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root root 61 11-13 06:03 log2013.log-rw-r--r-- 1 root root 0 11-13 06:03 log2014.log-rw-r--r-- 1 root root 0 11-13 06:06 log2015.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-13 06:08 test3drwxrwxr-x 2 root root 4096 11-13 05:50 test4 说明： -p参数会提示让你确认是否执行后面的命令,y执行，n不执行。 转载链接： http://www.cnblogs.com/peida/archive/2012/11/15/2770888.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-find之exec]]></title>
    <url>%2F2018%2F09%2F23%2FLinux%E5%91%BD%E4%BB%A4-find%E4%B9%8Bexec%2F</url>
    <content type="text"><![CDATA[find是我们很常用的一个Linux命令，但是我们一般查找出来的并不仅仅是看看而已，还会有进一步的操作，这个时候exec的作用就显现出来了。 exec解释：-exec参数后面跟的是command命令，它的终止是以；为结束标志的，所以这句命令后面的分号是不可缺少的，考虑到各个系统中分号会与不同的意义，所以前面加反斜杠。 {}花括号代表前面find查找出来的文件名。 使用find时，只要把想要的操作写在一个文件里，就可以用exec来配合find查找，很方便的。在有些操作系统中只允许-exec选项执行诸如l s或ls -l这样的命令。大多数用户使用这一选项是为了查找旧文件并删除它们。建议在真正执行rm命令删除文件之前，最好先用ls命令看一下，确认它们是所要删除的文件。 exec选项后面跟随着所要执行的命令或脚本，然后是一对儿{ }，一个空格和一个\，最后是一个分号。为了使用exec选项，必须要同时使用print选项。如果验证一下find命令，会发现该命令只输出从当前路径起的相对路径及文件名。 常用实例1）ls -l命令放在find命令的-exec选项中 1234567# find . -type f -exec ls -l &#123;&#125; \; -rw-r--r-- 1 root root 127 10-28 16:51 ./log2014.log-rw-r--r-- 1 root root 0 10-28 14:47 ./test4/log3-2.log-rw-r--r-- 1 root root 0 10-28 14:47 ./test4/log3-3.log-rw-r--r-- 1 root root 0 10-28 14:47 ./test4/log3-1.log-rw-r--r-- 1 root root 33 10-28 16:54 ./log2013.log-rw-r--r-- 1 root root 302108 11-03 06:19 ./log2012.log 说明： 上面的例子中，find命令匹配到了当前目录下的所有普通文件，并在-exec选项中使用ls -l命令将它们列出。 2）在目录中查找更改时间在n日以前的文件并删除它们 12345678910111213141516171819# ll总计 328-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.log-rw-r--r-- 1 root root 33 10-28 16:54 log2013.log-rw-r--r-- 1 root root 127 10-28 16:51 log2014.loglrwxrwxrwx 1 root root 7 10-28 15:18 log_link.log -&gt; log.log-rw-r--r-- 1 root root 25 10-28 17:02 log.log-rw-r--r-- 1 root root 37 10-28 17:07 log.txtdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 14:47 test3drwxrwxrwx 2 root root 4096 10-28 14:47 test4# find . -type f -mtime +14 -exec rm &#123;&#125; \;# ll总计 312-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.loglrwxrwxrwx 1 root root 7 10-28 15:18 log_link.log -&gt; log.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 11-12 19:32 test3drwxrwxrwx 2 root root 4096 11-12 19:32 test4 说明： 在shell中用任何方式删除文件之前，应当先查看相应的文件，一定要小心！当使用诸如mv或rm命令时，可以使用-exec选项的安全模式。它将在对每个匹配到的文件进行操作之前提示你。 3）在目录中查找更改时间在n日以前的文件并删除它们，在删除之前先给出提示 12345678910111213141516# ll总计 312-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.loglrwxrwxrwx 1 root root 7 10-28 15:18 log_link.log -&gt; log.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 11-12 19:32 test3drwxrwxrwx 2 root root 4096 11-12 19:32 test4# find . -name &quot;*.log&quot; -mtime +5 -ok rm &#123;&#125; \;&lt; rm ... ./log_link.log &gt; ? y&lt; rm ... ./log2012.log &gt; ? n# ll总计 312-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 11-12 19:32 test3drwxrwxrwx 2 root root 4096 11-12 19:32 test4 说明： 在上面的例子中， find命令在当前目录中查找所有文件名以.log结尾、更改时间在5日以上的文件，并删除它们，只不过在删除之前先给出提示。 按y键删除文件，按n键不删除。 4）-exec中使用grep命令 123# find /etc -name &quot;passwd*&quot; -exec grep &quot;root&quot; &#123;&#125; \;root:x:0:0:root:/root:/bin/bashroot:x:0:0:root:/root:/bin/bash 说明： 任何形式的命令都可以在-exec选项中使用。 在上面的例子中我们使用grep命令。find命令首先匹配所有文件名为“ passwd*”的文件，例如passwd、passwd.old、passwd.bak，然后执行grep命令看看在这些文件中是否存在一个root用户。 5）查找文件移动到指定目录 123456789101112131415161718192021# ll总计 12drwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-12 22:49 test3drwxrwxr-x 2 root root 4096 11-12 19:32 test4# cd test3/# ll总计 304-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.log-rw-r--r-- 1 root root 61 11-12 22:44 log2013.log-rw-r--r-- 1 root root 0 11-12 22:25 log2014.log# find . -name &quot;*.log&quot; -exec mv &#123;&#125; .. \;# ll总计 0[root@localhost test3]# cd ..# ll总计 316-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.log-rw-r--r-- 1 root root 61 11-12 22:44 log2013.log-rw-r--r-- 1 root root 0 11-12 22:25 log2014.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-12 22:50 test3drwxrwxr-x 2 root root 4096 11-12 19:32 test4 6）用exec选项执行cp命令 123456789101112131415161718192021# ll总计 0# cd ..# ll总计 316-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.log-rw-r--r-- 1 root root 61 11-12 22:44 log2013.log-rw-r--r-- 1 root root 0 11-12 22:25 log2014.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-12 22:50 test3drwxrwxr-x 2 root root 4096 11-12 19:32 test4# find . -name &quot;*.log&quot; -exec cp &#123;&#125; test3 \;cp: “./test3/log2014.log” 及 “test3/log2014.log” 为同一文件cp: “./test3/log2013.log” 及 “test3/log2013.log” 为同一文件cp: “./test3/log2012.log” 及 “test3/log2012.log” 为同一文件# cd test3# ll总计 304-rw-r--r-- 1 root root 302108 11-12 22:54 log2012.log-rw-r--r-- 1 root root 61 11-12 22:54 log2013.log-rw-r--r-- 1 root root 0 11-12 22:54 log2014.log 转载链接： http://www.cnblogs.com/peida/archive/2012/11/14/2769248.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-find命令概述]]></title>
    <url>%2F2018%2F09%2F23%2FLinux%E5%91%BD%E4%BB%A4-find%E5%91%BD%E4%BB%A4%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[Linux下find命令在目录结构中搜索文件，并执行指定的操作。Linux下find命令提供了相当多的查找条件，功能很强大。由于find具有强大的功能，所以它的选项也很多，其中大部分选项都值得我们花时间来了解一下。即使系统中含有网络文件系统( NFS)，find命令在该文件系统中同样有效，只你具有相应的权限。 在运行一个非常消耗资源的find命令时，很多人都倾向于把它放在后台执行，因为遍历一个大的文件系统可能会花费很长的时间(这里是指30G字节以上的文件系统)。 命令格式find pathname -options [-print -exec -ok ...] 命令功能用于在文件树种查找文件，并作出相应的处理 命令参数1234pathname: find命令所查找的目录路径。例如用.来表示当前目录，用/来表示系统根目录。 -print： find命令将匹配的文件输出到标准输出。 -exec： find命令对匹配的文件执行该参数所给出的shell命令。相应命令的形式为&apos;command&apos; &#123; &#125; \;，注意&#123; &#125;和\；之间的空格。 -ok： 和-exec的作用相同，只不过以一种更为安全的模式来执行该参数所给出的shell命令，在执行每一个命令之前，都会给出提示，让用户来确定是否执行。 命令选项12345678910111213141516171819202122232425262728-name 按照文件名查找文件。-perm 按照文件权限来查找文件。-prune 使用这一选项可以使find命令不在当前指定的目录中查找，如果同时使用-depth选项，那么-prune将被find命令忽略。-user 按照文件属主来查找文件。-group 按照文件所属的组来查找文件。-mtime -n +n 按照文件的更改时间来查找文件， - n表示文件更改时间距现在n天以内，+ n表示文件更改时间距现在n天以前。find命令还有-atime和-ctime 选项，但它们都和-m time选项。-nogroup 查找无有效所属组的文件，即该文件所属的组在/etc/groups中不存在。-nouser 查找无有效属主的文件，即该文件的属主在/etc/passwd中不存在。-newer file1 ! file2 查找更改时间比文件file1新但比文件file2旧的文件。-type 查找某一类型的文件，诸如：b - 块设备文件。d - 目录。c - 字符设备文件。p - 管道文件。l - 符号链接文件。f - 普通文件。-size n：[c] 查找文件长度为n块的文件，带有c时表示文件长度以字节计。-depth：在查找文件时，首先查找当前目录中的文件，然后再在其子目录中查找。-fstype：查找位于某一类型文件系统中的文件，这些文件系统类型通常可以在配置文件/etc/fstab中找到，该配置文件中包含了本系统中有关文件系统的信息。-mount：在查找文件时不跨越文件系统mount点。-follow：如果find命令遇到符号链接文件，就跟踪至链接所指向的文件。-cpio：对匹配的文件使用cpio命令，将这些文件备份到磁带设备中。另外,下面三个的区别:-amin n 查找系统中最后N分钟访问的文件-atime n 查找系统中最后n*24小时访问的文件-cmin n 查找系统中最后N分钟被改变文件状态的文件-ctime n 查找系统中最后n*24小时被改变文件状态的文件-mmin n 查找系统中最后N分钟被改变文件数据的文件-mtime n 查找系统中最后n*24小时被改变文件数据的文件 使用实例1）查找指定时间内修改过的文件 123456# find -atime -2../logs/monitor./.bashrc./.bash_profile./.bash_history 说明： 超找48小时内修改过的文件 2）根据关键字查找 123456789# find . -name &quot;*.log&quot; ./log_link.log./log2014.log./test4/log3-2.log./test4/log3-3.log./test4/log3-1.log./log2013.log./log2012.log./log.log 说明： 在当前目录查找 以.log结尾的文件。 “. “代表当前目录 3）按照目录或文件的权限来查找文件 12345# find /opt/soft/test/ -perm 777/opt/soft/test/log_link.log/opt/soft/test/test4/opt/soft/test/test5/test3/opt/soft/test/test3 说明： 查找/opt/soft/test/目录下 权限为 777的文件 4）按类型查找 12345find . -type f -name &quot;*.log&quot;./log2014.log./test4/log3-2.log./test4/log3-3.log./test4/log3-1.log 说明： 查找当目录，以.log结尾的普通文件 5）查找当前所有目录并排序 12345678# find . -type d | sort../scf./scf/bin./scf/doc./scf/lib./scf/service./scf/service/deploy 6）按大小查找文件 12345678# find . -size +1000c -print../test4./scf./scf/lib./scf/service./scf/service/deploy./scf/service/deploy/product 说明： 查找当前目录大于1K的文件 转载链接： http://www.cnblogs.com/peida/archive/2012/11/13/2767374.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-locate命令]]></title>
    <url>%2F2018%2F09%2F23%2FLinux%E5%91%BD%E4%BB%A4-locate%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[locate 让使用者可以很快速的搜寻档案系统内是否有指定的档案。其方法是先建立一个包括系统内所有档案名称及路径的数据库，之后当寻找时就只需查询这个数据库，而不必实际深入档案系统之中了。在一般的 distribution 之中，数据库的建立都被放在 crontab 中自动执行。 语法locate (选项)(参数) 选项12345678910-e 将排除在寻找的范围之外。-1 如果 是 1．则启动安全模式。在安全模式下，使用者不会看到权限无法看到 的档案。这会始速度减慢，因为 locate 必须至实际的档案系统中取得档案的 权限资料。-f 将特定的档案系统排除在外，例如我们没有到理要把 proc 档案系统中的档案 放在资料库中-q 安静模式，不会显示任何错误讯息-n 至多显示 n个输出-r 使用正规运算式 做寻找的条件-o 指定资料库存的名称-d 指定资料库的路径-h 显示辅助讯息-V 显示程式的版本讯息 参数查找字符串：要查找的文件名中含有的字符串。 功能locate命令可以在搜寻数据库是快速找到档案，数据库有updatedb程序来更新，updatedb是由cron daemon周期性建立的，locate命令在搜寻数据库时比由整个由硬盘来搜寻资料来得快，但locate所找到的档案若是最近才建立或刚更名的，可能会找不到，在内定值中，updatedb每天会跑一次，可以由修改crontab来更新设定值。（/etc/crontab） locate指令和find找寻档案的功能类似，但locate是透过update程序将硬盘中的所有档案盒目录资料先建立一个索引数据库，在执行locate时直接找该索引，查询速度会较快，索引数据库一般是由操作系统管理，但也可以直接下达update强迫系统立即修改索引数据库。 常用范例1）查找和pwd相关的所有文件 1234567# locate pwd/bin/pwd/etc/.pwd.lock/sbin/unix_chkpwd/usr/bin/pwdx/usr/include/pwd.h/usr/lib/python2.7/dist-packages/twisted/python/fakepwd.py 2） 搜索etc目录下所有以sh开头的文件 1234 # locate /etc/sh/etc/shadow/etc/shadow-/etc/shells 3）搜索etc目录下，所有以m开头的文件 12345# locate /etc/m/etc/magic/etc/magic.mime/etc/mailcap/etc/mailcap.order 参考链接： http://www.cnblogs.com/peida/archive/2012/11/12/2765750.html http://man.linuxde.net/locate_slocate]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-whereis命令]]></title>
    <url>%2F2018%2F09%2F22%2FLinux%E5%91%BD%E4%BB%A4-whereis%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[whereis命令用来定位指令的二进制程序、源代码文件和man手册页等相关文件的路径。 whereis命令只能用于程序名的搜索，而且只搜索二进制文件（参数-b）、man说明文件（参数-m）和源代码文件（参数-s）。如果省略参数，则返回所有信息。 和find相比，whereis查找的速度非常快，这是因为linux系统会将 系统内的所有文件都记录在一个数据库文件中，当使用whereis和下面即将介绍的locate时，会从数据库中查找数据，而不是像find命令那样，通 过遍历硬盘来查找，效率自然会很高。 但是该数据库文件并不是实时更新，默认情况下时一星期更新一次，因此，我们在用whereis和locate 查找文件时，有时会找到已经被删除的数据，或者刚刚建立文件，却无法查找到，原因就是因为数据库文件没有被更新。 语法whereis(选项)(参数) 选项1234567-b 定位可执行文件。-m 定位帮助文件。-s 定位源代码文件。-u 搜索默认路径下除可执行文件、源代码文件、帮助文件以外的其它文件。-B 指定搜索可执行文件的路径。-M 指定搜索帮助文件的路径。-S 指定搜索源代码文件的路径。 常用范例1）将和**文件相关的文件都查找出来 12# whereis svnsvn: /usr/bin/svn /usr/local/svn /usr/share/man/man1/svn.1.gz 说明： tomcat没安装，找不出来，svn安装找出了很多相关文件 2）只将二进制文件 查找出来 12# whereis -b svnsvn: /usr/bin/svn /usr/local/svn 说明： whereis -m svn 查出说明文档路径，whereis -s svn 找source源文件。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-which命令]]></title>
    <url>%2F2018%2F09%2F22%2FLinux%E5%91%BD%E4%BB%A4-which%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[我们经常在linux要查找某个文件，但不知道放在哪里了，可以使用下面的一些命令来搜索： which 查看可执行文件的位置。 whereis 查看文件的位置。 locate 配合数据库查看文件位置。 find 实际搜寻硬盘查询文件名称。 which命令的作用是，在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。 语法which 可执行文件名称 选项1234-n 指定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名。-p 与-n参数相同，但此处的包括了文件的路径。-w 指定输出时栏位的宽度。-V 显示版本信息 功能which指令会在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。 常用范例1）查找文件、显示命令路径 12# which pwd/bin/pwd 参考链接： http://www.cnblogs.com/peida/archive/2012/11/08/2759805.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-tail命令]]></title>
    <url>%2F2018%2F09%2F21%2FLinux%E5%91%BD%E4%BB%A4-tail%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[tail 命令从指定点开始将文件写到标准输出.使用tail命令的-f选项可以方便的查阅正在改变的日志文件,tail -f filename会把filename里最尾部的内容显示在屏幕上,并且不断刷新,使你看到最新的文件内容. 语法tail(选项)(参数) 选项12345678-f 循环读取-q 不显示处理信息-v 显示详细的处理信息-c&lt;数目&gt; 显示的字节数-n&lt;行数&gt; 显示行数--pid=PID 与-f合用,表示在进程ID,PID死掉之后结束. -q, --quiet, --silent 从不输出给出文件名的首部 -s, --sleep-interval=S 与-f合用,表示在每次反复的间隔休眠S秒 功能用于显示指定文件末尾内容，不指定文件时，作为输入信息进行处理。常用查看日志文件。 常用范例1）显示文件末尾内容 123456# tail -n 5 log2014.log 2014-092014-102014-112014-12=========================== 说明： 显示文件最后5行内容 2）循环查看文件内容 1234567891011121314# ping 192.168.120.204 &gt; test.log &amp;# tail -f test.log PING 192.168.120.204 (192.168.120.204) 56(84) bytes of data.64 bytes from 192.168.120.204: icmp_seq=1 ttl=64 time=0.038 ms64 bytes from 192.168.120.204: icmp_seq=2 ttl=64 time=0.036 ms64 bytes from 192.168.120.204: icmp_seq=3 ttl=64 time=0.033 ms64 bytes from 192.168.120.204: icmp_seq=4 ttl=64 time=0.027 ms64 bytes from 192.168.120.204: icmp_seq=5 ttl=64 time=0.032 ms64 bytes from 192.168.120.204: icmp_seq=6 ttl=64 time=0.026 ms64 bytes from 192.168.120.204: icmp_seq=7 ttl=64 time=0.030 ms64 bytes from 192.168.120.204: icmp_seq=8 ttl=64 time=0.029 ms64 bytes from 192.168.120.204: icmp_seq=9 ttl=64 time=0.044 ms64 bytes from 192.168.120.204: icmp_seq=10 ttl=64 time=0.033 ms64 bytes from 192.168.120.204: icmp_seq=11 ttl=64 time=0.027 ms 3）从第5行开始显示文件 12345678910111213141516171819202122# cat log2014.log 2014-012014-022014-032014-042014-052014-062014-072014-082014-092014-102014-112014-12# tail -n +5 log2014.log2014-052014-062014-072014-082014-092014-102014-112014-12 参考链接： http://www.cnblogs.com/peida/archive/2012/11/07/2758084.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-head命令]]></title>
    <url>%2F2018%2F09%2F21%2FLinux%E5%91%BD%E4%BB%A4-head%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[head 与 tail 就像它的名字一样的浅显易懂，它是用来显示开头或结尾某个数量的文字区块，head 用来显示档案的开头至标准输出中，而 tail 想当然尔就是看档案的结尾。 语法head(选项)(参数) 选项1234-n&lt;数字&gt;：指定显示头部内容的行数；-c&lt;字符数&gt;：指定显示头部内容的字符数；-v：总是显示文件名的头信息；-q：不显示文件名的头信息。 功能head 用来显示档案的开头至标准输出中，默认head命令打印其相应文件的开头10行。 常用范例1）显示文件的前n行 12345678910111213141516171819# cat log2014.log 2014-012014-022014-032014-042014-052014-062014-072014-082014-092014-102014-112014-12# head -n 5 log2014.log 2014-012014-022014-032014-042014-05 2）显示文件前n个字节 1234# head -c 20 log2014.log2014-012014-022014 3）文件的除了最后n个字节以外的内容 12345678910111213# head -c -32 log2014.log2014-012014-022014-032014-042014-052014-062014-072014-082014-092014-102014-112014-12 4）输出文件除了最后n行的全部内容 12345678# head -n -6 log2014.log2014-012014-022014-032014-042014-052014-062014-07 参考链接： http://www.cnblogs.com/peida/archive/2012/11/06/2756278.html http://man.linuxde.net/head]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-less命令]]></title>
    <url>%2F2018%2F09%2F21%2FLinux%E5%91%BD%E4%BB%A4-less%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[less 工具也是对文件或其它输出进行分页显示的工具，应该说是linux正统查看文件内容的工具，功能极其强大。less 的用法比起 more 更加的有弹性。在 more 的时候，我们并没有办法向前面翻， 只能往后面看，但若使用了 less 时，就可以使用 [pageup][pagedown] 等按键的功能来往前往后翻看文件，更容易用来查看一个文件的内容！除此之外，在 less 里头可以拥有更多的搜索功能，不止可以向下搜，也可以向上搜。 语法less(选项)(参数) 选项1234567891011121314151617181920212223242526-b &lt;缓冲区大小&gt; 设置缓冲区的大小-e 当文件显示结束后，自动离开-f 强迫打开特殊文件，例如外围设备代号、目录和二进制文件-g 只标志最后搜索的关键词-i 忽略搜索时的大小写-m 显示类似more命令的百分比-N 显示每行的行号-o &lt;文件名&gt; 将less 输出的内容在指定文件中保存起来-Q 不使用警告音-s 显示连续空行为一行-S 行过长时间将超出部分舍弃-x &lt;数字&gt; 将“tab”键显示为规定的数字空格/字符串：向下搜索“字符串”的功能?字符串：向上搜索“字符串”的功能n：重复前一个搜索（与 / 或 ? 有关）N：反向重复前一个搜索（与 / 或 ? 有关）b 向后翻一页d 向后翻半页h 显示帮助界面Q 退出less 命令u 向前滚动半页y 向前滚动一行空格键 滚动一行回车键 滚动一页[pagedown]： 向下翻动一页[pageup]： 向上翻动一页 功能less 与 more 类似，但使用 less 可以随意浏览文件，而 more 仅能向前移动，却不能向后移动，而且 less 在查看之前不会加载整个文件。 常用实例1）ps查看进程信息并通过less分页显示 1ps -ef | less 2 ) 查看命令历史使用记录并通过less分页显示 1history | less 3）浏览多个文件 1less log2013.log log2014.log 说明： 输入 ：n后，切换到 log2014.log 输入 ：p 后，切换到log2013.log 附加备注1.全屏导航 ctrl + F - 向前移动一屏 ctrl + B - 向后移动一屏 ctrl + D - 向前移动半屏 ctrl + U - 向后移动半屏 2.单行导航 j - 向前移动一行 k - 向后移动一行 3.其它导航 G - 移动到最后一行 g - 移动到第一行 q / ZZ - 退出 less 命令 4.其它有用的命令 v - 使用配置的编辑器编辑当前文件 h - 显示 less 的帮助文档 &amp;pattern - 仅显示匹配模式的行，而不是整个文件 5.标记导航 当使用 less 查看大文件时，可以在任何一个位置作标记，可以通过命令导航到标有特定标记的文本位置： ma - 使用 a 标记文本的当前位置 ‘a - 导航到标记 a 处 参考链接： http://www.cnblogs.com/peida/archive/2012/11/05/2754477.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-more命令]]></title>
    <url>%2F2018%2F09%2F19%2FLinux%E5%91%BD%E4%BB%A4-more%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[more命令，功能类似 cat ，cat命令是整个文件的内容从上到下显示在屏幕上。 more会以一页一页的显示方便使用者逐页阅读，而最基本的指令就是按空白键（space）就往下一页显示，按 b 键就会往回（back）一页显示，而且还有搜寻字串的功能 。more命令从前向后读取文件，因此在启动时就加载整个文件。 语法more(语法)(参数) 选项123456789+n 从笫n行开始显示-n 定义屏幕大小为n行+/pattern 在每个档案显示前搜寻该字串（pattern），然后从该字串前两行之后开始显示 -c 从顶部清屏，然后显示-d 提示“Press space to continue，’q’ to quit（按空格键继续，按q键退出）”，禁用响铃功能-l 忽略Ctrl+l（换页）字符-p 通过清除窗口而不是滚屏来对文件进行换页，与-c选项相似-s 把连续的多个空行显示为一行-u 把文件内容中的下画线去掉 功能more命令和cat的功能一样都是查看文件里的内容，但有所不同的是more可以按页来查看文件的内容，还支持直接跳转行等功能。 常用操作命令123456789Enter 向下n行，需要定义。默认为1行Ctrl+F 向下滚动一屏空格键 向下滚动一屏Ctrl+B 返回上一屏= 输出当前行的行号：f 输出文件名和当前行的行号V 调用vi编辑器!命令 调用Shell，并执行命令 q 退出more 常用范例1）显示文件中从第3行起的内容 123456789101112# cat log2012.log 2012-012012-022012-032012-04-day12012-04-day22012-04-day3# more +3 log2012.log 2012-032012-04-day12012-04-day22012-04-day3 2）从文件中查找第一个出现”day3”字符串的行，并从该处前两行开始显示输出 1234567# more +/day3 log2012.log ...skipping2012-04-day12012-04-day22012-04-day32012-052012-05-day1 3）设定每屏显示行数 123456# more -5 log2012.log 2012-012012-022012-032012-04-day12012-04-day2 4）列一个目录下的文件，由于内容太多，我们应该学会用more来分页显示。这得和管道 | 结合起来 1234567891011# ls -l | more -5总计 36-rw-r--r-- 1 root root 308 11-01 16:49 log2012.log-rw-r--r-- 1 root root 33 10-28 16:54 log2013.log-rw-r--r-- 1 root root 127 10-28 16:51 log2014.loglrwxrwxrwx 1 root root 7 10-28 15:18 log_link.log -&gt; log.log-rw-r--r-- 1 root root 25 10-28 17:02 log.log-rw-r--r-- 1 root root 37 10-28 17:07 log.txtdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 14:47 test3drwxrwxrwx 2 root root 4096 10-28 14:47 test4 说明： 每页显示5个文件信息，按 Ctrl+F 或者 空格键 将会显示下5条文件信息。 参考链接： http://www.cnblogs.com/peida/archive/2012/11/02/2750588.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-nl命令]]></title>
    <url>%2F2018%2F09%2F19%2FLinux%E5%91%BD%E4%BB%A4-nl%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[nl命令读取 file 参数（缺省情况下标准输入），计算输入中的行号，将计算过的行号写入标准输出。在输出中，nl命令根据您在命令行中指定的标志来计算左边的行。输入文本必须写在逻辑页中。每个逻辑页有头、主体和页脚节（可以有空节）。除非使用-p选项，nl 命令在每个逻辑页开始的地方重新设置行号。可以单独为头、主体和页脚节设置行计算标志（例如，头和页脚行可以被计算然而文本行不能）。其默认的结果与cat -n有点不太一样， nl 可以将行号做比较多的显示设计，包括位数与是否自动补齐0等等的功能。 语法nl (选项) (参数) 选项123456789-b ：指定行号指定的方式，主要有两种： -b a ：表示不论是否为空行，也同样列出行号(类似 cat -n)； -b t ：如果有空行，空的那一行不要列出行号(默认值)；-n ：列出行号表示的方法，主要有三种： -n ln ：行号在萤幕的最左方显示； -n rn ：行号在自己栏位的最右方显示，且不加 0 ； -n rz ：行号在自己栏位的最右方显示，且加 0 ；-w ：行号栏位的占用的位数。-p ：在逻辑定界符处不重新开始计算。 常用范例1）用 nl 列出 log2015.log 的内容： 123456# nl log2015.log1 2015-012 2015-023 ====== 说明：文件中的空白行，nl 不会加上行号 2）用 nl 列出 log2015.log 的内容，空本行也加上行号： 123456# nl -b a log2015.log1 2015-012 2015-02345 ====== 3）让行号前面自动补上0，统一输出格式： 1234567891011121314151617181920212223242526272829# nl -b a -n rz log2015.log000001 2015-01000002 2015-02000003 2015-03000004 2015-04000005 2015-05000006 2015-06000007 2015-07000008 2015-08000009 2015-09000010 2015-10000011 2015-11000012 2015-12000013 =======# nl -b a -n rz -w 3 log2015.log001 2015-01002 2015-02003 2015-03004 2015-04005 2015-05006 2015-06007 2015-07008 2015-08009 2015-09010 2015-10011 2015-11012 2015-12013 ======= 说明：nl -b a -n rz命令行号默认为六位，要调整位数可以加上参数-w 3调整为3位。 参考链接： http://man.linuxde.net/nl]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-cat命令]]></title>
    <url>%2F2018%2F09%2F19%2FLinux%E5%91%BD%E4%BB%A4-cat%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[cat命令的用途是连接文件或标准输入并打印。这个命令常用来显示文件内容，或者将几个文件连接起来显示，或者从标准输入读取内容并显示，它常与重定向符号配合使用。 语法cat(选项)(参数) 选项12345678910-A, --show-all 等价于 -vET-b, --number-nonblank 对非空输出行编号-e 等价于 -vE-E, --show-ends 在每行结束处显示 $-n, --number 对输出的所有行编号,由1开始对所有输出的行数编号-s, --squeeze-blank 有连续两行以上的空白行，就代换为一行的空白行 -t 与 -vT 等价-T, --show-tabs 将跳格字符显示为 ^I-u (被忽略)-v, --show-nonprinting 使用 ^ 和 M- 引用，除了 LFD 和 TAB 之外 功能1.一次显示整个文件:cat filename 2.从键盘创建一个文件:cat &gt; filename 只能创建新文件,不能编辑已有文件. 3.将几个文件合并为一个文件:cat file1 file2 &gt; file 常用范例1）把 log2012.log 的文件内容加上行号后输入 log.log 这个文件里 12345# cat log.log [root@localhost test]# cat -n log2012.log &gt; log.log# cat -n log.log 1 2012-01 2 2012-02 2）使用here doc来生成文件 12345678910111213# cat &gt;log.txt &lt;&lt;EOF&gt; Hello&gt; World&gt; Linux&gt; PWD=$(pwd)&gt; EOF# ls -l log.txt -rw-r--r-- 1 root root 37 10-28 17:07 log.txt# cat log.txt HelloWorldLinuxPWD=/opt/soft/test 说明： 注意粗体部分，here doc可以进行字符串替换。 备注： tac (反向列示) 12345# tac log.txt PWD=/opt/soft/testLinuxWorldHello 说明： tac 是将 cat 反写过来，所以他的功能就跟 cat 相反， cat 是由第一行到最后一行连续显示在萤幕上，而 tac 则是由最后一行到第一行反向在萤幕上显示出来！ 参考链接： http://www.cnblogs.com/peida/archive/2012/10/30/2746968.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-touch命令]]></title>
    <url>%2F2018%2F09%2F18%2FLinux%E5%91%BD%E4%BB%A4-touch%2F</url>
    <content type="text"><![CDATA[linux的touch命令不常用，一般在使用make的时候可能会用到，用来修改文件时间戳，或者新建一个不存在的文件。 语法touch(选项)(参数) 选项123456789-a：或--time=atime或--time=access或--time=use 只更改存取时间；-c：或--no-create 不建立任何文件；-d：&lt;时间日期&gt; 使用指定的日期时间，而非现在的时间；-f：此参数将忽略不予处理，仅负责解决BSD版本touch指令的兼容性问题；-m：或--time=mtime或--time=modify 只更该变动时间；-r：&lt;参考文件或目录&gt; 把指定文件或目录的日期时间，统统设成和参考文件或目录的日期时间相同；-t：&lt;日期时间&gt; 使用指定的日期时间，而非现在的时间；--help：在线帮助；--version：显示版本信息。 功能touch命令参数可更改文档或目录的日期时间，包括存取时间和更改时间。 常用范例1）创建不存在的文件 1234# touch log2012.log log2013.log# ll-rw-r--r-- 1 root root 0 10-28 16:01 log2012.log-rw-r--r-- 1 root root 0 10-28 16:01 log2013.log 如果log2014.log不存在，则不创建文件 1234# touch -c log2014.log# ll-rw-r--r-- 1 root root 0 10-28 16:01 log2012.log-rw-r--r-- 1 root root 0 10-28 16:01 log2013.log 2）更新log.log的时间和log2012.log时间戳相同 123456789# ll-rw-r--r-- 1 root root 0 10-28 16:01 log2012.log-rw-r--r-- 1 root root 0 10-28 16:01 log2013.log-rw-r--r-- 1 root root 0 10-28 14:48 log.log# touch -r log.log log2012.log # ll-rw-r--r-- 1 root root 0 10-28 14:48 log2012.log-rw-r--r-- 1 root root 0 10-28 16:01 log2013.log-rw-r--r-- 1 root root 0 10-28 14:48 log.log 3）设定文件的时间戳 123456789# ll-rw-r--r-- 1 root root 0 10-28 14:48 log2012.log-rw-r--r-- 1 root root 0 10-28 16:01 log2013.log-rw-r--r-- 1 root root 0 10-28 14:48 log.log# touch -t 201211142234.50 log.log# ll-rw-r--r-- 1 root root 0 10-28 14:48 log2012.log-rw-r--r-- 1 root root 0 10-28 16:01 log2013.log-rw-r--r-- 1 root root 0 2012-11-14 log.log 说明： -t time 使用指定的时间值 time 作为指定文件相应时间戳记的新值．此处的 time规定为如下形式的十进制数: [[CC]YY]MMDDhhmm[.SS] 这里，CC为年数中的前两位，即”世纪数”；YY为年数的后两位，即某世纪中的年数．如果不给出CC的值，则touch 将把年数CCYY限定在1969–2068之内．MM为月数，DD为天将把年数CCYY限定在1969–2068之内．MM为月数，DD为天数，hh 为小时数(几点)，mm为分钟数，SS为秒数．此处秒的设定范围是0–61，这样可以处理闰秒．这些数字组成的时间是环境变量TZ指定的时区中的一个时 间．由于系统的限制，早于1970年1月1日的时间是错误的。 参考链接： http://www.cnblogs.com/peida/archive/2012/10/30/2745714.html http://man.linuxde.net/touch]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-cp命令]]></title>
    <url>%2F2018%2F09%2F18%2FLinux%E5%91%BD%E4%BB%A4-cp%2F</url>
    <content type="text"><![CDATA[cp命令用来复制文件或者目录，是Linux系统中最常用的命令之一。一般情况下，shell会设置一个别名，在命令行下复制文件时，如果目标文件已经存在，就会询问是否覆盖，不管你是否使用-i参数。但是如果是在shell脚本中执行cp时，没有-i参数时不会询问是否覆盖。这说明命令行和shell脚本的执行方式有些不同。 语法cp(选项)(参数) 选项123456789101112-a：此参数的效果和同时指定&quot;-dpR&quot;参数相同；-d：当复制符号连接时，把目标文件或目录也建立为符号连接，并指向与源文件或目录连接的原始文件或目录；-f：强行复制文件或目录，不论目标文件或目录是否已存在；-i：覆盖既有文件之前先询问用户；-l：对源文件建立硬连接，而非复制文件；-p：保留源文件或目录的属性；-R/r：递归处理，将指定目录下的所有文件与子目录一并处理；-s：对源文件建立符号连接，而非复制文件；-u：使用这项参数后只会在源文件的更改时间较目标文件更新时或是名称相互对应的目标文件并不存在时，才复制文件；-S：在备份文件时，用指定的后缀“SUFFIX”代替文件的默认后缀；-b：覆盖已存在的文件目标前将目标文件备份；-v：详细显示命令执行的操作。 参数 源文件：制定源文件列表。默认情况下，cp命令不能复制目录，如果要复制目录，则必须使用-R选项； 目标文件：指定目标文件。当“源文件”为多个文件时，要求“目标文件”为指定的目录。 常用范例1）复制单个文件到目标目录，文件在目标文件中不存在 123456789101112# cp log.log test5# ll-rw-r--r-- 1 root root 0 10-28 14:48 log.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 14:47 test3drwxr-xr-x 2 root root 4096 10-28 14:53 test5# cd test5# ll-rw-r--r-- 1 root root 0 10-28 14:46 log5-1.log-rw-r--r-- 1 root root 0 10-28 14:46 log5-2.log-rw-r--r-- 1 root root 0 10-28 14:46 log5-3.log-rw-r--r-- 1 root root 0 10-28 14:53 log.log 说明： 在没有带-a参数时，两个文件的时间是不一样的。在带了-a参数时，两个文件的时间是一致的。 2）目标文件存在时，会询问是否覆盖 12345678910# cp log.log test5cp：是否覆盖“test5/log.log”? n# cp -a log.log test5cp：是否覆盖“test5/log.log”? y# cd test5/# ll-rw-r--r-- 1 root root 0 10-28 14:46 log5-1.log-rw-r--r-- 1 root root 0 10-28 14:46 log5-2.log-rw-r--r-- 1 root root 0 10-28 14:46 log5-3.log-rw-r--r-- 1 root root 0 10-28 14:48 log.log 说明： 目标文件存在时，会询问是否覆盖。这是因为cp是cp -i的别名。目标文件存在时，即使加了-f标志，也还会询问是否覆盖。 3）复制整个目录 目标目录存在时： 12345678910111213#cp -a test3 test5 # ll-rw-r--r-- 1 root root 0 10-28 14:48 log.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 14:47 test3drwxr-xr-x 3 root root 4096 10-28 15:11 test5# cd test5/# ll-rw-r--r-- 1 root root 0 10-28 14:46 log5-1.log-rw-r--r-- 1 root root 0 10-28 14:46 log5-2.log-rw-r--r-- 1 root root 0 10-28 14:46 log5-3.log-rw-r--r-- 1 root root 0 10-28 14:48 log.logdrwxrwxrwx 2 root root 4096 10-28 14:47 test3 目标目录不存在时： 1234567# cp -a test3 test4# ll-rw-r--r-- 1 root root 0 10-28 14:48 log.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 14:47 test3drwxrwxrwx 2 root root 4096 10-28 14:47 test4drwxr-xr-x 3 root root 4096 10-28 15:11 test5 说明： 注意目标目录存在与否结果是不一样的。目标目录存在时，整个源目录被复制到目标目录里面。 4）复制的 log.log 建立一个链接到 log_link.log 12345678# cp -s log.log log_link.log# lllrwxrwxrwx 1 root root 7 10-28 15:18 log_link.log -&gt; log.log-rw-r--r-- 1 root root 0 10-28 14:48 log.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 14:47 test3drwxrwxrwx 2 root root 4096 10-28 14:47 test4drwxr-xr-x 3 root root 4096 10-28 15:11 test5 说明： 那个 log_link.log 是由 -s 的参数造成的，建立的是一个『快捷方式』，所以您会看到在文件的最右边，会显示这个文件是『连结』到哪里去的！ 5）将文件file复制到目录/usr/men/tmp下，并改名为file1 1cp file /usr/men/tmp/file1 6）将目录/usr/men下的所有文件及其子目录复制到目录/usr/zh中 1cp -i /usr/men m*.c /usr/zh 我们在Linux下使用cp命令复制文件时候，有时候会需要覆盖一些同名文件，覆盖文件的时候都会有提示：需要不停的按Y来确定执行覆盖。文件数量不多还好，但是要是几百个估计按Y都要吐血了，于是折腾来半天总结了一个方法： 1234567891011cp aaa/* /bbb复制目录aaa下所有到/bbb目录下，这时如果/bbb目录下有和aaa同名的文件，需要按Y来确认并且会略过aaa目录下的子目录。cp -r aaa/* /bbb这次依然需要按Y来确认操作，但是没有忽略子目录。cp -r -a aaa/* /bbb依然需要按Y来确认操作，并且把aaa目录以及子目录和文件属性也传递到了/bbb。\cp -r -a aaa/* /bbb成功，没有提示按Y、传递了目录属性、没有略过目录。 参考链接： http://www.cnblogs.com/peida/archive/2012/10/29/2744185.html http://man.linuxde.net/cp]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基本操作17-预处理及存储过程]]></title>
    <url>%2F2018%2F09%2F17%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C17-%E9%A2%84%E5%A4%84%E7%90%86%E5%8F%8A%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[1.8 预处理预编译一次，可以多次执行。用来解决一条SQL语句频繁执行的问题。 12预处理语句：prepare 预处理名字 from ‘sql语句’执行预处理：execute 预处理名字 [using 变量] 例题一： 1234567891011121314151617mysql&gt; prepare stmt from &apos;select * from stuinfo&apos;; # 创建预处理Query OK, 0 rows affected (0.00 sec)Statement preparedmysql&gt; execute stmt; # 执行预处理+--------+----------+--------+--------+---------+------------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress |+--------+----------+--------+--------+---------+------------+| s25301 | 张秋丽 | 男 | 18 | 1 | 北京 || s25302 | 李文才 | 男 | 31 | 3 | 上海 || s25303 | 李斯文 | 女 | 22 | 2 | 北京 || s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 || s25305 | 诸葛丽丽 | 女 | 23 | 7 | 河南 || s25318 | 争青小子 | 男 | 26 | 6 | 天津 || s25319 | 梅超风 | 女 | 23 | 5 | 河北 |+--------+----------+--------+--------+---------+------------+7 rows in set (0.00 sec) 例题二：传递参数 123456789101112131415mysql&gt; delimiter // mysql&gt; prepare stmt from &apos;select * from stuinfo where stuno=?&apos; // -- ?是位置占位符Query OK, 0 rows affected (0.00 sec)Statement preparedmysql&gt; set @id=&apos;s25301&apos;; -- 变量以@开头，通过set给变量赋值 -&gt; execute stmt using @id // -- 执行预处理，传递参数Query OK, 0 rows affected (0.00 sec)+--------+---------+--------+--------+---------+------------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress |+--------+---------+--------+--------+---------+------------+| s25301 | 张秋丽 | 男 | 18 | 1 | 北京 |+--------+---------+--------+--------+---------+------------+1 row in set (0.00 sec) 1234脚下留心：1、?是位置占位符2、变量以@开头3、通过set给变量赋值 例题三：传递多个参数 1234567891011121314151617mysql&gt; prepare stmt from &apos;select * from stuinfo where stusex=? and stuaddress=?&apos; //Query OK, 0 rows affected (0.00 sec)Statement preparedmysql&gt; set @sex=&apos;男&apos;; -&gt; set @addr=&apos;北京&apos;; -&gt; execute stmt using @sex,@addr //Query OK, 0 rows affected (0.00 sec)Query OK, 0 rows affected (0.00 sec)+--------+---------+--------+--------+---------+------------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress |+--------+---------+--------+--------+---------+------------+| s25301 | 张秋丽 | 男 | 18 | 1 | 北京 |+--------+---------+--------+--------+---------+------------+1 row in set (0.00 sec) 1.9 存储过程【procedure】1.7.1 存储过程的优点 存储过程可以减少网络流量 允许模块化设计 支持事务 1.7.2 创建存储过程 语法： 123456create procedure 存储过程名(参数)begin //sql语句end;脚下留心：由于过程中有很多SQL语句，每个语句的结束都要用（；）结束。默认情况下，分号既表示语句结束，又表示向服务器发送SQL语句。我们希望分号仅表示语句的结束，不要将SQL语句发送到服务器执行，通过delimiter来更改结束符。 例题 123456mysql&gt; delimiter //mysql&gt; create procedure proc() -- 创建存储过程 -&gt; begin -&gt; select * from stuinfo; -&gt; end //Query OK, 0 rows affected (0.00 sec) 1.7.3 调用存储过程语法： 1call 存储过程名() 例题： 12345678910111213mysql&gt; call proc() // -- 调用存储过程+--------+----------+--------+--------+---------+------------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress |+--------+----------+--------+--------+---------+------------+| s25301 | 张秋丽 | 男 | 18 | 1 | 北京 || s25302 | 李文才 | 男 | 31 | 3 | 上海 || s25303 | 李斯文 | 女 | 22 | 2 | 北京 || s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 || s25305 | 诸葛丽丽 | 女 | 23 | 7 | 河南 || s25318 | 争青小子 | 男 | 26 | 6 | 天津 || s25319 | 梅超风 | 女 | 23 | 5 | 河北 |+--------+----------+--------+--------+---------+------------+7 rows in set (0.00 sec) 1.7.4 删除存储过程语法 1drop procedure [if exists] 存储过程名 例题： 12mysql&gt; drop procedure proc // -- 删除存储过程Query OK, 0 rows affected (0.00 sec) 1.7.5 查看存储过程的信息1show create procedure 存储过程名\G 例题 123456789101112mysql&gt; show create procedure proc \G*************************** 1. row *************************** Procedure: proc sql_mode: STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION Create Procedure: CREATE DEFINER=`root`@`localhost` PROCEDURE `proc`()beginselect * from stuinfo;endcharacter_set_client: gbkcollation_connection: gbk_chinese_ci Database Collation: utf8_general_ci1 row in set (0.00 sec) 1.7.6 显示所有的存储过程1mysql&gt; show procedure status \G 1.7.7 存储过程的参数存储过程的参数分为：输入参数（in）【默认】，输出参数（out），输入输出参数（inout） 存储过程不能使用return返回值，要返回值只能通过“输出参数”来向外传递值。 例题一：传递学号，获取对应的信息 1234567891011mysql&gt; create procedure proc(in param varchar(10)) -- 输入参数 -&gt; select * from stuinfo where stuno=param //Query OK, 0 rows affected (0.00 sec)mysql&gt; call proc(&apos;s25301&apos;) //+--------+---------+--------+--------+---------+------------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress |+--------+---------+--------+--------+---------+------------+| s25301 | 张秋丽 | 男 | 18 | 1 | 北京 |+--------+---------+--------+--------+---------+------------+1 row in set (0.00 sec) 例题二：查找同桌 12345678910111213141516mysql&gt; create procedure proc(name varchar(10)) -&gt; begin -&gt; declare seat tinyint; -- 声明局部变量 -&gt; select stuseat into seat from stuinfo where stuname=name; -- 将座位号保存到变量中 -&gt; select * from stuinfo where stuseat=seat+1 or stuseat=seat-1; -- 查找同桌 -&gt; end //Query OK, 0 rows affected (0.00 sec)mysql&gt; call proc(&apos;李文才&apos;) //+--------+----------+--------+--------+---------+------------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress |+--------+----------+--------+--------+---------+------------+| s25303 | 李斯文 | 女 | 22 | 2 | 北京 || s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 |+--------+----------+--------+--------+---------+------------+2 rows in set (0.00 sec) 强调 123451、通过declare关键字声明局部变量；全局变量@开头就可以了2、给变量赋值有两种方法 方法一：set 变量名=值 方法二：select 字段 into 变量 from 表 where 条件3、声明的变量不能与列名同名 例题三：输出参数 12345678910111213141516mysql&gt; create procedure proc(num int, out result int) //out 表示输出参数 -&gt; begin -&gt; set result=num*num; -&gt; end //Query OK, 0 rows affected (0.00 sec)mysql&gt; call proc(10,@result) //Query OK, 0 rows affected (0.00 sec)mysql&gt; select @result //+---------+| @result |+---------+| 100 |+---------+1 row in set (0.00 sec) 例题四：输入输出参数 12345678910111213141516171819mysql&gt; create procedure proc(inout num int) # inout 表示是输入输出参数 -&gt; begin -&gt; set num=num*num; -&gt; end //Query OK, 0 rows affected (0.00 sec)mysql&gt; set @num=10; -&gt; call proc(@num); -&gt; select @num //Query OK, 0 rows affected (0.00 sec)Query OK, 0 rows affected (0.00 sec)+------+| @num |+------+| 100 |+------+1 row in set (0.00 sec)]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL基本操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基本操作16-简单函数处理]]></title>
    <url>%2F2018%2F09%2F17%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C16-%E7%AE%80%E5%8D%95%E5%87%BD%E6%95%B0%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[1.7 函数1.7.1 数字类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950mysql&gt; select rand(); # 生成随机数+---------------------+| rand() |+---------------------+| 0.18474003969201822 |+---------------------+1 row in set (0.00 sec)mysql&gt; select * from stuinfo order by rand(); # 随机排序mysql&gt; select * from stuinfo order by rand() limit 2; # 随机抽两个学生+--------+----------+--------+--------+---------+------------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress |+--------+----------+--------+--------+---------+------------+| s25305 | 诸葛丽丽 | 女 | 23 | 7 | 河南 || s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 |+--------+----------+--------+--------+---------+------------+2 rows in set (0.00 sec)mysql&gt; select round(3.5); #四舍五入+------------+| round(3.5) |+------------+| 4 |+------------+1 row in set (0.00 sec)mysql&gt; select ceil(3.1); # 向上取整+-----------+| ceil(3.1) |+-----------+| 4 |+-----------+1 row in set (0.00 sec)mysql&gt; select floor(3.9); # 向下取整+------------+| floor(3.9) |+------------+| 3 |+------------+1 row in set (0.00 sec)mysql&gt; select truncate(3.1415926,3); # 截取数字+-----------------------+| truncate(3.1415926,3) |+-----------------------+| 3.141 |+-----------------------+1 row in set (0.00 sec) 1.7.2 字符串类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091mysql&gt; select ucase(&apos;i am a boy!&apos;); # 转成大写+----------------------+| ucase(&apos;i am a boy!&apos;) |+----------------------+| I AM A BOY! |+----------------------+1 row in set (0.00 sec)mysql&gt; select lcase(&apos;I Am A Boy!&apos;); #转成小写+----------------------+| lcase(&apos;I Am A Boy!&apos;) |+----------------------+| i am a boy! |+----------------------+1 row in set (0.00 sec)mysql&gt; select left(&apos;abcde&apos;,3); # 从左边开始截取，截取3个+-----------------+| left(&apos;abcde&apos;,3) |+-----------------+| abc |+-----------------+1 row in set (0.00 sec)mysql&gt; select right(&apos;abcde&apos;,3); # 从右边开始截取，截取3个+------------------+| right(&apos;abcde&apos;,3) |+------------------+| cde |+------------------+1 row in set (0.00 sec)mysql&gt; select substring(&apos;abcde&apos;,2,3); #从第2个位置开始截取，截取3个【位置从1开始】+------------------------+| substring(&apos;abcde&apos;,2,3) |+------------------------+| bcd |+------------------------+1 row in set (0.00 sec)mysql&gt; select concat(&apos;中国&apos;,&apos;上海&apos;); # 字符串相连+-----------------------+| concat(&apos;中国&apos;,&apos;上海&apos;) |+-----------------------+| 中国上海 |+-----------------------+1 row in set (0.00 sec)mysql&gt; select concat(stuname,&apos;-&apos;,stusex) from stuinfo; # 将表中的姓名和性别连接起来+----------------------------+| concat(stuname,&apos;-&apos;,stusex) |+----------------------------+| 张秋丽-男 || 李文才-男 || 李斯文-女 || 欧阳俊雄-男 || 诸葛丽丽-女 || 争青小子-男 || 梅超风-女 |+----------------------------+7 rows in set (0.00 sec)# coalesce(字段1，字段2) 如果字段1不为空就显示字段1，否则，显示字段2mysql&gt; select stuname,coalesce(writtenexam,&apos;缺考&apos;),coalesce(labexam,&apos;缺考&apos;) from stuinfo natural left join stumarks; # 将考试成绩为空的显示为缺考+----------+------------------------------+--------------------------+| stuname | coalesce(writtenexam,&apos;缺考&apos;) | coalesce(labexam,&apos;缺考&apos;) |+----------+------------------------------+--------------------------+| 张秋丽 | 77 | 82 || 李文才 | 50 | 90 || 李斯文 | 88 | 58 || 欧阳俊雄 | 65 | 50 || 诸葛丽丽 | 缺考 | 缺考 || 争青小子 | 56 | 48 || 梅超风 | 缺考 | 缺考 |+----------+------------------------------+--------------------------+mysql&gt; select length(&apos;锄禾日当午&apos;); # 字节长度+----------------------+| length(&apos;锄禾日当午&apos;) |+----------------------+| 10 |+----------------------+1 row in set (0.00 sec)mysql&gt; select char_length(&apos;锄禾日当午&apos;); # 字符个数+---------------------------+| char_length(&apos;锄禾日当午&apos;) |+---------------------------+| 5 |+---------------------------+1 row in set (0.00 sec) 1.7.3 时间类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162mysql&gt; select unix_timestamp(); #获取时间戳+------------------+| unix_timestamp() |+------------------+| 1537084508 |+------------------+1 row in set (0.00 sec)mysql&gt; select from_unixtime(unix_timestamp()); # 将时间戳转成年-月-日 小时:分钟:秒的格式+---------------------------------+| from_unixtime(unix_timestamp()) |+---------------------------------+| 2018-09-16 15:55:56 |+---------------------------------+1 row in set (0.00 sec)mysql&gt; select now(); # 获取当前日期时间+---------------------+| now() |+---------------------+| 2018-09-16 15:57:04 |+---------------------+1 row in set (0.00 sec)mysql&gt; select year(now()) 年,month(now()) 月, day(now()) 日,hour(now()) 小,minute(now()) 分钟,second(now()) 秒;+------+------+------+------+------+------+| 年 | 月 | 日 | 小时 | 分钟 | 秒 |+------+------+------+------+------+------+| 2018 | 9 | 16 | 15 | 59 | 14 |+------+------+------+------+------+------+1 row in set (0.00 sec)mysql&gt; select dayname(now()) 星期,monthname(now()),dayofyear(now()) 本年的第几天;+--------+------------------+--------------+| 星期 | monthname(now()) | 本年的第几天 |+--------+------------------+--------------+| Sunday | September | 259 |+--------+------------------+--------------+1 row in set (0.00 sec)mysql&gt; select datediff(now(),&apos;2008-8-8&apos;); # 日期相减+----------------------------+| datediff(now(),&apos;2008-8-8&apos;) |+----------------------------+| 3691 |+----------------------------+1 row in set (0.00 sec)mysql&gt; select convert(now(),date),convert(now(),time); # 将now()转成日期和时间+---------------------+---------------------+| convert(now(),date) | convert(now(),time) |+---------------------+---------------------+| 2018-09-16 | 16:07:24 |+---------------------+---------------------+mysql&gt; select cast(now() as date),cast(now() as time); # 将now()转成日期和时间+---------------------+---------------------+| cast(now() as date) | cast(now() as time) |+---------------------+---------------------+| 2018-09-16 | 16:08:03 |+---------------------+---------------------+1 row in set (0.00 sec) 1.7.4 加密函数123456+----------------------------------+------------------------------------------+| md5(&apos;root&apos;) | sha(&apos;root&apos;) |+----------------------------------+------------------------------------------+| 63a9f0ea7bb98050796b649e85481845 | dc76e9f0c0006e8f919e0c515c66dbba3982f785 |+----------------------------------+------------------------------------------+1 row in set (0.00 sec) 1.7.5 判断函数语法 1if(表达式,值1,值2) 例题： 123456789101112131415161718192021222324mysql&gt; select if(10%2=0,&apos;偶数&apos;,&apos;奇数&apos;);+--------------------------+| if(10%2=0,&apos;偶数&apos;,&apos;奇数&apos;) |+--------------------------+| 偶数 |+--------------------------+1 row in set (0.00 sec)# 语文和数学都超过60分才通过mysql&gt; select stuname,ch,math,if(ch&gt;=60 &amp;&amp; math&gt;=60,&apos;通过&apos;,&apos;不通过&apos;) &apos;是否通过&apos; from stu;+----------+------+------+----------+| stuname | ch | math | 是否通过 |+----------+------+------+----------+| 张秋丽 | 80 | NULL | 不通过 || 李文才 | 77 | 76 | 通过 || 李斯文 | 55 | 82 | 不通过 || 欧阳俊雄 | NULL | 74 | 不通过 || 诸葛丽丽 | 72 | 56 | 不通过 || 争青小子 | 86 | 92 | 通过 || 梅超风 | 74 | 67 | 通过 || Tom | 65 | 67 | 通过 || Tabm | 88 | 77 | 通过 |+----------+------+------+----------+9 rows in set (0.00 sec)]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL基本操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基本操作15-事务及索引]]></title>
    <url>%2F2018%2F09%2F17%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C15-%E4%BA%8B%E5%8A%A1%E5%8F%8A%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[1.5 事务【transaction】 事务是一个不可分割的执行单元 事务作为一个整体要么一起执行，要么一起回滚 插入测试数据 123456789mysql&gt; create table bank( -&gt; cardid char(4) primary key, -&gt; money int -&gt; );Query OK, 0 rows affected (0.00 sec)mysql&gt; insert into bank values (&apos;1001&apos;,1000),(&apos;1002&apos;,100);Query OK, 2 rows affected (0.00 sec)Records: 2 Duplicates: 0 Warnings: 0 1.5.1 事务操作123开启事务：start transaction或begin [work]提交事务：commit回滚事务：rollback 例题： 12345678910mysql&gt; delimiter // # 更改定界符mysql&gt; start transaction; # 开启事务 -&gt; update bank set money=money-100 where cardid=&apos;1001&apos;; -&gt; update bank set money=money+100 where cardid=&apos;1002&apos; //Query OK, 0 rows affected (0.00 sec)mysql&gt; commit // # 提交事务mysql&gt; rollback // # 回滚事务 1234思考：事务什么时候产生？什么时候结束？答：开启的时候产生，提交事务或回滚事务都结束脚下留心：只有innodb和BDB才支持事务，myisam不支持事务。 1.5.2 设置事务的回滚点语法： 12设置回滚点： savepoint 回滚点名回滚到回滚点： rollback to 回滚点 例题： 12345678910111213141516171819202122232425262728mysql&gt; start transaction;Query OK, 0 rows affected (0.00 sec)mysql&gt; insert into bank values (&apos;1003&apos;,1000);Query OK, 1 row affected (0.00 sec)mysql&gt; savepoint aa; # 设置回滚点 aaQuery OK, 0 rows affected (0.00 sec)mysql&gt; insert into bank values (&apos;1004&apos;,500);Query OK, 1 row affected (0.00 sec) mysql&gt; savepoint bb; # 设置回滚点bbQuery OK, 0 rows affected (0.00 sec) mysql&gt; rollback to aa; # 回滚到aa点Query OK, 0 rows affected (0.00 sec)mysql&gt; commit; # 提交事务mysql&gt; select * from bank ;+--------+-------+| cardid | money |+--------+-------+| 1001 | 800 || 1002 | 200 || 1003 | 1000 |+--------+-------+ 1.5.3 事务的特性（ACID） 原子性（Atomicity）：事务是一个整体，不可以再分，要么一起执行，要么一起不执行。 一致性（Consistency）：事务完成时，数据必须处于一致的状态。 隔离性（Isolation）：每个事务都是相互隔离的 永久性（Durability）：事务完成后，对数据的修改是永久性的。 1.6 索引【index】 索引的优点：查询速度快 索引的缺点： 增、删、改（数据操作语句）效率低了 索引占用空间 1.6.1 索引的类型 普通索引 唯一索引（唯一键） 主键索引：只要主键就自动创建主键索引，不需要手动创建。 全文索引，搜索引擎使用，MySQL不支持中文的全文索引，我们通过sphinx去解决中文的全文索引。 1.6.2 创建普通索引【create index】 语法： 12create index [索引名] on 表名 （字段名）alter table 表名 add index [索引的名称] （列名） 例题： 1234567891011121314151617# 创建索引方法一mysql&gt; create index ix_stuname on stuinfo(stuname);Query OK, 0 rows affected (0.08 sec)Records: 0 Duplicates: 0 Warnings: 0# 创建索引方法二mysql&gt; alter table stuinfo add index ix_address (stuaddress);Query OK, 0 rows affected (0.08 sec)Records: 0 Duplicates: 0 Warnings: 0# 创建表的时候就添加索引mysql&gt; create table emp( -&gt; id int, -&gt; name varchar(10), -&gt; index ix_name (name) # 创建索引 -&gt; );Query OK, 0 rows affected (0.00 sec) 1.6.3 创建唯一索引123语法一：create unique index 索引名 on 表名 （字段名）语法二：alter table 表名 add unqiue [index] [索引的名称] （列名）语法三：创建表的时候添加唯一索引，和创建唯一键是一样的。 例题 1234567891011121314151617# 方法一：mysql&gt; create unique index UQ_stuname on stu(stuname);Query OK, 0 rows affected (0.06 sec)Records: 0 Duplicates: 0 Warnings: 0# 方法二：mysql&gt; alter table stu add unique UQ_address (stuaddress);Query OK, 0 rows affected (0.02 sec)Records: 0 Duplicates: 0 Warnings: 0# 方法三mysql&gt; create table stu2( -&gt; id int, -&gt; name varchar(20), -&gt; unique UQ_name(name) -&gt; );Query OK, 0 rows affected (0.01 sec) 1.6.4 删除索引语法 1drop index 索引名 on 表名 例题 123mysql&gt; drop index ix_stuname on stuinfo;Query OK, 0 rows affected (0.03 sec)Records: 0 Duplicates: 0 Warnings: 0 1.6.5 创建索引的指导原则 该列用于频繁搜索 改列用于排序 公共字段要创建索引 如果表中的数据很少，不需要创建索引。MySQL搜索索引的时间比逐条搜索数据的时间要长。 如果一个字段上的数据只有几个不同的值，改字段不适合做索引，比如性别。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL基本操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基本操作14-视图及视图算法]]></title>
    <url>%2F2018%2F09%2F17%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C14-%E8%A7%86%E5%9B%BE%E5%8F%8A%E8%A7%86%E5%9B%BE%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1.4 视图【view】1、 视图是一张虚拟表，它表示一张表的部分或多张表的综合的结构。 2、 视图仅仅是表结构，没有表数据。视图的结构和数据建立在表的基础上。 1.4.1 创建视图语法 123create [or replace] view 视图的名称as select语句 例题： 1234mysql&gt; create view vw_stu -&gt; as -&gt; select stuname,stusex,writtenexam,labexam from stuinfo inner join stumarks using(stuno);Query OK, 0 rows affected (0.00 sec) 1多学一招：因为视图是一个表结构，所以创建视图后，会在数据库文件夹中多一个与视图名同名的.frm文件 1.4.2 使用视图视图是一张虚拟表，视图的用法和表的用法一样 1234567891011121314mysql&gt; select * from vw_stu;+----------+--------+-------------+---------+| stuname | stusex | writtenexam | labexam |+----------+--------+-------------+---------+| 李斯文 | 女 | 80 | 58 || 李文才 | 男 | 50 | 90 || 欧阳俊雄 | 男 | 65 | 50 || 张秋丽 | 男 | 77 | 82 || 争青小子 | 男 | 56 | 48 |+----------+--------+-------------+---------+mysql&gt; update vw_stu set writtenexam=88 where stuname=&apos;李斯文&apos;;Query OK, 1 row affected (0.05 sec)Rows matched: 1 Changed: 1 Warnings: 0 1.4.3 查看视图的结构语法： 1desc 视图名 例题 123456789mysql&gt; desc vw_stu;+-------------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------------+-------------+------+-----+---------+-------+| stuname | varchar(10) | NO | | NULL | || stusex | char(2) | NO | | NULL | || writtenexam | int(11) | YES | | NULL | || labexam | int(11) | YES | | NULL | |+-------------+-------------+------+-----+---------+-------+ 1.4.4 查看创建视图的语法语法： 1show create view 视图名 例题 1.4.5 显示所有视图1234567891011121314151617181920212223242526272829303132333435363738394041424344 #方法一：mysql&gt; show tables;+------------------+| Tables_in_itcast |+------------------+| stu || stuinfo || stumarks || t1 || t2 || vw_stu |# 方法二mysql&gt; select table_name from information_schema.views;+------------+| table_name |+------------+| vw_stu |+------------+1 row in set (0.05 sec)+------------------+#方法三mysql&gt; show table status where comment=&apos;view&apos; \G*************************** 1. row *************************** Name: vw_stu Engine: NULL Version: NULL Row_format: NULL Rows: NULL Avg_row_length: NULL Data_length: NULLMax_data_length: NULL Index_length: NULL Data_free: NULL Auto_increment: NULL Create_time: NULL Update_time: NULL Check_time: NULL Collation: NULL Checksum: NULL Create_options: NULL Comment: VIEW1 row in set (0.00 sec) 1.4.6 更改视图语法： 123alter view 视图名as select 语句 例题： 1234mysql&gt; alter view vw_stu -&gt; as -&gt; select * from stuinfo;Query OK, 0 rows affected (0.00 sec) 1.4.7 删除视图语法： 1drop view [if exists] 视图1,视图2,… 例题 12mysql&gt; drop view vw_stu;Query OK, 0 rows affected (0.00 sec) 1.4.8 视图的作用 筛选数据，防止未经许可访问敏感数据 隐藏表结构 降低SQL语句的复杂度 1.4.9 视图的算法 场景：找出语文成绩最高的男生和女生 1234567mysql&gt; select * from (select * from stu order by ch desc) as t group by stusex;+--------+----------+--------+--------+---------+------------+------+------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math |+--------+----------+--------+--------+---------+------------+------+------+| s25321 | Tabm | 女 | 23 | 9 | 河北 | 88 | 77 || s25318 | 争青小子 | 男 | 26 | 6 | 天津 | 86 | 92 |+--------+----------+--------+--------+---------+------------+------+------+ 我们可以将子查询封装到视图中 1234mysql&gt; create view vw_stu -&gt; as -&gt; select * from stu order by ch desc;Query OK, 0 rows affected (0.00 sec) 可以将上面的子查询更改成视图，但是，结果和上面不一样 1234567mysql&gt; select * from vw_stu group by stusex;+--------+---------+--------+--------+---------+------------+------+------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math |+--------+---------+--------+--------+---------+------------+------+------+| s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | 80 | NULL || s25303 | 李斯文 | 女 | 22 | 2 | 北京 | 55 | 82 |+--------+---------+--------+--------+---------+------------+------+------+ 原因：这是因为视图的算法造成的 1231. merge：合并算法，将视图的语句和外层的语句合并后在执行。2. temptable：临时表算法，将视图生成一个临时表，再执行外层语句3. undefined：未定义，MySQL到底用merge还是用temptable由MySQL决定，这是一个默认的算法，一般视图都会选择merge算法，因为merge效率高。 解决：在创建视图的时候指定视图的算法 123create algorithm=temptable view 视图名as select 语句 指定算法创建视图 123456789101112mysql&gt; create algorithm=temptable view vw_stu -&gt; as -&gt; select * from stu order by ch desc;Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from vw_stu group by stusex; # 结果是一致的+--------+----------+--------+--------+---------+------------+------+------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math |+--------+----------+--------+--------+---------+------------+------+------+| s25321 | Tabm | 女 | 23 | 9 | 河北 | 88 | 77 || s25318 | 争青小子 | 男 | 26 | 6 | 天津 | 86 | 92 |+--------+----------+--------+--------+---------+------------+------+------+]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL基本操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基本操作13-子查询]]></title>
    <url>%2F2018%2F09%2F17%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C13-%E5%AD%90%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[1.3 子查询语法 1语法：select 语句 where 条件 (select … from 表) 外面的查询称为父查询，括号中的查询称为子查询 子查询为父查询提供查询条件 1.3.1 例题 1、查找笔试80分的学生 123456mysql&gt; select * from stuinfo where stuno=(select stuno from stumarks where writtenexam=80);+--------+---------+--------+--------+---------+------------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress |+--------+---------+--------+--------+---------+------------+| s25303 | 李斯文 | 女 | 22 | 2 | 北京 |+--------+---------+--------+--------+---------+------------+ 2、查找笔试最高分的学生 123456789101112131415161718# 方法一：mysql&gt; select * from stuinfo where stuno=(select stuno from stumarks order by writtenexam desc limit 1);+--------+---------+--------+--------+---------+------------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress |+--------+---------+--------+--------+---------+------------+| s25303 | 李斯文 | 女 | 22 | 2 | 北京 |+--------+---------+--------+--------+---------+------------+1 row in set (0.00 sec)# 方法二：mysql&gt; select * from stuinfo where stuno=(select stuno from stumarks where writtenexam=(select max(writtenexam) from stumarks));+--------+---------+--------+--------+---------+------------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress |+--------+---------+--------+--------+---------+------------+| s25303 | 李斯文 | 女 | 22 | 2 | 北京 |+--------+---------+--------+--------+---------+------------+1 row in set (0.00 sec) 1脚下留心：上面的例题，子查询只能返回一个值。如果子查询返回多个值就不能用“=”了,需要用 in 1.3.2 in|not in子查询用于子查询的返回结果多个值。 1、查找笔试成绩及格的同学 123456789mysql&gt; select * from stuinfo where stuno in (select stuno from stumarks where writtenexam&gt;=60);+--------+----------+--------+--------+---------+------------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress |+--------+----------+--------+--------+---------+------------+| s25301 | 张秋丽 | 男 | 18 | 1 | 北京 || s25303 | 李斯文 | 女 | 22 | 2 | 北京 || s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 |+--------+----------+--------+--------+---------+------------+3 rows in set (0.00 sec) 2、查询不及格的同学 1234567mysql&gt; select * from stuinfo where stuno in (select stuno from stumarks where writtenexam&lt;=60);+--------+----------+--------+--------+---------+------------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress |+--------+----------+--------+--------+---------+------------+| s25302 | 李文才 | 男 | 31 | 3 | 上海 || s25318 | 争青小子 | 男 | 26 | 6 | 天津 |+--------+----------+--------+--------+---------+------------+ 3、查询没有通过的同学（不及格，缺考） 12345678910mysql&gt; select * from stuinfo where stuno not in (select stuno from stumarks where writtenexam&gt;=60);+--------+----------+--------+--------+---------+------------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress |+--------+----------+--------+--------+---------+------------+| s25302 | 李文才 | 男 | 31 | 3 | 上海 || s25305 | 诸葛丽丽 | 女 | 23 | 7 | 河南 || s25318 | 争青小子 | 男 | 26 | 6 | 天津 || s25319 | 梅超风 | 女 | 23 | 5 | 河北 |+--------+----------+--------+--------+---------+------------+4 rows in set (0.00 sec) 1.3.3 exists和not exists1、 如果有人笔试超过80分就显示所有的学生 123456789101112mysql&gt; select * from stuinfo where exists (select * from stumarks where writtenexam&gt;=80);+--------+----------+--------+--------+---------+------------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress |+--------+----------+--------+--------+---------+------------+| s25301 | 张秋丽 | 男 | 18 | 1 | 北京 || s25302 | 李文才 | 男 | 31 | 3 | 上海 || s25303 | 李斯文 | 女 | 22 | 2 | 北京 || s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 || s25305 | 诸葛丽丽 | 女 | 23 | 7 | 河南 || s25318 | 争青小子 | 男 | 26 | 6 | 天津 || s25319 | 梅超风 | 女 | 23 | 5 | 河北 |+--------+----------+--------+--------+---------+------------+ 2、 如果没有人超过80分就显示所有的学生 12mysql&gt; select * from stuinfo where not exists (select * from stumarks where writtenexam&gt;=80);Empty set (0.02 sec) 1.3.4 子查询分类1、标量子查询：子查询返回的结果就一个 2、列子查询：子查询返回的结果是一个列表 3、行子查询：子查询返回的结果是一行 例题：查询成绩最高的男生和女生 1234567mysql&gt; select stuname,stusex,ch from stu where (stusex,ch) in (select stusex,max(ch) from stu group by stusex);+----------+--------+------+| stuname | stusex | ch |+----------+--------+------+| 争青小子 | 男 | 86 || Tabm | 女 | 88 |+----------+--------+------+ 4、表子查询：子查询返回的结果当成一个表 例题：查询成绩最高的男生和女生 1234567mysql&gt; select stuname,stusex,ch from (select * from stu order by ch desc) as t group by stusex;+----------+--------+------+| stuname | stusex | ch |+----------+--------+------+| Tabm | 女 | 88 || 争青小子 | 男 | 86 |+----------+--------+------+ 1脚下留心：from后面是一个表，如果子查询的结果当成表来看，必须将子查询的结果取别名。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL基本操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基本操作12-多表查询1]]></title>
    <url>%2F2018%2F09%2F17%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C12-%E5%A4%9A%E8%A1%A8%E6%9F%A5%E8%AF%A21%2F</url>
    <content type="text"><![CDATA[1.1 目标 理解多表查询 理解子查询 能够创建视图 能够删除视图 能够查看创建视图的SQL语句 能够理解事务的作用 能够操作事务 理解索引的作用 能够创建索引 能够删除索引 知道常用的函数 了解预处理语句的作用 能够使用预处理语句 了解存储过程的作用 能够创建存储过程 能够调用存储过程 1.2 多表查询分类将多个表的数据横向的联合起来。1、 内连接2、 外连接 左外连接 右外连接3、 交叉连接4、 自然连接 1.2.1 内连接【inner join】123语法一：select 列名 from 表1 inner join 表2 on 表1.公共字段=表2.公共字段语法二：select 列名 from 表1,表2 where 表1.公共字段=表2.公共字段 例题 123456789101112131415161718192021222324252627282930313233343536方法一：mysql&gt; select stuname,stusex,writtenexam,labexam from stuinfo inner join stumarks on stuinfo.stuno=stumarks.stuno;+----------+--------+-------------+---------+| stuname | stusex | writtenexam | labexam |+----------+--------+-------------+---------+| 李斯文 | 女 | 80 | 58 || 李文才 | 男 | 50 | 90 || 欧阳俊雄 | 男 | 65 | 50 || 张秋丽 | 男 | 77 | 82 || 争青小子 | 男 | 56 | 48 |+----------+--------+-------------+---------+方法二：mysql&gt; select stuinfo.stuno,stuname,stusex,writtenexam,labexam from stuinfo,stumarks where stuinfo.stuno=stumarks.stuno;+--------+----------+--------+-------------+---------+| stuno | stuname | stusex | writtenexam | labexam |+--------+----------+--------+-------------+---------+| s25303 | 李斯文 | 女 | 80 | 58 || s25302 | 李文才 | 男 | 50 | 90 || s25304 | 欧阳俊雄 | 男 | 65 | 50 || s25301 | 张秋丽 | 男 | 77 | 82 || s25318 | 争青小子 | 男 | 56 | 48 |+--------+----------+--------+-------------+---------+可以给表取别名mysql&gt; select i.stuno,stuname,stusex,writtenexam,labexam from stuinfo i,stumarks s where i.stuno=s.stuno;+--------+----------+--------+-------------+---------+| stuno | stuname | stusex | writtenexam | labexam |+--------+----------+--------+-------------+---------+| s25303 | 李斯文 | 女 | 80 | 58 || s25302 | 李文才 | 男 | 50 | 90 || s25304 | 欧阳俊雄 | 男 | 65 | 50 || s25301 | 张秋丽 | 男 | 77 | 82 || s25318 | 争青小子 | 男 | 56 | 48 |+--------+----------+--------+-------------+---------+5 rows in set (0.00 sec) 脚下留下：显示公共字段需要指定表名 1234思考：select * from 表1 inner join 表2 on 表1.公共字段=表2.公共字段 和select * from 表2 inner join 表1 on 表1.公共字段=表2.公共字段 结果是否一样？答：一样的，因为内连接获取的是两个表的公共部分 123多学一招：三个表的内连接如何实现？select * from 表1 inner join 表2 on 表1.公共字段=表2.公共字段inner join 表3 on 表2.公共字段=表3.公共字段 1.2.2 左外连接【left join】以左边的表为标准，如果右边的表没有对应的记录，用NULL填充。 1语法：select 列名 from 表1 left join 表2 on 表1.公共字段=表2.公共字段 例题 123456789101112mysql&gt; select stuname,writtenexam,labexam from stuinfo left join stumarks on stuinfo.stuno=stumarks.stuno;+----------+-------------+---------+| stuname | writtenexam | labexam |+----------+-------------+---------+| 张秋丽 | 77 | 82 || 李文才 | 50 | 90 || 李斯文 | 80 | 58 || 欧阳俊雄 | 65 | 50 || 诸葛丽丽 | NULL | NULL || 争青小子 | 56 | 48 || 梅超风 | NULL | NULL |+----------+-------------+---------+ 12345思考：select * from 表1 left join 表2 on 表1.公共字段=表2.公共字段和select * from 表2 left join 表1 on 表1.公共字段=表2.公共字段 是否一样？答：不一样，左连接一左边的表为准。 1.2.3 右外连接【right join】以右边的表为标准，如果左边的表没有对应的记录，用NULL填充。 1语法：select 列名 from 表1 right join 表2 on 表1.公共字段=表2.公共字段 例题 123456789101112mysql&gt; select stuname,writtenexam,labexam from stuinfo right join stumarks on stuinfo.stuno=stumarks.stuno;+----------+-------------+---------+| stuname | writtenexam | labexam |+----------+-------------+---------+| 李斯文 | 80 | 58 || 李文才 | 50 | 90 || 欧阳俊雄 | 65 | 50 || 张秋丽 | 77 | 82 || 争青小子 | 56 | 48 || NULL | 66 | 77 |+----------+-------------+---------+6 rows in set (0.00 sec) 123456思考：select * from 表1 left join 表2 on 表1.公共字段=表2.公共字段和select * from 表2 right join 表1 on 表1.公共字段=表2.公共字段 是否一样？答：一样的 1.2.4 交叉连接【cross join】插入测试数据 123456789101112131415mysql&gt; create table t1( -&gt; id int, -&gt; name varchar(10) -&gt; );Query OK, 0 rows affected (0.06 sec)mysql&gt; insert into t1 values (1,&apos;tom&apos;),(2,&apos;berry&apos;);Query OK, 2 rows affected (0.00 sec)mysql&gt; create table t2( -&gt; id int, -&gt; score int);Query OK, 0 rows affected (0.02 sec)mysql&gt; insert into t2 values (1,88),(2,99); 1、如果没有连接表达式返回的是笛卡尔积 123456789mysql&gt; select * from t1 cross join t2; # 返回笛卡尔积+------+-------+------+-------+| id | name | id | score |+------+-------+------+-------+| 1 | tom | 1 | 88 || 2 | berry | 1 | 88 || 1 | tom | 2 | 99 || 2 | berry | 2 | 99 |+------+-------+------+-------+ 2、如果有连接表达式等价于内连接 1234567mysql&gt; select * from t1 cross join t2 where t1.id=t2.id;+------+-------+------+-------+| id | name | id | score |+------+-------+------+-------+| 1 | tom | 1 | 88 || 2 | berry | 2 | 99 |+------+-------+------+-------+ 1.2.5 自然连接【natural】1自动的判断连接条件，它是过同名字段来判断的 自然连接又分为： 自然内连接 natural join. 自然左外连接 natural left join. 自然右外连接 natural right join 例题： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# 自然内连接mysql&gt; select * from stuinfo natural join stumarks;+--------+----------+--------+--------+---------+------------+---------+-------------+---------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | examNo | writtenExam | labExam |+--------+----------+--------+--------+---------+------------+---------+-------------+---------+| s25303 | 李斯文 | 女 | 22 | 2 | 北京 | s271811 | 80 | 58 || s25302 | 李文才 | 男 | 31 | 3 | 上海 | s271813 | 50 | 90 || s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | s271815 | 65 | 50 || s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | s271816 | 77 | 82 || s25318 | 争青小子 | 男 | 26 | 6 | 天津 | s271819 | 56 | 48 |+--------+----------+--------+--------+---------+------------+---------+-------------+---------+5 rows in set (0.00 sec)# 自然左外连接mysql&gt; select * from stuinfo natural left join stumarks;+--------+----------+--------+--------+---------+------------+---------+-------------+---------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | examNo | writtenExam | labExam |+--------+----------+--------+--------+---------+------------+---------+-------------+---------+| s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | s271816 | 77 82 || s25302 | 李文才 | 男 | 31 | 3 | 上海 | s271813 | 50 | 90 || s25303 | 李斯文 | 女 | 22 | 2 | 北京 | s271811 | 80 | 58 || s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | s271815 | 65 50 || s25305 | 诸葛丽丽 | 女 | 23 | 7 | 河南 | NULL | NULL NULL || s25318 | 争青小子 | 男 | 26 | 6 | 天津 | s271819 | 56 48 || s25319 | 梅超风 | 女 | 23 | 5 | 河北 | NULL | NULL |ULL |+--------+----------+--------+--------+---------+------------+---------+-------------+---------+7 rows in set (0.00 sec)# 自然右外连接mysql&gt; select * from stuinfo natural right join stumarks;+--------+---------+-------------+---------+----------+--------+--------+---------+------------+| stuNo | examNo | writtenExam | labExam | stuName | stuSex | stuAge | stuSeat | stuAddress |+--------+---------+-------------+---------+----------+--------+--------+---------+------------+| s25303 | s271811 | 80 | 58 | 李斯文 | 女 | 22 | 2 | 北京 || s25302 | s271813 | 50 | 90 | 李文才 | 男 | 31 | 3 | 上海 || s25304 | s271815 | 65 | 50 | 欧阳俊雄 | 男 | 28 | 4 | 天津 || s25301 | s271816 | 77 | 82 | 张秋丽 | 男 | 18 | 1 | 北京 || s25318 | s271819 | 56 | 48 | 争青小子 | 男 | 26 | 6 | 天津 || s25320 | s271820 | 66 | 77 | NULL | NULL | NULL | NULL | NULL |+--------+---------+-------------+---------+----------+--------+--------+---------+------------+6 rows in set (0.00 sec) 自然连接结论： 表连接通过同名的字段来连接的 如果没有同名的字段返回笛卡尔积 会对结果进行整理，整理的规则如下 a) 连接字段保留一个 b) 连接字段放在最前面 c) 左外连接左边在前，右外连接右表在前 1.2.6 using() 用来指定连接字段。 using()也会对连接字段进行整理，整理方式和自然连接是一样的。 12345678910111213141516mysql&gt; select * from stuinfo inner join stumarks using(stuno); # using指定字段+--------+----------+--------+--------+---------+------------+---------+-------------+---------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | examNo | writtenExam | labExam |+--------+----------+--------+--------+---------+------------+---------+-------------+---------+| s25303 | 李斯文 | 女 | 22 | 2 | 北京 | s271811 | 80 | 58 || s25302 | 李文才 | 男 | 31 | 3 | 上海 | s271813 | 50 | 90 || s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | s271815 | 65 | 50 || s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | s271816 | 77 | 82 || s25318 | 争青小子 | 男 | 26 | 6 | 天津 | s271819 | 56 | 48 |+--------+----------+--------+--------+---------+------------+---------+-------------+---------+5 rows in set (0.00 sec)]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL基本操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-mv命令]]></title>
    <url>%2F2018%2F09%2F16%2FLinux%E5%91%BD%E4%BB%A4-mv%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[mv命令用来对文件或目录重新命名，或者将文件从一个目录移到另一个目录中。source表示源文件或目录，target表示目标文件或目录。如果将一个文件移到一个已经存在的目标文件中，则目标文件的内容将被覆盖。 mv命令可以用来将源文件移至一个目标文件中，或将一组文件移至一个目标目录中。源文件被移至目标文件有两种不同的结果： 如果目标文件是到某一目录文件的路径，源文件会被移到此目录下，且文件名不变。 如果目标文件不是目录文件，则源文件名（只能有一个）会变为此目标文件名，并覆盖己存在的同名文件。如果源文件和目标文件在同一个目录下，mv的作用就是改文件名。当目标文件是目录文件时，源文件或目录参数可以有多个，则所有的源文件都会被移至目标文件中。所有移到该目录下的文件都将保留以前的文件名。 注意事项：mv与cp的结果不同，mv好像文件“搬家”，文件个数并未增加。而cp对文件进行复制，文件个数增加了。 语法mv(选项)(参数) 选项12345678--backup=&lt;备份模式&gt;：若需覆盖文件，则覆盖前先行备份；-b：当文件存在时，覆盖前，为其创建一个备份；-f：若目标文件或目录与现有的文件或目录重复，则直接覆盖现有的文件或目录；-i：交互式操作，覆盖前先行询问用户，如果源文件与目标文件或目标目录中的文件同名，则询问用户是否覆盖目标文件。用户输入”y”，表示将覆盖目标文件；输入”n”，表示取消对源文件的移动。这样可以避免误将文件覆盖。--strip-trailing-slashes：删除源文件中的斜杠“/”；-S&lt;后缀&gt;：为备份文件指定后缀，而不使用默认的后缀；-t:--target-directory=&lt;目录&gt;,指定源文件要移动到目标目录；-u：当源文件比目标文件新或者目标文件不存在时，才执行移动操作。 参数 源文件：源文件列表。 目标文件：如果“目标文件”是文件名则在移动文件的同时，将其改名为“目标文件”；如果“目标文件”是目录名则将源文件移动到“目标文件”下。 常用范例1）文件改名 12345678910111213# ll总计 20drwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5-rw-r--r-- 1 root root 16 10-28 06:04 test.log# mv test.log test1.txt# ll总计 20drwxr-xr-x 6 root root 4096 10-27 01:58 scf-rw-r--r-- 1 root root 16 10-28 06:04 test1.txtdrwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5 2）移动文件 12345678910111213141516# ll总计 20drwxr-xr-x 6 root root 4096 10-27 01:58 scf-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5# mv test1.txt test3# ll总计 16drwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 06:09 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5# cd test3# ll总计 4-rw-r--r-- 1 root root 29 10-28 06:05 test1.txt 3）将文件log1.txt,log2.txt,log3.txt移动到目录test3中 12345678910111213141516171819202122232425262728293031# ll总计 28-rw-r--r-- 1 root root 8 10-28 06:15 log1.txt-rw-r--r-- 1 root root 12 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txtdrwxrwxrwx 2 root root 4096 10-28 06:09 test3# mv log1.txt log2.txt log3.txt test3# ll总计 16drwxrwxrwx 2 root root 4096 10-28 06:18 test3# cd test3/# ll总计 16-rw-r--r-- 1 root root 8 10-28 06:15 log1.txt-rw-r--r-- 1 root root 12 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txt-rw-r--r-- 1 root root 29 10-28 06:05 test1.txt# ll总计 20-rw-r--r-- 1 root root 8 10-28 06:15 log1.txt-rw-r--r-- 1 root root 12 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txtdrwxr-xr-x 2 root root 4096 10-28 06:21 logs-rw-r--r-- 1 root root 29 10-28 06:05 test1.txt# mv -t /opt/soft/test/test4/ log1.txt log2.txt log3.txt ]# cd ..# cd test4/# ll总计 12-rw-r--r-- 1 root root 8 10-28 06:15 log1.txt-rw-r--r-- 1 root root 12 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txt 4）将文件file1改名为file2，如果file2已经存在，则询问是否覆盖 12345678910111213# ll总计 12-rw-r--r-- 1 root root 8 10-28 06:15 log1.txt-rw-r--r-- 1 root root 12 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txt# cat log1.txt odfdfs# cat log2.txt ererwerwer# mv -i log1.txt log2.txt mv：是否覆盖“log2.txt”? y# cat log2.txt odfdfs 5）将文件file1改名为file2，即使file2存在，也是直接覆盖掉 12345678910111213141516171819202122# ll总计 8-rw-r--r-- 1 root root 8 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txt# cat log2.txt odfdfs# cat log3cat: log3: 没有那个文件或目录# ll总计 8-rw-r--r-- 1 root root 8 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txt# cat log2.txt odfdfs# cat log3.txt dfosdfsdfdss# mv -f log3.txt log2.txt # cat log2.txt dfosdfsdfdss# ll总计 4-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt 说明： log3.txt的内容直接覆盖了log2.txt内容，-f 这是个危险的选项，使用的时候一定要保持头脑清晰，一般情况下最好不用加上它。 6）目录的移动 12345678910111213141516171819202122232425ll-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt# ll-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt# cd ..# lldrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 3 root root 4096 10-28 06:24 test3drwxr-xr-x 2 root root 4096 10-28 06:48 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5# cd test3# lldrwxr-xr-x 2 root root 4096 10-28 06:21 logs-rw-r--r-- 1 root root 29 10-28 06:05 test1.txt# cd ..# mv test4 test3# lldrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 4 root root 4096 10-28 06:54 test3drwxr-xr-x 3 root root 4096 10-25 17:56 test5# cd test3/# lldrwxr-xr-x 2 root root 4096 10-28 06:21 log-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxr-xr-x 2 root root 4096 10-28 06:48 test4 说明： 如果目录dir2不存在，将目录dir1改名为dir2；否则，将dir1移动到dir2中。 7）移动当前文件夹下的所有文件到上一级目录 123456789101112# ll-rw-r--r-- 1 root root 25 10-28 07:02 log1.txt-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt# mv * ../# ll# cd ..# ll-rw-r--r-- 1 root root 25 10-28 07:02 log1.txt-rw-r--r-- 1 root root 13 10-28 06:16 log2.txtdrwxr-xr-x 2 root root 4096 10-28 06:21 logs-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxr-xr-x 2 root root 4096 10-28 07:02 test4 8）把当前目录的一个子目录里的文件移动到另一个子目录里 123456789101112131415161718192021222324# lldrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 4 root root 4096 10-28 07:02 test3drwxr-xr-x 3 root root 4096 10-25 17:56 test5# cd test3# ll-rw-r--r-- 1 root root 25 10-28 07:02 log1.txt-rw-r--r-- 1 root root 13 10-28 06:16 log2.txtdrwxr-xr-x 2 root root 4096 10-28 06:21 logs-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxr-xr-x 2 root root 4096 10-28 07:02 test4# cd ..# mv test3/*.txt test5# cd test5# ll-rw-r--r-- 1 root root 25 10-28 07:02 log1.txt-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxr-xr-x 2 root root 4096 10-25 17:56 test5-1# cd ..# cd test3/# lldrwxr-xr-x 2 root root 4096 10-28 06:21 logsdrwxr-xr-x 2 root root 4096 10-28 07:02 test4 9）文件被覆盖前做简单备份，前面加参数-b 123456789101112# ll-rw-r--r-- 1 root root 25 10-28 07:02 log1.txt-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxr-xr-x 2 root root 4096 10-25 17:56 test5-1# mv log1.txt -b log2.txtmv：是否覆盖“log2.txt”? y# ll-rw-r--r-- 1 root root 25 10-28 07:02 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt~-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxr-xr-x 2 root root 4096 10-25 17:56 test5-1 说明： -b 不接受参数，mv会去读取环境变量VERSION_CONTROL来作为备份策略。 –backup该选项指定如果目标文件存在时的动作，共有四种备份策略： 1.CONTROL=none或off : 不备份。 2.CONTROL=numbered或t：数字编号的备份 3.CONTROL=existing或nil：如果存在以数字编号的备份，则继续编号备份m+1…n： 执行mv操作前已存在以数字编号的文件log2.txt.~1~，那么再次执行将产生log2.txt~2~，以次类推。如果之前没有以数字编号的文件，则使用下面讲到的简单备份。 4.CONTROL=simple或never：使用简单备份：在被覆盖前进行了简单备份，简单备份只能有一份，再次被覆盖时，简单备份也会被覆盖。 参考链接： http://www.cnblogs.com/peida/archive/2012/10/27/2743022.html http://man.linuxde.net/mv]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基本操作11-排序分组联合]]></title>
    <url>%2F2018%2F09%2F16%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C11-%E6%8E%92%E5%BA%8F%E5%88%86%E7%BB%84%E8%81%94%E5%90%88%2F</url>
    <content type="text"><![CDATA[1.6.11 order by排序asc：升序【默认】 desc：降序 12345mysql&gt; select * from stu order by ch desc; # 语文成绩降序排列mysql&gt; select * from stu order by math asc; # 数学成绩升序排列mysql&gt; select * from stu order by math; # 默认升序排列 多列排序 12#年龄升序,成绩降序mysql&gt; select *,(ch+math) as &apos;总分&apos; from stu order by stuage asc,(ch+math) desc; 思考如下代码表示什么含义 1234select * from stu order by stuage desc,ch desc; #年龄降序，语文降序select * from stu order by stuage desc,ch asc; #年龄降序，语文升序select * from stu order by stuage,ch desc; #年龄升序、语文降序select * from stu order by stuage,ch; #年龄升序、语文升序 1.6.12 group by 【分组查询】将查询的结果分组，分组查询目的在于统计数据。 123456789101112131415161718192021# 按性别分组，显示每组的平均年龄mysql&gt; select avg(stuage) as &apos;年龄&apos;,stusex from stu group by stusex;+---------+--------+| 年龄 | stusex |+---------+--------+| 22.7500 | 女 || 25.4000 | 男 |+---------+--------+2 rows in set (0.00 sec)# 按地区分组，每个地区的平均年龄mysql&gt; select avg(stuage) as &apos;年龄&apos;,stuaddress from stu group by stuaddress;+---------+------------+| 年龄 | stuaddress |+---------+------------+| 31.0000 | 上海 || 21.3333 | 北京 || 27.0000 | 天津 || 23.0000 | 河北 || 23.0000 | 河南 |+---------+------------+5 rows in set (0.00 sec) 123脚下留心：1、如果是分组查询，查询字段必须是分组字段和聚合函数。2、查询字段是普通字段，只取第一个值 通过group_concat()函数将同一组的值连接起来显示 12345678mysql&gt; select group_concat(stuname),stusex from stu group by stusex;+-------------------------------------+--------+| group_concat(stuname) | stusex |+-------------------------------------+--------+| 李斯文,诸葛丽丽,梅超风,Tabm | 女 || 张秋丽,李文才,欧阳俊雄,争青小子,Tom | 男 |+-------------------------------------+--------+2 rows in set (0.00 sec) 123多学一招：【了解】1、分组后的结果默认会按升序排列显示2、也是可以使用desc实现分组后的降序 多列分组 123456789101112mysql&gt; select stuaddress,stusex,avg(stuage) from stu group by stuaddress,stusex;+------------+--------+-------------+| stuaddress | stusex | avg(stuage) |+------------+--------+-------------+| 上海 | 男 | 31.0000 || 北京 | 女 | 22.0000 || 北京 | 男 | 21.0000 || 天津 | 男 | 27.0000 || 河北 | 女 | 23.0000 || 河南 | 女 | 23.0000 |+------------+--------+-------------+6 rows in set (0.00 sec) 1.6.13 having条件123思考：数据库中的表是一个二维表，返回的结果是一张二维表，既然能在数据库的二维表中进行查询，能否在结果集的二维表上继续进行查询？答：可以，having条件就是在结果集上继续进行筛选。 例题 1234567891011121314151617181920212223mysql&gt; select * from stu where stusex=&apos;男&apos;; # 从数据库中查找+--------+----------+--------+--------+---------+------------+------+------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math |+--------+----------+--------+--------+---------+------------+------+------+| s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | 80 | NULL || s25302 | 李文才 | 男 | 31 | 3 | 上海 | 77 | 76 || s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | NULL | 74 || s25318 | 争青小子 | 男 | 26 | 6 | 天津 | 86 | 92 || s25320 | Tom | 男 | 24 | 8 | 北京 | 65 | 67 |+--------+----------+--------+--------+---------+------------+------+------+5 rows in set (0.00 sec)mysql&gt; select * from stu having stusex=&apos;男&apos;; # 从结果集中查找+--------+----------+--------+--------+---------+------------+------+------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math |+--------+----------+--------+--------+---------+------------+------+------+| s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | 80 | NULL || s25302 | 李文才 | 男 | 31 | 3 | 上海 | 77 | 76 || s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | NULL | 74 || s25318 | 争青小子 | 男 | 26 | 6 | 天津 | 86 | 92 || s25320 | Tom | 男 | 24 | 8 | 北京 | 65 | 67 |+--------+----------+--------+--------+---------+------------+------+------+5 rows in set (0.00 sec) 思考如下语句是否正确 having和where的区别： where是对原始数据进行筛选，having是对记录集进行筛选。 1.6.14 limit语法：limit 起始位置，显示长度 12345678910111213141516mysql&gt; select * from stu limit 0,2; # 从0的位置开始，取两条数据+--------+---------+--------+--------+---------+------------+------+------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math |+--------+---------+--------+--------+---------+------------+------+------+| s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | 80 | NULL || s25302 | 李文才 | 男 | 31 | 3 | 上海 | 77 | 76 |+--------+---------+--------+--------+---------+------------+------+------+2 rows in set (0.00 sec) mysql&gt; select * from stu limit 2,2; # 从2的位置开始，取两条数据+--------+----------+--------+--------+---------+------------+------+------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math |+--------+----------+--------+--------+---------+------------+------+------+| s25303 | 李斯文 | 女 | 22 | 2 | 北京 | 55 | 82 || s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | NULL | 74 |+--------+----------+--------+--------+---------+------------+------+------+ 起始位置可以省略，默认是从0开始 12345678mysql&gt; select * from stu limit 2;+--------+---------+--------+--------+---------+------------+------+------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math |+--------+---------+--------+--------+---------+------------+------+------+| s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | 80 | NULL || s25302 | 李文才 | 男 | 31 | 3 | 上海 | 77 | 76 |+--------+---------+--------+--------+---------+------------+------+------+2 rows in set (0.00 sec) 例题：找出班级总分前三名 12345678mysql&gt; select *,(ch+math) total from stu order by total desc limit 0,3;+--------+----------+--------+--------+---------+------------+------+------+-------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math | total |+--------+----------+--------+--------+---------+------------+------+------+-------+| s25318 | 争青小子 | 男 | 26 | 6 | 天津 | 86 | 92 | 178 || s25321 | Tabm | 女 | 23 | 9 | 河北 | 88 | 77 | 165 || s25302 | 李文才 | 男 | 31 | 3 | 上海 | 77 | 76 | 153 |+--------+----------+--------+--------+---------+------------+------+------+-------+ 多学一招：limit在update和delete语句中也是可以使用的。 1.6.15 查询语句中的选项查询语句中的选项有两个： 1、 all：显示所有数据 【默认】 2、 distinct：去除结果集中重复的数据 1234567891011mysql&gt; select distinct stuaddress from stu;+------------+| stuaddress |+------------+| 上海 || 天津 || 河南 || 河北 || 北京 |+------------+5 rows in set (0.00 sec) 1.7 union（联合）插入测试数据 12345678mysql&gt; create table GO1( -&gt; id int primary key, -&gt; name varchar(20));Query OK, 0 rows affected (0.06 sec)mysql&gt; insert into Go1 values (1,&apos;李白&apos;),(2,&apos;张秋丽&apos;);Query OK, 2 rows affected (0.02 sec)Records: 2 Duplicates: 0 Warnings: 0 1.7.1 union的使用作用：将多个select语句结果集纵向联合起来 1语法：select 语句 union [选项] select 语句 union [选项] select 语句 12345678910111213141516mysql&gt; select stuno,stuname from stu union select id,name from Go1;+--------+----------+| stuno | stuname |+--------+----------+| s25301 | 张秋丽 || s25302 | 李文才 || s25303 | 李斯文 || s25304 | 欧阳俊雄 || s25305 | 诸葛丽丽 || s25318 | 争青小子 || s25319 | 梅超风 || s25320 | Tom || s25321 | Tabm || 1 | 李白 || 2 | 张秋丽 |+--------+----------+ 例题：查询上海的男生和北京的女生 1234567891011121314151617mysql&gt; select stuname,stuaddress,stusex from stu where (stuaddress=&apos;上海&apos; and stusex=&apos;男&apos;) or (stuaddress=&apos;北京&apos; and stusex=&apos;女&apos;);+---------+------------+--------+| stuname | stuaddress | stusex |+---------+------------+--------+| 张秋丽 | 上海 | 男 || 梅超风 | 北京 | 女 |+---------+------------+--------+2 rows in set (0.00 sec)mysql&gt; select stuname,stuaddress,stusex from stu where stuaddress=&apos;上海&apos; and stusex=&apos;男&apos; union select stuname,stuaddress,stusex from stu where stuaddress=&apos;北京&apos; and stusex=&apos;女&apos;;+---------+------------+--------+| stuname | stuaddress | stusex |+---------+------------+--------+| 张秋丽 | 上海 | 男 || 梅超风 | 北京 | 女 |+---------+------------+--------+2 rows in set (0.02 sec) 1.7.2 union的选项union的选项有两个 1、 all：显示所有数据 2、 distinct：去除重复的数据【默认】 123456789101112131415mysql&gt; select name from go1 union select stuname from stu;+----------+| name |+----------+| 李白 || 张秋丽 || 李文才 || 李斯文 || 欧阳俊雄 || 诸葛丽丽 || 争青小子 || 梅超风 || Tom || Tabm |+----------+ 默认是去重复的 12345678910111213141516mysql&gt; select name from go1 union all select stuname from stu; # all不去重复记录+----------+| name |+----------+| 李白 || 张秋丽 || 张秋丽 || 李文才 || 李斯文 || 欧阳俊雄 || 诸葛丽丽 || 争青小子 || 梅超风 || Tom || Tabm |+----------+ 1.7.3 union的注意事项1、 union两边的select语句的字段个数必须一致 2、 union两边的select语句的字段名可以不一致，最终按第一个select语句的字段名。 3、 union两边的select语句中的数据类型可以不一致。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL基本操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-rmdir命令]]></title>
    <url>%2F2018%2F09%2F16%2FLinux%E5%91%BD%E4%BB%A4-rmdir%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[mdir命令。rmdir是常用的命令，该命令的功能是删除空目录，一个目录被删除之前必须是空的。（注意，rm - r dir命令可代替rmdir，但是有很大危险性。）删除某目录时也必须具有对父目录的写权限。 语法rmdir(选项)(参数) 选项12345-p或--parents：删除指定目录后，若该目录的上层目录已变成空目录，则将其一并删除；--ignore-fail-on-non-empty：此选项使rmdir命令忽略由于删除非空目录时导致的错误信息；-v或-verboes：显示命令的详细执行过程；--help：显示命令的帮助信息；--version：显示命令的版本信息。 参数目录列表：要删除的空目录列表。当删除多个空目录时，目录名之间使用空格隔开。 常用范例1）rmdir 不能删除非空目录 1234567891011121314151617181920212223242526272829303132# tree.|-- bin|-- doc| |-- info| `-- product|-- lib|-- logs| |-- info| `-- product`-- service `-- deploy |-- info `-- product12 directories, 0 files# rmdir docrmdir: doc: 目录非空# rmdir doc/info# rmdir doc/product# tree.|-- bin|-- doc|-- lib|-- logs| |-- info| `-- product`-- service `-- deploy |-- info `-- product10 directories, 0 files 2）rmdir -p 当子目录被删除后使它也成为空目录的话，则顺便一并删除 12345678910111213141516171819202122232425262728293031323334353637# tree.|-- bin|-- doc|-- lib|-- logs| `-- product`-- service `-- deploy |-- info `-- product10 directories, 0 files# rmdir -p logsrmdir: logs: 目录非空# tree.|-- bin|-- doc|-- lib|-- logs| `-- product`-- service `-- deploy |-- info `-- product9 directories, 0 files# rmdir -p logs/product# tree.|-- bin|-- doc|-- lib`-- service`-- deploy |-- info `-- product7 directories, 0 files 参考链接： http://www.cnblogs.com/peida/archive/2012/10/27/2742076.html http://man.linuxde.net/rmdir]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基本操作10-查询语句]]></title>
    <url>%2F2018%2F09%2F16%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C10-%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%2F</url>
    <content type="text"><![CDATA[1.6 查询语句1语法：select [选项] 列名 [from 表名] [where 条件] [group by 分组] [order by 排序][having 条件] [limit 限制] 1.6.1 字段表达式12345678910111213mysql&gt; select &apos;锄禾日当午&apos;;+------------+| 锄禾日当午 |+------------+| 锄禾日当午 |+------------+mysql&gt; select 10*10;+-------+| 10*10 |+-------+| 100 |+-------+ 通过as给字段取别名 123456789101112131415mysql&gt; select &apos;锄禾日当午&apos; as content;+------------+| content |+------------+| 锄禾日当午 |+------------+1 row in set (0.00 sec)mysql&gt; select 10*10 as result;+--------+| result |+--------+| 100 |+--------+1 row in set (0.00 sec) 多学一招：as可以省略 1234567mysql&gt; select 10*10 result;+--------+| result |+--------+| 100 |+--------+1 row in set (0.00 sec) 1.6.2 from子句from：来自，from后面跟的是数据源。数据源可以有多个。返回笛卡尔积。 插入测试表 12345678910111213141516171819mysql&gt; create table t1( -&gt; id int, -&gt; name varchar(10) -&gt; );Query OK, 0 rows affected (0.05 sec)mysql&gt; create table t2( -&gt; field1 varchar(10), -&gt; field2 varchar(10) -&gt; );Query OK, 0 rows affected (0.00 sec)mysql&gt; insert into t1 values (1,&apos;tom&apos;),(2,&apos;berry&apos;);Query OK, 2 rows affected (0.00 sec)Records: 2 Duplicates: 0 Warnings: 0mysql&gt; insert into t2 values (&apos;333&apos;,&apos;333&apos;),(&apos;444&apos;,&apos;444&apos;);Query OK, 2 rows affected (0.02 sec)Records: 2 Duplicates: 0 Warnings: 0 测试多个数据源 12345678910mysql&gt; select * from t1,t2; # 返回笛卡尔积+------+-------+--------+--------+| id | name | field1 | field2 |+------+-------+--------+--------+| 1 | tom | 333 | 333 || 2 | berry | 333 | 333 || 1 | tom | 444 | 444 || 2 | berry | 444 | 444 |+------+-------+--------+--------+4 rows in set (0.00 sec) 1.6.3 dual表dual表是一个伪表。在有些特定情况下，没有具体的表的参与，但是为了保证select语句的完整又必须要一个表名，这时候就使用伪表。 123456mysql&gt; select 10*10 as result from dual; #dual表是用来保证select语句的完整性。+--------+| result |+--------+| 100 |+--------+ 1.6.4 where子句where后面跟的是条件，在数据源中进行筛选。返回条件为真记录 MySQL支持的运算符 &gt; 大于 &lt;小于 &gt;= &lt;= = != and 与 or 或 not 非 12mysql&gt; select * from stu where stusex=&apos;男&apos;; # 查找性别是男的记录mysql&gt; select * from stu where stuage&gt;=20; # 查找年龄不低于20的记录 思考：如下代码输出什么 12select * from stu where 1 # 返回所有数据库select * from stu where 0 #返回空记录 思考：如何查找北京和上海的学生 123456789mysql&gt; select * from stu where stuaddress=&apos;上海&apos; or stuaddress=&apos;北京&apos;;+--------+---------+--------+--------+---------+------------+------+------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math |+--------+---------+--------+--------+---------+------------+------+------+| s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | 80 | NULL || s25302 | 李文才 | 男 | 31 | 3 | 上海 | 77 | 76 || s25303 | 李斯文 | 女 | 22 | 2 | 北京 | 55 | 82 || s25320 | Tom | 男 | 24 | 8 | 北京 | 65 | 67 |+--------+---------+--------+--------+---------+------------+------+------+ 1.6.5 in | not in 上面的查询上海和北京的学生的SQL可以通过in语句来实现 1mysql&gt; select * from stu where stuaddress in (&apos;北京&apos;,&apos;上海&apos;); 练习： 1、查找学号是s25301,s25302,s25303的学生 1mysql&gt; select * from stu where stuno in (&apos;s25301&apos;,&apos;s25302&apos;,&apos;s25303&apos;); 2、查找年龄是18,19,20的学生 1mysql&gt; select * from stu where stuage in(18,19,20); 3、查找不是北京和上海的学生 1mysql&gt; select * from stu where stuaddress not in (&apos;北京&apos;,&apos;上海&apos;); 1.6.6 between…and|not between…and查找某个范围的记录 1、查找年龄在18~20之间的学生 123mysql&gt; select * from stu where stuage&gt;=18 and stuage&lt;=20; # 方法一mysql&gt; select * from stu where stuage between 18 and 20; # 方法二 2、查找年龄不在18~20之间的学生 12345mysql&gt; select * from stu where stuage&lt;18 or stuage&gt;20; #方法一mysql&gt; select * from stu where not (stuage&gt;=18 and stuage&lt;=20);mysql&gt; select * from stu where stuage not between 18 and 20; 1.6.7 is null | is not null 脚下留心：查询一个为空的字段不能用等于，必须用is null 查找缺考的学生 1234567mysql&gt; select * from stu where ch is null or math is null; # 查找缺考的人+--------+----------+--------+--------+---------+------------+------+------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math |+--------+----------+--------+--------+---------+------------+------+------+| s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | 80 | NULL || s25304 | 欧阳俊雄 | 男 | 28 | 4 | 天津 | NULL | 74 |+--------+----------+--------+--------+---------+------------+------+------+ 查找参加考试的学生 1mysql&gt; select * from stu where ch is not null and math is not null; 1.6.8 聚合函数 sum() 求和 avg() 求平均值 max() 求最大值 min() 求最小值 count() 求记录数 12345678910#求语文总分、语文平均分、语文最高分、语文最低分、总人数mysql&gt; select sum(ch) &apos;语文总分&apos;,avg(ch) &apos;语文平均分&apos;, max(ch) &apos;语文最高分&apos;,min(ch) &apos;语文最低分&apos;,count(*) &apos;总人数&apos; from stu;+----------+------------+------------+------------+--------+| 语文总分 | 语文平均分 | 语文最高分 | 语文最低分 | 总人数 |+----------+------------+------------+------------+--------+| 597 | 74.6250 | 88 | 55 | 9 |+----------+------------+------------+------------+--------+1 row in set (0.00 sec) 1.6.9 通配符 _ [下划线] 表示任意一个字符 % 表示任意字符 练习 1、满足“T_m”的有（A、C） A：Tom B：Toom C：Tam D：Tm E：Tmo 2、满足“T_m_”的有（B、C ） A:Tmom B:Tmmm C:T1m2 D:Tmm E:Tm 3、满足“张%”的是（A、B、C、D） A:张三 B：张三丰 C：张牙舞爪 D：张 E：小张 4、满足“%诺基亚%”的是（A、B、C、D） A：诺基亚2100 B：2100诺基亚 C：把我的诺基亚拿过来 D：诺基亚 1.6.10 模糊查询（like）12345678910111213141516# 查找姓张的同学mysql&gt; select * from stu where stuname like &apos;张%&apos;;+--------+---------+--------+--------+---------+------------+------+------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math |+--------+---------+--------+--------+---------+------------+------+------+| s25301 | 张秋丽 | 男 | 18 | 1 | 北京 | 80 | NULL |+--------+---------+--------+--------+---------+------------+------+------+1 row in set (0.00 sec)#例题mysql&gt; select * from stu where stuname like &apos;T_m&apos;;+--------+---------+--------+--------+---------+------------+------+------+| stuNo | stuName | stuSex | stuAge | stuSeat | stuAddress | ch | math |+--------+---------+--------+--------+---------+------------+------+------+| s25320 | Tom | 男 | 24 | 8 | 北京 | 65 | 67 |+--------+---------+--------+--------+---------+------------+------+------+1 row in set (0.00 sec) ####]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL基本操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库设计思维与模式]]></title>
    <url>%2F2018%2F09%2F15%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E6%80%9D%E7%BB%B4%E4%B8%8E%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[1.1 今日目标 理解实体之间的关系 理解绘制E-R图 理解三范式 理解范式和性能的关系 1.2 数据库基本概念1、关系：两个表的公共字段 2、行：也称记录，也称实体 3、列：也称字段，也称属性 123就表结构而言，表分为行和列；就表数据而言，分为记录和字段；就面向对象而言，一个记录就是一个实体，一个字段就是一个属性。 4、数据冗余：相同的数据存储在不同的地方 1234脚下留心：1、冗余只能减少，不能杜绝。2、减少冗余的方法是分表3、为减少数据查找的麻烦，允许数据有一定的冗余 5、数据完整性：正确性+准确性=数据完整性 12正确性：数据类型正确准确性：数据范围要准确 思考：学生的年龄是整型，输入1000岁，正确性和准确性如何？ 答：正确的，但不准确 思考：年龄是整形的，收入了字符串，正确性和准确性如何？ 答：不正确 1.3 实体和实体之间的关系 1、一对一 2、一对多 （多对一） 3、多对多 1.3.1 一对多 1：N1、主表中的一条记录对应从表中的多条记录。 2、一对多和多对一是一样的 如何实现一对多？ 答：主键和非主键建关系 问题：说出几个一对多的关系？ 答：班级表和学生表、 班主表和学生表 1.3.2 一对一（1:1）1、主表中的一条记录对应从表中的一条记录 如何实现一对一？ 主键和主键建关系就能实现一对一。 123思考：一对一两个表完全可以用一个表实现，为什么还要分成两个表？答：在字段数量很多情况下，数据量也就很大，每次查询都需要检索大量数据，这样效率低下。我们可以将所有字段分成两个部分，“常用字段”和“不常用字段”，这样对大部分查询者来说效率提高了。【表的垂直分割】 1.3.3 多对多（N：M）主表中的一条记录对应从表中的多条记录，从表中的一条记录对应主表中的多条记录 班级和老师的关系 如何实现多对多？ 答：建立第三张表来保存关系。 问题：说出几个多对多的关系？ 1、科目表和学生表的关系 2、商品表和订单表 3、游戏目录表和玩家表 1.4 数据库设计的步骤 1.4.1 数据库设计具体步骤1、 收集信息：与该系统有关人员进行交流、坐谈，充分理解数据库需要完成的任务 2、 标识对象（实体－Entity）标识数据库要管理的关键对象或实体 3、 标识每个实体的属性（Attribute） 4、 标识对象之间的关系（Relationship） 5、 将模型转换成数据库 6、 规范化 1.4.2 绘制E-R图 E-R（Entity－Relationship）实体关系图 E-R图的语法 绘制E-R图 1.4.3 将E-R图转成表1、 实体转成表，属性转成字段 2、 如果没有合适的字段做主键，给表添加一个自动增长列做主键。 1.4.4 例题1、项目需求 12345BBS论坛的基本功能：用户注册和登录，后台数据库需要存放用户的注册信息和在线状态信息；用户发贴，后台数据库需要存放贴子相关信息，如贴子内容、标题等；用户可以对发帖进行回复；论坛版块管理：后台数据库需要存放各个版块信息，如版主、版块名称、贴子数等； 2、标识对象 ​ 参与的对象有：用户、发的帖子、跟帖、板块 3、标识对象的属性 4、建立关系，绘制E-R图 5、将E-R图转出表结构 1.5 数据规范化Codd博士定义了6个范式来规范化数据库，范式由小到大来约束，范式越高冗余越小，但表的个数也越多。实验证明，三范式是性价比最高的。 1.5.1 第一范式：确保每列原子性第一范式确保每个字段不可再分 思考：如下表设计是否合理？ 不合理。不满足第一范式，上课时间可以再分 思考：地址包含省、市、县、地区是否需要拆分？ 答：如果仅仅起地址的作用，不需要统计，可以不拆分；如果有按地区统计的功能需要拆分。 在实际项目中，建议拆分。 1.5.2 第二范式：非键字段必须依赖于键字段一个表只能描述一件事 思考：如下表设计是否合理？ 1.5.3 第三范式：消除传递依赖在所有的非键字段中，不能有传递依赖 下列设计是否满足第三范式？ 不满足，因为语文和数学确定了，总分就确定了。 123多学一招：上面的设计不满足第三范式，但是高考分数表就是这样设计的，为什么？答：高考分数峰值访问量非常大，这时候就是性能更重要。当性能和规范化冲突的时候，我们首选性能。这就是“反三范式”。 1.5.4 数据库设计的例题1、需求 123公司承担多个工程项目，每一项工程有：工程号、工程名称、施工人员等公司有多名职工，每一名职工有：职工号、姓名、性别、职务（工程师、技术员）等公司按照工时和小时工资率支付工资，小时工资率由职工的职务决定（例如，技术员的小时工资率与工程师不同） 2、工资表 3、将工资表转成数据库表 4、这个表存在的问题 ​ A：新人入职需要虚拟一个项目 ​ B：职务更改，小时工资率可能会忘记更改，造成数据不完整 ​ C：有人离职，删除记录后，工程也没有了 5、规范化表 ​ 第一步：这个表满足第一范式 ​ 第二步：这个表不是描述了一件事情 第三步：是否满足第三范式 更改如下：]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL基本操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-rm]]></title>
    <url>%2F2018%2F09%2F14%2FLinux%E5%91%BD%E4%BB%A4-rm%2F</url>
    <content type="text"><![CDATA[rm命令可以删除一个目录中的一个或多个文件或目录，也可以将某个目录及其下属的所有文件及其子目录均删除掉。对于链接文件，只是删除整个链接文件，而原有文件保持不变。 rm是一个危险的命令，使用的时候要特别当心，尤其对于新手，否则整个系统就会毁在这个命令（比如在/（根目录）下执行rm * -rf）。所以，我们在执行rm之前最好先确认一下在哪个目录，到底要删除什么东西，操作时保持高度清醒的头脑。 语法rm (选项)(参数) 选项123456-d：直接把欲删除的目录的硬连接数据删除成0，删除该目录；-f：强制删除文件或目录；-i：删除已有文件或目录之前先询问用户；-r或-R：递归处理，将指定目录下的所有文件与子目录一并处理；--preserve-root：不对根目录进行递归操作；-v：显示指令的详细执行过程。 参数文件：指定被删除的文件列表，如果参数中含有目录，则必须加上-r或者-R选项。 常用范例1）删除文件file，系统会先询问是否删除。 12# rm log.log rm：是否删除 一般文件 “log.log”? y 输入rm log.log命令后，系统会询问是否删除，输入y后就会删除文件，不想删除则数据n。 2）强行删除file，系统不再提示 1rm -f log1.log 3）删除任何.log文件；删除前逐一询问确认 1rm -i *.log 4）将 test1子目录及子目录中所有档案删除 1rm -r test1]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-mkdir]]></title>
    <url>%2F2018%2F09%2F14%2FLinux%E5%91%BD%E4%BB%A4-mkdir%2F</url>
    <content type="text"><![CDATA[mkdir命令用来创建目录。该命令创建由dirname命名的目录。如果在目录名的前面没有加任何路径名，则在当前目录下创建由dirname指定的目录；如果给出了一个已经存在的路径，将会在该目录下创建一个指定的目录。在创建目录时，应保证新建的目录与它所在目录下的文件没有重名。 语法cd (选项) (参数) 选项12345-Z：设置安全上下文，当使用SELinux时有效；-m&lt;目标属性&gt;或--mode&lt;目标属性&gt;建立目录的同时设置目录的权限；-p或--parents 若所要建立目录的上层目录目前尚未建立，则会一并建立上层目录；-v, --verbose 每次创建新目录都显示信息--version 显示版本信息。 常用范例1）创建一个空目录 1mkdir test1 2）递归创建多个目录 1mkdir -p test2/test22 3）创建权限为777的目录 1mkdir -m 777 test3 4）一个命令创建项目的目录结构 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#mkdir -vp scf/&#123;lib/,bin/,doc/&#123;info,product&#125;,logs/&#123;info,product&#125;,service/deploy/&#123;info,product&#125;&#125;mkdir: 已创建目录 “scf”mkdir: 已创建目录 “scf/lib”mkdir: 已创建目录 “scf/bin”mkdir: 已创建目录 “scf/doc”mkdir: 已创建目录 “scf/doc/info”mkdir: 已创建目录 “scf/doc/product”mkdir: 已创建目录 “scf/logs”mkdir: 已创建目录 “scf/logs/info”mkdir: 已创建目录 “scf/logs/product”mkdir: 已创建目录 “scf/service”mkdir: 已创建目录 “scf/service/deploy”mkdir: 已创建目录 “scf/service/deploy/info”mkdir: 已创建目录 “scf/service/deploy/product”# tree scf/scf/|-- bin|-- doc| |-- info| `-- product|-- lib|-- logs| |-- info| `-- product`-- service `-- deploy |-- info `-- product12 directories, 0 files]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基本操作9]]></title>
    <url>%2F2018%2F09%2F13%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C9%2F</url>
    <content type="text"><![CDATA[1.15 数据完整性介绍 1.15.1 保证实体完整性1、 主键约束 2、 唯一约束 3、 自动增长列 1.15.2 保证域完整性1、 数据类型约束 2、 非空约束 3、 默认值约束 1.15.3 保证引用完整性1、外键约束：从表中的公共字段是主表的外键 1.16 引用完整性1.16.1 主表和从表两个表建立关系（两个表只要有公共字段就有关系），一个表称为主表，一个表称为从表。 外键约束可以实现： 1、 主表中没有的从表中不允许插入 2、 从表中有的主表中不允许删除 3、 不能更改主表中的值而导致从表中的记录孤立存在。 4、 先删除从表，再删除主表 1.16.2 外键（foreign key）1、 外键：从表中的公共字段，公共字段的名字可以不一样，但是数据类型必须一样。 2、 外键约束用来保证引用完整性 1.16.3 添加外键方法一：创建表的时候添加外键 12345678910create table stuinfo( stuno char(4) primary key, name varchar(10) not null);create table stumarks( stuid char(4) primary key, score tinyint unsigned, foreign key (stuid) references stuinfo(stuno)); 方法二：修改表的时候添加外键 1234567891011121314151617mysql&gt; create table stuinfo( -&gt; stuno char(4) primary key, -&gt; name varchar(10) not null -&gt; );Query OK, 0 rows affected (0.00 sec)mysql&gt; create table stumarks( -&gt; stuid char(4) primary key, -&gt; score tinyint unsigned -&gt; );Query OK, 0 rows affected (0.06 sec)语法： alter table 从表 add foreign key (从表的公共字段) references 主表(公共字段)mysql&gt; alter table stumarks add foreign key (stuid) references stuinfo(stuno);Query OK, 0 rows affected (0.06 sec)Records: 0 Duplicates: 0 Warnings: 0 脚下留心：要创建外键必须是innodb引擎，myisam不支持外键约束 1.16.4 查看外键 1.16.5 删除外键通过外键的名字删除外键 1语法：alter table 表名 drop foreign key 外键名 例题 123mysql&gt; alter table stumarks drop foreign key stumarks_ibfk_1;Query OK, 0 rows affected (0.02 sec)Records: 0 Duplicates: 0 Warnings: 0 。 1.17 外键操作1、 严格操作（前面讲的是严格操作） 2、 置空操作（set null）：如果主表记录删除或更新，从表置空 3、 级联操作（cascade）：如果主表记录删除或更新，从表级联 一般来说：主表删除的时候，从表置空操作，主表更新的时候，从表级联操作。 1语法：foreign key(外键) references 主表(关键字段)[主表删除是的动作][主表更新时候的动作] 例题 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950mysql&gt; create table stuinfo( -&gt; stuno char(4) primary key, -&gt; name varchar(10) not null -&gt; );Query OK, 0 rows affected (0.02 sec)mysql&gt; create table stumarks( -&gt; stuid int auto_increment primary key, -&gt; stuno char(4) , -&gt; score tinyint unsigned, -&gt; foreign key (stuno) references stuinfo(stuno) on delete set null on update cascade -&gt; );Query OK, 0 rows affected (0.00 sec)mysql&gt; insert into stuinfo values (&apos;s101&apos;,&apos;tom&apos;);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into stumarks values (null,&apos;s101&apos;,88);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from stuinfo;+-------+------+| stuno | name |+-------+------+| s101 | tom |+-------+------+1 row in set (0.00 sec)mysql&gt; update stuinfo set stuno=&apos;s102&apos; where stuno=&apos;s101&apos;; # 更新时级联Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; select * from stumarks;+-------+-------+-------+| stuid | stuno | score |+-------+-------+-------+| 1 | s102 | 88 |+-------+-------+-------+1 row in set (0.00 sec)mysql&gt; delete from stuinfo where stuno=&apos;s102&apos;; # 删除时置空Query OK, 1 row affected (0.02 sec)mysql&gt; select * from stumarks;+-------+-------+-------+| stuid | stuno | score |+-------+-------+-------+| 1 | NULL | 88 |+-------+-------+-------+1 row in set (0.00 sec) 1.18客户端介绍第一：命令行 第二：MySQL-Front和Navicat MySQL-Front]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL基本操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基本操作8]]></title>
    <url>%2F2018%2F09%2F13%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C8%2F</url>
    <content type="text"><![CDATA[1.11.2 创建组合键 1.11.3 查看主键 1.11.3 删除主键 1.11.4 选择主键的原则1、 最少性：尽量选择一个字段做主键 2、 稳定性：尽量选择更新少的列做主键 3、 尽量选择数字型的列做主键 1.11.5 主键思考题1、在主键列输入的数值，允许为空吗? 不可以 2、 一个表可以有多个主键吗? 不可以 3、 在一个学校数据库中，如果一个学校内允许重名的学员，但是一个班级内不允许学员重名，可以组合班级和姓名两个字段一起来作为主键吗？ 可以 4、 标识列（自动增长列）允许为字符数据类型吗？ 不可以 5、 表中没有合适的列作为主键怎么办？ 添加自动增加列 6、 如果标识列A的初始值为1，增长量为1，则输入三行数据以后，再删除两行，下次再输入数据行的时候，标识值从多少开始？ 从4开始 1.12 列属性——唯一键特点： 1、不能重复，可以为空 2、一个表可以有多个唯一键 作用： 1、 保证数据不能重复。保证数据完整性 2、 加快数据访问 1.12.1 添加唯一键方法一：创建表的时候添加唯一键 1234567891011121314mysql&gt; create table t22( -&gt; id int primary key, -&gt; name varchar(20) unique, #通过unique添加唯一键 -&gt; addr varchar(100) unique -&gt; );Query OK, 0 rows affected (0.00 sec)mysql&gt; insert into t22 values (1,&apos;tom&apos;,&apos;上海&apos;);Query OK, 1 row affected (0.05 sec)mysql&gt; insert into t22 values (2,&apos;tom&apos;,&apos;北京&apos;); # name重复了，报错ERROR 1062 (23000): Duplicate entry &apos;tom&apos; for key &apos;name&apos;mysql&gt; insert into t22 values (2,&apos;berry&apos;,&apos;上海&apos;); # addr重复了 ERROR 1062 (23000): Duplicate entry &apos;上海&apos; for key &apos;addr&apos; 还有一种方法 123456789mysql&gt; create table t26( -&gt; id int, -&gt; name varchar(20), -&gt; addr varchar(20), -&gt; primary key(id), -&gt; unique (name), # 添加唯一键 -&gt; unique (addr) -&gt; );Query OK, 0 rows affected (0.06 sec) 方法二：修改表的时候添加唯一键 123456789mysql&gt; create table t23( -&gt; id int primary key, -&gt; name varchar(20) -&gt; );Query OK, 0 rows affected (0.02 sec)mysql&gt; alter table t23 add unique (name); # 添加一个唯一键Query OK, 0 rows affected (0.02 sec)Records: 0 Duplicates: 0 Warnings: 0 一次添加多个唯一键 12345678910mysql&gt; create table t24( -&gt; id int primary key, -&gt; name varchar(20), -&gt; addr varchar(20) -&gt; );Query OK, 0 rows affected (0.06 sec)mysql&gt; alter table t24 add unique(name),add unique(addr); Query OK, 0 rows affected (0.09 sec)Records: 0 Duplicates: 0 Warnings: 0 添加组合唯一键 12345678910mysql&gt; create table t25( -&gt; id int primary key, -&gt; name varchar(20), -&gt; addr varchar(20) -&gt; );Query OK, 0 rows affected (0.09 sec)mysql&gt; alter table t25 add unique(name,addr);Query OK, 0 rows affected (0.01 sec)Records: 0 Duplicates: 0 Warnings: 0 1.12.2查看唯一键123456789101112131415161718192021222324mysql&gt; show create table t26\G*************************** 1. row *************************** Table: t26Create Table: CREATE TABLE `t26` ( `id` int(11) NOT NULL DEFAULT &apos;0&apos;, `name` varchar(20) DEFAULT NULL, `addr` varchar(20) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `name` (`name`), # 唯一键 UNIQUE KEY `addr` (`addr`) # 唯一键) ENGINE=InnoDB DEFAULT CHARSET=utf81 row in set (0.00 sec)mysql&gt; show create table t25\G*************************** 1. row *************************** Table: t25Create Table: CREATE TABLE `t25` ( `id` int(11) NOT NULL, `name` varchar(20) DEFAULT NULL, `addr` varchar(20) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `name` (`name`,`addr`) # 组合唯一键) ENGINE=InnoDB DEFAULT CHARSET=utf81 row in set (0.00 sec) 添加唯一键，给唯一键取名 1234567891011121314151617mysql&gt; create table t27( -&gt; name varchar(20) -&gt; );Query OK, 0 rows affected (0.03 sec)mysql&gt; alter table t27 add unique UQ_name(name);Query OK, 0 rows affected (0.00 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; show create table t27\G*************************** 1. row *************************** Table: t27Create Table: CREATE TABLE `t27` ( `name` varchar(20) DEFAULT NULL, UNIQUE KEY `UQ_name` (`name`) # 唯一键的名字是UQ_name) ENGINE=InnoDB DEFAULT CHARSET=utf81 row in set (0.00 sec) 1.12.3 删除唯一键通过唯一键的名字来删除唯一键 1语法：alter table 表名 drop index 唯一键名称 问题：主键和唯一键的区别？ 1、主键不能重复，不能为空，唯一键不能重复，可以为空 2、主键只有一个，唯一键可以有多个。 1.13列属性——备注（comment）为了程序员之间的相互交流 1.14 SQL注释单行注释：–或# 多行注释：/ /]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL基本操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基本操作7]]></title>
    <url>%2F2018%2F09%2F13%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C7%2F</url>
    <content type="text"><![CDATA[1.6 数据类型——booleanMySQL不支持boolean类型，true和false在数据库中对应1和0。 1234567891011121314151617mysql&gt; create table t15( -&gt; field boolean -&gt; );Query OK, 0 rows affected (0.00 sec)mysql&gt; insert into t15 values (true),(false); # true和false在数据库中对应1和0Query OK, 2 rows affected (0.00 sec)Records: 2 Duplicates: 0 Warnings: 0mysql&gt; select * from t15;+-------+| field |+-------+| 1 || 0 |+-------+2 rows in set (0.00 sec) 1.7 关于数据类型的思考题 手机号码一般使用什么数据类型存储? char 电话号码使用什么数据类型 varchar 性别一般使用什么数据类型存储? char enum 学生年龄信息一般使用什么数据类型存储? tinyint 照片信息一般使用什么数据类型存储? binary 薪水一般使用什么数据类型存储? decimal 多学一招：一个字段到底选数字还是字符，取决于有没有计算的可能，如果没有计算的可能即使是数字也要用字符类型，比如手机号、QQ号，… 1.8 列属性——是否为空(null | not null)null：可以为空 not null：不可以为空 思考题 学员姓名允许为空吗? 非空 家庭地址允许为空吗? 非空 电子邮件信息允许为空吗? 可以为空 考试成绩允许为空吗? 可以为空 1.9 列属性——默认值（default）1、如果一个字段没有插入值，可以默认插入一个指定的值。 2、default关键字用来插入默认值 123456789101112131415161718mysql&gt; create table t16( -&gt; id int unsigned, -&gt; addr varchar(20) not null default &apos;地址不详&apos; -&gt; );Query OK, 0 rows affected (0.06 sec)mysql&gt; insert into t16 values (1,&apos;北京&apos;),(2,default);Query OK, 2 rows affected (0.00 sec)Records: 2 Duplicates: 0 Warnings: 0mysql&gt; select * from t16;+------+----------+| id | addr |+------+----------+| 1 | 北京 || 2 | 地址不详 |+------+----------+2 rows in set (0.00 sec) 1.10 列属性——自动增长（auto_increment）1、字段的值从1开始，每次递增1，特点就在字段中的数据不可能重复，适合为记录生成唯一的id 2、自动增长都是无符号整数。 3、在MySQL中，auto_increment必须是主键。但是主键不一定是自动增长的。 4、如果要给自动增长列插入数据，使用null关键字。 5、自动增长列上的数据被删除，默认情况下此记录的编号不再使用。 1.11 列属性——主键（primary key）主键：唯一标识表中记录的一个或一组列 主键的特点：不能重复，不能为空 一个表只能有一个主键，主键可以有多个字段组成。 主键的作用： 1、 保证数据完整性 2、 加快查询速度 1.11.1 添加主键方法一：创建表的时候添加主键 1234567891011121314151617181920212223242526mysql&gt; create table t17( -&gt; id varchar(5) primary key, # 创建主键 -&gt; name varchar(10) not null -&gt; );Query OK, 0 rows affected (0.00 sec)mysql&gt; insert into t17 values (&apos;s2531&apos;,&apos;tom&apos;),(&apos;s2532&apos;,&apos;berry&apos;);Query OK, 2 rows affected (0.00 sec)Records: 2 Duplicates: 0 Warnings: 0mysql&gt; select * from t17;+-------+-------+| id | name |+-------+-------+| s2531 | tom || s2532 | berry |+-------+-------+2 rows in set (0.00 sec)# 如果插入主键相同数据会报错mysql&gt; insert into t17 values (&apos;s2531&apos;,&apos;tom&apos;);ERROR 1062 (23000): Duplicate entry &apos;s2531&apos; for key &apos;PRIMARY&apos;# 主键不能插入null值mysql&gt; insert into t17 values (null,&apos;tom&apos;);ERROR 1048 (23000): Column &apos;id&apos; cannot be null 方法二：创建表的时候添加主键 123456789101112131415mysql&gt; create table t18( -&gt; id int, -&gt; name varchar(10), -&gt; primary key(id) -&gt; );Query OK, 0 rows affected (0.00 sec)mysql&gt; desc t18;+-------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+-------------+------+-----+---------+-------+| id | int(11) | NO | PRI | 0 | || name | varchar(10) | YES | | NULL | |+-------+-------------+------+-----+---------+-------+2 rows in set (0.00 sec) 方法三：更改表的时候添加主键 123456789101112131415161718mysql&gt; create table t20( -&gt; id int, -&gt; name varchar(10) -&gt; );Query OK, 0 rows affected (0.00 sec)mysql&gt; alter table t20 add primary key (id); # 更改表添加主键Query OK, 0 rows affected (0.08 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc t20;+-------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+-------------+------+-----+---------+-------+| id | int(11) | NO | PRI | 0 | || name | varchar(10) | YES | | NULL | |+-------+-------------+------+-----+---------+-------+2 rows in set (0.00 sec) ####]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL基本操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基本操作6]]></title>
    <url>%2F2018%2F09%2F12%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C6%2F</url>
    <content type="text"><![CDATA[1.3 数据类型——枚举（enum）1、从集合中选择一个数据（单选） 123456789101112131415161718192021mysql&gt; create table t8( -&gt; name varchar(20), -&gt; sex enum(&apos;男&apos;,&apos;女&apos;,&apos;保密&apos;) # 枚举 -&gt; )charset=utf8;Query OK, 0 rows affected (0.06 sec)mysql&gt; insert into t8 values (&apos;tom&apos;,&apos;男&apos;);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into t8 values (&apos;berry&apos;,&apos;女&apos;);Query OK, 1 row affected (0.05 sec)mysql&gt; insert into t8 values (&apos;rose&apos;,&apos;未知&apos;); # 报错，只能插入枚举值ERROR 1265 (01000): Data truncated for column &apos;sex&apos; at row 1mysql&gt; select * from t8;+-------+------+| name | sex |+-------+------+| tom | 男 || berry | 女 |+-------+------+ 2、MySQL的枚举类型是通过整数来管理的，第一个值是1，第二个值是2，以此类推。 1234567mysql&gt; select sex+0 from t8;+-------+| sex+0 |+-------+| 1 || 2 |+-------+ 1234567mysql&gt; select sex+0 from t8;+-------+| sex+0 |+-------+| 1 || 2 |+-------+ 3、既然枚举在数据库内部存储的是整数，那么可以直接插入数字 123456789101112mysql&gt; insert into t8 values (&apos;rose&apos;,3); # 可以直接插入数字Query OK, 1 row affected (0.00 sec)mysql&gt; select * from t8;+-------+------+| name | sex |+-------+------+| tom | 男 || berry | 女 || rose | 保密 |+-------+------+3 rows in set (0.00 sec) 枚举的优点： 1、 运行速度快（数字比字符串运算速度快） 2、 限制数据，保证数据完整性 3、 节省空间 123思考：已知枚举占用2个字节，请问最多有多少个枚举值？答：2个字节=16位，可以保存数字（0-65535），枚举是从1开始，所以枚举最多可以有65535个枚举值。 1.4 数据类型——集合（set）从集合中选择一些数据（多选） 12345678910111213141516mysql&gt; create table t9( -&gt; hobby set(&apos;爬山&apos;,&apos;读书&apos;,&apos;游泳&apos;,&apos;敲代码&apos;) -&gt; );Query OK, 0 rows affected (0.08 sec)mysql&gt; insert into t9 values (&apos;爬山&apos;);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into t9 values (&apos;爬山,游泳&apos;);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into t9 values (&apos;游泳,爬山&apos;); # 插入顺序不一样，但是显示的顺序是一样的Query OK, 1 row affected (0.02 sec)mysql&gt; insert into t9 values (&apos;爬山,游泳,开车&apos;); # 报错，插入集合中没有的选项会报错ERROR 1265 (01000): Data truncated for column &apos;hobby&apos; at row 1 每个集合的元素都分配一个固定的数字，分配的方式从左往右按2的0、1、2、…次方 123思考：已知集合占用8个字节，最多可以表示几个选项？答：8个字节=64位，一个位表示1个选项，最多可以表示64个选项。 1.5 数据类型——日期类型 数据类型 描述 datetime 日期时间，占用8个字节 date 日期 占用3个字节 time 时间 占用3个字节 timestamp 时间戳，占用4个字节 year 年份 占用1个字节 1、datetime 格式：年-月-日 小时:分钟:秒 12345678910111213141516171819202122mysql&gt; create table t10( -&gt; field datetime -&gt; );Query OK, 0 rows affected (0.02 sec)mysql&gt; insert into t10 values (&apos;2025-10-12 10:12:36&apos;);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into t10 values (&apos;100-10-12 10:12:36&apos;);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into t10 values (&apos;10000-10-12 10:12:36&apos;); #datetime保存范围是：1~9999年ERROR 1292 (22007): Incorrect datetime value: &apos;10000-10-12 10:12:36&apos; for column &apos;field&apos; at row 1mysql&gt; select * from t10;+---------------------+| field |+---------------------+| 2025-10-12 10:12:36 || 0100-10-12 10:12:36 |+---------------------+2 rows in set (0.00 sec) 2、date 日期格式 1234567891011121314mysql&gt; create table t11( -&gt; field date -&gt; );Query OK, 0 rows affected (0.00 sec)mysql&gt; insert into t11 values (&apos;2025-10-12&apos;);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from t11;+------------+| field |+------------+| 2025-10-12 |+------------+ 3、timestamp：时间戳 timestamp类型和 datetime类型在表现上是一样的。他们的区别：datetime是从1到9999，而timestamp从1970年~2038年，2038年01月19日11:14:07秒以后就超出timestamp范围了。 1234567891011121314151617181920212223mysql&gt; create table t12( -&gt; field timestamp -&gt; );Query OK, 0 rows affected (0.00 sec)mysql&gt; insert into t12 values (&apos;1975-5-5 12:12:12&apos;);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into t12 values (&apos;1969-5-5 12:12:12&apos;); # 超出范围ERROR 1292 (22007): Incorrect datetime value: &apos;1969-5-5 12:12:12&apos; for column &apos;field&apos; at row 1mysql&gt; insert into t12 values (&apos;2038-1-19 11:14:07&apos;);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into t12 values (&apos;2038-1-19 11:14:08&apos;); # 超出范围ERROR 1292 (22007): Incorrect datetime value: &apos;2038-1-19 11:14:08&apos; for column &apos;field&apos; at row 1mysql&gt; select * from t12;+---------------------+| field |+---------------------+| 1975-05-05 12:12:12 || 2038-01-19 11:14:07 |+---------------------+ 4、year 因为只占用1个字节，最多只能表示255个年份，范围是1901-2155之间的年份 123456789101112131415mysql&gt; create table t13( -&gt; field year -&gt; );Query OK, 0 rows affected (0.06 sec)mysql&gt; insert into t13 values (2025);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into t13 values (1900); # 超出范围ERROR 1264 (22003): Out of range value for column &apos;field&apos; at row 1mysql&gt; insert into t13 values (2155);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into t13 values (2156); # 超出范围ERROR 1264 (22003): Out of range value for column &apos;field&apos; at row 1 5、time 表示时间或时间间隔，范围是-838:59:59~838:59:59 1234567891011121314151617mysql&gt; create table t14( -&gt; field time -&gt; );Query OK, 0 rows affected (0.00 sec)mysql&gt; insert into t14 values (&apos;12:12:12&apos;);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into t14 values (&apos;212:12:12&apos;);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into t14 values (&apos;838:59:59&apos;);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into t14 values (&apos;839:00:00&apos;); # 操作范围ERROR 1292 (22007): Incorrect time value: &apos;839:00:00&apos; for column &apos;field&apos; at row 1mysql&gt; 多学一招：time支持以天的方式插入 123456789101112mysql&gt; insert into t14 values (&apos;10 10:10:10&apos;);Query OK, 1 row affected (0.02 sec)mysql&gt; select * from t14;+-----------+| field |+-----------+| 12:12:12 || 212:12:12 || 838:59:59 || 250:10:10 |+-----------+]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL基本操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基本操作5]]></title>
    <url>%2F2018%2F09%2F12%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C5%2F</url>
    <content type="text"><![CDATA[1.1 数据类型——值类型1.1.1 整型 类型 字节 范围 tinyint 1 -128~127 smallint 2 -32768~32767 mediumint 3 -8388608~8388607 int 4 -2^31^~2^31^-1 bigint 8 -2^63^~2^63^-1 1、无符号整数（unsigned）：无符号数没有负数，正数部分是有符号的两倍。 例题 12345678910111213141516mysql&gt; create table stu( -&gt; id smallint unsigned auto_increment primary key comment &apos;主键&apos;, -&gt; age tinyint unsigned not null comment &apos;年龄&apos;, -&gt; money bigint unsigned comment &apos;存款&apos; -&gt; );Query OK, 0 rows affected (0.06 sec)mysql&gt; desc stu;+-------+----------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+----------------------+------+-----+---------+----------------+| id | smallint(5) unsigned | NO | PRI | NULL | auto_increment || age | tinyint(3) unsigned | NO | | NULL | || money | bigint(20) unsigned | YES | | NULL | |+-------+----------------------+------+-----+---------+----------------+3 rows in set, 3 warnings (0.00 sec) 2、整型支持显示宽度（最小的显示位数） 比如int(5)，如果数值的位数小于5位，前面加上前导0。比如输入12，显示00012；大于5位就不添加前导0。 1脚下留心：必须结合zerofill才起作用 123456789101112131415161718192021222324252627mysql&gt; create table stu( -&gt; id int(5), -&gt; age int(5) zerofill # 填充前导0 -&gt; );Query OK, 0 rows affected (0.02 sec)mysql&gt; desc stu;+-------+--------------------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+--------------------------+------+-----+---------+-------+| id | int(5) | YES | | NULL | || age | int(5) unsigned zerofill | YES | | NULL | |+-------+--------------------------+------+-----+---------+-------+2 rows in set (0.02 sec)mysql&gt; insert into stu values (1,11);mysql&gt; insert into stu values (1111111,2222222);Query OK, 1 row affected (0.00 sec)mysql&gt; select * from stu;+---------+---------+| id | age |+---------+---------+| 1 | 00011 || 1111111 | 2222222 | # 注意：age填充了前导0+---------+---------+2 rows in set (0.00 sec) 1.1.2 浮点型（保存近似值小数） 浮点型 占用字节 范围 float（单精度） 4 -3.4E+38~3.4E+38 double（双精度） 8 -1.8E+308~1.8E+308 1、浮点数声明: float(M,D) double(M,D) M：总位数 D：小数位数 例题； 12345678910111213141516mysql&gt; create table t1( -&gt; num1 float(5,2), #总位数是5，小数位数是2，那么整数位数是3， -&gt; num2 double(4,1) -&gt; );Query OK, 0 rows affected (0.08 sec)mysql&gt; insert into t1 values (1.23,1.23); #如果精度超出了允许的范围，会四舍五入Query OK, 1 row affected (0.00 sec)mysql&gt; select * from t1;+------+------+| num1 | num2 |+------+------+| 1.23 | 1.2 | #如果精度超出了允许的范围，会四舍五入+------+------+1 row in set (0.00 sec) 2、浮点的精度可能会丢失【精度指的是小数】 1.1.3 定点数语法：decimal(M,D) 123456789101112131415mysql&gt; create table t4( -&gt; num decimal(20,19) -&gt; );Query OK, 0 rows affected (0.00 sec)mysql&gt; insert into t4 values (1.1234567890123456789);Query OK, 1 row affected (0.01 sec)mysql&gt; select * from t4;+-----------------------+| num |+-----------------------+| 1.1234567890123456789 |+-----------------------+1 row in set (0.00 sec) 123多学一招：1、定点数是变长的，大致每9个数字用4个字节来存储。定点数之所以能保存精确的小数，因为整数和小数是分开存储的。占用的资源比浮点数要多。2、定点数和浮点数都支持显示宽度和无符号数。 1.2 数据类型——字符型 数据类型 描述 长度 char(长度) 定长 最大255 varchar(长度) 变长 最大65535 tinytext 大段文本 2^8^-1=255 text 大段文本 2^16^-1=65535 mediumtext 大段文本 2^24^-1 longtext 大段文本 2^32^-1 1、char(10)和varchar(10)的区别？ 答：相同点：它们最多只能保存10个字符； ​ 不同点：char不回收多余的字符，varchar会回收多余的字符。 ​ char效率高，浪费空间，varchar节省空间，效率比char低。 2、char的最大长度是255。 3、varchar理论长度是65535字节,实际根本达不到。具体长度与字符编码有关。 4、一个记录的总长度不能超过65535个字节。 5、大块文本（text）不计算在总长度中,一个大块文本只占用10个字节来保存文本的地址。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL基本操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基本操作4]]></title>
    <url>%2F2018%2F09%2F12%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C4%2F</url>
    <content type="text"><![CDATA[1.6 SQL分类DDL（data definition language）数据库定义语言create、alter、drop、shopDML（data manipulation language）数据操纵语言select、update、insert、deleteDCL（Data Control Language）数据库控制语言,是用来设置或更改数据库用户或角色权限的语句1.7 数据表的文件介绍一个数据库对应一个文件夹 一个表对应一个或多个文件 引擎是myisam，一个表对应三个文件 引擎是innodb,一个表对应一个表结构文件 所有的innodb引擎的数据统一的存放在data\ibdata1文件中。如果数据量很大，MySQL会自动的创建ibdata2，ibdata3，…，目的就是为了便于管理。 引擎是memory，数据存储在内存中，重启服务数据丢失，但是读取速度非常快。 1.8 字符集字符集：字符在保存和传输时对应的二进制编码集合。 创建测试数据库 12345mysql&gt; create table stu( -&gt; id int primary key, -&gt; name varchar(20) -&gt; );Query OK, 0 rows affected (0.00 sec) 插入中文报错 分析原因： 客户端通过GBK发送的命令 但是，服务用utf8解释命令 设置服务器，用gbk字符编码接受客户端发来的命令 测试：插入中文，成功 查询数据，发现数据乱码 原因：以utf返回的结果，客户端用gbk来接受 解决：服务器用gbk返回数据 再次测试，查询数据 总结：客户端编码、character_set_client、character_set_results三个编码的值一致即可操作中文。 多学一招：我们只要设置“set names 字符编码”，就可以更改character_set_client、character_set_results的值。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL基本操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基本操作3]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C3%2F</url>
    <content type="text"><![CDATA[1.5 数据操作创建测试表 1234567mysql&gt; create table stu( -&gt; id int auto_increment primary key comment &apos;主键&apos;, -&gt; name varchar(20) not null, -&gt; addr varchar(50) default &apos;地址不详&apos;, -&gt; score int comment &apos;成绩&apos; -&gt; );Query OK, 0 rows affected (0.01 sec) 1.5.1 插入数据插入一条数据1语法：insert into 表名 (字段名, 字段名,…) values (值1, 值1,…) 例题一：插入数据 12mysql&gt; insert into stu (id,name,addr,score) values (1,&apos;tom&apos;,&apos;上海&apos;,88);Query OK, 1 row affected (0.11 sec) 例题二：插入的字段可以和表的字段顺序不一致。值的顺序必须和插入字段的顺序一致。 12mysql&gt; insert into stu (name,score,addr,id) values (&apos;berry&apos;,77,&apos;北京&apos;,2);Query OK, 1 row affected (0.00 sec) 例题三：可以插入部分字段，但是，非空字段必须插入 1mysql&gt; insert into stu (id,name,addr) values (3,&apos;ketty&apos;,&apos;上海&apos;); 例题四：自动增长字段不用插入，数据库会自动插入增长的数字 12mysql&gt; insert into stu (name,addr) values (&apos;rose&apos;,&apos;北京&apos;);Query OK, 1 row affected (0.00 sec) 例题五：自动增长列的值插入null即可 12mysql&gt; insert into stu (id,name,addr,score) values (null,&apos;李白&apos;,&apos;上海&apos;,66);Query OK, 1 row affected (0.00 sec) 例题六：插入值的顺序和个数与表字段的顺序和个数一致，插入的字段可以省略 12mysql&gt; insert into stu values (null,&apos;杜甫&apos;,&apos;北京&apos;,null);Query OK, 1 row affected (0.00 sec) 例题七：通过default关键字插入默认值 1mysql&gt; insert into stu values (null,&apos;李清照&apos;,default,66); 12脚下留心：1、插入字段的顺序与值的顺序必须一致 插入多条数据123mysql&gt; insert into stu values (null,&apos;辛弃疾&apos;,default,66),(null,&apos;岳飞&apos;,&apos;河南&apos;,77);Query OK, 2 rows affected (0.00 sec)Records: 2 Duplicates: 0 Warnings: 0 1.5.2 更新数据语法： 1update 表名 set 字段=值 [where 条件] 例题一：将1号学生的地址改成山东 1mysql&gt; update stu set addr=&apos;山东&apos; where id=1 例题二：将ketty的成绩改为99 1mysql&gt; update stu set score=99 where name=&apos;ketty&apos;; 例题三：将berry地址改成上海，成绩改成66 1mysql&gt; update stu set addr=&apos;上海&apos;,score=66 where name=&apos;berry&apos;; 例题四：将上海的学生成绩改为60 1mysql&gt; update stu set score=60 where addr=&apos;上海&apos;; 例题五：条件可以省略，如果省略，更改所有数据（将所有数据的地址改为湖南，成绩改为70） 1mysql&gt; update stu set addr=&apos;湖南&apos;,score=70; 例题六：将2、3的学生成绩改为65 1mysql&gt; update stu set score=65 where id=2 or id=3; 1.5.3 删除数据语法 1delete from 表名 [where 条件] 例题一：删除学号是1号的学生 1mysql&gt; delete from stu where id=1; 例题二：删除成绩小于等于65分的 1mysql&gt; delete from stu where score&lt;=65; 例题三：删除表中所有记录 1mysql&gt; delete from stu; 1.5.4 清空表语法： 1truncate table 表名 例题 12mysql&gt; truncate table stu;Query OK, 0 rows affected (0.00 sec) 123脚下留心：delete from 表和truncate table 表区别？delete from 表：遍历表记录，一条一条的删除truncate table：将原表销毁，再创建一个同结构的新表。就清空表而言，这种方法效率高。 1.5.5查询表语法： 1select 列名 from 表 例题： 1234567891011121314151617181920212223mysql&gt; select name,score from stu;+------+-------+| name | score |+------+-------+| rose | 88 |+------+-------+1 row in set (0.00 sec)mysql&gt; select id,name,addr,score from stu;+----+------+------+-------+| id | name | addr | score |+----+------+------+-------+| 1 | rose | 上海 | 88 |+----+------+------+-------+1 row in set (0.00 sec)mysql&gt; select * from stu; # *表示所有字段+----+------+------+-------+| id | name | addr | score |+----+------+------+-------+| 1 | rose | 上海 | 88 |+----+------+------+-------+1 row in set (0.00 sec) ##]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL基本操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基本操作2]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C2%2F</url>
    <content type="text"><![CDATA[1.4 表的操作1.4.1 显示所有表语法： 1show tables 1.4.2 创建表语法： 1234create table [if not exists] 表名( 字段名 数据类型 [null|not null] [auto_increment] [primary key] [comment], 字段名 数据类型 [default]…)engine=存储引擎 单词 123456null | not null 空|非空default 默认值auto_increment 自动增长primary key 主键comment 备注engine 引擎 innodb myisam memory 引擎是决定数据存储的方式 创建简单的表 123456789101112131415161718192021mysql&gt; create database itcast;Query OK, 1 row affected (0.00 sec)mysql&gt; use itcast;Database changedmysql&gt; show tables;Empty set (0.05 sec)# 创建表mysql&gt; create table stu( -&gt; id int, -&gt; name varchar(30) -&gt; );Query OK, 0 rows affected (0.13 sec)# 查看创建的表mysql&gt; show tables;+------------------+| Tables_in_itcast |+------------------+| stu |+------------------+ 创建复杂的表 12345678910mysql&gt; set names gbk; # 设置字符编码Query OK, 0 rows affected (0.05 sec)mysql&gt; create table if not exists teacher( -&gt; id int auto_increment primary key comment &apos;主键&apos;, -&gt; name varchar(20) not null comment &apos;姓名&apos;, -&gt; phone varchar(20) comment &apos;电话号码&apos;, -&gt; `add` varchar(100) default &apos;地址不详&apos; comment &apos;地址&apos; -&gt; )engine=innodb;Query OK, 0 rows affected (0.09 sec) 多学一招：create table 数据库名.表名，用于给指定的数据库创建表 1234mysql&gt; create table data.stu( #给data数据库中创建stu表 -&gt; id int, -&gt; name varchar(10));Query OK, 0 rows affected (0.00 sec) 1.4.3 显示创建表的语句语法： 1show create table 表名 显示创建teacher表的语句 1234567891011121314151617181920mysql&gt; show create table teacher;+---------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+---------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| teacher | CREATE TABLE `teacher` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &apos;主键&apos;, `name` varchar(20) NOT NULL COMMENT &apos;姓名&apos;, `phone` varchar(20) DEFAULT NULL COMMENT &apos;电话号码&apos;, `add` varchar(100) DEFAULT &apos;地址不详&apos; COMMENT &apos;地址&apos;, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 | 将两个字段竖着排列 show create table 表名\G 1234567891011mysql&gt; show create table teacher\G;*************************** 1. row *************************** Table: teacherCreate Table: CREATE TABLE `teacher` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &apos;主键&apos;, `name` varchar(20) NOT NULL COMMENT &apos;姓名&apos;, `phone` varchar(20) DEFAULT NULL COMMENT &apos;电话号码&apos;, `add` varchar(100) DEFAULT &apos;地址不详&apos; COMMENT &apos;地址&apos;, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf81 row in set (0.00 sec) 1.4.4 查看表结构语法： 1desc[ribe] 表名 查看teacher表的结构 123456789101112131415161718192021mysql&gt; describe teacher;+-------+--------------+------+-----+----------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+--------------+------+-----+----------+----------------+| id | int(11) | NO | PRI | NULL | auto_increment || name | varchar(20) | NO | | NULL | || phone | varchar(20) | YES | | NULL | || add | varchar(100) | YES | | 地址不详 | |+-------+--------------+------+-----+----------+----------------+4 rows in set (0.08 sec)mysql&gt; desc teacher;+-------+--------------+------+-----+----------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+--------------+------+-----+----------+----------------+| id | int(11) | NO | PRI | NULL | auto_increment || name | varchar(20) | NO | | NULL | || phone | varchar(20) | YES | | NULL | || add | varchar(100) | YES | | 地址不详 | |+-------+--------------+------+-----+----------+----------------+4 rows in set (0.01 sec) 1.4.5 删除表语法： 1drop table [if exists] 表1，表2,… 删除表 12mysql&gt; drop table stu;Query OK, 0 rows affected (0.08 sec) 如果删除一个不存在的表就会报错，删除的时候可以判断一下，存在就删除。 12345mysql&gt; drop table stu;ERROR 1051 (42S02): Unknown table &apos;stu&apos;mysql&gt; drop table if exists stu;Query OK, 0 rows affected, 1 warning (0.00 sec) 可以一次删除多个表 12mysql&gt; drop table a1,a2;Query OK, 0 rows affected (0.00 sec) 1.4.6 修改表1语法：alter table 表名 1、添加字段：alter table 表名add [column] 字段名 数据类型 [位置] 例题一：添加字段 123456789101112131415mysql&gt; alter table teacher add age int;Query OK, 0 rows affected (0.09 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc teacher;+-------+--------------+------+-----+----------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+--------------+------+-----+----------+----------------+| id | int(11) | NO | PRI | NULL | auto_increment || name | varchar(20) | NO | | NULL | || phone | varchar(20) | YES | | NULL | || add | varchar(100) | YES | | 地址不详 | || age | int(11) | YES | | NULL | |+-------+--------------+------+-----+----------+----------------+5 rows in set (0.00 sec) 例题二：在第一个位置上添加字段 123456789101112131415mysql&gt; alter table teacher add email varchar(30) first;Query OK, 0 rows affected (0.00 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc teacher;+-------+--------------+------+-----+----------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+--------------+------+-----+----------+----------------+| email | varchar(30) | YES | | NULL | || id | int(11) | NO | PRI | NULL | auto_increment || name | varchar(20) | NO | | NULL | || phone | varchar(20) | YES | | NULL | || add | varchar(100) | YES | | 地址不详 | || age | int(11) | YES | | NULL | |+-------+--------------+------+-----+----------+----------------+ 例题三：在指定的字段后添加字段 1234567891011121314151617mysql&gt; alter table teacher add sex varchar(2) after name;Query OK, 0 rows affected (0.00 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc teacher;+-------+--------------+------+-----+----------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+--------------+------+-----+----------+----------------+| email | varchar(30) | YES | | NULL | || id | int(11) | NO | PRI | NULL | auto_increment || name | varchar(20) | NO | | NULL | || sex | varchar(2) | YES | | NULL | || phone | varchar(20) | YES | | NULL | || add | varchar(100) | YES | | 地址不详 | || age | int(11) | YES | | NULL | |+-------+--------------+------+-----+----------+----------------+7 rows in set (0.00 sec) 2、删除字段：alter table 表 drop [column] 字段名 123mysql&gt; alter table teacher drop email;Query OK, 0 rows affected (0.06 sec)Records: 0 Duplicates: 0 Warnings: 0 3、修改字段(改名改类型)：alter table 表 change [column] 原字段名 新字段名 数据类型 … 将字段sex改为xingbie，数据类型为int 123mysql&gt; alter table teacher change sex xingbie int;Query OK, 0 rows affected (0.00 sec)Records: 0 Duplicates: 0 Warnings: 0 4、修改字段（不改名）:alter table 表 modify 字段名 字段属性… 将性别的数据类型改为varchar(2) 123mysql&gt; alter table teacher modify xingbie varchar(2);Query OK, 0 rows affected (0.00 sec)Records: 0 Duplicates: 0 Warnings: 0 5、修改引擎：alter table 表名 engine=引擎名 123mysql&gt; alter table teacher engine=myisam;Query OK, 0 rows affected (0.05 sec)Records: 0 Duplicates: 0 Warnings: 0 6、修改表名：alter table 表名 rename to 新表名 12345678910mysql&gt; alter table teacher rename to stu;Query OK, 0 rows affected (0.00 sec)mysql&gt; show tables;+------------------+| Tables_in_itcast |+------------------+| stu |+------------------+1 row in set (0.00 sec) 1.4.7 复制表1语法一：create table 新表 select 字段 from 旧表 特点：不能复制父表的主键，能够复制父表的数据 12345678910111213141516171819202122mysql&gt; create table stu1 select * from stu;Query OK, 1 row affected (0.06 sec)Records: 1 Duplicates: 0 Warnings: 0mysql&gt; select * from stu1; # 查看数据复制到新表中+----+------+------+-------+| id | name | addr | score |+----+------+------+-------+| 1 | rose | 上海 | 88 |+----+------+------+-------+1 row in set (0.00 sec)mysql&gt; desc stu1; # 主键没有复制+-------+-------------+------+-----+----------+-------+| Field | Type | Null | Key | Default | Extra |+-------+-------------+------+-----+----------+-------+| id | int(11) | NO | | 0 | || name | varchar(20) | NO | | NULL | || addr | varchar(50) | YES | | 地址不详 | || score | int(11) | YES | | NULL | |+-------+-------------+------+-----+----------+-------+4 rows in set (0.00 sec) 1语法二：create table 新表 like 旧表 特点：只能复制表结构，不能复制表数据 123456789101112131415Query OK, 0 rows affected (0.00 sec)mysql&gt; select * from stu2; # 数据没有复制Empty set (0.01 sec)mysql&gt; desc stu2; # 主键复制了+-------+-------------+------+-----+----------+----------------+| Field | Type | Null | Key | Default | Extra |+-------+-------------+------+-----+----------+----------------+| id | int(11) | NO | PRI | NULL | auto_increment || name | varchar(20) | NO | | NULL | || addr | varchar(50) | YES | | 地址不详 | || score | int(11) | YES | | NULL | |+-------+-------------+------+-----+----------+----------------+4 rows in set (0.00 sec) ##]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL基本操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基本操作1]]></title>
    <url>%2F2018%2F09%2F11%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C1%2F</url>
    <content type="text"><![CDATA[1.1 连接服务器通过命令行面板连接 1234host：主机 -husername：用户名 -upassword：密码 -pport：端口 -P 1多学一招：如果MySQL服务器在本地，IP地址可以省略；如果MySQL服务器用的是3306端口，-P也是可以省略 1.2关闭连接12345方法一：exit方法二：quit方法三：\q 1脚下留心：MySQL中的命令后面要加分号，windows命令行的命令后面不用加分号。 1.3数据库的操作1.3.1 显示数据库123456789101112语法：show databases mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || test |+--------------------+4 rows in set (0.11 sec) 安装MySQL后，MySQL自带了4个数据库 information_schema：存储了MySQL服务器管理数据库的信息。 performance_schema：MySQL5.5新增的表，用来保存数据库服务器性能的参数 mysql：MySQL系统数据库，保存的登录用户名，密码，以及每个用户的权限等等 test：给用户学习和测试的数据库。 1.3.2 创建数据库1语法：create database [if not exists] `数据名` [字符编码] 创建数据库： 12mysql&gt; create database stu;Query OK, 1 row affected (0.09 sec) 如果创建的数据库已存在，就会报错 12mysql&gt; create database stu;ERROR 1007 (HY000): Can&apos;t create database &apos;stu&apos;; database exists 解决：创建数据库的时候判断一下数据库是否存在，如果不存在再创建 12mysql&gt; create database if not exists stu;Query OK, 1 row affected, 1 warning (0.00 sec) 如果数据库名是关键字和特殊字符要报错 解决：在特殊字符、关键字行加上反引号 12mysql&gt; create database `create`;Query OK, 1 row affected (0.05 sec) 1多学一招：为了创建数据库时万无一失，我们可以在所有的数据库名上加上反引号 创建数据库的时候可以指定字符编码 12345mysql&gt; create database teacher charset=gbk;Query OK, 1 row affected (0.01 sec)gbk 简体中文gb2312： 简体中文utf8： 通用字符编码 1脚下留心：创建数据库如果不指定字符编码，默认和MySQL服务器的字符编码是一致的。 1.3.3 删除数据库1语法：drop database [if exists] 数据库名 删除数据库 12mysql&gt; drop database teacher;Query OK, 0 rows affected (0.00 sec) 如果删除的数据库不存在，会报错 123mysql&gt; drop database teacher;ERROR 1008 (HY000): Can&apos;t drop database &apos;teacher&apos;; database doesn&apos;t existmysql&gt; 解决：删除之前判断一下，如果存在就删除 12mysql&gt; drop database if exists teacher;Query OK, 0 rows affected, 1 warning (0.00 sec) 1.3.4 显示创建数据库的SQL语句1语法：show create database 数据库名 123456789101112131415mysql&gt; show create database stu;+----------+--------------------------------------------------------------+| Database | Create Database |+----------+--------------------------------------------------------------+| stu | CREATE DATABASE `stu` /*!40100 DEFAULT CHARACTER SET utf8 */ |+----------+--------------------------------------------------------------+1 row in set (0.01 sec)mysql&gt; show create database teacher;+----------+-----------------------------------------------------------------+| Database | Create Database |+----------+-----------------------------------------------------------------+| teacher | CREATE DATABASE `teacher` /*!40100 DEFAULT CHARACTER SET gbk */ |+----------+-----------------------------------------------------------------+1 row in set (0.00 sec) 1.3.5 修改数据库修改数据库的字符编码 语法： 1alter database 数据库名 charset=字符编码 例题 12345678910mysql&gt; alter database teacher charset=utf8;Query OK, 1 row affected (0.00 sec)mysql&gt; show create database teacher;+----------+------------------------------------------------------------------+| Database | Create Database |+----------+------------------------------------------------------------------+| teacher | CREATE DATABASE `teacher` /*!40100 DEFAULT CHARACTER SET utf8 */ |+----------+------------------------------------------------------------------+1 row in set (0.00 sec) 1.3.6 选择数据库语法： 1use 数据库名 选择数据库 12mysql&gt; use stu;Database changed]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL基本操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图文讲解MySQL安装教程]]></title>
    <url>%2F2018%2F09%2F11%2F%E5%9B%BE%E6%96%87%E8%AE%B2%E8%A7%A3MySQL%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[今天来讲解一下MySQL的安装教程 1：首先获取一个安装文件，如下图，可以走网上或者某些途径拿到 2：然后双击安装，如图 3：选择安装模式，这里我们选择自定义安装 4：选择数据库以及数据库文件安装位置 在这里我们数据库和数据库文件直接选择安装在C盘下面 5：下面一些很多都可以直接点Next选择默认的配置 这里的并发数一般选择系统的默认给我们设置的 端口也选择系统默认的，一般不用改 这里的编码方式选择utf8 服务名称可以自己设置，一般默认，下面的选项是添加环境变量，如果不勾选安装完自己也可以添加一下 这里初始化一下密码 然后点击安装等待4个勾全部勾上点击完成6：MySQL目录 这里是安装的目录，里面的data就是之前选择数据文件安装的路径，我们放在一起所以在这里，你可以自己设置路径7：启动/关闭MySQL服务方法一：在服务面板中启动或关闭控制面板项——管理工具——服务，选择相应服务，右键执行操作 方法二：通过命令行启动\关闭net start 服务名： 启动MySQL服务 net stop 服务器： 关闭MySQL服务 注意：必须通过管理员身份启动命令行这样数据库就安装好了，然后就可以进入数据库操作了]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL安装教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-pwd命令]]></title>
    <url>%2F2018%2F09%2F10%2FLinux%E5%91%BD%E4%BB%A4-pwd%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux中用 pwd 命令来查看”当前工作目录“的完整路径。 简单得说，每当你在终端进行操作时，你都会有一个当前工作目录。 在不太确定当前位置时，就会使用pwd来判定当前目录在文件系统内的确切位置。 语法1pwd（选项） 选项1234-L 目录连接链接时，输出连接路径-P 输出物理路径--help：显示帮助信息；--version：显示版本信息。 常用范例显示当前位置 1pwd]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-cd命令]]></title>
    <url>%2F2018%2F09%2F10%2FLinux%E5%91%BD%E4%BB%A4-cd%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux cd 命令可以说是Linux中最基本的命令语句，其他的命令语句要进行操作，都是建立在使用 cd 命令上的。所以，学习Linux 常用命令，首先就要学好 cd 命令的使用方法技巧。 语法1cd (选项) (参数) 选项123-p 如果要切换到的目标目录是一个符号连接，直接切换到符号连接指向的目标目录-L 如果要切换的目标目录是一个符号的连接，直接切换到字符连接名代表的目录，而非符号连接所指向的目标目录。- 当仅实用&quot;-&quot;一个选项时，当前工作目录将被切换到环境变量&quot;OLDPWD&quot;所表示的目录。 常用范例1）进入系统根目录 1cd / 2）进入当前用户主目录 12cd ~cd 3）跳转到指定目录 1cd /opt/soft 4）返回进入此目录之前所在的目录 1cd -]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令-ls]]></title>
    <url>%2F2018%2F09%2F10%2FLinux%E5%91%BD%E4%BB%A4-ls%2F</url>
    <content type="text"><![CDATA[ls命令时linux下最常用的命令。ls命令就是list的缩写，缺省下ls用来打印出当前目录的清单，如果ls指定其他目录，那么就会显示指定目录里的文件及文件夹清单。 通过ls命令不仅可以查看linux文件夹包含的文件，而且可以查看文件权限（包括目录、文件夹、文件权限），查看目录信息等等。 语法1ls (选项) （参数） 选项常用选项 123456789-a：显示所有档案及目录（ls内定将档案名或目录名称为“.”的视为影藏，不会列出）；-l：以长格式显示目录下的内容列表。输出的信息从左到右依次包括文件名，文件类型、权限模式、硬连接数、所有者、组、文件大小和文件的最后修改时间等；-h:–human-readable 以容易理解的格式列出文件大小 (例如 1K 234M 2G);-s：显示文件和目录的大小，以区块为单位；-t：用文件和目录的更改时间排序；-r：以文件名反序排列并输出目录内容列表；-d：仅显示目录名，而不显示目录下的内容列表。显示符号链接文件本身，而不显示其所指向的目录列表；-R：递归处理，将指定目录下的所有文件及子目录一并处理；--color[=WHEN]：使用不同的颜色高亮显示不同类型的。 其他选项 123456789101112131415-A：显示除影藏文件“.”和“..”以外的所有文件列表；-C：多列显示输出结果。这是默认选项；-F：在每个输出项后追加文件的类型标识符，具体含义：“*”表示具有可执行权限的普通文件，“/”表示目录，“@”表示符号链接，“|”表示命令管道FIFO，“=”表示sockets套接字。当文件为普通文件时，不输出任何标识符；-b：将文件中的不可输出的字符以反斜线“”加字符编码的方式输出；-f：此参数的效果和同时指定“aU”参数相同，并关闭“lst”参数的效果；-i：显示文件索引节点号（inode）。一个索引节点代表一个文件；-k：以KB（千字节）为单位显示文件大小；-m：用“,”号区隔每个文件和目录的名称；--n：以用户识别码和群组识别码替代其名称；-L：如果遇到性质为符号链接的文件或目录，直接列出该链接所指向的原始文件或目录；-c：与“-lt”选项连用时，按照文件状态时间排序输出目录内容，排序的依据是文件的索引节点中的ctime字段,与“-l”选项连用时，则排序的一句是文件的状态改变时间；--file-type：与“-F”选项的功能相同，但是不显示“*”；--full-time：列出完整的日期与时间；–-help 显示此帮助信息–-version 显示版本信息 参数目录：指定要显示列表的目录，也可以是具体的文件。 常用范例1）列出/opt文件夹下的所有文件和目录的详细资料 1# ls -l -R /opt/ 在使用 ls 命令时要注意命令的格式：在命令提示符后，首先是命令的关键字，接下来是命令参数，在命令参数之前要有一短横线“-”，所有的命令参数都有特定的作用，自己可以根据需要选用一个或者多个参数，在命令参数的后面是命令的操作对象。在以上这条命令“ ls -l -R /home/peidachang”中，“ls” 是命令关键字，“-l -R”是参数，“ /home/peidachang”是命令的操作对象。在这条命令中，使用到了两个参数，分别为“l”和“R”，当然，你也可以把他们放在一起使用，如下所示： 1ls -lR /opt 2）列出当前目录中所有以“t”开头的目录的详细内容，可以使用如下命令： 1#ls -l t* 可以查看当前目录下文件名以“t”开头的所有文件的信息。其实，在命令格式中，方括号内的内容都是可以省略的，对于命令ls而言，如果省略命令参数和操作对象，直接输入“ ls ”，则将会列出当前工作目录的内容清单。 3）列出目前工作目录下所有名称是s 开头的档案，愈新的排愈后面，可以使用如下命令： 1#ls -ltr s* 4）列出目前工作目录下所有档案及目录;目录于名称后加”/“, 可执行档于名称后加”*“ 1# ls -AF 5）计算当前目录下的文件数和目录数 12ls -l * |grep &quot;^-&quot;|wc -l ---文件个数 ls -l * |grep &quot;^d&quot;|wc -l ---目录个数 6）在ls中列出文件的绝对路径 1ls | sed &quot;s:^:`pwd`/:&quot; 7）列出当前目录下的所有文件（包括隐藏文件）的绝对路径， 对目录不做递归 1find $PWD -maxdepth 1 | xargs ls -ld 8）递归列出当前目录下的所有文件（包括隐藏文件）的绝对路径 1find $PWD | xargs ls -ld 9）指定文件时间输出格式 12ls -tl --time-style=full-iso ls -ctl --time-style=long-iso 10）列出文件并标记颜色分类 1ls --color=auto 颜色蓝色—–目录绿色—–可执行文件白色—–一般性文件，如文本文件，配置文件等红色—–压缩文件或归档文件浅蓝色—-链接文件红色闪烁—-链接文件存在问题黄色—–设备文件青黄色—-管道文件 参考链接： http://man.linuxde.net/ls http://www.9usb.net/201005/linux-ls.html http://www.cnblogs.com/peida/archive/2012/10/23/2734829.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Docker镜像]]></title>
    <url>%2F2018%2F09%2F10%2F%E4%BD%BF%E7%94%A8Docker%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[镜像（image）是Docker三大核心概念中最为重要的，自Docker诞生之日起“镜像”就是相关社区最为热门的关键词。 Docker运行容器前需要本地存在对应的镜像，如果镜像没保存在本地，Docker会尝试从默认镜像仓库下载（默认使用Docker Hub公共注册服务器中的仓库），用户也可以通过配置，使用自定义的镜像仓库。 获取镜像镜像是运行容器的前提，官方的Docker Hub网站已经提供了数十万个镜像供大家开放下载。 可以使用docker pull命令直接从Docker Hub镜像源来下载镜像。改命令的格式为docker pull NAME[:TAG]。其中，NAME是镜像仓库的名称（用来区分镜像），TAG是镜像的标签（往往用来表示版本信息）。通常情况下，描述一个镜像需要包括“名称+标签”信息。 例如，获取一个Ubuntu14.04系统的基础镜像可以使用如下的命令： 1docker pull ubuntu:14.04 对于docker镜像来说，如果不显示指定TAG，则默认会选择latest标签，这会下载仓库中最新版本的镜像。 从稳定性上考虑，不要在生产环境中忽略镜像的标签信息或使用默认的latest标记的镜像。 使用images命令列出镜像123docker images REPOSITORY TAG IMAGE ID CREATED SIZEdocker.io/tomcat latest 08f8166740f8 3 months ago 366.7 MB 使用tag命令添加镜像标签1docker tag docker.io/tomcat:latest mytomcat:latest 使用inspect命令查看详细信息12345678910111213docker inspect docker.io/tomcat:latest [ &#123; &quot;Id&quot;: &quot;sha256:08f8166740f822b79f1306648591c1013105ccb5dca0a15320c54e991e0f9538&quot;, &quot;RepoTags&quot;: [ &quot;docker.io/tomcat:latest&quot; ], &quot;RepoDigests&quot;: [], &quot;Parent&quot;: &quot;&quot;, &quot;Comment&quot;: &quot;&quot;, &quot;Created&quot;: &quot;2017-05-05T23:55:12.275453692Z&quot;, &quot;Container&quot;: &quot;172a4b1f8457373887172ff3f36c15708bbda7430c43963796ffd98f3dd6345e&quot;,..... 返回的是一个JSON格式的信息，如果我们只要其中一项内容时，可以使用参数-f来指定，例如，获取镜像的Os 12docker inspect -f &#123;&#123;&quot;.Architecture&quot;&#125;&#125; docker.io/tomcat:latest amd64 删除镜像使用标签删除镜像 使用docker rmi 命令可以删除镜像，命令格式为dockerrmi IMAGE [IMAGE…],其中IMAGE可以为标签或ID。 如果想强行删除镜像，可以使用-f参数。 创建镜像创建镜像的方法主要有三种：基于已有镜像的容器创建、基于本地模板导入、基于Dockerfile创建。 基于已有镜像的容器创建该方法主要是使用docker commit命令。命令格式为dockercommit [OPTIONS] CONTAINER [REPOSRITORY[:TAG]]，主要信息包括： -a，–author=””：作者信息 - -c，–change=[]：提交时执行Dockerfile指令，包括CMD|ENTERYPOINT|ENV|EXPOSE|LABEL|ONBUILD|USER|VOLUME|WORKDIR等； -m，–message=“”：提交消息； -p ，–pause=true：提交时暂停容器执行。 基于本地模板导入略 搜索镜像使用docker search命令可以搜索远端仓库中共享的镜像，默认搜索官方仓库中的镜像。用法为docker search TERM，支持的参数主要包括 –automated=true|false:仅显示自动创建的镜像，默认为否； –no-trunc=true|false:输出信息不截断显示，默认为否； -s，–stars=X:指定仅显示评价为指定星级以上的镜像，默认为0，即输出所有镜像。 存出和载入镜像用户可以使用docker save和docker load命令来存出和载入镜像。 存出镜像如果要导出镜像到本地，可以使用docker save名利，例如，导出本地的tomcat:latest镜像为tomcat.tart，如下所示： 1docker save -o /images/tomcat.tart tomcat:latest 之后，用户就可以通过复制tomcat.tar文件将改镜像分享给他人。 载入镜像可以使用docker load将导出的tar文件再导入本地镜像库，例如从tomcat.tar 导入镜像到本地镜像列表，如下所示： 12docker load --input tomcat.tar 或docker load &lt; tomcat.tar 这将导入镜像及其相关的元数据信息（包括标签等）。导入成功后，可以使用docker images命令进行查看。 上传镜像可以使用docker push 命令上传镜像到仓库，默认上传到DockerHub官方仓库（需要登录）。命令格式为： docker push NAME[:TAG] 用户在Docker Hub网站注册后可以上传自制的镜像。例如用户user上传本地的test：latest镜像，可以先添加新的标签user/test:latest，然后用docker push命令上传镜像： 12docker tag test:latest user/test:latestdocker push user/test:latest 第一次上传时，会提示输入登录信息或进行注册。]]></content>
      <categories>
        <category>git使用及讲解</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初识容器与Docker]]></title>
    <url>%2F2018%2F09%2F10%2F%E5%88%9D%E8%AF%86%E5%AE%B9%E5%99%A8%E4%B8%8EDocker%2F</url>
    <content type="text"><![CDATA[如果说主机时代大家拼的是单个服务器物理性能（如CPU主频和内存），那么在云时代，最为看重的则是凭借虚拟化技术所构建的集群处理能力。 伴随着信息技术的飞速发展，虚拟化技术早已经广泛应用到各种关键场景中。从20世纪60年代IBM推出的大型主机虚拟化，到后来以Xen、KVM为代表的虚拟机虚拟化，再到现在以Docker为代表的的容器技术，虚拟化技术自身也在不断进行创新和突破。 什么是DockerDocker开源背景Docker是基于Go语言实现的开源容器项目，诞生于2013年年初，最初发起者是dotCloud公司。 Docker项目已加入了linux基金会，并遵循Apache2.0协议，全部开源代码均在https://github.com/docker/docker上进行维护。在linux基金会最近一次关于“最受欢迎的云计算开源项目”的调查中，Docker仅次于2010年发起的Openstack项目，并仍处于上升趋势。 Docker的构想是要实现“Build，Ship and Run Any App，Anywhere”，即通过对应用的封装（Packaging）、分发（Distribution）、部署（Deployment）、运行（Runtime）生命周期进行管理，达到应用组件“一次封装，到处运行”的目的。 linux容器技术—巨人的肩膀跟着大部分新兴技术的诞生一样，Docker也并非“从石头缝里蹦出来的”，而是站在前人的肩膀上，其中最重要的就是linux容器（linux Containers，LXC）技术。 从Linux容器到Docker简单地讲，可以将Docker容器理解为一种轻量级的沙盒（sandbox）。每个容器内运行着一个应用，不同的容器相互隔离，容器之间也可以通过网络互相通信。容器的创建和停止都十分快速，几乎跟创建和终止原生应用一致；另外，容器自身对系统资源的额外需求也十分有限，远远低于传统虚拟机。很多时候，甚至直接把容器当作应用本身也没有任何问题。 有理由相信，Docker技术会进一步成熟，将会成为更受欢迎的容器虚拟化技术实现，并在云计算和DevOps等领域得到更广泛的应用。 Docker容器虚拟化的好处Docker提供了一种聪明的方式，通过容器来打包应用，解耦应用和运行平台。意味着迁移的时候，只需要在新的服务器上启动需要的容器就可以了，无论新旧服务器是否同一类型的平台。这无疑将节约大量的宝贵时间，并降低部署过程出现问题的风险。 Docker在开发和运维中的优势更快的交付和部署 更高效的资源利用 更轻松的迁移和扩展 更简单的更新管理 Docker与虚拟机的比较 特性 容器 虚拟机 启动速度 秒级 分钟级 性能 接近原生 较弱 内存代价 很小 较多 硬盘使用 一般为MB 一般为GB 运行密度 单机支持上千个容器 一般为几十个 隔离性 安全隔离 完全隔离 迁移性 优秀 一般 Docker与虚拟化]]></content>
      <categories>
        <category>git使用及讲解</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过blockchain-go分析区块链交易原理]]></title>
    <url>%2F2018%2F09%2F09%2F%E9%80%9A%E8%BF%87blockchain-go%E5%88%86%E6%9E%90%E5%8C%BA%E5%9D%97%E9%93%BE%E4%BA%A4%E6%98%93%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[1.背景在去中心化的区块链中进行交易（转账）是怎么实现的呢？本篇通过blockchain_go来分析一下。需要进行交易，首先就需要有交易的双方以及他们的认证机制，其次是各自的资金账户规则。在分布式账本系统里面，需要有机制能够准确验证一个用户身份以及对账户资金的精确计算，不能出现一丁点差错。在区块链中交易通过Transaction表示，自己的账户余额并不是在每个节点上保存各个用户的一个最终数字，而是通过历史交易信息计算而来（历史交易不可篡改），其中的关键机制是UTXO。 2.身份认证在区块链身份认证是采用RSA非对称加密体系完成，每个用户在会拥有一个“钱包”，钱包是通过安全的椭圆曲线加密算法生成，其中包括一对公私钥。私钥自己保留不能暴露，用作加密，签名等，公钥公开给所有人，用于信息验证等。只要是用私钥签名的信息，就可以通过配对的公钥解码认证，不可抵赖。在blockchain_go中，钱包实现如下： 1234567891011121314151617181920212223// Wallet stores private and public keystype Wallet struct &#123; PrivateKey ecdsa.PrivateKey PublicKey []byte&#125;// NewWallet creates and returns a Walletfunc NewWallet() *Wallet &#123; private, public := newKeyPair() wallet := Wallet&#123;private, public&#125; return &amp;wallet&#125;func newKeyPair() (ecdsa.PrivateKey, []byte) &#123; curve := elliptic.P256() //椭圆曲线 private, err := ecdsa.GenerateKey(curve, rand.Reader) //生成私钥 if err != nil &#123; log.Panic(err) &#125; pubKey := append(private.PublicKey.X.Bytes(),private.PublicKey.Y.Bytes()...) //合成公钥 return *private, pubKey&#125; 钱包最重要的功能就是为用户提供身份认证和加解密的公私钥对。 3.什么是Transaction区块链中的Transaction（交易）就是一批输入和输出的集合，比如A通过交易给B10个代币（token），那么交易就是A输入10代币，输出变成B得到10代币，这样A就减少10代币，B增加10代币，再将这个交易信息存储到区块链中固化后，A和B在区块链中的账号状态就发生了永久性不可逆的变化。 在blockchain_go中transaction的定义如下： 123456789101112131415161718// TXInput represents a transaction inputtype TXInput struct &#123; Txid []byte Vout int Signature []byte PubKey []byte&#125;// TXOutput represents a transaction outputtype TXOutput struct &#123; Value int PubKeyHash []byte&#125;type Transaction struct &#123; ID []byte //交易唯一ID Vin []TXInput //交易输入序列 Vout []TXOutput //交易输出序列&#125; 从定义可以看到Transaction就是输入和输出的集合，输入和输出的关系如下图： 其中tx0，tx1，tx2等是独立的交易，每个交易通过输入产生输出，下面重点看看一个交易的输入和输出单位是怎么回事。 先看输出TXOutput： Value : 表示这个输出中的代币数量PubKeyHash : 存放了一个用户的公钥的hash值，表示这个输出里面的Value是属于哪个用户的输入单元TXInput: Txid : 交易ID（这个输入使用的是哪个交易的输出）Vout : 该输入单元指向本次交易输出数组的下标，通俗讲就是，这个输入使用的是Txid中的第几个输出。Signature : 输入发起方（转账出去方）的私钥签名本Transaction，表示自己认证了这个输入TXInput。PubKey : 输入发起方的公钥通俗来讲，一个TXInput结构表示 : 1我要使用哪个交易(Txid)的哪个输出数组（Transaction.Vout）的下标(Vout)作为我本次输入的代币数值（TXOutput.Value) 因为交易的输入其实是需要指明要输入多少代币（Value），但是TXInput中并没有直接的代币字段，而唯一有代币字段的是在TXOuput中，所以这里使用的方式是在TXInput中指明了自己需要使用的代币在哪个TXOutput中。 TXInput中的Signature字段是发起用户对本次交易输入的签名，PubKey存放了用户的公钥，用于之前的验证（私钥签名，公钥验证）。 3.什么是UTXOUTXO 是 Unspent Transaction Output 的缩写，意指“为花费的交易输出”，是中本聪最早在比特币中采用的一种技术方案。因为比特币中没有账户的概念，也就没有保存用户余额数值的机制。因为区块链中的历史交易都是被保存且不可修改的，而每一个交易（如前所述的Transaction）中又保存了“谁转移了多少给谁”的信息，所以要计算用户账户余额，只需要遍历所有交易进行累计即可。 从第三节的交易图可以看到，每笔交易的输入TXInput都是使用的是其他交易的输出TXOutput（只有输出中保存了该输出是属于哪个用户，价值多少）。如果一笔交易的输出被另外一个交易的输入引用了（TXInput中的Vout指向了该TXOutput），那么这笔输出就是“已花费”。如果一笔交易的输出没有被任何交易的输入引用，那么就是“未花费”。分析上图的tx3交易： tx3有3个输入： input 0 ：来自tx0的output0，花费了这个tx0.output0.input 1 ：来自tx1的output1，花费了这个tx1.output1.input 2 ：来自了tx2的output0，花费了这个tx2.output0.tx3有2个输出： output 0 ：没有被任何后续交易引用，表示“未花费”。output 1 ：被tx4的input1引用，表示已经被花费。因为每一个output都包括一个value和一个公钥身份，所以遍历所有区块中的交易，找出其中所有“未花费”的输出，就可以计算出用户的账户余额。 4.查找未花费的Output如果一个账户需要进行一次交易，把自己的代币转给别人，由于没有一个账号系统可以直接查询余额和变更，而在utxo模型里面一个用户账户余额就是这个用户的所有utxo（未花费的输出）记录的合集，因此需要查询用户的转账额度是否足够，以及本次转账需要消耗哪些output（将“未花费”的output变成”已花费“的output），通过遍历区块链中每个区块中的每个交易中的output来得到结果。 下面看看怎么查找一个特定用户的utxo，utxo_set.go相关代码如下： 123456789101112131415161718192021222324252627282930// FindSpendableOutputs finds and returns unspent outputs to reference in inputsfunc (u UTXOSet) FindSpendableOutputs(pubkeyHash []byte, amount int) (int, map[string][]int) &#123; unspentOutputs := make(map[string][]int) accumulated := 0 db := u.Blockchain.db err := db.View(func(tx *bolt.Tx) error &#123; b := tx.Bucket([]byte(utxoBucket)) c := b.Cursor() for k, v := c.First(); k != nil; k, v = c.Next() &#123; txID := hex.EncodeToString(k) outs := DeserializeOutputs(v) for outIdx, out := range outs.Outputs &#123; if out.IsLockedWithKey(pubkeyHash) &amp;&amp; accumulated &lt; amount &#123; accumulated += out.Value unspentOutputs[txID] = append(unspentOutputs[txID], outIdx) &#125; &#125; &#125; return nil &#125;) if err != nil &#123; log.Panic(err) &#125; return accumulated, unspentOutputs&#125; FindSpendableOutputs查找区块链上pubkeyHash账户的utxo集合，直到这些集合的累计未花费金额达到需求的amount为止。 blockchain_go中使用嵌入式key-value数据库boltdb存储区块链和未花费输出等信息，其中utxoBucket是所有用户未花费输出的bucket，其中的key表示交易ID，value是这个交易中未被引用的所有output的集合。所以通过遍历查询本次交易需要花费的output，得到Transaction的txID和这个output在Transaction中的输出数组中的下标组合unspentOutputs。 另外一个重点是utxobucket中保存的未花费输出结合是关于所有账户的，要查询特定账户需要对账户进行判断，因为TXOutput中有pubkeyhash字段，用来表示该输出属于哪个用户，此处采用out.IsLockedWithKey(pubkeyHash)判断特定output是否是属于给定用户。 5.新建Transaction需要发起一笔交易的时候，需要新建一个Transaction，通过交易发起人的钱包得到足够的未花费输出，构建出交易的输入和输出，完成签名即可，blockchain_go中的实现如下： 1234567891011121314151617181920212223242526272829303132333435363738// NewUTXOTransaction creates a new transactionfunc NewUTXOTransaction(wallet *Wallet, to string, amount int, UTXOSet *UTXOSet) *Transaction &#123; var inputs []TXInput var outputs []TXOutput pubKeyHash := HashPubKey(wallet.PublicKey) acc, validOutputs := UTXOSet.FindSpendableOutputs(pubKeyHash, amount) if acc &lt; amount &#123; log.Panic(&quot;ERROR: Not enough funds&quot;) &#125; // Build a list of inputs for txid, outs := range validOutputs &#123; txID, err := hex.DecodeString(txid) if err != nil &#123; log.Panic(err) &#125; for _, out := range outs &#123; input := TXInput&#123;txID, out, nil, wallet.PublicKey&#125; inputs = append(inputs, input) &#125; &#125; // Build a list of outputs from := fmt.Sprintf(&quot;%s&quot;, wallet.GetAddress()) outputs = append(outputs, *NewTXOutput(amount, to)) if acc &gt; amount &#123; outputs = append(outputs, *NewTXOutput(acc-amount, from)) // a change &#125; tx := Transaction&#123;nil, inputs, outputs&#125; tx.ID = tx.Hash() UTXOSet.Blockchain.SignTransaction(&amp;tx, wallet.PrivateKey) return &amp;tx&#125; 函数参数： wallet : 用户钱包参数，存储用户的公私钥，用于交易的签名和验证。to : 交易转账的目的地址（转账给谁）。amount : 需要交易的代币额度。UTXOSet : uxto集合，查询用户的未花费输出。查询需要的未花费输出： 1acc, validOutputs := UTXOSet.FindSpendableOutputs(pubKeyHash, amount) 因为用户的总金额是通过若干未花费输出累计起来的，而每个output所携带金额不一而足，所以每次转账可能需要消耗多个不同的output，而且还可能涉及找零问题。以上查询返回了一批未花费输出列表validOutputs和他们总共的金额acc. 找出来的未花费输出列表就是本次交易的输入，并将输出结果构造output指向目的用户，并检查是否有找零，将找零返还。 如果交易顺利完成，转账发起人的“未花费输出”被消耗掉变成了花费状态，而转账接收人to得到了一笔新的“未花费输出”，之后他自己需要转账时，查询自己的未花费输出，即可使用这笔钱。 最后需要对交易进行签名，表示交易确实是由发起人本人发起（私钥签名），而不是被第三人冒充。 6.Transaction的签名和验证6.1 签名交易的有效性需要首先建立在发起人签名的基础上，防止他人冒充转账或者发起人抵赖，blockchain_go中交易签名实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// SignTransaction signs inputs of a Transactionfunc (bc *Blockchain) SignTransaction(tx *Transaction, privKey ecdsa.PrivateKey) &#123; prevTXs := make(map[string]Transaction) for _, vin := range tx.Vin &#123; prevTX, err := bc.FindTransaction(vin.Txid) if err != nil &#123; log.Panic(err) &#125; prevTXs[hex.EncodeToString(prevTX.ID)] = prevTX &#125; tx.Sign(privKey, prevTXs)&#125;// Sign signs each input of a Transactionfunc (tx *Transaction) Sign(privKey ecdsa.PrivateKey, prevTXs map[string]Transaction) &#123; if tx.IsCoinbase() &#123; return &#125; for _, vin := range tx.Vin &#123; if prevTXs[hex.EncodeToString(vin.Txid)].ID == nil &#123; log.Panic(&quot;ERROR: Previous transaction is not correct&quot;) &#125; &#125; txCopy := tx.TrimmedCopy() for inID, vin := range txCopy.Vin &#123; prevTx := prevTXs[hex.EncodeToString(vin.Txid)] txCopy.Vin[inID].Signature = nil txCopy.Vin[inID].PubKey = prevTx.Vout[vin.Vout].PubKeyHash dataToSign := fmt.Sprintf(&quot;%x\n&quot;, txCopy) r, s, err := ecdsa.Sign(rand.Reader, &amp;privKey, []byte(dataToSign)) if err != nil &#123; log.Panic(err) &#125; signature := append(r.Bytes(), s.Bytes()...) tx.Vin[inID].Signature = signature txCopy.Vin[inID].PubKey = nil &#125;&#125; 交易输入的签名信息是放在TXInput中的signature字段，其中需要包括用户的pubkey，用于之后的验证。需要对每一个输入做签名。 6.2 验证交易签名是发生在交易产生时，交易完成后，Transaction会把交易广播给邻居。节点在进行挖矿时，会整理一段时间的所有交易信息，将这些信息打包进入新的区块，成功加入区块链以后，这个交易就得到了最终的确认。但是在挖矿节点打包交易前，需要对交易的有效性做验证，以防虚假数据，验证实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879// MineBlock mines a new block with the provided transactionsfunc (bc *Blockchain) MineBlock(transactions []*Transaction) *Block &#123; var lastHash []byte var lastHeight int for _, tx := range transactions &#123; // TODO: ignore transaction if it&apos;s not valid if bc.VerifyTransaction(tx) != true &#123; log.Panic(&quot;ERROR: Invalid transaction&quot;) &#125; &#125; ... ... ... return block&#125;// VerifyTransaction verifies transaction input signaturesfunc (bc *Blockchain) VerifyTransaction(tx *Transaction) bool &#123; if tx.IsCoinbase() &#123; return true &#125; prevTXs := make(map[string]Transaction) for _, vin := range tx.Vin &#123; prevTX, err := bc.FindTransaction(vin.Txid) if err != nil &#123; log.Panic(err) &#125; prevTXs[hex.EncodeToString(prevTX.ID)] = prevTX &#125; return tx.Verify(prevTXs)&#125;// Verify verifies signatures of Transaction inputsfunc (tx *Transaction) Verify(prevTXs map[string]Transaction) bool &#123; if tx.IsCoinbase() &#123; return true &#125; for _, vin := range tx.Vin &#123; if prevTXs[hex.EncodeToString(vin.Txid)].ID == nil &#123; log.Panic(&quot;ERROR: Previous transaction is not correct&quot;) &#125; &#125; txCopy := tx.TrimmedCopy() curve := elliptic.P256() for inID, vin := range tx.Vin &#123; prevTx := prevTXs[hex.EncodeToString(vin.Txid)] txCopy.Vin[inID].Signature = nil txCopy.Vin[inID].PubKey = prevTx.Vout[vin.Vout].PubKeyHash r := big.Int&#123;&#125; s := big.Int&#123;&#125; sigLen := len(vin.Signature) r.SetBytes(vin.Signature[:(sigLen / 2)]) s.SetBytes(vin.Signature[(sigLen / 2):]) x := big.Int&#123;&#125; y := big.Int&#123;&#125; keyLen := len(vin.PubKey) x.SetBytes(vin.PubKey[:(keyLen / 2)]) y.SetBytes(vin.PubKey[(keyLen / 2):]) dataToVerify := fmt.Sprintf(&quot;%x\n&quot;, txCopy) rawPubKey := ecdsa.PublicKey&#123;Curve: curve, X: &amp;x, Y: &amp;y&#125; if ecdsa.Verify(&amp;rawPubKey, []byte(dataToVerify), &amp;r, &amp;s) == false &#123; return false &#125; txCopy.Vin[inID].PubKey = nil &#125; return true&#125; 可以看到验证的时候也是每个交易的每个TXInput都单独进行验证，和签名过程很相似，需要构造相同的交易数据txCopy，验证时会用到签名设置的TxInput.PubKeyHash生成一个原始的PublicKey，将前面的signature分拆后通过ecdsa.Verify进行验证。 7.总结 以上简单分析和整理了blockchain_go中的交易和UTXO机制的实现过程，加深了区块链中的挖矿，交易和转账的基础技术原理的理解。 转载自http://www.bugclosed.com/post/38]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go的几种死锁情况分析]]></title>
    <url>%2F2018%2F09%2F09%2Fgo%E7%9A%84%E5%87%A0%E7%A7%8D%E6%AD%BB%E9%94%81%E6%83%85%E5%86%B5%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[在go语言中用channel通信稍不注意就会发生死锁情况，下面我们来看一下几种常见的死锁情况 第一种：同一个goroutine中，使用同一个 channel 读写。123456package mainfunc main()&#123; ch:=make(chan int) //这就是在main程里面发生的死锁情况 ch&lt;-6 // 这里会发生一直阻塞的情况，执行不到下面一句 &lt;-ch&#125; 这是最简单的死锁情况 看运行结果 第二种：2个 以上的go程中， 使用同一个 channel 通信。 读写channel 先于 go程创建。123456789package mainfunc main()&#123; ch:=make(chan int) ch&lt;-666 //这里一直阻塞，运行不到下面 go func ()&#123; &lt;-ch //这里虽然创建了子go程用来读出数据，但是上面会一直阻塞运行不到下面 &#125;()&#125; 这里如果想不成为死锁那匿名函数go程就要放到ch&lt;-666这条语句前面 看运行结果 还是同样的错误，死锁。 第三种：2个以上的go程中，使用多个 channel 通信。 A go 程 获取channel 1 的同时，尝试使用channel 2， 同一时刻，B go 程 获取channel 2 的同时，尝试使用channel 112345678910111213141516171819package mainfunc main() &#123; ch1 := make(chan int) ch2 := make(chan int) go func() &#123; //匿名子go程 for &#123; select &#123; //这里互相等对方造成死锁 case &lt;-ch1: //这里ch1有数据读出才会执行下一句 ch2 &lt;- 777 &#125; &#125; &#125;() for &#123; //主go程 select &#123; case &lt;-ch2 : //这里ch2有数据读出才会执行下一句 ch1 &lt;- 999 &#125; &#125;&#125; 第三种是互相等对方造成死锁 第四种： 在go语言中， channel 和 读写锁、互斥锁 尽量避免交叉混用。——“隐形死锁”。如果必须使用。推荐借助“条件变量”12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package mainimport ( &quot;runtime&quot; &quot;math/rand&quot; &quot;time&quot; &quot;fmt&quot; &quot;sync&quot;)// 使用读写锁var rwMutex2 sync.RWMutexfunc readGo2(idx int, in &lt;-chan int) &#123; // 读go程 for &#123; time.Sleep(time.Millisecond * 500) // 放大实验现象// 一个go程可以读 无限 次。 rwMutex2.RLock() // 读模式加 读写锁 num := &lt;-in // 从 公共的 channel 中获取数据 fmt.Printf(&quot;%dth 读 go程，读到：%d\n&quot;, idx, num) rwMutex2.RUnlock() // 解锁 读写锁 &#125;&#125;func writeGo2(idx int, out chan&lt;- int) &#123; for &#123; // 一个go程可以写 无限 次。 // 生产一个随机数 num := rand.Intn(500) rwMutex2.Lock() // 写模式加 读写锁 out &lt;- num fmt.Printf(&quot;-----%dth 写 go程，写入：%d\n&quot;, idx, num) rwMutex2.Unlock() // 解锁 读写锁 //time.Sleep(time.Millisecond * 200) // 放大实验现象 &#125;&#125;func main() &#123; // 播种随机数种子。 rand.Seed(time.Now().UnixNano()) // 创建 模拟公共区的 channel ch := make(chan int, 5) for i:=0; i&lt;5; i++ &#123; // 同时创建 N 个 读go程 go readGo2(i+1, ch) &#125; for i:=0; i&lt;5; i++ &#123; // 同时创建 N 个 写go程 go writeGo2(i+1, ch) &#125; for &#123; // 防止 主 go 程 退出 runtime.GC() &#125;&#125; 这是一种隐形的死锁，我们来看一下结果 注意这几种的死锁情况]]></content>
      <categories>
        <category>GO语言</category>
      </categories>
      <tags>
        <tag>go语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git详解-git实战]]></title>
    <url>%2F2018%2F09%2F09%2Fgit%E8%AF%A6%E8%A7%A3-git%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[本章介绍开始使用 Git 前的相关知识。我们会先了解一些版本控制工具的历史背景，然后试着让 Git 在你的系统上跑起来，直到最后配置好，可以正常开始开发工作。读完本章，你就会明白为什么 Git 会如此流行，为什么你应该立即开始使用它。 关于版本控制什么是版本控制？我真的需要吗？版本控制是一种记录若干文件内容变化，以便将来查阅特定版本修订情况的系统。在本书所展示的例子中，我们仅对保存着软件源代码的文本文件作版本控制管理，但实际上，你可以对任何类型的文件进行版本控制。 如果你是位图形或网页设计师，可能会需要保存某一幅图片或页面布局文件的所有修订版本（这或许是你非常渴望拥有的功能）。采用版本控制系统 （VCS）是个明智的选择。有了它你就可以将某个文件回溯到之前的状态，甚至将整个项目都回退到过去某个时间点的状态。你可以比较文件的变化细节，查出最 后是谁修改了哪个地方，从而导致出现怪异问题，又是谁在何时报告了某个功能缺陷等等。使用版本控制系统通常还意味着，就算你乱来一气把整个项目中的文件改 的改删的删，你也照样可以轻松恢复到原先的样子。但额外增加的工作量却微乎其微。 本地版本控制系统 许多人习惯用复制整个项目目录的方式来保存不同的版本，或许还会改名加上备份时间以示区别。这么做唯一的好处就是简单。不过坏处也不少：有时候会混淆所在的工作目录，一旦弄错文件丢了数据就没法撤销恢复。 为了解决这个问题，人们很久以前就开发了许多种本地版本控制系统，大多都是采用某种简单的数据库来记录文件的历次更新差异 其中最流行的一种叫做 rcs，现今许多计算机系统上都还看得到它的踪影。甚至在流行的 Mac OS X 系统上安装了开发者工具包之后，也可以使用 rcs 命令。它的工作原理基本上就是保存并管理文件补丁（patch）。文件补丁是一种特定格式的文本文件，记录着对应文件修订前后的内容变化。所以，根据每次 修订后的补丁，rcs 可以通过不断打补丁，计算出各个版本的文件内容。 集中化的版本控制系统 接下来人们又遇到一个问题，如何让在不同系统上的开发者协同工作？于是，集中化的版本控制系统（ Centralized Version Control Systems，简称 CVCS ）应运而生。这类系统，诸如 CVS，Subversion 以及 Perforce 等，都有一个单一的集中管理的服务器，保存所有文件的修订版本，而协同工作的人们都通过客户端连到这台服务器，取出最新的文件或者提交更新。多年以来，这 已成为版本控制系统的标准做法。 这种做法带来了许多好处，特别是相较于老式的本地 VCS 来说。现在，每个人都可以在一定程度上看到项目中的其他人正在做些什么。而管理员也可以轻松掌控每个开发者的权限，并且管理一个 CVCS 要远比在各个客户端上维护本地数据库来得轻松容易。 事分两面，有好有坏。这么做最显而易见的缺点是中央服务器的单点故障。如果宕机一小时，那么在这一小时内，谁都无法提交更新，也就无法协同工作。要 是中央服务器的磁盘发生故障，碰巧没做备份，或者备份不够及时，就还是会有丢失数据的风险。最坏的情况是彻底丢失整个项目的所有历史更改记录，而被客户端 提取出来的某些快照数据除外，但这样的话依然是个问题，你不能保证所有的数据都已经有人事先完整提取出来过。本地版本控制系统也存在类似问题，只要整个项 目的历史记录被保存在单一位置，就有丢失所有历史更新记录的风险。 分布式版本控制系统 于是分布式版本控制系统（ Distributed Version Control System，简称 DVCS ）面世了。在这类系统中，像 Git，Mercurial，Bazaar 以及 Darcs 等，客户端并不只提取最新版本的文件快照，而是把原始的代码仓库完整地镜像下来。这么一来，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜 像出来的本地仓库恢复。因为每一次的提取操作，实际上都是一次对代码仓库的完整备份。 进一步，许多这类系统都可以指定和若干不同的远端代码仓库进行交互。籍此，你就可以在同一个项目中，分别和不同工作小组的人相互协作。你可以根据需要设定不同的协作流程，比如层次模型式的工作流，而这在以前的集中式系统中是无法实现的。 Git 基础 那么，简单地说，Git 究竟是怎样的一个系统呢？请注意，接下来的内容非常重要，若是理解了 Git 的思想和基本工作原理，用起来就会知其所以然，游刃有余。在开始学习 Git 的时候，请不要尝试把各种概念和其他版本控制系统（诸如 Subversion 和 Perforce 等）相比拟，否则容易混淆每个操作的实际意义。Git 在保存和处理各种信息的时候，虽然操作起来的命令形式非常相近，但它与其他版本控制系统的做法颇为不同。理解这些差异将有助于你准确地使用 Git 提供的各种工具。 直接记录快照，而非差异比较 Git 和其他版本控制系统的主要差别在于，Git 只关心文件数据的整体是否发生变化，而大多数其他系统则只关心文件内容的具体差异。这类系统 （CVS，Subversion，Perforce，Bazaar 等等）每次记录有哪些文件作了更新，以及都更新了哪些行的什么内容 Git 并不保存这些前后变化的差异数据。实际上，Git 更像是把变化的文件作快照后，记录在一个微型的文件系统中。每次提交更新时，它会纵览一遍所有文件的指纹信息并对文件作一快照，然后保存一个指向这次快照 的索引。为提高性能，若文件没有变化，Git 不会再次保存，而只对上次保存的快照作一链接。Git 的工作方式如图所示 这是 Git 同其他系统的重要区别。它完全颠覆了传统版本控制的套路，并对各个环节的实现方式作了新的设计。Git 更像是个小型的文件系统，但它同时还提供了许多以此为基础的超强工具，而不只是一个简单的 VCS。稍后在第三章讨论 Git 分支管理的时候，我们会再看看这样的设计究竟会带来哪些好处。 近乎所有操作都是本地执行 在 Git 中的绝大多数操作都只需要访问本地文件和资源，不用连网。但如果用 CVCS 的话，差不多所有操作都需要连接网络。因为 Git 在本地磁盘上就保存着所有当前项目的历史更新，所以处理起来速度飞快。 举个例子，如果要浏览项目的历史更新摘要，Git 不用跑到外面的服务器上去取数据回来，而直接从本地数据库读取后展示给你看。所以任何时候你都可以马上翻阅，无需等待。如果想要看当前版本的文件和一个月 前的版本之间有何差异，Git 会取出一个月前的快照和当前文件作一次差异运算，而不用请求远程服务器来做这件事，或是把老版本的文件拉到本地来作比较。 用 CVCS 的话，没有网络或者断开 VPN 你就无法做任何事情。但用 Git 的话，就算你在飞机或者火车上，都可以非常愉快地频繁提交更新，等到了有网络的时候再上传到远程仓库。同样，在回家的路上，不用连接 VPN 你也可以继续工作。换作其他版本控制系统，这么做几乎不可能，抑或非常麻烦。比如 Perforce，如果不连到服务器，几乎什么都做不了（译注：默认无法发出命令p4 edit file 开始编辑文件，因为 Perforce 需要联网通知系统声明该文件正在被谁修订。但实际上手工修改文件权限可以绕过这个限制，只是完成后还是无法提交更新。）；如果是 Subversion 或 CVS，虽然可以编辑文件，但无法提交更新，因为数据库在网络上。看上去好像这些都不是什么大问题，但实际体验过之后，你就会惊喜地发现，这其实是会带来很大不同的。 时刻保持数据完整性 在保存到 Git 之前，所有数据都要进行内容的校验和（checksum）计算，并将此结果作为数据的唯一标识和索引。换句话说，不可能在你修改了文件或目录之后，Git 一无所知。这项特性作为 Git 的设计哲学，建在整体架构的最底层。所以如果文件在传输时变得不完整，或者磁盘损坏导致文件数据缺失，Git 都能立即察觉。 Git 使用 SHA-1 算法计算数据的校验和，通过对文件的内容或目录的结构计算出一个 SHA-1 哈希值，作为指纹字符串。该字串由 40 个十六进制字符（0-9 及 a-f）组成，看起来就像是： 124b9da6552252987aa493b52f8696cd6d3b00373 Git 的工作完全依赖于这类指纹字串，所以你会经常看到这样的哈希值。实际上，所有保存在 Git 数据库中的东西都是用此哈希值来作索引的，而不是靠文件名。 多数操作仅添加数据 常用的 Git 操作大多仅仅是把数据添加到数据库。因为任何一种不可逆的操作，比如删除数据，都会使回退或重现历史版本变得困难重重。在别的 VCS 中，若还未提交更新，就有可能丢失或者混淆一些修改的内容，但在 Git 里，一旦提交快照之后就完全不用担心丢失数据，特别是养成定期推送到其他仓库的习惯的话。 这种高可靠性令我们的开发工作安心不少，尽管去做各种试验性的尝试好了，再怎样也不会弄丢数据。至于 Git 内部究竟是如何保存和恢复数据的，我们会在第九章讨论 Git 内部原理时再作详述。 文件的三种状态 好，现在请注意，接下来要讲的概念非常重要。对于任何一个文件，在 Git 内都只有三种状态：已提交（committed），已修改（modified）和已暂存（staged）。已提交表示该文件已经被安全地保存在本地数据库 中了；已修改表示修改了某个文件，但还没有提交保存；已暂存表示把已修改的文件放在下次提交时要保存的清单中。 由此我们看到 Git 管理项目时，文件流转的三个工作区域：Git 的工作目录，暂存区域，以及本地仓库。 每个项目都有一个 Git 目录（译注：如果 git clone 出来的话，就是其中 .git 的目录；如果git clone --bare 的话，新建的目录本身就是 Git 目录。），它是 Git 用来保存元数据和对象数据库的地方。该目录非常重要，每次克隆镜像仓库的时候，实际拷贝的就是这个目录里面的数据。 从项目中取出某个版本的所有文件和目录，用以开始后续工作的叫做工作目录。这些文件实际上都是从 Git 目录中的压缩对象数据库中提取出来的，接下来就可以在工作目录中对这些文件进行编辑。 所谓的暂存区域只不过是个简单的文件，一般都放在 Git 目录中。有时候人们会把这个文件叫做索引文件，不过标准说法还是叫暂存区域。 Git 工作流程如下 1. 在工作目录中修改某些文件。 2. 对修改后的文件进行快照，然后保存到暂存区域。 3. 提交更新，将保存在暂存区域的文件快照永久转储到 Git 目录中。 所以，我们可以从文件所处的位置来判断状态：如果是 Git 目录中保存着的特定版本文件，就属于已提交状态；如果作了修改并已放入暂存区域，就属于已暂存状态；如果自上次取出后，作了修 改但还没有放到暂存区域，就 是已修改状态。到第二章的时候，我们会进一步了解其中细节，并学会如何根据文件状态实施后续操作，以及怎样跳过暂存直接提交。 在正式使用前，我们还需要弄清楚Git的三种重要模式，分别是已提交、已修改、已暂存 已提交(committed):表示数据文件已经顺利提交到Git数据库中。 已修改(modified):表示数据文件已经被修改，但未被保存到Git数据库中。 已暂存(staged):表示数据文件已经被修改，并会在下次提交时提交到Git数据库中。 实战 先创建一个工程的目录mkdir test_project cd test_project git init 初始化git工作目录（git init –bare功能相同） git init的结果（这个隐藏的git目录里面的内容和–bare创建的相同） git init –bare 路径 4.touch readme 创建一个文件 5.git status 查看状态 第一次查看，这个文件还没有添加到暂存区的 6.git add readme 将readme文件添加到暂存区 既然有添加，那就有删除（此处说的是暂存区的操作，不会删除文件） git rm –cached readme 7.git status 再次查看暂存区的状态 将readme添加到暂存区后的状态 8.git commit -m “first commit” 提交到自己的中央仓库（init就是创建自己的中央仓库） 9.git log查看日志（相当与svn的提交日志） 到目前为止自己本地仓库就提交结束了 之后就是提交到远程仓库了 10.git remote –v 查看本地存储的远程仓库信息，如果是clone出来的工程这个结果如下 origin 表示的是远程仓库的别名（默认为origin，也可以自己起，fetch更新类似于update，push推数据相当于commit） 如果不是clone的工程，就不会有任何结果，要自己添加，命令如下： git remote add test ssh://root@10.0.0.5/usr/GitData/DingDang/.git 11.做完这步然后就是远程推数据了（必须保证本地仓库里面有提交，注意是本地仓库而不是暂存区） git push test 到此自己创建的文件就推到了远程的git仓库了 12.还有一个功能比较重要，本地仓库的版本回退 git reset –hard HEAD^ #还原历史提交版本上一次 git reset –hard 版本号 #就是上图黄色的部分，仅需要前7位即可 如果回退过头了，log是看不到未来的版本号的，想看可以用git reflog查看 转载链接Git详解之-Git实战]]></content>
      <categories>
        <category>git使用及讲解</category>
      </categories>
      <tags>
        <tag>git工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git分支详解]]></title>
    <url>%2F2018%2F09%2F08%2Fgit%E5%88%86%E6%94%AF%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[几乎每一种版本控制系统都以某种形式支持分支。使用分支意味着你可以从开发主线上分离开来，然后在不影响主线的同时继续工作。在很多版本控制系统中，这是个昂贵的过程，常常需要创建一个源代码目录的完整副本，对大型项目来说会花费很长时间。 有人把 Git 的分支模型称为“必杀技特性”，而正是因为它，将 Git 从版本控制系统家族里区分出来。Git 有何特别之处呢？Git 的分支可谓是难以置信的轻量级，它的新建操作几乎可以在瞬间完成，并且在不同分支间切换起来也差不多一样快。和许多其他版本控制系统不同，Git 鼓励在工作流程中频繁使用分支与合并，哪怕一天之内进行许多次都没有关系。理解分支的概念并熟练运用后，你才会意识到为什么 Git 是一个如此强大而独特的工具，并从此真正改变你的开发方式。 何谓分支 为了理解 Git 分支的实现方式，我们需要回顾一下 Git 是如何储存数据的。或许你还记得第一章的内容，Git 保存的不是文件差异或者变化量，而只是一系列文件快照。 在 Git 中提交时，会保存一个提交（commit）对象，该对象包含一个指向暂存内容快照的指针，包含本次提交的作者等相关附属信息，包含零个或多个指向该提交对 象的父对象指针：首次提交是没有直接祖先的，普通提交有一个祖先，由两个或多个分支合并产生的提交则有多个祖先。 为直观起见，我们假设在工作目录中有三个文件，准备将它们暂存后提交。暂存操作会对每一个文件计算校验和（即第一章中提到的 SHA-1 哈希字串），然后把当前版本的文件快照保存到 Git 仓库中（Git 使用 blob 类型的对象存储这些快照），并将校验和加入暂存区域： 121 $ git add README test.rb LICENSE2 $ git commit -m &apos;initial commit of my project&apos; 当使用 git commit 新建一个提交对象前，Git 会先计算每一个子目录（本例中就是项目根目录）的校验和，然后在 Git 仓库中将这些目录保存为树（tree）对象。之后 Git 创建的提交对象，除了包含相关提交信息以外，还包含着指向这个树对象（项目根目录）的指针，如此它就可以在将来需要的时候，重现此次快照的内容了。 现在，Git 仓库中有五个对象：三个表示文件快照内容的 blob 对象；一个记录着目录树内容及其中各个文件对应 blob 对象索引的 tree 对象；以及一个包含指向 tree 对象（根目录）的索引和其他提交信息元数据的 commit 对象。概念上来说，仓库中的各个对象保存的数据和相互关系看起来如图所示： 作些修改后再次提交，那么这次的提交对象会包含一个指向上次提交对象的指针（译注：即下图中的 parent 对象）。两次提交后，仓库历史会变成下图： 现在来谈分支。Git 中的分支，其实本质上仅仅是个指向 commit 对象的可变指针。Git 会使用 master 作为分支的默认名字。在若干次提交后，你其实已经有了一个指向最后一次提交对象的 master 分支，它在每次提交的时候都会自动向前移动。 那么，Git 又是如何创建一个新的分支的呢？答案很简单，创建一个新的分支指针。比如新建一个 testing 分支，可以使用 git branch 命令： 1 $ git branch testing 这会在当前 commit 对象上新建一个分支指针 那么，Git 是如何知道你当前在哪个分支上工作的呢？其实答案也很简单，它保存着一个名为 HEAD 的特别指针。请注意它和你熟知的许多其他版本控制系统（比如 Subversion 或 CVS）里的 HEAD 概念大不相同。在 Git 中，它是一个指向你正在工作中的本地分支的指针（译注：将 HEAD 想象为当前分支的别名。）。运行git branch 命令，仅仅是建立了一个新的分支，但不会自动切换到这个分支中去，所以在这个例子中，我们依然还在 master 分支里工作 要切换到其他分支，可以执行 git checkout 命令。我们现在转换到新建的 testing 分支： 1 $ git checkout testing 这样 HEAD 就指向了 testing 分支 这样的实现方式会给我们带来什么好处呢？好吧，现在不妨再提交一次： 12 $ vim test.rb $ git commit -a -m &apos;made a change&apos; 非常有趣，现在 testing 分支向前移动了一格，而 master 分支仍然指向原先 git checkout 时所在的 commit 对象。现在我们回到 master 分支看看： 1 $ git checkout master 这条命令做了两件事。它把 HEAD 指针移回到 master 分支，并把工作目录中的文件换成了 master 分支所指向的快照内容。也就是说，现在开始所做的改动，将始于本项目中一个较老的版本。它的主要作用是将 testing 分支里作出的修改暂时取消，这样你就可以向另一个方向进行开发。 我们作些修改后再次提交： 12 $ vim test.rb $ git commit -a -m &apos;made other changes&apos; 现在我们的项目提交历史产生了分叉，因为刚才我们创建了一个分支，转换到其中进行了一些工作，然后又回到原来的主分支进行了另外一些工作。这些改变分别孤立在不同的分支里：我们可以 在不同分支里反复切换，并在时机成熟时把它们合并到一起。而所有这些工作，仅仅需要branch 和 checkout 这两条命令就可以完成 由于 Git 中的分支实际上仅是一个包含所指对象校验和（40 个字符长度 SHA-1 字串）的文件，所以创建和销毁一个分支就变得非常廉价。说白了，新建一个分支就是向一个文件写入 41 个字节（外加一个换行符）那么简单，当然也就很快了。 这和大多数版本控制系统形成了鲜明对比，它们管理分支大多采取备份所有项目文件到特定目录的方式，所以根据项目文件数量和大小不同，可能花费的时间 也会有相当大的差别，快则几秒，慢则数分钟。而 Git 的实现与项目复杂度无关，它永远可以在几毫秒的时间内完成分支的创建和切换。同时，因为每次提交时都记录了祖先信息（译注：即parent 对象），将来要合并分支时，寻找恰当的合并基础（译注：即共同祖先）的工作其实已经自然而然地摆在那里了，所以实现起来非常容易。Git 鼓励开发者频繁使用分支，正是因为有着这些特性作保障。 接下来看看，我们为什么应该频繁使用分支。 分支的新建与合并 现在让我们来看一个简单的分支与合并的例子，实际工作中大体也会用到这样的工作流程： 1. 开发某个网站。 2. 为实现某个新的需求，创建一个分支。 3. 在这个分支上开展工作。 假设此时，你突然接到一个电话说有个很严重的问题需要紧急修补，那么可以按照下面的方式处理： 1. 返回到原先已经发布到生产服务器上的分支。 2. 为这次紧急修补建立一个新分支，并在其中修复问题。 3. 通过测试后，回到生产服务器所在的分支，将修补分支合并进来，然后再推送到生产服务器上。 4. 切换到之前实现新需求的分支，继续工作。 分支的新建与切换 首先，我们假设你正在项目中愉快地工作，并且已经提交了几次更新 现在，你决定要修补问题追踪系统上的 #53 问题。顺带说明下，Git 并不同任何特定的问题追踪系统打交道。这里为了说明要解决的问题，才把新建的分支取名为 iss53。要新建并切换到该分支，运行git checkout 并加上 -b参数： 12 $ git checkout -b iss53 Switched to a new branch &quot;iss53&quot; 这相当于执行下面这两条命令： 12 $ git branch iss53 $ git checkout iss53 接着你开始尝试修复问题，在提交了若干次更新后，iss53 分支的指针也会随着向前推进，因为它就是当前分支（换句话说，当前的 HEAD 指针正指向 iss53）： 12$ vim index.html$ git commit -a -m &apos;added a new footer [issue 53]&apos; 现在你就接到了那个网站问题的紧急电话，需要马上修补。有了 Git ，我们就不需要同时发布这个补丁和 iss53里作出的修改，也不需要在创建和发布该补丁到服务器之前花费大力气来复原这些修改。唯一需要的仅仅是切换回master 分支。 不过在此之前，留心你的暂存区或者工作目录里，那些还没有提交的修改，它会和你即将检出的分支产生冲突从而阻止 Git 为你切换分支。切换分支的时候最好保持一个清洁的工作区域。稍后会介绍几个绕过这种问题的办法（分别叫做 stashing 和 commit amending）。目前已经提交了所有的修改，所以接下来可以正常转换到master 分支： 12 $ git checkout master Switched to branch &quot;master&quot; 此时工作目录中的内容和你在解决问题 #53 之前一模一样，你可以集中精力进行紧急修补。这一点值得牢记：Git 会把工作目录的内容恢复为检出某分支时它所指向的那个提交对象的快照。它会自动添加、删除和修改文件以确保目录的内容和你当时提交时完全一样。 接下来，你得进行紧急修补。我们创建一个紧急修补分支 hotfix 来开展工作，直到搞定： 123456$ git checkout -b &apos;hotfix&apos;Switched to a new branch &quot;hotfix&quot;$ vim index.html$ git commit -a -m &apos;fixed the broken email address&apos;[hotfix]: created 3a0874c: &quot;fixed the broken email address&quot; 1 files changed, 0 insertions(+), 1 deletions(-) 有必要作些测试，确保修补是成功的，然后回到 master 分支并把它合并进来，然后发布到生产服务器。用 git merge 命令来进行合并： 123456$ git checkout master$ git merge hotfixUpdating f42c576..3a0874cFast forward README | 1 - 1 files changed, 0 insertions(+), 1 deletions(-) 请注意，合并时出现了“Fast forward”的提示。由于当前 master 分支所在的提交对象是要并入的 hotfix 分支的直接上游，Git 只需把master 分支指针直接右移。换句话说，如果顺着一个分支走下去可以到达另一个分支的话，那么 Git 在合并两者时，只会简单地把指针右移，因为这种单线的历史分支不存在任何需要解决的分歧，所以这种合并过程可以称为快进（Fast forward）。 现在最新的修改已经在当前 master 分支所指向的提交对象中了，可以部署到生产服务器上去了 在那个超级重要的修补发布以后，你想要回到被打扰之前的工作。由于当前 hotfix 分支和 master 都指向相同的提交对象，所以hotfix 已经完成了历史使命，可以删掉了。使用 git branch 的 -d 选项执行删除操作： 12 $ git branch -d hotfix Deleted branch hotfix (3a0874c). 现在回到之前未完成的 #53 问题修复分支上继续工作（图 3-15）： 123456$ git checkout iss53Switched to branch &quot;iss53&quot;$ vim index.html$ git commit -a -m &apos;finished the new footer [issue 53]&apos;[iss53]: created ad82d7a: &quot;finished the new footer [issue 53]&quot; 1 files changed, 1 insertions(+), 0 deletions(-) 不用担心之前 hotfix 分支的修改内容尚未包含到 iss53 中来。如果确实需要纳入此次修补，可以用git merge master 把 master 分支合并到 iss53；或者等 iss53 完成之后，再将iss53分支中的更新并入 master。 分支的合并 在问题 #53 相关的工作完成之后，可以合并回 master 分支。实际操作同前面合并 hotfix 分支差不多，只需回到master 分支，运行 git merge 命令指定要合并进来的分支： 12345$ git checkout master$ git merge iss53Merge made by recursive. README | 1 + 1 files changed, 1 insertions(+), 0 deletions(-) 请注意，这次合并操作的底层实现，并不同于之前 hotfix 的并入方式。因为这次你的开发历史是从更早的地方开始分叉的。由于当前 master 分支所指向的提交对象（C4）并不是 iss53 分支的直接祖先，Git 不得不进行一些额外处理。就此例而言，Git 会用两个分支的末端（C4 和 C5）以及它们的共同祖先（C2）进行一次简单的三方合并计算。图 3-16 用红框标出了 Git 用于合并的三个提交对象： 这次，Git 没有简单地把分支指针右移，而是对三方合并后的结果重新做一个新的快照，并自动创建一个指向它的提交对象（C6）。这个提交对象比较特殊，它有两个祖先（C4 和 C5）。 值得一提的是 Git 可以自己裁决哪个共同祖先才是最佳合并基础；这和 CVS 或 Subversion（1.5 以后的版本）不同，它们需要开发者手工指定合并基础。所以此特性让 Git 的合并操作比其他系统都要简单不少。 既然之前的工作成果已经合并到 master 了，那么 iss53 也就没用了。你可以就此删除它，并在问题追踪系统里关闭该问题。 1 $ git branch -d iss53 Checkout 历史版本从某个历史版本创建新的分支在 Git 中从当前分支创建并检出新分支的命令是 1git checkout -b name-of-new-branch 这个命令实际上是 1git checkout -b name-of-new-branch current-branch 的简写形式。也就是说，当我们不指定 checkout 起点时，Git 默认从当前活动分支开始创建新的分支。 Git 的每个提交都有一个 SHA1 散列值（Hash 值）作为 ID。我们可以在 checkout 命令中使用这些 ID 作为起点。比如： 1git checkout -b name-of-new-branch 169d2dc 这样，Git 的活动分支会切换到 name-of-new-branch 这个分支上，而它的内容与 169d2dc 这个分支一致。 注意：SHA1 的散列值有 40 个字母，相当长。所以 Git 允许我们在不引起歧义的情况下，使用散列值的前几位作为缩写。 提示：你也可以用 git branch name-of-new-branch 169d2dc 来创建一个历史分支，而不切换到该分支。 将某个历史版本 checkout 到工作区首先说明，这样做会产生一个分离的 HEAD 指针，所以个人不推荐这么做。 如果我们工作在 master 分支上，希望 checkout 到 dev 分支上，我们会这么做： 1git checkout dev 这里 dev 实际上是一个指针的别名，其本质也是一个 SHA1 散列值。所以，我们很自然地可以用 1git checkout &lt;sha1-of-a-commit&gt; 将某个历史版本 checkout 到工作区。 将某个文件的历史版本 checkout 到工作区大多数时候，我们可能只需要对某一个文件做细小的修补，因此只 checkout 该文件就行了，并不需要操作整个 commit 或分支。 上一节我们介绍了如何将某个历史版本完整地 checkout 到工作区。实际上，我们只需要在上一节的命令之后加上需要 checkout 的文件即可。 1git checkout &lt;sha1-of-a-commit&gt; &lt;/path/to/your/file&gt; 当然，有时候你需要将某个文件的历史版本 checkout 出来，并以一个新的名字保存。这时候可以这么做： 遇到冲突时的分支合并 有时候合并操作并不会如此顺利。如果在不同的分支中都修改了同一个文件的同一部分，Git 就无法干净地把两者合到一起（译注：逻辑上说，这种问题只能由人来裁决。）。如果你在解决问题 #53 的过程中修改了hotfix 中修改的部分，将得到类似下面的结果： 1234$ git merge iss53Auto-merging index.htmlCONFLICT (content): Merge conflict in index.htmlAutomatic merge failed; fix conflicts and then commit the result. Git 作了合并，但没有提交，它会停下来等你解决冲突。要看看哪些文件在合并时发生冲突，可以用 git status 查阅： 123456789101112[master*]$ git statusindex.html: needs merge# On branch master# Changed but not updated:# (use &quot;git add ...&quot; to update what will be committed)# (use &quot;git checkout -- ...&quot; to discard changes in working directory)## unmerged: index.html# 任何包含未解决冲突的文件都会以未合并（unmerged）的状态列出。Git 会在有冲突的文件里加入标准的冲突解决标记，可以通过它们来手工定位并解决这些冲突。可以看到此文件包含类似下面这样的部分： 12345&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD:index.htmlcontact : email.support@github.com=======please contact us at support@github.com&gt;&gt;&gt;&gt;&gt;&gt;&gt; iss53:index.html 可以看到 ======= 隔开的上半部分，是 HEAD（即 master 分支，在运行merge 命令时所切换到的分支）中的内容，下半部分是在 iss53 分支中的内容。解决冲突的办法无非是二者选其一或者由你亲自整合到一起。比如你可以通过把这段内容替换为下面这样来解决： please contact us at email.support@github.com 这个解决方案各采纳了两个分支中的一部分内容，而且我还删除了 &lt;&lt;&lt;&lt;&lt;&lt;&lt;，======= 和 &gt;&gt;&gt;&gt;&gt;&gt;&gt; 这些行。在解决了所有文件里的所有冲突后，运行 git add 将把它们标记为已解决状态（译注：实际上就是来一次快照保存到暂存区域。）。因为一旦暂存，就表示冲突已经解决。如果你想用一个有图形界面的工具来解决这些问题，不妨运行git mergetool，它会调用一个可视化的合并工具并引导你解决所有冲突： 12345678$ git mergetoolmerge tool candidates: kdiff3 tkdiff xxdiff meld gvimdiff opendiff emerge vimdiffMerging the files: index.htmlNormal merge conflict for &apos;index.html&apos;: &#123;local&#125;: modified &#123;remote&#125;: modifiedHit return to start merge resolution tool (opendiff): 如果不想用默认的合并工具（Git 为我默认选择了 opendiff，因为我在 Mac 上运行了该命令），你可以在上方”merge tool candidates”里找到可用的合并工具列表，输入你想用的工具名。我们将在第七章讨论怎样改变环境中的默认值。 退出合并工具以后，Git 会询问你合并是否成功。如果回答是，它会为你把相关文件暂存起来，以表明状态为已解决。 再运行一次 git status 来确认所有冲突都已解决： 1234567891011$ git status# On branch master# Changes to be committed:# (use &quot;git reset HEAD ...&quot; to unstage)## modified: index.html# 如果觉得满意了，并且确认所有冲突都已解决，也就是进入了暂存区，就可以用 git commit 来完成这次合并提交。提交的记录差不多是这样： 123456789Merge branch &apos;iss53&apos;Conflicts: index.html## It looks like you may be committing a MERGE.# If this is not correct, please remove the file# .git/MERGE_HEAD# and try again. 如果想给将来看这次合并的人一些方便，可以修改该信息，提供更多合并细节。比如你都作了哪些改动，以及这么做的原因。有时候裁决冲突的理由并不直接或明显，有必要略加注解。 分支的管理 到目前为止，你已经学会了如何创建、合并和删除分支。除此之外，我们还需要学习如何管理分支，在日后的常规工作中会经常用到下面介绍的管理命令。 git branch 命令不仅仅能创建和删除分支，如果不加任何参数，它会给出当前所有分支的清单： 1234$ git branch iss53* master testing 注意看 master 分支前的 * 字符：它表示当前所在的分支。也就是说，如果现在提交更新，master 分支将随着开发进度前移。若要查看各个分支最后一个提交对象的信息，运行git branch -v： 1234$ git branch -v iss53 93b412c fix javascript issue* master 7a98805 Merge branch &apos;iss53&apos; testing 782fd34 add scott to the author list in the readmes 要从该清单中筛选出你已经（或尚未）与当前分支合并的分支，可以用 --merge 和 --no-merged选项（Git 1.5.6 以上版本）。比如用git branch --merge 查看哪些分支已被并入当前分支（译注：也就是说哪些分支是当前分支的直接上游。）： 123$ git branch --merged iss53* master 之前我们已经合并了 iss53，所以在这里会看到它。一般来说，列表中没有 * 的分支通常都可以用 git branch -d 来删掉。原因很简单，既然已经把它们所包含的工作整合到了其他分支，删掉也不会损失什么。 另外可以用 git branch --no-merged 查看尚未合并的工作： 12$ git branch --no-merged testing 它会显示还未合并进来的分支。由于这些分支中还包含着尚未合并进来的工作成果，所以简单地用 git branch -d删除该分支会提示错误，因为那样做会丢失数据： 123$ git branch -d testingerror: The branch &apos;testing&apos; is not an ancestor of your current HEAD.If you are sure you want to delete it, run &apos;git branch -D testing&apos;. 不过，如果你确实想要删除该分支上的改动，可以用大写的删除选项 -D 强制执行，就像上面提示信息中给出的那样。 利用分支进行开发的工作流程 现在我们已经学会了新建分支和合并分支，可以（或应该）用它来做点什么呢？在本节，我们会介绍一些利用分支进行开发的工作流程。而正是由于分支管理的便捷，才衍生出了这类典型的工作模式，你可以根据项目的实际情况选择一种用用看。 长期分支 由于 Git 使用简单的三方合并，所以就算在较长一段时间内，反复多次把某个分支合并到另一分支，也不是什么难事。也就是说，你可以同时拥有多个开放的分支，每个分支用于完成特定的任务，随着开发的推进，你可以随时把某个特性分支的成果并到其他分支中。 许多使用 Git 的开发者都喜欢用这种方式来开展工作，比如仅在 master 分支中保留完全稳定的代码，即已经发布或即将发布的代码。与此同时，他们还有一个名为develop 或 next 的平行分支，专门用于后续的开发，或仅用于稳定性测试 — 当然并不是说一定要绝对稳定，不过一旦进入某种稳定状态，便可以把它合并到master 里。这样，在确保这些已完成的特性分支（短期分支，比如之前的 iss53 分支）能够通过所有测试，并且不会引入更多错误之后，就可以并到主干分支中，等待下一次的发布。 本质上我们刚才谈论的，是随着提交对象不断右移的指针。稳定分支的指针总是在提交历史中落后一大截，而前沿分支总是比较靠前 或者把它们想象成工作流水线，或许更好理解一些，经过测试的提交对象集合被遴选到更稳定的流水线 你可以用这招维护不同层次的稳定性。某些大项目还会有个 proposed（建议）或 pu（proposed updates，建议更新）分支，它包含着那些可能还没有成熟到进入next 或 master 的内容。这么做的目的是拥有不同层次的稳定性：当这些分支进入到更稳定的水平时，再把它们合并到更高层分支中去。再次说明下，使用多个长期分支的做法并非必需，不过一般来说，对于特大型项目或特复杂的项目，这么做确实更容易管理。 特性分支 在任何规模的项目中都可以使用特性（Topic）分支。一个特性分支是指一个短期的，用来实现单一特性或与其相关工作的分支。可能你在以前的版本控 制系统里从未做过类似这样的事情，因为通常创建与合并分支消耗太大。然而在 Git 中，一天之内建立、使用、合并再删除多个分支是常见的事。 我们在上节的例子里已经见过这种用法了。我们创建了 iss53 和 hotfix 这两个特性分支，在提交了若干更新后，把它们合并到主干分支，然后删除。该技术允许你迅速且完全的进行语境切换 — 因为你的工作分散在不同的流水线里，每个分支里的改变都和它的目标特性相关，浏览代码之类的事情因而变得更简单了。你可以把作出的改变保持在特性分支中几 分钟，几天甚至几个月，等它们成熟以后再合并，而不用在乎它们建立的顺序或者进度。 现在我们来看一个实际的例子。请看下图，由下往上，起先我们在 master 工作到 C1，然后开始一个新分支 iss91 尝试修复 91 号缺陷，提交到 C6 的时候，又冒出一个解决该问题的新办法，于是从之前 C4 的地方又分出一个分支iss91v2，干到 C8 的时候，又回到主干 master 中提交了 C9 和 C10，再回到 iss91v2 继续工作，提交 C11，接着，又冒出个不太确定的想法，从 master 的最新提交 C10 处开了个新的分支dumbidea 做些试验。 现在，假定两件事情：我们最终决定使用第二个解决方案，即 iss91v2 中的办法；另外，我们把 dumbidea 分支拿给同事们看了以后，发现它竟然是个天才之作。所以接下来，我们准备抛弃原来的iss91 分支（实际上会丢弃 C5 和 C6），直接在主干中并入另外两个分支。最终的提交历史将变成下图 请务必牢记这些分支全部都是本地分支，这一点很重要。当你在使用分支及合并的时候，一切都是在你自己的 Git 仓库中进行的 — 完全不涉及与服务器的交互。 远程分支 远程分支（remote branch）是对远程仓库中的分支的索引。它们是一些无法移动的本地分支；只有在 Git 进行网络交互时才会更新。远程分支就像是书签，提醒着你上次连接远程仓库时上面各分支的位置。 我们用 (远程仓库名)/(分支名) 这样的形式表示远程分支。比如我们想看看上次同 origin 仓库通讯时master的样子，就应该查看 origin/master 分支。如果你和同伴一起修复某个问题，但他们先推送了一个iss53 分支到远程仓库，虽然你可能也有一个本地的 iss53 分支，但指向服务器上最新更新的却应该是 origin/iss53 分支。 可能有点乱，我们不妨举例说明。假设你们团队有个地址为 git.ourcompany.com 的 Git 服务器。如果你从这里克隆，Git 会自动为你将此远程仓库命名为origin，并下载其中所有的数据，建立一个指向它的 master 分支的指针，在本地命名为 origin/master，但你无法在本地更改其数据。接着，Git 建立一个属于你自己的本地master 分支，始于 origin 上 master 分支相同的位置，你可以就此开始工作 一次 Git 克隆会建立你自己的本地分支 master 和远程分支 origin/master，它们都指向 origin/master 分支的最后一次提交。 如果你在本地 master 分支做了些改动，与此同时，其他人向 git.ourcompany.com 推送了他们的更新，那么服务器上的master 分支就会向前推进，而于此同时，你在本地的提交历史正朝向不同方向发展。不过只要你不和服务器通讯，你的 origin/master 指针仍然保持原位不会移动 在本地工作的同时有人向远程仓库推送内容会让提交历史开始分流。 可以运行 git fetch origin 来同步远程服务器上的数据到本地。该命令首先找到 origin 是哪个服务器（本例为git.ourcompany.com），从上面获取你尚未拥有的数据，更新你本地的数据库，然后把 origin/master 的指针移到它最新的位置上 为了演示拥有多个远程分支（在不同的远程服务器上）的项目是如何工作的，我们假设你还有另一个仅供你的敏捷开发小组使用的内部服务器 git.team1.ourcompany.com。可以用第二章中提到的git remote add 命令把它加为当前项目的远程分支之一。我们把它命名为 teamone，以便代替原始的 Git 地址 现在你可以用 git fetch teamone 来获取小组服务器上你还没有的数据了。由于当前该服务器上的内容是你 origin 服务器上的子集，Git 不会下载任何数据，而只是简单地创建一个名为teamone/master 的分支，指向 teamone 服务器上 master 分支所在的提交对象31b8e 推送本地分支 要想和其他人分享某个本地分支，你需要把它推送到一个你拥有写权限的远程仓库。你的本地分支不会被自动同步到你引入的远程服务器上，除非你明确执行推送操作。换句话说，对于无意分享的分支，你尽管保留为私人分支好了，而只推送那些协同工作要用到的特性分支。 如果你有个叫 serverfix 的分支需要和他人一起开发，可以运行 git push (远程仓库名) (分支名)： 1234567$ git push origin serverfixCounting objects: 20, done.Compressing objects: 100% (14/14), done.Writing objects: 100% (15/15), 1.74 KiB, done.Total 15 (delta 5), reused 0 (delta 0)To git@github.com:schacon/simplegit.git * [new branch] serverfix -&gt; serverfix 这其实有点像条捷径。Git 自动把 serverfix 分支名扩展为 refs/heads/serverfix:refs/heads/serverfix，意为“取出我在本地的 serverfix 分支，推送到远程仓库的 serverfix 分支中去”。我们将在第九章进一步介绍refs/heads/ 部分的细节，不过一般使用的时候都可以省略它。也可以运行 git push origin serverfix:serferfix 来实现相同的效果，它的意思是“上传我本地的 serverfix 分支到远程仓库中去，仍旧称它为 serverfix 分支”。通过此语法，你可以把本地分支推送到某个命名不同的远程分支：若想把远程分支叫作awesomebranch，可以用 git push origin serverfix:awesomebranch 来推送数据。 接下来，当你的协作者再次从服务器上获取数据时，他们将得到一个新的远程分支 origin/serverfix： 1234567$ git fetch originremote: Counting objects: 20, done.remote: Compressing objects: 100% (14/14), done.remote: Total 15 (delta 5), reused 0 (delta 0)Unpacking objects: 100% (15/15), done.From git@github.com:schacon/simplegit * [new branch] serverfix -&gt; origin/serverfix 值得注意的是，在 fetch 操作下载好新的远程分支之后，你仍然无法在本地编辑该远程仓库中的分支。换句话说，在本例中，你不会有一个新的serverfix 分支，有的只是一个你无法移动的 origin/serverfix 指针。 如果要把该内容合并到当前分支，可以运行 git merge origin/serverfix。如果想要一份自己的 serverfix来开发，可以在远程分支的基础上分化出一个新的分支来： 123$ git checkout -b serverfix origin/serverfixBranch serverfix set up to track remote branch refs/remotes/origin/serverfix.Switched to a new branch &quot;serverfix&quot; 这会切换到新建的 serverfix 本地分支，其内容同远程分支 origin/serverfix 一致，这样你就可以在里面继续开发了。 跟踪远程分支 从远程分支 checkout 出来的本地分支，称为跟踪分支(tracking branch)。跟踪分支是一种和远程分支有直接联系的本地分支。在跟踪分支里输入git push，Git 会自行推断应该向哪个服务器的哪个分支推送数据。反过来，在这些分支里运行 git pull 会获取所有远程索引，并把它们的数据都合并到本地分支中来。 在克隆仓库时，Git 通常会自动创建一个名为 master 的分支来跟踪 origin/master。这正是git push 和 git pull 一开始就能正常工作的原因。当然，你可以随心所欲地设定为其它跟踪分支，比如origin 上除了 master之外的其它分支。刚才我们已经看到了这样的一个例子：git checkout -b [分支名] [远程名]/[分支名]。如果你有 1.6.2 以上版本的 Git，还可以用--track 选项简化： 123$ git checkout --track origin/serverfixBranch serverfix set up to track remote branch refs/remotes/origin/serverfix.Switched to a new branch &quot;serverfix&quot; 要为本地分支设定不同于远程分支的名字，只需在前个版本的命令里换个名字： 123$ git checkout -b sf origin/serverfixBranch sf set up to track remote branch refs/remotes/origin/serverfix.Switched to a new branch &quot;sf&quot; 现在你的本地分支 sf 会自动向 origin/serverfix 推送和抓取数据了。 删除远程分支如果不再需要某个远程分支了，比如搞定了某个特性并把它合并进了远程的 master 分支（或任何其他存放稳定代码的地方），可以用这个非常无厘头的语法来删除它：git push [远程名] :[分支名]。如果想在服务器上删除serverfix 分支，运行下面的命令： 123$ git push origin :serverfixTo git@github.com:schacon/simplegit.git - [deleted] serverfix 咚！服务器上的分支没了。你最好特别留心这一页，因为你一定会用到那个命令，而且你很可能会忘掉它的语法。有种方便记忆这条命令的方法：记住我们不久前见过的 git push [远程名] [本地分支]:[远程分支] 语法，如果省略 [本地分支]，那就等于是在说“在这里提取空白然后把它变成[远程分支]”。 分支的衍合 把一个分支整合到另一个分支的办法有两种：merge 和 rebase（译注：rebase 的翻译暂定为“衍合”，大家知道就可以了。）。在本章我们会学习什么是衍合，如何使用衍合，为什么衍合操作如此富有魅力，以及我们应该在什么情况下使用衍合。 基本的衍合操作开发进程分叉到两个不同分支，又各自提交了更新。 之前介绍过，最容易的整合分支的方法是 merge 命令，它会把两个分支最新的快照（C3 和 C4）以及二者最新的共同祖先（C2）进行三方合并，合并的结果是产生一个新的提交对象（C5）。 其实，还有另外一个选择：你可以把在 C3 里产生的变化补丁在 C4 的基础上重新打一遍。在 Git 里，这种操作叫做衍合（rebase）。有了 rebase 命令，就可以把在一个分支里提交的改变移到另一个分支里重放一遍。 在上面这个例子中，运行： 1234$ git checkout experiment$ git rebase masterFirst, rewinding head to replay your work on top of it...Applying: added staged command 它的原理是回到两个分支最近的共同祖先，根据当前分支（也就是要进行衍合的分支 experiment）后续的历次提交对象（这里只有一个 C3），生成一系列文件补丁，然后以基底分支（也就是主干分支master）最后一个提交对象（C4）为新的出发点，逐个应用之前准备好的补丁文件，最后会生成一个新的合并提交对象（C3’），从而改写 experiment 的提交历史，使它成为 master 分支的直接下游，如图 现在回到 master 分支，进行一次快进合并 现在的 C3’ 对应的快照，其实和普通的三方合并，即上个例子中的 C5 对应的快照内容一模一样了。虽然最后整合得到的结果没有任何区别，但衍合能产生一个更为整洁的提交历史。如果视察一个衍合过的分支的历史记录，看起来会更 清楚：仿佛所有修改都是在一根线上先后进行的，尽管实际上它们原本是同时并行发生的。 一般我们使用衍合的目的，是想要得到一个能在远程分支上干净应用的补丁 — 比如某些项目你不是维护者，但想帮点忙的话，最好用衍合：先在自己的一个分支里进行开发，当准备向主项目提交补丁的时候，根据最新的origin/master 进行一次衍合操作然后再提交，这样维护者就不需要做任何整合工作（译注：实际上是把解决分支补丁同最新主干代码之间冲突的责任，化转为由提交补丁的人来解决。），只需根据你提供的仓库地址作一次快进合并，或者直接采纳你提交的补丁。 请注意，合并结果中最后一次提交所指向的快照，无论是通过衍合，还是三方合并，都会得到相同的快照内容，只不过提交历史不同罢了。衍合是按照每行的修改次序重演一遍修改，而合并是把最终结果合在一起。 有趣的衍合 衍合也可以放到其他分支进行，并不一定非得根据分化之前的分支。以图 3-31 的历史为例，我们为了给服务器端代码添加一些功能而创建了特性分支 server，然后提交 C3 和 C4。然后又从 C3 的地方再增加一个client 分支来对客户端代码进行一些相应修改，所以提交了 C8 和 C9。最后，又回到 server 分支提交了 C10。 假设在接下来的一次软件发布中，我们决定先把客户端的修改并到主线中，而暂缓并入服务端软件的修改（因为还需要进一步测试）。这个时候，我们就可以把基于 server 分支而非 master 分支的改变（即 C8 和 C9），跳过 server 直接放到master 分支中重演一遍，但这需要用 git rebase 的 --onto 选项指定新的基底分支master： 1$ git rebase --onto master server client 这好比在说：“取出 client 分支，找出 client 分支和 server 分支的共同祖先之后的变化，然后把它们在master 上重演一遍”。是不是有点复杂？不过它的结果如图 3-32 所示，非常酷（译注：虽然 client 里的 C8, C9 在 C3 之后，但这仅表明时间上的先后，而非在 C3 修改的基础上进一步改动，因为server 和 client 这两个分支对应的代码应该是两套文件，虽然这么说不是很严格，但应理解为在 C3 时间点之后，对另外的文件所做的 C8，C9 修改，放到主干重演。）： 现在可以快进 master 分支了： 12$ git checkout master$ git merge client 现在我们决定把 server 分支的变化也包含进来。我们可以直接把 server 分支衍合到 master，而不用手工切换到 server 分支后再执行衍合操作 — git rebase [主分支] [特性分支]命令会先取出特性分支server，然后在主分支 master 上重演： 1$ git rebase master server 于是，server 的进度应用到 master 的基础上， 然后就可以快进主干分支 master 了： 12$ git checkout master$ git merge server 现在 client 和 server 分支的变化都已经集成到主干分支来了，可以删掉它们了。最终我们的提交历史会变成图 3-35 的样子： 12$ git branch -d client$ git branch -d server 衍合的风险 呃，奇妙的衍合也并非完美无缺，要用它得遵守一条准则： 一旦分支中的提交对象发布到公共仓库，就千万不要对该分支进行衍合操作。 如果你遵循这条金科玉律，就不会出差错。否则，人民群众会仇恨你，你的朋友和家人也会嘲笑你，唾弃你。 在进行衍合的时候，实际上抛弃了一些现存的提交对象而创造了一些类似但不同的新的提交对象。如果你把原来分支中的提交对象发布出去，并且其他人更新下载后在其基础上开展工作，而稍后你又用git rebase 抛弃这些提交对象，把新的重演后的提交对象发布出去的话，你的合作者就不得不重新合并他们的工作，这样当你再次从他们那里获取内容时，提交历史就会变得一团糟。 下面我们用一个实际例子来说明为什么公开的衍合会带来问题。假设你从一个中央服务器克隆然后在它的基础上搞了一些开发，提交历史 现在，某人在 C1 的基础上做了些改变，并合并他自己的分支得到结果 C6，推送到中央服务器。当你抓取并合并这些数据到你本地的开发分支中后，会得到合并结果 C7，历史提交会变成 接下来，那个推送 C6 上来的人决定用衍合取代之前的合并操作；继而又用 git push --force 覆盖了服务器上的历史，得到 C4’。而之后当你再从服务器上下载最新提交后，会得到： 下载更新后需要合并，但此时衍合产生的提交对象 C4’ 的 SHA-1 校验值和之前 C4 完全不同，所以 Git 会把它们当作新的提交对象处理，而实际上此刻你的提交历史 C7 中早已经包含了 C4 的修改内容，于是合并操作会把 C7 和 C4’ 合并为 C8 C8 这一步的合并是迟早会发生的，因为只有这样你才能和其他协作者提交的内容保持同步。而在 C8 之后，你的提交历史里就会同时包含 C4 和 C4’，两者有着不同的 SHA-1 校验值，如果用git log 查看历史，会看到两个提交拥有相同的作者日期与说明，令人费解。而更糟的是，当你把这样的历史推送到服务器后，会再次把这些衍合后的提交引入到中央服务 器，进一步困扰其他人（译注：这个例子中，出问题的责任方是那个发布了 C6 后又用衍合发布 C4’ 的人，其他人会因此反馈双重历史到共享主干，从而混淆大家的视听。）。 如果把衍合当成一种在推送之前清理提交历史的手段，而且仅仅衍合那些尚未公开的提交对象，就没问题。如果衍合那些已经公开的提交对象，并且已经有人基于这些提交对象开展了后续开发工作的话，就会出现叫人沮丧的麻烦。 小结 读到这里，你应该已经学会了如何创建分支并切换到新分支，在不同分支间转换，合并本地分支，把分支推送到共享服务器上，使用共享分支与他人协作，以及在分享之前进行衍合。 转载链接Git详解三Git分支]]></content>
      <categories>
        <category>git使用及讲解</category>
      </categories>
      <tags>
        <tag>git工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络协议-最全的网络协议图]]></title>
    <url>%2F2018%2F09%2F08%2F%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E6%9C%80%E5%85%A8%E7%9A%84%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[转载自http://www.52im.net 图片较大，建议单击放大或者下载后查看]]></content>
      <categories>
        <category>网络编程协议</category>
      </categories>
      <tags>
        <tag>通信协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go语言并发讲解，虚拟内存讲解]]></title>
    <url>%2F2018%2F09%2F08%2Fgo%E8%AF%AD%E8%A8%80%E5%B9%B6%E5%8F%91%E8%AE%B2%E8%A7%A3%EF%BC%8C%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E8%AE%B2%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[并行和并发今天我们来讲一下在计算机编程中并行和并发的意思并行(parallel)：指在同一时刻，有多条指令在多个处理器上同时执行。并发(concurrency)：指在同一时刻只能有一条指令执行，但多个进程指令被快速的轮换执行，使得在宏观上具有多个进程同时执行的效果，但在微观上并不是同时执行的，只是把时间分成若干段，通过cpu时间片轮转使多个进程快速交替的执行。如果字面意思上不好理解的话那么我们可以来看一个例子就可以很轻松的理解出大师曾以咖啡机的例子来解释并行和并发的区别。 并行是两个队列同时使用两台咖啡机 （真正的多任务）并发是两个队列交替使用一台咖啡机 （ 假 的多任务）在计算机上想要实现并行该怎么办，那么我们就要像图中一样增加硬件设备，那么计算机就要增加cpu，但是计算机的cpu是有限的，所以我们就要设计并发来实现在计算机cpu不变的情况下增加运算能力，这就是并发的字面意思。 常见并发编程技术进程并发程序和进程程序，是指编译好的二进制文件，在磁盘上，不占用系统资源(内存、打开的文件、设备、锁….)进程，是一个抽象的概念，与操作系统原理联系紧密。进程是活跃的程序，占用系统资源。在内存中执行。(程序运行起来，产生一个进程)程序 → 剧本(纸) 进程 → 戏 (舞台、演员、灯光、道具…)同一个剧本可以在多个舞台同时上演。同样，同一个程序也可以加载为不同的进程(彼此之间互不影响)如：同时开两个终端。各自都有一个bash但彼此ID不同。在windows系统下，通过查看“任务管理器”，可以查看相应的进程。包括我们在基础班写的“飞机大战”等程序，运行起来后也可以在“任务管理器”中查看到。运行起来的程序就是一个进程。 进程状态进程基本的状态有5种。分别为初始态，就绪态，运行态，挂起态与终止态。其中初始态为进程准备阶段，常与就绪态结合来看。 进程并发在使用进程 实现并发时会出现什么问题呢？1：系统开销比较大，占用资源比较多，开启进程数量比较少。2：在unix/linux系统下，还会产生“孤儿进程”和“僵尸进程”。在操作系统运行过程中，可以产生很多的进程。在unix/linux系统中，正常情况下，子进程是通过父进程fork创建的，子进程再创建新的进程。并且父进程永远无法预测子进程到底什么时候结束。 当一个进程完成它的工作终止之后，它的父进程需要调用系统调用取得子进程的终止状态。孤儿进程孤儿进程: 父进程先于子进程结束，则子进程成为孤儿进程，子进程的父进程成为init进程，称为init进程领养孤儿进程。僵尸进程僵尸进程: 进程终止，父进程尚未回收，子进程残留资源（PCB）存放于内核中，变成僵尸（Zombie）进程。Windows下的进程和Linux下的进程是不一样的，它比较懒惰，从来不执行任何东西，只是为线程提供执行环境。然后由线程负责执行包含在进程的地址空间中的代码。当创建一个进程的时候，操作系统会自动创建这个进程的第一个线程，成为主线程。 线程并发什么是线程LWP：light weight process 轻量级的进程，本质仍是进程 (Linux下)进程：独立地址空间，拥有PCB 线程：有独立的PCB，但没有独立的地址空间(共享) 区别：在于是否共享地址空间。独居(进程)；合租(线程)。线程：最小的执行单位进程：最小分配资源单位，可看成是只有一个线程的进程。Windows系统下，可以直接忽略进程的概念，只谈线程。因为线程是最小的执行单位，是被系统独立调度和分派的基本单位。而进程只是给线程提供执行环境。线程同步同步即协同步调，按预定的先后次序运行。线程同步，指一个线程发出某一功能调用时，在没有得到结果之前，该调用不返回。同时其它线程为保证数据一致性，不能调用该功能。举例1： 银行存款 5000。柜台，折：取3000；提款机，卡：取 3000。剩余：2000举例2： 内存中100字节，线程T1欲填入全1， 线程T2欲填入全0。但如果T1执行了50个字节失去cpu，T2执行，会将T1写过的内容覆盖。当T1再次获得cpu继续 从失去cpu的位置向后写入1，当执行结束，内存中的100字节，既不是全1，也不是全0。产生的现象叫做“与时间有关的错误”(time related)。为了避免这种数据混乱，线程需要同步。“同步”的目的，是为了避免数据混乱，解决与时间有关的错误。实际上，不仅线程间需要同步，进程间、信号间等等都需要同步机制。因此，所有“多个控制流，共同操作一个共享资源”的情况，都需要同步。 协程并发协程：coroutine。也叫轻量级线程。与传统的系统级线程和进程相比，协程最大的优势在于“轻量级”。可以轻松创建上万个而不会导致系统资源衰竭。而线程和进程通常很难超过1万个。这也是协程别称“轻量级线程”的原因。一个线程中可以有任意多个协程，但某一时刻只能有一个协程在运行，多个协程分享该线程分配到的计算机资源。多数语言在语法层面并不直接支持协程，而是通过库的方式支持，但用库的方式支持的功能也并不完整，比如仅仅提供协程的创建、销毁与切换等能力。如果在这样的轻量级线程中调用一个同步 IO 操作，比如网络通信、本地文件读写，都会阻塞其他的并发执行轻量级线程，从而无法真正达到轻量级线程本身期望达到的目标。在协程中，调用一个任务就像调用一个函数一样，消耗的系统资源最少！但能达到进程、线程并发相同的效果。在一次并发任务中，进程、线程、协程均可以实现。从系统资源消耗的角度出发来看，进程相当多，线程次之，协程最少。 Go并发Go 在语言级别支持协程，叫goroutine。Go 语言标准库提供的所有系统调用操作（包括所有同步IO操作），都会出让CPU给其他goroutine。这让轻量级线程的切换管理不依赖于系统的线程和进程，也不需要依赖于CPU的核心数量。有人把Go比作21世纪的C语言。第一是因为Go语言设计简单，第二，21世纪最重要的就是并行程序设计，而Go从语言层面就支持并行。同时，并发程序的内存管理有时候是非常复杂的，而Go语言提供了自动垃圾回收机制。Go语言为并发编程而内置的上层API基于顺序通信进程模型CSP(communicating sequential processes)。这就意味着显式锁都是可以避免的，因为Go通过相对安全的通道发送和接受数据以实现同步，这大大地简化了并发程序的编写。Go语言中的并发程序主要使用两种手段来实现。goroutine和channel。 Goroutine什么是Goroutinegoroutine是Go语言并行设计的核心，有人称之为go程。 goroutine说到底其实就是协程，它比线程更小，十几个goroutine可能体现在底层就是五六个线程，Go语言内部帮你实现了这些goroutine之间的内存共享。执行goroutine只需极少的栈内存(大概是4~5KB)，当然会根据相应的数据伸缩。也正因为如此，可同时运行成千上万个并发任务。goroutine比thread更易用、更高效、更轻便。一般情况下，一个普通计算机跑几十个线程就有点负载过大了，但是同样的机器却可以轻松地让成百上千个goroutine进行资源竞争。 Goroutine的创建只需在函数调⽤语句前添加 go 关键字，就可创建并发执⾏单元。开发⼈员无需了解任何执⾏细节，调度器会自动将其安排到合适的系统线程上执行。在并发编程中，我们通常想将一个过程切分成几块，然后让每个goroutine各自负责一块工作，当一个程序启动时，主函数在一个单独的goroutine中运行，我们叫它main goroutine。新的goroutine会用go语句来创建。而go语言的并发设计，让我们很轻松就可以达成这一目的。示例代码： 1234567891011121314151617181920package mainimport ( &quot;fmt&quot; &quot;time&quot;)func main()&#123; go func()&#123; //加一个go关键字就创建了一个子go程 for i:=0;i&lt;5;i++&#123; fmt.Println(&quot;这里是一个匿名函数go进程&quot;) //打印一次 time.Sleep(time.Second) //延时一秒 &#125; &#125;() for i:=0;i&lt;5;i++&#123; fmt.Println(&quot;main&quot;) time.Sleep(time.Second) //延时一秒 &#125;&#125; 打印结果如下 这就是go的并发，只需要在前面加一个关键字就可以了，在这里子go程和主go程相互夺取cpu，cpu用来分配时间轮转片，轮到谁就执行，在这个程序里面因为都延时了1秒，所以运行一次就会给对方运行 一个程序要想运行，必须要有“进行地址（虚拟地址）空间”， 所有系统都一样 下面我们来看一下虚拟内存的讲解，我们先来看一张图 我们图中是拿了一个512M的物理内存来举例子，电脑假设为32位的电脑，在32位电脑上，我们运行一个程序图中左边都有两个go程序，都会分配4G的空间给程序，分别为代码区，只读数据区，数据区，未初始化数据区，堆区，栈区，内核区，但是我们的物理内存只有512M，那么两个程序占8G，那么够用吗，其实是够的，这是为什么？，这是因为在程序运行是CPU中的MMU会映射一个虚拟内存出来，你可以当作想象吧，我们平时看到的内存条什么的物理内存都会有一个物理地址，但是我们是不能直接拿物理地址来操作程序什么的，我们平时操作的地址都是CPU映射出来的虚拟内存的虚拟地址，图中我们在虚拟内存中声明了两个变量，这样CPU通过MMU来在真实的物理内存上面映射两个物理地址，类似于将物理地址和虚拟地址链接一下，然后等程序运行完毕，直接将虚拟内存释放，这样的话运行程序在32位电脑上虚拟出来的4G都是虚拟出来的。 如果想要了解更多的硬件问题推荐一下《计算机组成原理》这本书可以去了解一下]]></content>
      <categories>
        <category>GO语言</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>内存讲解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络协议]]></title>
    <url>%2F2018%2F09%2F08%2F%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[协议从应用的角度出发，协议可理解为“规则”，是数据传输和数据的解释的规则。假设，A、B双方欲传输文件。规定： 第一次，传输文件名，接收方接收到文件名，应答OK给传输方； 第二次，发送文件的尺寸，接收方接收到该数据再次应答一个OK； 第三次，传输文件内容。同样，接收方接收数据完成后应答OK表示文件内容接收成功。由此，无论A、B之间传递何种文件，都是通过三次数据传输来完成。A、B之间形成了一个最简单的数据传输规则。双方都按此规则发送、接收数据。A、B之间达成的这个相互遵守的规则即为协议。 这种仅在A、B之间被遵守的协议称之为原始协议。当此协议被更多的人采用，不断的增加、改进、维护、完善。最终形成一个稳定的、完整的文件传输协议，被广泛应用于各种文件传输过程中。该协议就成为一个标准协议。最早的ftp协议就是由此衍生而来。 典型协议 传输层 常见协议有TCP/UDP协议。 应用层 常见的协议有HTTP协议，FTP协议。 网络层 常见协议有IP协议、ICMP协议、IGMP协议。 网络接口层 常见协议有ARP协议、RARP协议。 TCP传输控制协议（Transmission Control Protocol）是一种面向连接的、可靠的、基于字节流的传输层通信协议。 UDP用户数据报协议（User Datagram Protocol）是OSI参考模型中一种无连接的传输层协议，提供面向事务的简单不可靠信息传送服务。 HTTP超文本传输协议（Hyper Text Transfer Protocol）是互联网上应用最为广泛的一种网络协议。 FTP文件传输协议（File Transfer Protocol） IP协议是因特网互联协议（Internet Protocol） ICMP协议是Internet控制报文协议（Internet Control Message Protocol）它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。 IGMP协议是 Internet 组管理协议（Internet Group Management Protocol），是因特网协议家族中的一个组播协议。该协议运行在主机和组播路由器之间。 ARP协议是正向地址解析协议（Address Resolution Protocol），通过已知的IP，寻找对应主机的MAC地址。 RARP是反向地址转换协议，通过MAC地址确定IP地址。 分层模型网络分层架构为了减少协议设计的复杂性，大多数网络模型均采用分层的方式来组织。每一层都有自己的功能，就像建筑物一样，每一层都靠下一层支持。每一层利用下一层提供的服务来为上一层提供服务，本层服务的实现细节对上层屏蔽。 越下面的层，越靠近硬件；越上面的层，越靠近用户。至于每一层叫什么名字，对应编程而言不重要，但面试的时候，面试官可能会问每一层的名字。业内普遍的分层方式有两种。OSI七层模型 和TCP/IP四层模型。可以通过背诵两个口诀来快速记忆：OSI七层模型：物、数、网、传、会、表、应TCP/IP四层模型：链、网、传、应 物理层：主要定义物理设备标准，如网线的接口类型、光纤的接口类型、各种传输介质的传输速率等。它的主要作用是传输比特流（就是由1、0转化为电流强弱来进行传输，到达目的地后再转化为1、0，也就是我们常说的数模转换与模数转换）。这一层的数据叫做比特。 数据链路层：定义了如何让格式化数据以帧为单位进行传输，以及如何让控制对物理介质的访问。这一层通常还提供错误检测和纠正，以确保数据的可靠传输。如：串口通信中使用到的115200、8、N、1 网络层：在位于不同地理位置的网络中的两个主机系统之间提供连接和路径选择。Internet的发展使得从世界各站点访问信息的用户数大大增加，而网络层正是管理这种连接的层。 传输层：定义了一些传输数据的协议和端口号（WWW端口80等），如：TCP（传输控制协议，传输效率低，可靠性强，用于传输可靠性要求高，数据量大的数据），UDP（用户数据报协议，与TCP特性恰恰相反，用于传输可靠性要求不高，数据量小的数据，如QQ聊天数据就是通过这种方式传输的）。 主要是将从下层接收的数据进行分段和传输，到达目的地址后再进行重组。常常把这一层数据叫做段。 会话层：通过传输层(端口号：传输端口与接收端口)建立数据传输的通路。主要在你的系统之间发起会话或者接受会话请求（设备之间需要互相认识可以是IP也可以是MAC或者是主机名）。 表示层：可确保一个系统的应用层所发送的信息可以被另一个系统的应用层读取。例如，PC程序与另一台计算机进行通信，其中一台计算机使用扩展二一十进制交换码(EBCDIC)，而另一台则使用美国信息交换标准码（ASCII）来表示相同的字符。如有必要，表示层会通过使用一种通格式来实现多种数据格式之间的转换。 应用层：是最靠近用户的OSI层。这一层为用户的应用程序（例如电子邮件、文件传输和终端仿真）提供网络服务。 层与协议每一层都是为了完成一种功能，为了实现这些功能，就需要大家都遵守共同的规则。大家都遵守这规则，就叫做“协议”（protocol）。网络的每一层，都定义了很多协议。这些协议的总称，叫“TCP/IP协议”。TCP/IP协议是一个大家族，不仅仅只有TCP和IP协议，它还包括其它的协议，如下图： 各层功能 链路层以太网规定，连入网络的所有设备，都必须具有“网卡”接口。数据包必须是从一块网卡，传送到另一块网卡。通过网卡能够使不同的计算机之间连接，从而完成数据通信等功能。网卡的地址——MAC 地址，就是数据包的物理发送地址和物理接收地址。 网络层网络层的作用是引进一套新的地址，使得我们能够区分不同的计算机是否属于同一个子网络。这套地址就叫做“网络地址”，就是我们平时所说的IP地址。这个IP地址好比我们的手机号码，通过手机号码可以得到用户所在的归属地。网络地址帮助我们确定计算机所在的子网络，MAC 地址则将数据包送到该子网络中的目标网卡。网络层协议包含的主要信息是源IP和目的IP。于是，“网络层”出现以后，每台计算机有了两种地址，一种是 MAC 地址，另一种是网络地址。两种地址之间没有任何联系，MAC 地址是绑定在网卡上的，网络地址则是管理员分配的，它们只是随机组合在一起。网络地址帮助我们确定计算机所在的子网络，MAC 地址则将数据包送到该子网络中的目标网卡。因此，从逻辑上可以推断，必定是先处理网络地址，然后再处理 MAC 地址。 传输层当我们一边聊QQ，一边聊微信，当一个数据包从互联网上发来的时候，我们怎么知道，它是来自QQ的内容，还是来自微信的内容？也就是说，我们还需要一个参数，表示这个数据包到底供哪个程序（进程）使用。这个参数就叫做“端口”（port），它其实是每一个使用网卡的程序的编号。每个数据包都发到主机的特定端口，所以不同的程序就能取到自己所需要的数据。端口特点： 对于同一个端口，在不同系统中对应着不同的进程 对于同一个系统，一个端口只能被一个进程拥有 应用层应用程序收到“传输层”的数据，接下来就要进行解读。由于互联网是开放架构，数据来源五花八门，必须事先规定好格式，否则根本无法解读。“应用层”的作用，就是规定应用程序的数据格式。 通信过程两台计算机通过TCP/IP协议通讯的过程如下所示：]]></content>
      <categories>
        <category>网络编程协议</category>
      </categories>
      <tags>
        <tag>通信协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git知识点详解]]></title>
    <url>%2F2018%2F09%2F07%2Fgit%E7%9F%A5%E8%AF%86%E7%82%B9%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Git知识点详解 文件状态现在我们手上已经有了一个真实项目的 Git 仓库，并从这个仓库中取出了所有文件的工作拷贝。接下来，对这些文件作些修改，在完成了一个阶段的目标之后，提交本次更新到仓库。 请记住，工作目录下面的所有文件都不外乎这两种状态：已跟踪或未跟踪。已跟踪的文件是指本来就被纳入版本控制管理的文件，在上次快照中有它们的记 录，工作一段时间后，它们的状态可能是未更新，已修改或者已放入暂存区。而所有其他文件都属于未跟踪文件。它们既没有上次更新时的快照，也不在当前的暂存 区域。初次克隆某个仓库时，工作目录中的所有文件都属于已跟踪文件，且状态为未修改。 在编辑过某些文件之后，Git 将这些文件标为已修改。我们逐步把这些修改过的文件放到暂存区域，直到最后一次性提交所有这些暂存起来的文件，如此重复。如下图： 检查当前文件状态要确定哪些文件当前处于什么状态，可以用 git status 命令。如果在克隆仓库之后立即执行此命令，会看到类似这样的输出： 123$ git status# On branch masternothing to commit (working directory clean) 这说明你现在的工作目录相当干净。换句话说，当前没有任何跟踪着的文件，也没有任何文件在上次提交后更改过。此外，上面的信息还表明，当前目录下没 有出现任何处于未跟踪的新文件，否则 Git 会在这里列出来。最后，该命令还显示了当前所在的分支是 master，这是默认的分支名称，实际是可以修改的，现在先不用考虑。下一章我们就会详细讨论分支和引用。 现在让我们用 vim 编辑一个新文件 README，保存退出后运行 git status 会看到该文件出现在未跟踪文件列表中： 12345678$ vim README$ git status# On branch master# Untracked files:# (use &quot;git add ...&quot; to include in what will be committed)## READMEnothing added to commit but untracked files present (use &quot;git add&quot; to track) 就是在“Untracked files”这行下面。Git 不会自动将之纳入跟踪范围，除非你明明白白地告诉它“我需要跟踪该文件”，因而不用担心把临时文件什么的也归入版本管理。不过现在的例子中，我们确实想要跟踪管理 README 这个文件。 跟踪新文件 使用命令 git add 开始跟踪一个新文件。所以，要跟踪 README 文件，运行： 1$ git add README 此时再运行 git status 命令，会看到 README 文件已被跟踪，并处于暂存状态： 1234567$ git status# On branch master# Changes to be committed:# (use &quot;git reset HEAD ...&quot; to unstage)## new file: README# 只要在 “Changes to be committed” 这行下面的，就说明是已暂存状态。如果此时提交，那么该文件此时此刻的版本将被留存在历史记录中。你可能会想起之前我们使用git init 后就运行了 git add 命令，开始跟踪当前目录下的文件。在 git add 后面可以指明要跟踪的文件或目录路径。如果是目录的话，就说明要递归跟踪该目录下的所有文件。（译注：其实git add 的潜台词就是把目标文件快照放入暂存区域，也就是 add file into staged area，同时未曾跟踪过的文件标记为需要跟踪。这样就好理解后续 add 操作的实际意义了。） 暂存已修改文件 现在我们修改下之前已跟踪过的文件 benchmarks.rb，然后再次运行 status 命令，会看到这样的状态报告： 123456789101112$ git status# On branch master# Changes to be committed:# (use &quot;git reset HEAD ...&quot; to unstage)## new file: README## Changed but not updated:# (use &quot;git add ...&quot; to update what will be committed)## modified: benchmarks.rb# 文件 benchmarks.rb 出现在 “Changed but not updated” 这行下面，说明已跟踪文件的内容发生了变化，但还没有放到暂存区。要暂存这次更新，需要运行git add 命令（这是个多功能命令，根据目标文件的状态不同，此命令的效果也不同：可以用它开始跟踪新文件，或者把已跟踪的文件放到暂存区，还能用于合并时把有冲突的文件标记为已解决状态等）。现在让我们运行git add 将 benchmarks.rb 放到暂存区，然后再看看 git status 的输出： 123456789$ git add benchmarks.rb$ git status# On branch master# Changes to be committed:# (use &quot;git reset HEAD ...&quot; to unstage)## new file: README# modified: benchmarks.rb# 现在两个文件都已暂存，下次提交时就会一并记录到仓库。假设此时，你想要在 benchmarks.rb 里再加条注释，重新编辑存盘后，准备好提交。不过且慢，再运行git status 看看： 1234567891011121314$ vim benchmarks.rb $ git status# On branch master# Changes to be committed:# (use &quot;git reset HEAD ...&quot; to unstage)## new file: README# modified: benchmarks.rb## Changed but not updated:# (use &quot;git add ...&quot; to update what will be committed)## modified: benchmarks.rb# 怎么回事？benchmarks.rb 文件出现了两次！一次算未暂存，一次算已暂存，这怎么可能呢？好吧，实际上 Git 只不过暂存了你运行 git add 命令时的版本，如果现在提交，那么提交的是添加注释前的版本，而非当前工作目录中的版本。所以，运行了git add 之后又作了修订的文件，需要重新运行 git add 把最新版本重新暂存起来： 123456789$ git add benchmarks.rb$ git status# On branch master# Changes to be committed:# (use &quot;git reset HEAD ...&quot; to unstage)## new file: README# modified: benchmarks.rb# 忽略某些文件一般我们总会有些文件无需纳入 Git 的管理，也不希望它们总出现在未跟踪文件列表。通常都是些自动生成的文件，比如日志文件，或者编译过程中创建的临时文件等。我们可以创建一个名为 .gitignore 的文件，列出要忽略的文件模式。来看一个实际的例子： 123$ cat .gitignore*.[oa]*~ 第一行告诉 Git 忽略所有以 .o 或 .a 结尾的文件。一般这类对象文件和存档文件都是编译过程中出现的，我们用不着跟踪它们的版本。第二行告诉 Git 忽略所有以波浪符（~）结尾的文件，许多文本编辑软件（比如 Emacs）都用这样的文件名保存副本。此外，你可能还需要忽略 log，tmp 或者 pid 目录，以及自动生成的文档等等。要养成一开始就设置好 .gitignore 文件的习惯，以免将来误提交这类无用的文件。 文件 .gitignore 的格式规范如下： 所有空行或者以注释符号 ＃ 开头的行都会被 Git 忽略。 可以使用标准的 glob 模式匹配。 匹配模式最后跟反斜杠（/）说明要忽略的是目录。 要忽略指定模式以外的文件或目录，可以在模式前加上惊叹号（!）取反。 所谓的 glob 模式是指 shell 所使用的简化了的正则表达式。星号（*）匹配零个或多个任意字符；[abc] 匹配任何一个列在方括号中的字符（这个例子要么匹配一个 a，要么匹配一个 b，要么匹配一个 c）；问号（?）只匹配一个任意字符；如果在方括号中使用短划线分隔两个字符，表示所有在这两个字符范围内的都可以匹配（比如[0-9] 表示匹配所有 0 到 9 的数字）。 我们再看一个 .gitignore 文件的例子： 123456# 此为注释 – 将被 Git 忽略*.a # 忽略所有 .a 结尾的文件!lib.a # 但 lib.a 除外/TODO # 仅仅忽略项目根目录下的 TODO 文件，不包括 subdir/TODObuild/ # 忽略 build/ 目录下的所有文件doc/*.txt # 会忽略 doc/notes.txt 但不包括 doc/server/arch.txt 查看已暂存和未暂存的更新实际上 git status 的显示比较简单，仅仅是列出了修改过的文件，如果要查看具体修改了什么地方，可以用 git diff 命令。稍后我们会详细介绍git diff，不过现在，它已经能回答我们的两个问题了：当前做的哪些更新还没有暂存？有哪些更新已经暂存起来准备好了下次提交？ git diff 会使用文件补丁的格式显示具体添加和删除的行。 假如再次修改 README 文件后暂存，然后编辑 benchmarks.rb 文件后先别暂存，运行 status命令，会看到： 123456789101112$ git status# On branch master# Changes to be committed:# (use &quot;git reset HEAD ...&quot; to unstage)## new file: README## Changed but not updated:# (use &quot;git add ...&quot; to update what will be committed)## modified: benchmarks.rb# 要查看尚未暂存的文件更新了哪些部分，不加参数直接输入 git diff： 12345678910111213141516$ git diffdiff --git a/benchmarks.rb b/benchmarks.rbindex 3cb747f..da65585 100644--- a/benchmarks.rb+++ b/benchmarks.rb@@ -36,6 +36,10 @@ def main @commit.parents[0].parents[0].parents[0] end+ run_code(x, &apos;commits 1&apos;) do+ git.commits.size+ end+ run_code(x, &apos;commits 2&apos;) do log = git.commits(&apos;master&apos;, 15) log.size 此命令比较的是工作目录中当前文件和暂存区域快照之间的差异，也就是修改之后还没有暂存起来的变化内容。 若要看已经暂存起来的文件和上次提交时的快照之间的差异，可以用 git diff --cached 命令。（Git 1.6.1 及更高版本还允许使用git diff --staged，效果是相同的，但更好记些。）来看看实际的效果： 123456789101112$ git diff --cacheddiff --git a/README b/READMEnew file mode 100644index 0000000..03902a1--- /dev/null+++ b/README2@@ -0,0 +1,5 @@+grit+ by Tom Preston-Werner, Chris Wanstrath+ http://github.com/mojombo/grit++Grit is a Ruby library for extracting information from a Git repository 请注意，单单 git diff 不过是显示还没有暂存起来的改动，而不是这次工作和上次提交之间的差异。所以有时候你一下子暂存了所有更新过的文件后，运行git diff 后却什么也没有，就是这个原因。 像之前说的，暂存 benchmarks.rb 后再编辑，运行 git status 会看到暂存前后的两个版本： 12345678910111213$ git add benchmarks.rb$ echo &apos;# test line&apos; &gt;&gt; benchmarks.rb$ git status# On branch master## Changes to be committed:## modified: benchmarks.rb## Changed but not updated:## modified: benchmarks.rb# 现在运行 git diff 看暂存前后的变化： 12345678910$ git diffdiff --git a/benchmarks.rb b/benchmarks.rbindex e445e28..86b2f7c 100644--- a/benchmarks.rb+++ b/benchmarks.rb@@ -127,3 +127,4 @@ end main() ##pp Grit::GitRuby.cache_client.stats+# test line 然后用 git diff --cached 查看已经暂存起来的变化： 12345678910111213141516$ git diff --cacheddiff --git a/benchmarks.rb b/benchmarks.rbindex 3cb747f..e445e28 100644--- a/benchmarks.rb+++ b/benchmarks.rb@@ -36,6 +36,10 @@ def main @commit.parents[0].parents[0].parents[0] end+ run_code(x, &apos;commits 1&apos;) do+ git.commits.size+ end+ run_code(x, &apos;commits 2&apos;) do log = git.commits(&apos;master&apos;, 15) log.size 提交更新现在的暂存区域已经准备妥当可以提交了。在此之前，请一定要确认还有什么修改过的或新建的文件还没有 git add过，否则提交的时候不会记录这些还没暂存起来的变化。所以，每次准备提交前，先用git status 看下，是不是都已暂存起来了，然后再运行提交命令 git commit： 1$ git commit 这种方式会启动文本编辑器以便输入本次提交的说明。（默认会启用 shell 的环境变量 $EDITOR 所指定的软件，一般都是 vim 或 emacs。当然也可以按照第一章介绍的方式，使用git config --global core.editor 命令设定你喜欢的编辑软件。） 编辑器会显示类似下面的文本信息（本例选用 Vim 的屏显方式展示）： 123456789101112# Please enter the commit message for your changes. Lines starting# with &apos;#&apos; will be ignored, and an empty message aborts the commit.# On branch master# Changes to be committed:# (use &quot;git reset HEAD ...&quot; to unstage)## new file: README# modified: benchmarks.rb~~~&quot;.git/COMMIT_EDITMSG&quot; 10L, 283C 可以看到，默认的提交消息包含最后一次运行 git status 的输出，放在注释行里，另外开头还有一空行，供你输入提交说明。你完全可以去掉这些注释行，不过留着也没关系，多少能帮你回想起这次更新的内容有哪些。（如果觉得这还不够，可以用-v 选项将修改差异的每一行都包含到注释中来。）退出编辑器时，Git 会丢掉注释行，将说明内容和本次更新提交到仓库。 另外也可以用 -m 参数后跟提交说明的方式，在一行命令中提交更新： 1234$ git commit -m &quot;Story 182: Fix benchmarks for speed&quot;[master]: created 463dc4f: &quot;Fix benchmarks for speed&quot; 2 files changed, 3 insertions(+), 0 deletions(-) create mode 100644 README 好，现在你已经创建了第一个提交！可以看到，提交后它会告诉你，当前是在哪个分支（master）提交的，本次提交的完整 SHA-1 校验和是什么（463dc4f），以及在本次提交中，有多少文件修订过，多少行添改和删改过。 记住，提交时记录的是放在暂存区域的快照，任何还未暂存的仍然保持已修改状态，可以在下次提交时纳入版本管理。每一次运行提交操作，都是对你项目作一次快照，以后可以回到这个状态，或者进行比较。 跳过使用暂存区域尽管使用暂存区域的方式可以精心准备要提交的细节，但有时候这么做略显繁琐。Git 提供了一个跳过使用暂存区域的方式，只要在提交的时候，给 git commit 加上-a 选项，Git 就会自动把所有已经跟踪过的文件暂存起来一并提交，从而跳过 git add 步骤： 看到了吗？提交之前不再需要 git add 文件 benchmarks.rb 了。 移除文件要从 Git 中移除某个文件，就必须要从已跟踪文件清单中移除（确切地说，是从暂存区域移除），然后提交。可以用 git rm 命令完成此项工作，并连带从工作目录中删除指定的文件，这样以后就不会出现在未跟踪文件清单中了。 如果只是简单地从工作目录中手工删除文件，运行 git status 12345678910$ git status# On branch master## Changed but not updated:## modified: benchmarks.rb#$ git commit -a -m &apos;added new benchmarks&apos;[master 83e38c7] added new benchmarks 1 files changed, 5 insertions(+), 0 deletions(-) 时就会在 “Changed but not updated” 部分（也就是未暂存清单）看到： 123456789$ rm grit.gemspec$ git status# On branch master## Changed but not updated:# (use &quot;git add/rm ...&quot; to update what will be committed)## deleted: grit.gemspec# 然后再运行 git rm 记录此次移除文件的操作： 12345678910$ git rm grit.gemspecrm &apos;grit.gemspec&apos;$ git status# On branch master## Changes to be committed:# (use &quot;git reset HEAD ...&quot; to unstage)## deleted: grit.gemspec# 最后提交的时候，该文件就不再纳入版本管理了。如果删除之前修改过并且已经放到暂存区域的话，则必须要用强制删除选项 -f（译注：即 force 的首字母），以防误删除文件后丢失修改的内容。 另外一种情况是，我们想把文件从 Git 仓库中删除（亦即从暂存区域移除），但仍然希望保留在当前工作目录中。换句话说，仅是从跟踪清单中删除。比如一些大型日志文件或者一堆.a 编译文件，不小心纳入仓库后，要移除跟踪但不删除文件，以便稍后在 .gitignore 文件中补上，用 --cached 选项即可： 1$ git rm --cached readme.txt 后面可以列出文件或者目录的名字，也可以使用 glob 模式。比方说： 1$ git rm log/\*.log 注意到星号 * 之前的反斜杠 \，因为 Git 有它自己的文件模式扩展匹配方式，所以我们不用 shell 来帮忙展开（译注：实际上不加反斜杠也可以运行，只不过按照 shell 扩展的话，仅仅删除指定目录下的文件而不会递归匹配。上面的例子本来就指定了目录，所以效果等同，但下面的例子就会用递归方式匹配，所以必须加反斜 杠。）。此命令删除所有log/ 目录下扩展名为 .log 的文件。类似的比如： 1$ git rm \*~ 会递归删除当前目录及其子目录中所有 ~ 结尾的文件。 移动文件不像其他的 VCS 系统，Git 并不跟踪文件移动操作。如果在 Git 中重命名了某个文件，仓库中存储的元数据并不会体现出这是一次改名操作。不过 Git 非常聪明，它会推断出究竟发生了什么，至于具体是如何做到的，我们稍后再谈。 既然如此，当你看到 Git 的 mv 命令时一定会困惑不已。要在 Git 中对文件改名，可以这么做： 1$ git mv file_from file_to 它会恰如预期般正常工作。实际上，即便此时查看状态信息，也会明白无误地看到关于重命名操作的说明： 12345678910$ git mv README.txt README$ git status# On branch master# Your branch is ahead of &apos;origin/master&apos; by 1 commit.## Changes to be committed:# (use &quot;git reset HEAD..&quot; to unstage)## renamed: README.txt -&gt; README# 其实，运行 git mv 就相当于运行了下面三条命令： 123$ mv README.txt README$ git rm README.txt$ git add README 如此分开操作，Git 也会意识到这是一次改名，所以不管何种方式都一样。当然，直接用 git mv轻便得多，不过有时候用其他工具批处理改名的话，要记得在提交前删除老的文件名，再添加新的文件名。 查看提交历史 在提交了若干更新之后，又或者克隆了某个项目，想回顾下提交历史，可以使用 git log 命令查看。 接下来的例子会用我专门用于演示的 simplegit 项目，运行下面的命令获取该项目源代码： 1git clone git://github.com/schacon/simplegit-progit.git 然后在此项目中运行 git log，应该会看到下面的输出： 123456789101112131415161718192021222324252627$ git logcommit ca82a6dff817ec66f44342007202690a93763949Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version numbercommit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Sat Mar 15 16:40:33 2008 -0700 removed unnecessary test codecommit a11bef06a3f659402fe7563abf99ad00de2209e6Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Sat Mar 15 10:31:28 2008 -0700 first commit 默认不用任何参数的话，git log 会按提交时间列出所有的更新，最近的更新排在最上面。看到了吗，每次更新都有一个 SHA-1 校验和、作者的名字和电子邮件地址、提交时间，最后缩进一个段落显示提交说明。 git log 有许多选项可以帮助你搜寻感兴趣的提交，接下来我们介绍些最常用的。 我们常用 -p 选项展开显示每次提交的内容差异，用 -2 则仅显示最近的两次更新： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687$ git log -p -2commit ca82a6dff817ec66f44342007202690a93763949Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version numberdiff --git a/Rakefile b/Rakefileindex a874b73..8f94139 100644--- a/Rakefile+++ b/Rakefile@@ -5,7 +5,7 @@ require &apos;rake/gempackagetask&apos; spec = Gem::Specification.new do |s|- s.version = &quot;0.1.0&quot;+ s.version = &quot;0.1.1&quot; s.author = &quot;Scott Chacon&quot;commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Sat Mar 15 16:40:33 2008 -0700 removed unnecessary test codediff --git a/lib/simplegit.rb b/lib/simplegit.rbindex a0a60ae..47c6340 100644--- a/lib/simplegit.rb+++ b/lib/simplegit.rb@@ -18,8 +18,3 @@ class SimpleGit end end--if $0 == __FILE__- git = SimpleGit.new- puts git.show-end\ No newline at end of file在做代码审查，或者要快速浏览其他协作者提交的更新都作了哪些改动时，就可以用这个选项。此外，还有许多摘要选项可以用，比如 --stat，仅显示简要的增改行数统计：$ git log --stat commit ca82a6dff817ec66f44342007202690a93763949Author: Scott Chacon &lt;schacon@gee-mail.com&gt;Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number Rakefile | 2 +- 1 files changed, 1 insertions(+), 1 deletions(-)commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7Author: Scott Chacon &lt;schacon@gee-mail.com&gt;Date: Sat Mar 15 16:40:33 2008 -0700 removed unnecessary test code lib/simplegit.rb | 5 ----- 1 files changed, 0 insertions(+), 5 deletions(-)commit a11bef06a3f659402fe7563abf99ad00de2209e6Author: Scott Chacon &lt;schacon@gee-mail.com&gt;Date: Sat Mar 15 10:31:28 2008 -0700 first commit README | 6 ++++++ Rakefile | 23 +++++++++++++++++++++++ lib/simplegit.rb | 25 +++++++++++++++++++++++++ 3 files changed, 54 insertions(+), 0 deletions(-) 每个提交都列出了修改过的文件，以及其中添加和移除的行数，并在最后列出所有增减行数小计。还有个常用的 --pretty 选项，可以指定使用完全不同于默认格式的方式展示提交历史。比如用oneline 将每个提交放在一行显示，这在提交数很大时非常有用。另外还有 short，full 和fuller 可以用，展示的信息或多或少有些不同，请自己动手实践一下看看效果如何。 但最有意思的是 format，可以定制要显示的记录格式，这样的输出便于后期编程提取分析，像这样： 12345678$ git log --pretty=format:&quot;%h - %an, %ar : %s&quot;$ git log --pretty=onelineca82a6dff817ec66f44342007202690a93763949 changed the version number085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 removed unnecessary test codea11bef06a3f659402fe7563abf99ad00de2209e6 first commitca82a6d - Scott Chacon, 11 months ago : changed the version number085bb3b - Scott Chacon, 11 months ago : removed unnecessary test codea11bef0 - Scott Chacon, 11 months ago : first commit 表 列出了常用的格式占位符写法及其代表的意义。 1 你一定奇怪_作者（author）_和_提交者（committer）_之间究竟有何差别，其实作者指的是实际作出修改的人，提交者指的是最后将此 工作成果提交到仓库的人。所以，当你为某个项目发布补丁，然后某个核心成员将你的补丁并入项目时，你就是作者，而那个核心成员就是提交者。我们会在第五章 再详细介绍两者之间的细微差别。 用 oneline 或 format 时结合 --graph 选项，可以看到开头多出一些 ASCII 字符串表示的简单图形，形象地展示了每个提交所在的分支及其分化衍合情况。在我们之前提到的 Grit 项目仓库中可以看到： 12345678910111213141516171819202122232425262728$ git log --pretty=format:&quot;%h %s&quot; --graph* 2d3acf9 ignore errors from SIGCHLD on trap* 5e3ee11 Merge branch &apos;master&apos; of git://github.com/dustin/grit|\| * 420eac9 Added a method for getting the current branch.* | 30e367c timeout code and tests* | 5a09431 add timeout protection to grit* | e1193f8 support for heads with slashes in them|/* d6016bc require time for xmlschema* 11d191e Merge b选项 说明%H 提交对象（commit）的完整哈希字串%h 提交对象的简短哈希字串%T 树对象（tree）的完整哈希字串%t 树对象的简短哈希字串%P 父对象（parent）的完整哈希字串%p 父对象的简短哈希字串%an 作者（author）的名字%ae 作者的电子邮件地址%ad 作者修订日期（可以用 -date= 选项定制格式）%ar 作者修订日期，按多久以前的方式显示%cn 提交者(committer)的名字%ce 提交者的电子邮件地址%cd 提交日期%cr 提交日期，按多久以前的方式显示%s 提交说明ranch &apos;defunkt&apos; into local 以上只是简单介绍了一些 git log 命令支持的选项。表 2-2 还列出了一些其他常用的选项及其释义。 123456789-p 按补丁格式显示每个更新之间的差异。--stat 显示每次更新的文件修改统计信息。--shortstat 只显示 --stat 中最后的行数修改添加移除统计。--name-only 仅在提交信息后显示已修改的文件清单。--name-status 显示新增、修改、删除的文件清单。--abbrev-commit 仅显示 SHA-1 的前几个字符，而非所有的 40 个字符。--relative-date 使用较短的相对时间显示（比如，“2 weeks ago”）。--graph 显示 ASCII 图形表示的分支合并历史。--pretty 使用其他格式显示历史提交信息。可用的选项包括 oneline，short，full，fuller 和 format（后跟指定格式） 限制输出长度除了定制输出格式的选项之外，git log 还有许多非常实用的限制输出长度的选项，也就是只输出部分提交信息。之前我们已经看到过 -2 了，它只显示最近的两条提交，实际上，这是 -选项的写法，其中的 n 可以是任何自然数，表示仅显示最近的若干条提交。不过实践中我们是不太用这个选项的，Git 在输出所有提交时会自动调用分页程序（less），要看更早的更新只需翻到下页即可。 另外还有按照时间作限制的选项，比如 --since 和 --until。下面的命令列出所有最近两周内的提交： 1$ git log --since=2.weeks 你可以给出各种时间格式，比如说具体的某一天（“2008-01-15”），或者是多久以前（“2 years 1 day 3 minutes ago”）。 还可以给出若干搜索条件，列出符合的提交。用 --author 选项显示指定作者的提交，用 --grep选项搜索提交说明中的关键字。（请注意，如果要得到同时满足这两个选项搜索条件的提交，就必须用--all-match 选项。） 如果只关心某些文件或者目录的历史提交，可以在 git log 选项的最后指定它们的路径。因为是放在最后位置上的选项，所以用两个短划线（--）隔开之前的选项和后面限定的路径名。 表 2-3 还列出了其他常用的类似选项。 123456选项 说明-(n) 仅显示最近的 n 条提交--since, --after 仅显示指定时间之后的提交。--until, --before 仅显示指定时间之前的提交。--author 仅显示指定作者相关的提交。--committer 仅显示指定提交者相关的提交。 来看一个实际的例子，如果要查看 Git 仓库中，2008 年 10 月期间，Junio Hamano 提交的但未合并的测试脚本（位于项目的 t/ 目录下的文件），可以用下面的查询命令： 12345678$ git log --pretty=&quot;%h - %s&quot; --author=gitster --since=&quot;2008-10-01&quot; \ --before=&quot;2008-11-01&quot; --no-merges -- t/5610e3b - Fix testcase failure when extended attributeacd3b9e - Enhance hold_lock_file_for_&#123;update,append&#125;()f563754 - demonstrate breakage of detached checkout wid1a43f2 - reset --hard/read-tree --reset -u: remove un51a94af - Fix &quot;checkout --track -b newbranch&quot; on detacb0ad11e - pull: allow &quot;git pull origin $something:$cur Git 项目有 20,000 多条提交，但我们给出搜索选项后，仅列出了其中满足条件的 6 条。 使用图形化工具查阅提交历史有时候图形化工具更容易展示历史提交的变化，随 Git 一同发布的 gitk 就是这样一种工具。它是用 Tcl/Tk 写成的，基本上相当于 git log 命令的可视化版本，凡是git log 可以用的选项也都能用在 gitk 上。在项目工作目录中输入 gitk 命令后，就会启动 上半个窗口显示的是历次提交的分支祖先图谱，下半个窗口显示当前点选的提交对应的具体差异。 撤销操作任何时候，你都有可能需要撤消刚才所做的某些操作。接下来，我们会介绍一些基本的撤消操作相关的命令。请注意，有些操作并不总是可以撤消的，所以请务必谨慎小心，一旦失误，就有可能丢失部分工作成果。 修改最后一次提交有时候我们提交完了才发现漏掉了几个文件没有加，或者提交信息写错了。想要撤消刚才的提交操作，可以使用 --amend 选项重新提交： 1$ git commit --amend 此命令将使用当前的暂存区域快照提交。如果刚才提交完没有作任何改动，直接运行此命令的话，相当于有机会重新编辑提交说明，但将要提交的文件快照和之前的一样。 启动文本编辑器后，会看到上次提交时的说明，编辑它确认没问题后保存退出，就会使用新的提交说明覆盖刚才失误的提交。 如果刚才提交时忘了暂存某些修改，可以先补上暂存操作，然后再运行 --amend 提交： 123$ git commit -m &apos;initial commit&apos;$ git add forgotten_file$ git commit --amend 上面的三条命令最终只是产生一个提交，第二个提交命令修正了第一个的提交内容。 取消已经暂存的文件接下来的两个小节将演示如何取消暂存区域中的文件，以及如何取消工作目录中已修改的文件。不用担心，查看文件状态的时候就提示了该如何撤消，所以不需要死记硬背。来看下面的例子，有两个修改过的文件，我们想要分开提交，但不小心用git add . 全加到了暂存区域。该如何撤消暂存其中的一个文件呢？其实，git status 的命令输出已经告诉了我们该怎么做： 123456789$ git add .$ git status# On branch master# Changes to be committed:# (use &quot;git reset HEAD ...&quot; to unstage)## modified: README.txt# modified: benchmarks.rb# 就在 “Changes to be committed” 下面，括号中有提示，可以使用 git reset HEAD ...的方式取消暂存。好吧，我们来试试取消暂存 benchmarks.rb 文件： 123456789101112131415$ git reset HEAD benchmarks.rbbenchmarks.rb: locally modified$ git status# On branch master# Changes to be committed:# (use &quot;git reset HEAD ...&quot; to unstage)## modified: README.txt## Changed but not updated:# (use &quot;git add ...&quot; to update what will be committed)# (use &quot;git checkout -- ...&quot; to discard changes in working directory)## modified: benchmarks.rb# 这条命令看起来有些古怪，先别管，能用就行。现在 benchmarks.rb 文件又回到了之前已修改未暂存的状态。 取消对文件的修改如果觉得刚才对 benchmarks.rb 的修改完全没有必要，该如何取消修改，回到之前的状态（也就是修改之前的版本）呢？git status 同样提示了具体的撤消方法，接着上面的例子，现在未暂存区域看起来像这样： 123456# Changed but not updated:# (use &quot;git add ...&quot; to update what will be committed)# (use &quot;git checkout -- ...&quot; to discard changes in working directory)## modified: benchmarks.rb# 在第二个括号中，我们看到了抛弃文件修改的命令（至少在 Git 1.6.1 以及更高版本中会这样提示，如果你还在用老版本，我们强烈建议你升级，以获取最佳的用户体验），让我们试试看： 12345678$ git checkout -- benchmarks.rb$ git status# On branch master# Changes to be committed:# (use &quot;git reset HEAD ...&quot; to unstage)## modified: README.txt# 可以看到，该文件已经恢复到修改前的版本。你可能已经意识到了，这条命令有些危险，所有对文件的修改都没有了，因为我们刚刚把之前版本的文件复制过 来重写了此文件。所以在用这条命令前，请务必确定真的不再需要保留刚才的修改。如果只是想回退版本，同时保留刚才的修改以便将来继续工作，可以用下章介绍 的 stashing 和分支来处理，应该会更好些。 记住，任何已经提交到 Git 的都可以被恢复。即便在已经删除的分支中的提交，或者用 --amend重新改写的提交，都可以被恢复（关于数据恢复的内容见第九章）。所以，你可能失去的数据，仅限于没有提交过的，对 Git 来说它们就像从未存在过一样。 远程仓库的使用 要参与任何一个 Git 项目的协作，必须要了解该如何管理远程仓库。远程仓库是指托管在网络上的项目仓库，可能会有好多个，其中有些你只能读，另外有些可以写。同他人协作开发某 个项目时，需要管理这些远程仓库，以便推送或拉取数据，分享各自的工作进展。管理远程仓库的工作，包括添加远程库，移除废弃的远程库，管理各式远程库分 支，定义是否跟踪这些分支，等等。本节我们将详细讨论远程库的管理和使用。 查看当前的远程库 要查看当前配置有哪些远程仓库，可以用 git remote 命令，它会列出每个远程库的简短名字。在克隆完某个项目后，至少可以看到一个名为 origin 的远程库，Git 默认使用这个名字来标识你所克隆的原始仓库： 12345678910$ git clone git://github.com/schacon/ticgit.gitInitialized empty Git repository in /private/tmp/ticgit/.git/remote: Counting objects: 595, done.remote: Compressing objects: 100% (269/269), done.remote: Total 595 (delta 255), reused 589 (delta 253)Receiving objects: 100% (595/595), 73.31 KiB | 1 KiB/s, done.Resolving deltas: 100% (255/255), done.$ cd ticgit$ git remoteorigin 也可以加上 -v 选项（译注：此为 --verbose 的简写，取首字母），显示对应的克隆地址： 12$ git remote -vorigin git://github.com/schacon/ticgit.git 如果有多个远程仓库，此命令将全部列出。比如在我的 Grit 项目中，可以看到： 1234567$ cd grit$ git remote -vbakkdoor git://github.com/bakkdoor/grit.gitcho45 git://github.com/cho45/grit.gitdefunkt git://github.com/defunkt/grit.gitkoke git://github.com/koke/grit.gitorigin git@github.com:mojombo/grit.git 这样一来，我就可以非常轻松地从这些用户的仓库中，拉取他们的提交到本地。请注意，上面列出的地址只有 origin 用的是 SSH URL 链接，所以也只有这个仓库我能推送数据上去（我们会在第四章解释原因）。 添加远程仓库 要添加一个新的远程仓库，可以指定一个简单的名字，以便将来引用，运行 git remote add [shortname] [url]： 123456$ git remoteorigin$ git remote add pb git://github.com/paulboone/ticgit.git$ git remote -vorigin git://github.com/schacon/ticgit.gitpb git://github.com/paulboone/ticgit.git 现在可以用字串 pb 指代对应的仓库地址了。比如说，要抓取所有 Paul 有的，但本地仓库没有的信息，可以运行 git fetch pb： 12345678$ git fetch pbremote: Counting objects: 58, done.remote: Compressing objects: 100% (41/41), done.remote: Total 44 (delta 24), reused 1 (delta 0)Unpacking objects: 100% (44/44), done.From git://github.com/paulboone/ticgit * [new branch] master -&gt; pb/master * [new branch] ticgit -&gt; pb/ticgit 现在，Paul 的主干分支（master）已经完全可以在本地访问了，对应的名字是 pb/master，你可以将它合并到自己的某个分支，或者切换到这个分支，看看有些什么有趣的更新。 从远程仓库抓取数据正如之前所看到的，可以用下面的命令从远程仓库抓取数据到本地： 1$ git fetch [remote-name] 此命令会到远程仓库中拉取所有你本地仓库中还没有的数据。运行完成后，你就可以在本地访问该远程仓库中的所有分支，将其中某个分支合并到本地，或者只是取出某个分支，一探究竟。（我们会在第三章详细讨论关于分支的概念和操作。） 如果是克隆了一个仓库，此命令会自动将远程仓库归于 origin 名下。所以，git fetch origin 会抓取从你上次克隆以来别人上传到此远程仓库中的所有更新（或是上次 fetch 以来别人提交的更新）。有一点很重要，需要记住，fetch 命令只是将远端的数据拉到本地仓库，并不自动合并到当前工作分支，只有当你确实准备好了，才能手工合并。 如果设置了某个分支用于跟踪某个远端仓库的分支（参见下节及第三章的内容），可以使用 git pull 命令自动抓取数据下来，然后将远端分支自动合并到本地仓库中当前分支。在日常工作中我们经常这么用，既快且好。实际上，默认情况下git clone 命令本质上就是自动创建了本地的 master 分支用于跟踪远程仓库中的 master 分支（假设远程仓库确实有 master 分支）。所以一般我们运行git pull，目的都是要从原始克隆的远端仓库中抓取数据后，合并到工作目录中的当前分支。 推送数据到远程仓库项目进行到一个阶段，要同别人分享目前的成果，可以将本地仓库中的数据推送到远程仓库。实现这个任务的命令很简单： git push [remote-name] [branch-name]。如果要把本地的 master 分支推送到origin 服务器上（再次说明下，克隆操作会自动使用默认的 master 和 origin 名字），可以运行下面的命令： 1$ git push origin master 只有在所克隆的服务器上有写权限，或者同一时刻没有其他人在推数据，这条命令才会如期完成任务。如果在你推数据前，已经有其他人推送了若干更新，那 你的推送操作就会被驳回。你必须先把他们的更新抓取到本地，合并到自己的项目中，然后才可以再次推送。有关推送数据到远程仓库的详细内容见第三章。 查看远程仓库信息我们可以通过命令 git remote show [remote-name] 查看某个远程仓库的详细信息，比如要看所克隆的 origin 仓库，可以运行： 12345678$ git remote show origin* remote origin URL: git://github.com/schacon/ticgit.git Remote branch merged with &apos;git pull&apos; while on branch master master Tracked remote branches master ticgit 除了对应的克隆地址外，它还给出了许多额外的信息。它友善地告诉你如果是在 master 分支，就可以用 git pull 命令抓取数据合并到本地。另外还列出了所有处于跟踪状态中的远端分支。 上面的例子非常简单，而随着使用 Git 的深入，git remote show 给出的信息可能会像这样： 123456789101112131415161718192021$ git remote show origin* remote origin URL: git@github.com:defunkt/github.git Remote branch merged with &apos;git pull&apos; while on branch issues issues Remote branch merged with &apos;git pull&apos; while on branch master master New remote branches (next fetch will store in remotes/origin) caching Stale tracking branches (use &apos;git remote prune&apos;) libwalker walker2 Tracked remote branches acl apiv2 dashboard2 issues master postgres Local branch pushed with &apos;git push&apos; master:master 它告诉我们，运行 git push 时缺省推送的分支是什么（译注：最后两行）。它还显示了有哪些远端分支还没有同步到本地（译注：第六行的caching 分支），哪些已同步到本地的远端分支在远端服务器上已被删除（译注：Stale tracking branches 下面的两个分支），以及运行git pull 时将自动合并哪些分支（译注：前四行中列出的 issues 和 master 分支）。 远程仓库的删除和重命名在新版 Git 中可以用 git remote rename 命令修改某个远程仓库在本地的简短名称，比如想把 pb改成paul，可以这么运行： 1234$ git remote rename pb paul$ git remoteoriginpaul 注意，对远程仓库的重命名，也会使对应的分支名称发生变化，原来的 pb/master 分支现在成了 paul/master。 碰到远端仓库服务器迁移，或者原来的克隆镜像不再使用，又或者某个参与者不再贡献代码，那么需要移除对应的远端仓库，可以运行 git remote rm 命令： 123$ git remote rm paul$ git remoteorigin 打标签同大多数 VCS 一样，Git 也可以对某一时间点上的版本打上标签。人们在发布某个软件版本（比如 v1.0 等等）的时候，经常这么做。本节我们一起来学习如何列出所有可用的标签，如何新建标签，以及各种不同类型标签之间的差别。 列出已有的标签 列出现有标签的命令非常简单，直接运行 git tag 即可： 123$ git tagv0.1v1.3 显示的标签按字母顺序排列，所以标签的先后并不表示重要程度的轻重。 我们可以用特定的搜索模式列出符合条件的标签。在 Git 自身项目仓库中，有着超过 240 个标签，如果你只对 1.4.2 系列的版本感兴趣，可以运行下面的命令： 12345$ git tag -l &apos;v1.4.2.*&apos;v1.4.2.1v1.4.2.2v1.4.2.3v1.4.2.4 新建标签 Git 使用的标签有两种类型：轻量级的（lightweight）和含附注的（annotated）。轻量级标签就像是个不会变化的分支，实际上它就是个指向特 定提交对象的引用。而含附注标签，实际上是存储在仓库中的一个独立对象，它有自身的校验和信息，包含着标签的名字，电子邮件地址和日期，以及标签说明，标 签本身也允许使用 GNU Privacy Guard (GPG) 来签署或验证。一般我们都建议使用含附注型的标签，以便保留相关信息；当然，如果只是临时性加注标签，或者不需要旁注额外信息，用轻量级标签也没问题。 含附注的标签创建一个含附注类型的标签非常简单，用 -a （译注：取 annotated 的首字母）指定标签名字即可： 12345$ git tag -a v1.4 -m &apos;my version 1.4&apos;$ git tagv0.1v1.3v1.4 而 -m 选项则指定了对应的标签说明，Git 会将此说明一同保存在标签对象中。如果没有给出该选项，Git 会启动文本编辑软件供你输入标签说明。 可以使用 git show 命令查看相应标签的版本信息，并连同显示打标签时的提交对象。 12345678910111213$ git show v1.4tag v1.4Tagger: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Mon Feb 9 14:45:11 2009 -0800my version 1.4commit 15027957951b64cf874c3557a0f3547bd83b3ff6Merge: 4a447f7... a6b4c97...Author: Scott Chacon &lt;schacon@gee-mail.com&gt;Date: Sun Feb 8 19:02:46 2009 -0800 Merge branch &apos;experiment&apos; 我们可以看到在提交对象信息上面，列出了此标签的提交者和提交时间，以及相应的标签说明。 轻量级标签轻量级标签实际上就是一个保存着对应提交对象的校验和信息的文件。要创建这样的标签，一个 -a，-s 或 -m 选项都不用，直接给出标签名字即可： 1234567$ git tag v1.4-lw$ git tagv0.1v1.3v1.4v1.4-lwv1.5 现在运行 git show 查看此标签信息，就只有相应的提交对象摘要： 12345678910$ git show v1.4-lwcommit 15027957951b64cf874c3557a0f3547bd83b3ff6Merge: 4a447f7... a6b4c97...Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Sun Feb 8 19:02:46 2009 -0800 Merge branch &apos;experiment&apos; 验证标签可以使用 git tag -v [tag-name] （译注：取 verify 的首字母）的方式验证已经签署的标签。此命令会调用 GPG 来验证签名，所以你需要有签署者的公钥，存放在 keyring 中，才能验证： 123456789$ git tag -v v1.4.2.1object 883653babd8ee7ea23e6a5c392bb739348b1eb61type committag v1.4.2.1tagger Junio C Hamano &lt;junkio@cox.net&gt; 1158138501 -0700 GIT 1.4.2.1Minor fixes since 1.4.2, including git-mv and git-http with alternates.gpg: Signature made Wed Sep 13 02:08:25 2006 PDT using DSA key ID F3119B9Agpg: Good signature from &quot;Junio C Hamano &lt;junkio@cox.net&gt;&quot;gpg: aka &quot;[jpeg image of size 1513]&quot;Primary key fingerprint: 3565 2A26 2040 E066 C9A7 4A7D C0C6 D9A4 F311 9B9A 分享标签默认情况下，git push 并不会把标签传送到远端服务器上，只有通过显式命令才能分享标签到远端仓库。其命令格式如同推送分支，运行git push origin [tagname] 即可： 1234567$ git push origin v1.5Counting objects: 50, done.Compressing objects: 100% (38/38), done.Writing objects: 100% (44/44), 4.56 KiB, done.Total 44 (delta 18), reused 8 (delta 1)To git@github.com:schacon/simplegit.git* [new tag] v1.5 -&gt; v1.5 如果要一次推送所有本地新增的标签上去，可以使用 --tags 选项： 1234567891011$ git push origin --tagsCounting objects: 50, done.Compressing objects: 100% (38/38), done.Writing objects: 100% (44/44), 4.56 KiB, done.Total 44 (delta 18), reused 8 (delta 1)To git@github.com:schacon/simplegit.git * [new tag] v0.1 -&gt; v0.1 * [new tag] v1.2 -&gt; v1.2 * [new tag] v1.4 -&gt; v1.4 * [new tag] v1.4-lw -&gt; v1.4-lw * [new tag] v1.5 -&gt; v1.5 现在，其他人克隆共享仓库或拉取数据同步后，也会看到这些标签。 技巧和窍门在结束本章之前，我还想和大家分享一些 Git 使用的技巧和窍门。很多使用 Git 的开发者可能根本就没用过这些技巧，我们也不是说在读过本书后非得用这些技巧不可，但至少应该有所了解吧。说实话，有了这些小窍门，我们的工作可以变得更简单，更轻松，更高效。 自动补全如果你用的是 Bash shell，可以试试看 Git 提供的自动完成脚本。下载 Git 的源代码，进入 contrib/completion 目录，会看到一个git-completion.bash 文件。将此文件复制到你自己的用户主目录中（译注：按照下面的示例，还应改名加上点：cp git-completion.bash ~/.git-completion.bash），并把下面一行内容添加到你的.bashrc文件中： 1source ~/.git-completion.bash 也可以为系统上所有用户都设置默认使用此脚本。Mac 上将此脚本复制到 /opt/local/etc/bash_completion.d 目录中，Linux 上则复制到/etc/bash_completion.d/ 目录中。这两处目录中的脚本，都会在 Bash 启动时自动加载。 如果在 Windows 上安装了 msysGit，默认使用的 Git Bash 就已经配好了这个自动完成脚本，可以直接使用。 在输入 Git 命令的时候可以敲两次跳格键（Tab），就会看到列出所有匹配的可用命令建议： 12$ git co commit config 此例中，键入 git co 然后连按两次 Tab 键，会看到两个相关的建议（命令） commit 和 config。继而输入 m会自动完成git commit 命令的输入。 命令的选项也可以用这种方式自动完成，其实这种情况更实用些。比如运行 git log 的时候忘了相关选项的名字，可以输入开头的几个字母，然后敲 Tab 键看看有哪些匹配的： 123$ git log --s --shortstat --since= --src-prefix= --stat --summary 这个技巧不错吧，可以节省很多输入和查阅文档的时间。 Git命令别名Git 并不会推断你输入的几个字符将会是哪条命令，不过如果想偷懒，少敲几个命令的字符，可以用 git config 为命令设置别名。来看看下面的例子： 1234$ git config --global alias.co checkout$ git config --global alias.br branch$ git config --global alias.ci commit$ git config --global alias.st status 现在，如果要输入 git commit 只需键入 git ci 即可。而随着 Git 使用的深入，会有很多经常要用到的命令，遇到这种情况，不妨建个别名提高效率。 使用这种技术还可以创造出新的命令，比方说取消暂存文件时的输入比较繁琐，可以自己设置一下： 1$ git config --global alias.unstage &apos;reset HEAD --&apos; 这样一来，下面的两条命令完全等同： 12$ git unstage fileA$ git reset HEAD fileA 显然，使用别名的方式看起来更清楚。另外，我们还经常设置 last 命令： 1$ git config --global alias.last &apos;log -1 HEAD&apos; 然后要看最后一次的提交信息，就变得简单多了： 1234$ git lastcommit 66938dae3329c7aebe598c2246a8e6af90d04646Author: Josh Goebel &lt;dreamer3@example.com&gt;Date: Tue Aug 26 19:48:51 2008 +0800 可以看出，实际上 Git 只是简单地在命令中替换了你设置的别名。不过有时候我们希望运行某个外部命令，而非 Git 的附属工具，这个好办，只需要在命令前加上 ! 就行。如果你自己写了些处理 Git 仓库信息的脚本的话，就可以用这种技术包装起来。作为演示，我们可以设置用 git visual启动gitk： 1$ git config --global alias.visual &quot;!gitk&quot; 到目前为止，你已经学会了最基本的 Git 操作：创建和克隆仓库，做出更新，暂存并提交这些更新，以及查看所有历史更新记录。接下来，我们将学习 Git 的必杀技特性：分支模型。 转载链接Git细节拾遗]]></content>
      <categories>
        <category>git使用及讲解</category>
      </categories>
      <tags>
        <tag>git工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git的基础使用]]></title>
    <url>%2F2018%2F09%2F07%2Fgit%E5%92%8Csvn%E7%9A%84%E8%AF%A6%E7%BB%86%E5%AF%B9%E6%AF%94%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[Git是一个分布式的版本控制工具，本篇文章从介绍Git开始，重点在于介绍Git的基本命令和使用技巧，让你尝试使用Git的同时，体验到原来一个版 本控制工具可以对开发产生如此之多的影响，文章分为两部分，第一部分介绍Git的一些常用命令，其中穿插介绍Git的基本概念和原理，第二篇重点介绍 Git的使用技巧，最后会在Git Hub上创建一个开源项目开启你的Git实战之旅。 Git是什么Git在Wikipedia上的定义：它是一个免费的、分布式的版本控制工具，或是一个强调了速度快的源代码管理工具。Git最初被Linus Torvalds开发出来用于管理Linux内核的开发。每一个Git的工作目录都是一个完全独立的代码库，并拥有完整的历史记录和版本追踪能力，不依赖 于网络和中心服务器。 Git的出现减轻了许多开发者和开源项目对于管理分支代码的压力，由于对分支的良好控制，更鼓励开发者对自己感兴趣的项目做出贡献。其实许多开源项目 包括Linux kernel, Samba, X.org Server, Ruby on Rails，都已经过渡到使用Git作为自己的版本控制工具。对于我们这些喜欢写代码的开发者嘛，有两点最大的好处，我们可以在任何地点(在上班的地铁 上)提交自己的代码和查看代码版本;我们可以开许许多多个分支来实践我们的想法，而合并这些分支的开销几乎可以忽略不计。 Git 初始化 现在进入本篇文章真正的主题，介绍一下Git的基本命令和操作，会从Git的版本库的初始化，基本操作和独有的常用命令三部分着手，让大家能够开始使用Git。 Git通常有两种方式来进行初始化: git clone: 这是较为简单的一种初始化方式，当你已经有一个远程的Git版本库，只需要在本地克隆一份，例如’git clone git://github.com/someone/some_project.git some_project’命令就是将’git://github.com/someone/some_project.git’这个URL地址的远程版 本库完全克隆到本地some_project目录下面 git init和git remote：这种方式稍微复杂一些，当你本地创建了一个工作目录，你可以进入这个目录，使用 git init 命令进行初始化，Git以后就会对该目录下的文件进行版本控制，这时候如果你需要将它放到远程服务器上，可以在远程服务器上创建一个目录，并把 可访问的URL记录下来，此时你就可以利用 git remote add 命令来增加一个远程服务器端，例如’git remote add origin git://github.com/someone/another_project.git’这条命令就会增加URL地址为’git: //github.com/someone/another_project.git’，名称为origin的远程服务器，以后提交代码的时候只需要使用 origin别名即可 Git 基本命令 现在我们有了本地和远程的版本库，让我们来试着用用Git的基本命令吧： git pull：从版本库(既可以是远程的也可以是本地的)将代码更新到本地，例如：’git pull origin master’就是将origin这个版本库的代码更新到本地的master主枝，该功能类似于SVN的update git add：将所有改动的文件（新增和有变动的）放在暂存区，由git进行管理 git rm：从当前的工作空间中和索引中删除文件，例如’git rm app/model/user.rb’，移除暂存区 git commit：提交当前工作空间的修改内容，类似于SVN的commit命令，例如’git commit -m “story #3, add user model”‘，提交的时候必须用-m来输入一条提交信息 git push：将本地commit的代码更新到远程版本库中，例如’git push origin branchname’就会将本地的代码更新到名为orgin的远程版本库中 git log：查看历史日志 git revert：还原一个版本的修改，必须提供一个具体的Git版本号，例如’git revert bbaf6fb5060b4875b18ff9ff637ce118256d6f20’，Git的版本号都是生成的一个哈希值、 上面的命令几乎都是每个版本控制工具所公有的，下面就开始尝试一下Git独有的一些命令： Git 独有命令 git branch：对分支的增、删、查等操作，例如 git branch new_branch 会从当前的工作版本创建一个叫做new_branch的新分支，git branch -D new_branch 就会强制删除叫做new_branch的分支，git branch 就会列出本地所有的分支 git checkout：Git的checkout有两个作用，其一是在 不同的branch之间进行切换，例如 ‘git checkout new_branch’就会切换到new_branch的分支上去;另一个功能是 还原代码的作用，例如git checkout app/model/user.rb 就会将user.rb文件从上一个已提交的版本中更新回来，未提交的内容全部会回滚 git rebase：用下面两幅图解释会比较清楚一些，rebase命令执行后，实际上是将分支点从C移到了G，这样分支也就具有了从C到G的功能 （使历史更加简洁明了） git reset：回滚到指定的版本号，我们有A-G提交的版本，其中C 的版本号是 bbaf6fb，我们执行了’git reset bbaf6fb’那么结果就只剩下了A-C三个提交的版本 git stash：将当前未提交的工作存入Git工作栈中，时机成熟的时候再应用回来，这里暂时提一下这个命令的用法，后面在技巧篇会重点讲解 git config：新增、更改Git的各种设置，例如：git config branch.master.remote origin 就将master的远程版本库设置为别名叫做origin版本库 git tag：将某个版本打上一个标签，例如：git tag revert_version bbaf6fb50 来标记这个被你还原的版本，那么以后你想查看该版本时，就可以使用 revert_version标签名，而不是哈希值了 Git其他命令add #添加文件内容至索引 branch #列出、创建或删除分支 checkout #检出一个分支或路径到工作区 clone #克隆一个版本库到一个新目录 commit #最近一次的提交，–amend修改最近一次提交说明 diff #显示提交之间、提交和工作区之间等的差异 fetch #从另外一个版本库下载对象和引用 init #创建一个空的 Git 版本库或重新初始化一个已存在的版本库 log #显示提交日志 –stat 具体文件的改动 reflog #记录丢失的历史 merge #合并两个或更多开发历史，–squash 把分支所有提交合并成一个提交 mv #移动或重命名一个文件、目录或符号链接 pull #获取并合并另外的版本库或一个本地分支（相当于git fetch和git merge） push #更新远程引用和相关的对象 rebase #本地提交转移至更新后的上游分支中 reset #重置当前HEAD到指定状态 rm #从工作区和索引中删除文件 show #显示各种类型的对象 status #显示工作区状态 tag #创建、列出、删除或校验一个GPG签名的 tag 对象 cherry-pick #从其他分支复制指定的提交，然后导入到现在的分支 git分支命令创建分支： git branch linux #创建分支 git checkout linux #切换分支 git branch #查看当前分支情况,当前分支前有*号 git add readme.txt #提交到暂存区 git commit -m “new branch” #提交到git版本仓库 git checkout master #我们在提交文件后再切回master分支 分支合并：（合并前必须保证在master主干上） git branch #查看在哪个位置 git merge Linux #合并创建的Linux分支（–no–ff默认情况下，Git执行”快进式合并”（fast-farward merge），会直接将Master分支指向Develop分支。使用–no–ff参数后，会执行正常合并，在Master分支上生成一个新节点。） git branch -d linux #确认合并后删除分支 如果有冲突： git merge linux #合并Linux分支(冲突) Auto-merging readme.txt CONFLICT (content): Merge conflict in readme.txt Automatic merge failed; fix conflicts and then commit the result. 那么此时，我们在master与linux分支上都分别对中readme文件进行了修改并提交了，那这种情况下Git就没法再为我们自动的快速合并了，它只能告诉我们readme文件的内容有冲突，需要手工处理冲突的内容后才能继续合并 自己修改完readme.txt文件后再次提交 git全局配置1234567891011yum install git #安装Gitgit config –global user.name “xubusi” #配置git使用用户git config –global user.email “xubusi@mail.com” #配置git使用邮箱git config –global color.ui true #加颜色 git config –list #所有配置的信息（上面的结果）user.name=xubusiuser.email=xubusi@mail.comcolor.ui=true .git目录结构Git之所以能够提供方便的本地分支等特性，是与它的文件存储机制有关的。Git存储版本控制信息时使用它自己定义的一套文件系统存储机制，在代码根目录下有一个.git文件夹，会有如下这样的目录结构： 123456789HEADbranches/configdescriptionhooks/indexinfo/objects/refs/ 有几个比较重要的文件和目录需要解释一下： HEAD：文件存放根节点的信息，其实目录结构就表示一个树型结构，Git采用这种树形结构来存储版本信息， 那么HEAD就表示根; refs：目录存储了你在当前版本控制目录下的各种不同引用(引用指的是你本地和远程所用到的各个树分支的信息)，它有heads、 remotes、stash、tags四个子目录，分别存储对不同的根、远程版本库、Git栈和标签的四种引用，你可以通过命令’git show-ref’更清晰地查看引用信息; logs：目录根据不同的引用存储了日志信息。因此，Git只需要代码根目录下的这一个.git目录就可以记录完 整的版本控制信息，而不是像SVN那样根目录和子目录下都有.svn目录。那么下面就来看一下Git与SVN的区别吧 .gitigmore: 放一些不需要git管理的文件（例：IDE的工作目录 .idea，） git与svn的不同VN(Subversion)是当前使用最多的版本控制工具。与它相比较，Git最大的优势在于两点：易于本地增加分支和分布式的特性。 下面两幅图可以形象的展示Git与SVN的不同之处 GIT对于易于本地增加分支，图中Git本地和服务器端结构都很灵活，所有版本都存储在一个目录中，你只需要进行分支的切换即可达到在某个分支工作的效果。 SVN则完全不同，如果你需要在本地试验一些自己的代码，只能本地维护多个不同的拷贝，每个拷贝对应一个SVN服务器地址。 分布式对于Git而言，你可以本地提交代码，所以在上面的图中，Git有利于将一个大任务分解，进行本地的多次提交，而SVN只能在本地进行大量的一 次性更改，导致将来合并到主干上造成巨大的风险。Git的代码日志是在本地的，可以随时查看。SVN的日志在服务器上的，每次查看日志需要先从服务器上下 载下来。我工作的小组，代码服务器在美国，每次查看小组几年前所做的工作时，日志下载就需要十分钟，这不能不说是一个痛苦。后来我们迁移到Git上，利用 Git日志在本地的特性，我用Ruby编写了一个Rake脚本，可以查看某个具体任务的所有代码历史，每次只需要几秒钟，大大方便我的工作。当然分布式并 不是说用了Git就不需要一个代码中心服务器，如果你工作在一个团队里，还是需要一个服务器来保存所有的代码的。 实际的例子： 以前我所 在的小组使用SVN作为版本控制工具，当我正在试图增强一个模块，工作做到一半，由于会改变原模块的行为导致代码服务器上许多测试的失败，所以并没有提交 代码。这时候上级对我说，现在有一个很紧急的Bug需要处理， 必须在两个小时内完成。我只好将本地的所有修改diff，并输出成为一个patch文件，然后回滚有关当前任务的所有代码，再开始修改Bug的任务，等到 修改好后，在将patch应用回来。前前后后要完成多个繁琐的步骤，这还不计中间代码发生冲突所要进行的工作量。 可是如果使用Git， 我们只需要开一个分支或者转回到主分支上，就可以随时开始Bug修改的任务，完成之后，只要切换到原来的分支就可以优雅的继续以前的任务。只要你愿意，每 一个新的任务都可以开一个分支，完成后，再将它合并到主分支上，轻松而优雅。 gitlab介绍安装服务相关命令安装有可能的依赖： yum install openssh-server yum install postfix yum install cronie 安装gitlab： curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh #下载数据源 yum install gitlab-ce 安装完成后： gitlab-ctl reconfigure #使配置文件生效 但是会初始化除了gitlab.rb之外的所有文件 gitlab-ctl status #查看状态 gitlab-ctl stop #停服务 gitlab-ctl start #起服务 gitlab-ctl tail #查看日志的命令（Gitlab 默认的日志文件存放在/var/log/gitlab 目录下） 如下表示启动成功：（全是run，有down表示有的服务没启动成功） 然后打开浏览器输入ip或者域名 相关目录.git/config #版本库特定的配置设置，可用–file修改 ~/.gitconfig #用户特定的配置设置，可用–global修改 /var/opt/gitlab/git-data/repositories/root #库默认存储目录 /opt/gitlab #是gitlab的应用代码和相应的依赖程序 /var/opt/gitlab #此目录下是运行gitlab-ctl reconfigure命令编译后的应用数据和配置文件，不需要人为修改配置/etc/gitlab #此目录下存放了以omnibus-gitlab包安装方式时的配置文件，这里的配置文件才需要管理员手动编译配置/var/log/gitlab #此目录下存放了gitlab各个组件产生的日志 /var/opt/gitlab/backups/ #备份文件生成的目录 相关文件/opt/gitlab/embedded/service/gitlab-rails/config #配置文件（修改clone的ip地址） /etc/gitlab/gitlab.rb #设置相关选项进行配置（gitlab地址就在这） /var/opt/gitlab/git-data #Git存储库数据（默认) 转载链接Git使用基础篇]]></content>
      <categories>
        <category>git使用及讲解</category>
      </categories>
      <tags>
        <tag>git工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git和svn的详细对比表]]></title>
    <url>%2F2018%2F09%2F07%2Fgit%E7%9A%84%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[刚开始工作那会，工作做版本控制的选型，几个tl最后选的git，当时不是很懂，只知道git性能多一些，现在回头看了一下这个表格，更加明白他们之间的差异了，git完胜！ 版本工具差异 svn git 系统特点 1.集中式版本控制系统（文档管理很方便）2.企业内部并行集中开发3.windows系统上开发推荐使用4.克隆一个拥有将近一万个提交(commit),五个分支,每个分支有大约1500个文件，用时将近一个小时 1.分布式系统（代码管理很方便）2.开源项目开发3.mac,Linux系统上开发推荐使用4.克隆一个拥有将近一万个提交(commit),五个分支,每个分支有大约1500个文件，用时1分钟 灵活性 1.搭载svn的服务器出现故障，无法与之交互2.所有的svn操作都需要中央仓库交互（例：拉分支，看日志等） 1.可以单机操作，git服务器故障也可以在本地git仓库工作2.除了push和pull（或fetch）操作，其他都可以在本地操作3.根据自己开发任务任意在本地创建分支4.日志都是在本地查看，效率较高 安全性 较差，定期备份，并且是整个svn都得备份 较高，每个开发者的本地就是一套完整版本库，记录着版本库的所有信息（gitlab集成了备份功能） 分支方面 1.拉分支更像是copy一个路径2.可针对任何子目录进行branch3.拉分支的时间较慢，因为拉分支相当于copy4.创建完分支后，影响全部成员，每个人都会拥有这个分支5.多分支并行开发较重（工作较多而且繁琐） 1.我可以在Git的任意一个提交点（commit point）开启分支！（git checkout -b newbranch HashId）2.拉分支时间较快，因为拉分支只是创建文件的指针和HEAD3.自己本地创建的分支不会影响其他人4.比较适合多分支并行开发5.git checkout hash值(切回之前的版本，无需版本回退)6.强大的cherry-pick 版本控制 1.保存前后变化的差异数据，作为版本控制2.版本号进行控制，每次操作都会产生一个高版本号（svn的全局版本号，这是svn一个较大的特点，git是hash值） 1.git只关心文件数据的整体发生变化，更像是把文件做快照，文件没有改变时，分支只想这个文件的指针不会改变，文件发生改变，指针指向新版本2. 40 位长的哈希值作为版本号，没有先后之分3.git rebase操作可以更好的保持提交记录的整洁 工作流程 1.每次更改文件之前都得update操作，有的时候修改过程中这个文件有更新，commit不会成功2.有冲突，会打断提交动作（冲突解决是一个提交速度的竞赛：手快者，先提交，平安无事；手慢者，后提交，可能遇到麻烦的冲突解决。） 1.开始工作前进行fetch操作，完成开发工作后push操作，有冲突解决冲突2.git的提交过程不会被打断，有冲突会标记冲突文件3.gitflow流程（经典） 内容管理 svn对中文支持好，操作简单，适用于大众 对程序的源代码管理方便，代码库占用的空间少，易于分支化管理 学习成本 使用起来更方便，svn对中文支持好，操作简单，适用于大众 更在乎效率而不是易用性，成本较高（有很多独有的命令，rebase，远程仓库交互的命令，等等） 权限管理 svn的权限管理相当严格，可以按组、个人针对某个子目录的权限控制（每个目录下都会有个.svn的隐藏文件） git没有严格的权限管理控制，只有账号角色划分（在项目的home文件下有且只有一个.svn目录） 管理平台 有吧（这个“吧”字，肯定有，但本人没有接触过） gitlab（建议使用，集成的功能较多，API开发），gerrit，github等 转载链接： git和svn的详细对比]]></content>
      <categories>
        <category>git使用及讲解</category>
      </categories>
      <tags>
        <tag>git工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github向导]]></title>
    <url>%2F2018%2F09%2F07%2Fgithub%E5%90%91%E5%AF%BC%2F</url>
    <content type="text"><![CDATA[Hello World项目是计算机编程的悠久传统。这是一个简单的练习，让你开始学习新的东西。让我们开始使用GitHub！ 你将学到如下内容： 1: 创建和使用一个仓库。 2: 开始和管理一个分支。 3: 更改一个文件，然后推送到仓库，并且附带一些注释。 4: 打开和合并一个推送请求。 创建一个仓库仓库用来组织一个单一的项目，可以包含目录和文件，图片，视频，表格和数据集等所有项目所需要的内容。建议增加一个README文件用来描述项目相关信息。github可以直接生成一个空的README文件。 1: 进入github，在右上角找到+号，然后选择新建项目。 2: 输入项目名称，比如wuman-Small-projects。 3: 写一些简短的描述。 4: 选择可见等级； 5: 单击创建项目，即可完成创建。 创建完成后，如果是空的项目，会显示一个命令列表，以帮助用户通过git进行操作： 命令行指令 Git 全局设置 12git config --global user.name &quot;wumansgy&quot;git config --global user.email &quot;wumansgy@wumansgy.com&quot; 创建新版本库 123456git clone https://github.com/wumansgy/wuman-Small-projects.gitcd hello-worldtouch README.mdgit add README.mdgit commit -m &quot;add README&quot;git push -u origin master 已存在的文件夹 123456cd existing_foldergit initgit remote add origin https://github.com/wumansgy/wuman-Small-projects.gitgit add .git commitgit push -u origin master 已存在的 Git 版本库 1234cd existing_repogit remote add origin https://github.com/wumansgy/wuman-Small-projects.gitgit push -u origin --allgit push -u origin --tags 创建一个分支github上默认分支为master。并且还提供了将分支合并的功能。 1: 打开hello-world仓库首页。 2: 在项目名称之后单击+号，弹出菜单，并选择新分支，赚到分支创建页。 3：输入分支名称，单击绿色创建分支按钮，即可创建成功。 4: 创建成功后，回到hello-world项目首页，可以看到新创建的分支。 更改和提交更新1: 在hello-world项目首页，在对应项目名称的后面单击+号，弹出菜单，并选择新文件（也可以选择上传文件以上传一个新的本地文件，或者单击新目录以创建一个新目录）。 或者如果有文件存在，打开对应的文件，然后单击编辑按钮，以开始编辑一个存在的文件。 2: 我们以新文件为例，如下图，输入文件名称，文件内容，并且在下方输入注释，然后单击提交修改即可完成新文件或者修改文件的功能： 开启一个推送请求如果将某个分支的更改情况推送到另外一个分支，或者master，需要提交一个推送请求。 1: 打开hello-world项目首页，单击最上头的合并请求。 2: 单击绿色的新建合并请求。 3: 选择来源分支（即当前分支newbranch）与目标分支（比如master），单击比较分支后继续。 4: 填写标题和描述，确定来源分支和目标分支，以及确定最下方的提交和变更内容，最后单击绿色的提交新的合并请求。 合并一个推送请求经过步骤3之后，项目的所有者或者在上述步骤中指定了指派人，会收到一个合并请求的通知。 当确认后，会进行具体的合并过程。 此过程，也可以通过命令行来完成，具体过程如下 检出，在本地审查和合并 Step 1. 获取并检出此合并请求的分支 12git fetch origingit checkout -b newbranch origin/newbranch Step 2. 本地审查变更 Step 3. 合并分支并修复出现的任何冲突 Step 4. 推送合并的结果到 GitLab 1git push origin master 常用的命令行功能1: 更新 12$ git fetch origin 更新主分支的更新$ git fetch 更新所有内容 2: 克隆 1$ git clone https://github.com/wumansgy/wuman-Small-projects.git 3: 在某个分支上克隆 1$ git clone -b newbranch https://github.com/wumansgy/wuman-Small-projects.git 4: 合并 1$ git merge origin/master 5: 更新，然后合并 1$ git pull 6: 添加文件 1$ git add [file.name](http://file.name) 7: 删除文件 1$ git rm [file.name](http://file.name) 8: 添加注释 1$ git commit -m ‘add a new file’ 9: 推送更改 1$ git push -u origin/master]]></content>
      <categories>
        <category>git使用及讲解</category>
      </categories>
      <tags>
        <tag>git工具使用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP通信三次握手四次挥手]]></title>
    <url>%2F2018%2F09%2F06%2FTcp%E9%80%9A%E4%BF%A1%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%2F</url>
    <content type="text"><![CDATA[TCP通信过程下图是一次TCP通讯的时序图。TCP连接建立断开。包含大家熟知的三次握手和四次握手 在这个例子中，首先客户端主动发起连接、发送请求，然后服务器端响应请求，然后客户端主动关闭连接。两条竖线表示通讯的两端，从上到下表示时间的先后顺序。注意，数据从一端传到网络的另一端也需要时间，所以图中的箭头都是斜的。 三次握手：所谓三次握手（Three-Way Handshake）即建立TCP连接，就是指建立一个TCP连接时，需要客户端和服务端总共发送3个包以确认连接的建立。好比两个人在打电话：Client:“喂，你听得到吗？”Server:“我听得到，你听得到我吗？”Client:“我能听到你，今天balabala…” 建立连接（三次握手）的过程：1.客户端发送一个带SYN标志的TCP报文到服务器。这是上图中三次握手过程中的段1。客户端发出SYN位表示连接请求。序号是1000，这个序号在网络通讯中用作临时的地址，每发一个数据字节，这个序号要加1，这样在接收端可以根据序号排出数据包的正确顺序，也可以发现丢包的情况。另外，规定SYN位和FIN位也要占一个序号，这次虽然没发数据，但是由于发了SYN位，因此下次再发送应该用序号1001。mss表示最大段尺寸，如果一个段太大，封装成帧后超过了链路层的最大长度，就必须在IP层分片，为了避免这种情况，客户端声明自己的最大段尺寸，建议服务器端发来的段不要超过这个长度。2.服务器端回应客户端，是三次握手中的第2个报文段，同时带ACK标志和SYN标志。表示对刚才客户端SYN的回应；同时又发送SYN给客户端，询问客户端是否准备好进行数据通讯。服务器发出段2，也带有SYN位，同时置ACK位表示确认，确认序号是1001，表示“我接收到序号1000及其以前所有的段，请你下次发送序号为1001的段”，也就是应答了客户端的连接请求，同时也给客户端发出一个连接请求，同时声明最大尺寸为1024。3.客户必须再次回应服务器端一个ACK报文，这是报文段3。客户端发出段3，对服务器的连接请求进行应答，确认序号是8001。在这个过程中，客户端和服务器分别给对方发了连接请求，也应答了对方的连接请求，其中服务器的请求和应答在一个段中发出。因此一共有三个段用于建立连接，称为“三方握手”。在建立连接的同时，双方协商了一些信息，例如，双方发送序号的初始值、最大段尺寸等。数据传输的过程：1.客户端发出段4，包含从序号1001开始的20个字节数据。2.服务器发出段5，确认序号为1021，对序号为1001-1020的数据表示确认收到，同时请求发送序号1021开始的数据，服务器在应答的同时也向客户端发送从序号8001开始的10个字节数据。3.客户端发出段6，对服务器发来的序号为8001-8010的数据表示确认收到，请求发送序号8011开始的数据。在数据传输过程中，ACK和确认序号是非常重要的，应用程序交给TCP协议发送的数据会暂存在TCP层的发送缓冲区中，发出数据包给对方之后，只有收到对方应答的ACK段才知道该数据包确实发到了对方，可以从发送缓冲区中释放掉了，如果因为网络故障丢失了数据包或者丢失了对方发回的ACK段，经过等待超时后TCP协议自动将发送缓冲区中的数据包重发。 四次挥手：所谓四次挥手（Four-Way-Wavehand）即终止TCP连接，就是指断开一个TCP连接时，需要客户端和服务端总共发送4个包以确认连接的断开。在socket编程中，这一过程由客户端或服务器任一方执行close来触发。好比两个人打完电话要挂断：Client:“我要说的事情都说完了，我没事了。挂啦？”Server:“等下，我还有一个事儿。Balabala…”Server:“好了，我没事儿了。挂了啊。”Client:“ok！拜拜”关闭连接（四次握手）的过程：由于TCP连接是全双工的，因此每个方向都必须单独进行关闭。这原则是当一方完成它的数据发送任务后就能发送一个FIN来终止这个方向的连接。收到一个 FIN只意味着这一方向上没有数据流动，一个TCP连接在收到一个FIN后仍能发送数据。首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。1.客户端发出段7，FIN位表示关闭连接的请求。2.服务器发出段8，应答客户端的关闭连接请求。3.服务器发出段9，其中也包含FIN位，向客户端发送关闭连接请求。4.客户端发出段10，应答服务器的关闭连接请求。建立连接的过程是三次握手，而关闭连接通常需要4个段，服务器的应答和关闭连接请求通常不合并在一个段中，因为有连接半关闭的情况，这种情况下客户端关闭连接之后就不能再发送数据给服务器了，但是服务器还可以发送数据给客户端，直到服务器也关闭连接为止。 这就是简单的3次握手和四次挥手的讲解，如果可以理解记住如下状态那就更好 总结过程：TCP状态转换： 1. 主动端：CLOSE –&gt; SYN –&gt; SYN_SEND状态 –&gt; ESTABLISHED状态（数据通信期间处于的状态） —&gt; FIN –&gt; FIN_WAIT_1状态。—&gt; 接收 ACK —&gt; FIN_WAIT_2状态 (半关闭—— 只出现在主动端) —&gt; 接收FIN、回ACK ——&gt; TIME_WAIT (等2MSL)—&gt; 确保最后一个ACK能被对端收到。(只出现在主动端)2. 被动端：CLOSE –&gt; LISTEN —&gt; ESTABLISHED状态（数据通信期间处于的状态） —&gt; 接收 FIN、回复ACK –&gt; CLOSE_WAIT(对应 对端处于 半关闭) –&gt; 发送FIN –&gt; LAST_ACK —&gt; 接收ACK —&gt; CLOSE]]></content>
      <categories>
        <category>网络编程协议</category>
      </categories>
      <tags>
        <tag>TCP/IP</tag>
        <tag>通信协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通信Socket编程]]></title>
    <url>%2F2018%2F09%2F06%2F%E9%80%9A%E4%BF%A1Socket%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Socket编程什么是Socket：Socket，英文含义是【插座、插孔】，一般称之为套接字，用于描述IP地址和端口。可以实现不同程序间的数据通信。Socket起源于Unix，而Unix基本哲学之一就是“一切皆文件”，都可以用“打开open –&gt; 读写write/read –&gt; 关闭close”模式来操作。Socket就是该模式的一个实现，网络的Socket数据传输是一种特殊的I/O，Socket也是一种文件描述符。Socket也具有一个类似于打开文件的函数调用：Socket()，该函数返回一个整型的Socket描述符，随后的连接建立、数据传输等操作都是通过该Socket实现的。套接字的内核实现较为复杂，不宜在学习初期深入学习，了解到如下结构足矣。 套接字通讯原理示意在TCP/IP协议中，“IP地址+TCP或UDP端口号”唯一标识网络通讯中的一个进程。“IP地址+端口号”就对应一个socket。欲建立连接的两个进程各自有一个socket来标识，那么这两个socket组成的socket pair就唯一标识一个连接。因此可以用Socket来描述网络连接的一对一关系。常用的Socket类型有两种：流式Socket（SOCK_STREAM）和数据报式Socket（SOCK_DGRAM）。流式是一种面向连接的Socket，针对于面向连接的TCP服务应用；数据报式Socket是一种无连接的Socket，对应于无连接的UDP服务应用。 网络应用程序设计模式C/S模式传统的网络应用设计模式，客户机(client)/服务器(server)模式。需要在通讯两端各自部署客户机和服务器来完成数据通信。B/S模式浏览器(Browser)/服务器(Server)模式。只需在一端部署服务器，而另外一端使用每台PC都默认配置的浏览器即可完成数据的传输。优缺点对于C/S模式来说，其优点明显。客户端位于目标主机上可以保证性能，将数据缓存至客户端本地，从而提高数据传输效率。且，一般来说客户端和服务器程序由一个开发团队创作，所以他们之间所采用的协议相对灵活。可以在标准协议的基础上根据需求裁剪及定制。例如，腾讯所采用的通信协议，即为ftp协议的修改剪裁版。因此，传统的网络应用程序及较大型的网络应用程序都首选C/S模式进行开发。如，知名的网络游戏魔兽世界。3D画面，数据量庞大，使用C/S模式可以提前在本地进行大量数据的缓存处理，从而提高观感。C/S模式的缺点也较突出。由于客户端和服务器都需要有一个开发团队来完成开发。工作量将成倍提升，开发周期较长。另外，从用户角度出发，需要将客户端安插至用户主机上，对用户主机的安全性构成威胁。这也是很多用户不愿使用C/S模式应用程序的重要原因。B/S模式相比C/S模式而言，由于它没有独立的客户端，使用标准浏览器作为客户端，其工作开发量较小。只需开发服务器端即可。另外由于其采用浏览器显示数据，因此移植性非常好，不受平台限制。如早期的偷菜游戏，在各个平台上都可以完美运行。B/S模式的缺点也较明显。由于使用第三方浏览器，因此网络应用支持受限。另外，没有客户端放到对方主机上，缓存数据不尽如人意，从而传输数据量受到限制。应用的观感大打折扣。第三，必须与浏览器一样，采用标准http协议进行通信，协议选择不灵活。因此在开发过程中，模式的选择由上述各自的特点决定。根据实际需求选择应用程序设计模式。TCP的C/S架构 简单的C/S模型通信 Server端： 12345678910Listen函数： func Listen(network, address string) (Listener, error) network：选用的协议：TCP、UDP， 如：“tcp”或 “udp” address：IP地址+端口号, 如：“127.0.0.1:8000”或 “:8000”Listener 接口：type Listener interface &#123; Accept() (Conn, error) Close() error Addr() Addr&#125; Conn 接口： 12345678910type Conn interface &#123; Read(b []byte) (n int, err error) Write(b []byte) (n int, err error) Close() error LocalAddr() Addr RemoteAddr() Addr SetDeadline(t time.Time) error SetReadDeadline(t time.Time) error SetWriteDeadline(t time.Time) error&#125; 参看 https://studygolang.com/pkgdoc 中文帮助文档中的demo： 示例代码： TCP服务器.go 1234567891011121314151617181920212223242526272829303132333435package mainimport ( &quot;net&quot; &quot;fmt&quot;)func main() &#123; // 创建监听 listener, err:= net.Listen(&quot;tcp&quot;, &quot;:8000&quot;) if err != nil &#123; fmt.Println(&quot;listen err:&quot;, err) return &#125; defer listener.Close() // 主协程结束时，关闭listener fmt.Println(&quot;服务器等待客户端建立连接...&quot;) // 等待客户端连接请求 conn, err := listener.Accept() if err != nil &#123; fmt.Println(&quot;accept err:&quot;, err) return &#125; defer conn.Close() // 使用结束，断开与客户端链接 fmt.Println(&quot;客户端与服务器连接建立成功...&quot;) // 接收客户端数据 buf := make([]byte, 1024) // 创建1024大小的缓冲区，用于read n, err := conn.Read(buf) if err != nil &#123; fmt.Println(&quot;read err:&quot;, err) return &#125; fmt.Println(&quot;服务器读到:&quot;, string(buf[:n])) // 读多少，打印多少。&#125; 如图，在整个通信过程中，服务器端有两个socket参与进来，但用于通信的只有 conn 这个socket。它是由 listener创建的。隶属于服务器端。 Client 端： 123func Dial(network, address string) (Conn, error) network：选用的协议：TCP、UDP，如：“tcp”或 “udp” address：服务器IP地址+端口号, 如：“121.36.108.11:8000”或 “www.itcast.cn:8000” Conn 接口： 12345678910type Conn interface &#123; Read(b []byte) (n int, err error) Write(b []byte) (n int, err error) Close() error LocalAddr() Addr RemoteAddr() Addr SetDeadline(t time.Time) error SetReadDeadline(t time.Time) error SetWriteDeadline(t time.Time) error&#125; 客户端实现 1234567891011121314151617181920212223package mainimport ( "net" "fmt")func main() &#123; // 主动发起连接请求 conn, err := net.Dial("tcp", "127.0.0.1:8000") if err != nil &#123; fmt.Println("Dial err:", err) return &#125; defer conn.Close() // 结束时，关闭连接 // 发送数据 _, err = conn.Write([]byte("Are u ready?")) if err != nil &#123; fmt.Println("Write err:", err) return &#125;&#125; 下一章节将讲解一下并发模型的服务器，以及TCP通信过程，还有UDP服务器的讲解；]]></content>
      <categories>
        <category>网络编程协议</category>
      </categories>
      <tags>
        <tag>通信协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构--散列表（哈希表）2]]></title>
    <url>%2F2018%2F09%2F06%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%95%A3%E5%88%97%E8%A1%A8%E5%93%88%E5%B8%8C%E8%A1%A82%2F</url>
    <content type="text"><![CDATA[本文主要采用： 构造方法：除留余数法： f(key)=key%p (P&lt;=m m:散列表的长度) 处理散列冲突方法：链地址法（单链表） 代码实例：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125package main import &quot;fmt&quot; /* 除留余数发定址 线性探测发解决冲突*/type keyType int //key值的类型type valueType int //value值的类型const maxSize = 12 //hastable的最大长度//除留余数发： f(key)=key%p (P&lt;=m m:散列表的长度)var p = 11var nullKey = keyType(-65535)var nullValue = valueType(-65535) //无效的数据 type hashData struct &#123; key keyType //key值 value valueType //value值 next *hashData&#125; var hashTable [maxSize]hashData //定义哈希表，大小为maxSize，类型为：hashData//初始化哈希表func initHashTable() &#123; for i := 0; i &lt; len(hashTable); i++ &#123; // 头结点 p := new(hashData) p.key = nullKey //空值 p.value = nullValue //空值 p.next = nil dataNode := hashData&#123;keyType(nullKey), valueType(nullValue), p&#125; hashTable[i] = dataNode &#125;&#125; //向哈希表添加数据元素func insertHashTable(ht *[maxSize]hashData, key keyType, value valueType) bool &#123; //先查找，如果key值已经存在，则替换成key新对应的value data:=searchHashTable(ht,key) if data!=nil&#123; //已经存在 data.value=value return true &#125; addr := int(key) % p //开辟空间 新建节点 q := new(hashData) q.key = key //赋 key值 q.value = value //赋value值 r := ht[addr].next //找到最末尾元素 for r.next != nil &#123; r = r.next &#125; q.next = r.next r.next = q return true&#125; //查找数据func searchHashTable(ht *[maxSize]hashData, key keyType) (data *hashData) &#123; //按照添加的位置 找对应的数据（链表），而不是对数组遍历 addr := int(key) % p //fmt.Println(&quot;------------&quot;,addr) data = nil q := ht[addr].next for q != nil &#123; if q.key == key &#123; return q //如果找个，返回对应的节点（指针指向此节点） &#125; q = q.next //移动到下一个位置继续 &#125; return&#125; //删除数据func deleteHashTable(ht *[maxSize]hashData, key keyType) bool &#123; addr := int(key) % p q := ht[addr].next r := q.next for r != nil &#123; //删除节点 if r.key == key &#123; q.next = r.next return true &#125; q = r r = q.next &#125; return false&#125;func main() &#123; //初始化哈希表 initHashTable() //添加数据 // 元素0对应的数据 insertHashTable(&amp;hashTable, 0, 48) m := searchHashTable(&amp;hashTable, 0) if m != nil &#123; fmt.Printf(&quot;【%d】：%d\n&quot;, m.key, m.value) &#125; else &#123; fmt.Println(&quot;没有查找到数据！&quot;) &#125; //添加key已经存在的数据 insertHashTable(&amp;hashTable,0,666) m = searchHashTable(&amp;hashTable, 0) if m != nil &#123; fmt.Printf(&quot;【%d】：%d\n&quot;, m.key, m.value) &#125; else &#123; fmt.Println(&quot;没有查找到数据！&quot;) &#125; //删除数据元素 deleteHashTable(&amp;hashTable, 0) //删除之后 再次查找 m = searchHashTable(&amp;hashTable, 0) if m != nil &#123; fmt.Printf(&quot;【%d】：%d\n&quot;, m.key, m.value) &#125; else &#123; fmt.Println(&quot;没有查找到数据！&quot;) &#125; &#125;]]></content>
      <categories>
        <category>数据结构和算法</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构--散列表（哈希表）1]]></title>
    <url>%2F2018%2F09%2F06%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%95%A3%E5%88%97%E8%A1%A8%E5%93%88%E5%B8%8C%E8%A1%A81%2F</url>
    <content type="text"><![CDATA[本文主要采用： 构造方法：除留余数法： f(key)=key%p (P&lt;=m m:散列表的长度) 处理散列冲突方法：线性探测法 代码实例：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112package main import &quot;fmt&quot; /* 除留余数发定址 线性探测发解决冲突*/type keyType int //key值的类型type valueType int //value值的类型 const maxSize = 12 //hastable的最大长度//除留余数发： f(key)=key%p (P&lt;=m m:散列表的长度)var p = 11var nullValue = keyType(-65535) //无效的数据 type hashData struct &#123; key keyType //key值 value valueType //value值 //count int //探查次数&#125; var hashTable [maxSize]hashData //定义哈希表，大小为maxSize，类型为：hashData//初始化哈希表func initHashTable() &#123; for i:=0;i&lt;len(hashTable);i++&#123; dataNode:=hashData&#123;nullValue,0,&#125; hashTable[i]=dataNode &#125;&#125;//向哈希表添加数据元素func insertHashTable(ht *[maxSize]hashData, key keyType, value valueType) bool&#123; count := 0 //添加时 查找次数 addr := int(key) % p //线性探测发： f(key)=( f(key)+d)%m (d=1,d=2,d=3...) d := 0 for count &lt; maxSize &#123; addr := (addr + d) % p if ht[addr].key ==nullValue &#123; dataNode := hashData&#123;key, value, &#125; ht[addr] = dataNode return true &#125; d++ count++ &#125; return false&#125;//查找数据func searchHashTable( ht *[maxSize]hashData,key keyType) (positon int) &#123; //addr:=int(key)%p positon=-1 //没有找到，返回值为：-1 for index,data:=range ht&#123; if data.key==key &#123; positon=index return //返回对应于数组的下标 &#125; &#125; return&#125;//删除数据func deleteHashTable(ht *[maxSize]hashData,key keyType) bool &#123; for index,data:=range ht&#123; if data.key==key &#123; /* 特别注意;这种方法不能更改数据 data.key=nullValue //重置key data.value=0 //清空数据 */ dataNode:=hashData&#123;nullValue,0&#125; ht[index]=dataNode return true &#125; &#125; return false &#125;func main() &#123; //初始化哈希表 initHashTable() //向哈希表中添加10个数据 for i:=0;i&lt;10;i++&#123; insertHashTable(&amp;hashTable,keyType(i),valueType(i*100)) &#125; fmt.Println(hashTable) //打印，是否添加成功 //查找 index:=searchHashTable(&amp;hashTable,keyType(3)) if index==-1 &#123; fmt.Println(&quot;没有查询到对应的数据&quot;) &#125;else &#123; value:=hashTable[index].value fmt.Printf(&quot;key：%d对应的value：%d\n&quot;,index,value) &#125; //删除数据元素 deleteState:=deleteHashTable(&amp;hashTable,keyType(3)) if deleteState &#123; fmt.Println(&quot;找到对应的元素，删除成功！&quot;) &#125;else &#123; fmt.Println(&quot;没有找到元素，删除失败！&quot;) &#125; //再次查找，看是否真正删除 index1:=searchHashTable(&amp;hashTable,keyType(3)) if index1==-1 &#123; fmt.Println(&quot;没有查询到对应的数据&quot;) &#125;else &#123; value:=hashTable[index1].value fmt.Printf(&quot;key：%d对应的value：%d&quot;,index1,value) &#125; //fmt.Println(hashTable)&#125;]]></content>
      <categories>
        <category>数据结构和算法</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫小Demo]]></title>
    <url>%2F2018%2F09%2F05%2F%E7%88%AC%E5%8F%96%E8%B1%86%E7%93%A3%E8%AF%84%E5%88%86Demo%2F</url>
    <content type="text"><![CDATA[爬虫爬虫简介： 是一个程序，用来获取指定网站数据信息。 明确 url 。确定爬取对象 发送请求。获取服务器响应数据。 解析数据，提取有用数据内容。 保存、分析数据结果。 今天我们用go并发来简单写一个小Demo来爬取一下豆瓣评分网站的数据 首先来思路分析一下该怎么做： 明确 url。找出url之间的一些小规律，比如豆瓣的url规律如下 1234567https://movie.douban.com/top250?start=0&amp;filter= 1https://movie.douban.com/top250?start=25&amp;filter= 2 https://movie.douban.com/top250?start=50&amp;filter= 3https://movie.douban.com/top250?start=75&amp;filter= 4 之间的规律很好找 待提取字符特性： 提示用户指定爬取起始、终止页 封装 doWork 函数， 按起始、终止页面循环爬取网页数据 组织每个网页的 url。 下一页 = +25 封装函数 HttpGetDB（url）result，err { http.Get(url), resp.Body.Read(buf), n==0 break, result+= string(buf[:n}) } 爬取网页的所有数据 通过result 返回给调用者。 解析、编译正则表达式 —— 提取 “电影名称”fileNames 传出的是[][]string ， 下标为【1】是不带匹配参考项。 解析、编译正则表达式 —— 提取 “评分”传出的是[][]string ， 下标为【1】是不带匹配参考项。 解析、编译正则表达式 —— 提取 “评价人数”传出的是[][]string ， 下标为【1】是不带匹配参考项。 封装函数，将上述内容写入文件。save2File（ [][]string） 创建并发go程 提取所有网页数据。 创建阻止主go程提取退出的 channel ， SpiderPageDB() 末尾处，写channel doWork 中，添加新 for ，读channel 代码实现：首先可以封装一个函数来爬取多少页到多少页，并且每一页构造一个go程 123456789101112func doWork(start, end int) &#123; page := make(chan int) // 循环创建多个goroutine，提高爬取效率 for i:=start; i&lt;=end; i++ &#123; go SpiderPageDB(i, page) &#125; // 循环读取 channel， 协调主、子go程调用顺序 for i:=start; i&lt;=end; i++ &#123; fmt.Printf(&quot;第%d页爬取完成\n&quot;, &lt;-page) &#125;&#125; 获取每一页的数据函数 123456789101112131415161718192021func HttpGetDB(url string) (result string, err error) &#123; resp, err1 := http.Get(url) if err1 != nil &#123; err = err1 return &#125; defer resp.Body.Close() buf := make([]byte, 4096) for &#123; n, err2 := resp.Body.Read(buf) if n == 0 &#123; break &#125; if err2 != nil &amp;&amp; err2 != io.EOF &#123; err = err2 return &#125; result += string(buf[:n]) &#125; return&#125; 得到每一个数据然后分析数据解析数据 123456789101112131415161718192021222324252627282930func SpiderPageDB(i int, page chan&lt;- int) &#123; url := &quot;https://movie.douban.com/top250?start=&quot; + strconv.Itoa((i-1)*25) + &quot;&amp;filter=&quot; result, err := HttpGetDB(url) if err != nil &#123; fmt.Println(&quot;HttpGetDB err:&quot;, err) return &#125; // 编译、解析正则表达式 —— 电影名 ret1 := regexp.MustCompile(`&lt;img width=&quot;100&quot; alt=&quot;(?s:(.*?))&quot; src=&quot;` ) // 提取有效信息 fileNames := ret1.FindAllStringSubmatch(result, -1) // 编译、解析正则表达式 —— 分数 pattern := `&lt;span class=&quot;rating_num&quot; property=&quot;v:average&quot;&gt;(.*?)&lt;/span&gt;` ret2 := regexp.MustCompile(pattern ) // 提取有效信息 fileScore := ret2.FindAllStringSubmatch(result, -1)/* for _, one := range fileScore &#123; fmt.Println(&quot;fileName:&quot;, one[1]) &#125;*/ // 编译、解析正则表达式 —— 评分人数 ret3 := regexp.MustCompile(`&lt;span&gt;(\d*?)人评价&lt;/span&gt;`) // 提取有效信息 peopleNum := ret3.FindAllStringSubmatch(result, -1) // 写入到一个文件中 save2file(i, fileNames, fileScore, peopleNum) page &lt;- i // 写入channel ，协调主go程与子go程调用顺序。&#125; 最后保存数据到文件中 123456789101112131415161718192021func save2file(idx int, fileNames, fileScore, peopleNum [][]string) &#123; // 组织保存文件路径及名程 path := &quot;D:/ecec/第&quot; + strconv.Itoa(idx) + &quot;页.txt&quot; f, err := os.Create(path) if err != nil &#123; fmt.Println(&quot;Create err:&quot;, err) return &#125; defer f.Close() // 获取 一个网页中的条目数 —— 25 n := len(fileNames) // 写一行标题 f.WriteString(&quot;电影名称&quot; + &quot;\t&quot; + &quot;评分&quot; + &quot;\t&quot; + &quot;评价人数&quot; + &quot;\n&quot;) // 依次按序写入电影相关条目。 for i:=0; i&lt;n; i++ &#123; f.WriteString(fileNames[i][1] + &quot;\t&quot; + fileScore[i][1] + &quot;\t&quot; + peopleNum[i][1] + &quot;\n&quot;) &#125;&#125; 最后直接在main里面就可以调用 完整代码如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109package mainimport ( "fmt" "strconv" "net/http" "io" "regexp" "os")func HttpGetDB(url string) (result string, err error) &#123; resp, err1 := http.Get(url) if err1 != nil &#123; err = err1 return &#125; defer resp.Body.Close() buf := make([]byte, 4096) for &#123; n, err2 := resp.Body.Read(buf) if n == 0 &#123; break &#125; if err2 != nil &amp;&amp; err2 != io.EOF &#123; err = err2 return &#125; result += string(buf[:n]) &#125; return&#125;func SpiderPageDB(i int, page chan&lt;- int) &#123; url := "https://movie.douban.com/top250?start=" + strconv.Itoa((i-1)*25) + "&amp;filter=" result, err := HttpGetDB(url) if err != nil &#123; fmt.Println("HttpGetDB err:", err) return &#125; // 编译、解析正则表达式 —— 电影名 ret1 := regexp.MustCompile(`&lt;img width="100" alt="(?s:(.*?))" src="` ) // 提取有效信息 fileNames := ret1.FindAllStringSubmatch(result, -1) // 编译、解析正则表达式 —— 分数 pattern := `&lt;span class="rating_num" property="v:average"&gt;(.*?)&lt;/span&gt;` ret2 := regexp.MustCompile(pattern ) // 提取有效信息 fileScore := ret2.FindAllStringSubmatch(result, -1)/* for _, one := range fileScore &#123; fmt.Println("fileName:", one[1]) &#125;*/ // 编译、解析正则表达式 —— 评分人数 ret3 := regexp.MustCompile(`&lt;span&gt;(\d*?)人评价&lt;/span&gt;`) // 提取有效信息 peopleNum := ret3.FindAllStringSubmatch(result, -1) // 写入到一个文件中 save2file(i, fileNames, fileScore, peopleNum) page &lt;- i // 写入channel ，协调主go程与子go程调用顺序。&#125;func save2file(idx int, fileNames, fileScore, peopleNum [][]string) &#123; // 组织保存文件路径及名程 path := "C:/exec/第" + strconv.Itoa(idx) + "页.txt" f, err := os.Create(path) if err != nil &#123; fmt.Println("Create err:", err) return &#125; defer f.Close() // 获取 一个网页中的条目数 —— 25 n := len(fileNames) // 写一行标题 f.WriteString("电影名称" + "\t" + "评分" + "\t" + "评价人数" + "\n") // 依次按序写入电影相关条目。 for i:=0; i&lt;n; i++ &#123; f.WriteString(fileNames[i][1] + "\t" + fileScore[i][1] + "\t" + peopleNum[i][1] + "\n") &#125;&#125;func doWork(start, end int) &#123; page := make(chan int) // 循环创建多个goroutine，提高爬取效率 for i:=start; i&lt;=end; i++ &#123; go SpiderPageDB(i, page) &#125; // 循环读取 channel， 协调主、子go程调用顺序 for i:=start; i&lt;=end; i++ &#123; fmt.Printf("第%d页爬取完成\n", &lt;-page) &#125;&#125;func main() &#123; var start, end int fmt.Print("请输入爬取起始页面（&gt;=1）:") fmt.Scan(&amp;start) fmt.Print("请输入爬取终止页面（&gt;=start）:") fmt.Scan(&amp;end) doWork(start, end)&#125;]]></content>
      <categories>
        <category>GO语言</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>go并发简单爬虫Demo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符二进制转换]]></title>
    <url>%2F2018%2F09%2F05%2F%E5%AD%97%E7%AC%A6%E4%BA%8C%E8%BF%9B%E5%88%B6%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[字符二进制转换运用位操作左移和右移来实现字符二进制转换的一个源码（自己也可以去实现） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112package Btosimport ( "errors" "regexp")const ( zero = byte('0') one = byte('1') lsb = byte('[') // left square brackets rsb = byte(']') // right square brackets space = byte(' '))var uint8arr [8]uint8// ErrBadStringFormat represents a error of input string's format is illegal .var ErrBadStringFormat = errors.New("bad string format")// ErrEmptyString represents a error of empty input string.var ErrEmptyString = errors.New("empty string")func init() &#123; uint8arr[0] = 128 uint8arr[1] = 64 uint8arr[2] = 32 uint8arr[3] = 16 uint8arr[4] = 8 uint8arr[5] = 4 uint8arr[6] = 2 uint8arr[7] = 1&#125;// append bytes of string in binary format.func appendBinaryString(bs []byte, b byte) []byte &#123; var a byte for i := 0; i &lt; 8; i++ &#123; a = b b &lt;&lt;= 1 b &gt;&gt;= 1 switch a &#123; case b: bs = append(bs, zero) default: bs = append(bs, one) &#125; b &lt;&lt;= 1 &#125; return bs&#125;// ByteToBinaryString get the string in binary format of a byte or uint8.func ByteToBinaryString(b byte) string &#123; buf := make([]byte, 0, 8) buf = appendBinaryString(buf, b) return string(buf)&#125;// BytesToBinaryString get the string in binary format of a []byte or []int8.func BytesToBinaryString(bs []byte) string &#123; l := len(bs) bl := l*8 + l + 1 buf := make([]byte, 0, bl) buf = append(buf, lsb) for _, b := range bs &#123; buf = appendBinaryString(buf, b) buf = append(buf, space) &#125; buf[bl-1] = rsb return string(buf)&#125;// regex for delete useless string which is going to be in binary format.var rbDel = regexp.MustCompile(`[^01]`)// BinaryStringToBytes get the binary bytes according to the// input string which is in binary format.func BinaryStringToBytes(s string) (bs []byte) &#123; if len(s) == 0 &#123; panic(ErrEmptyString) &#125; s = rbDel.ReplaceAllString(s, "") l := len(s) if l == 0 &#123; panic(ErrBadStringFormat) &#125; mo := l % 8 l /= 8 if mo != 0 &#123; l++ &#125; bs = make([]byte, 0, l) mo = 8 - mo var n uint8 for i, b := range []byte(s) &#123; m := (i + mo) % 8 switch b &#123; case one: n += uint8arr[m] &#125; if m == 7 &#123; bs = append(bs, n) n = 0 &#125; &#125; return&#125;]]></content>
      <categories>
        <category>GO语言</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>二进制转换</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go语言贪食蛇和c语言区别]]></title>
    <url>%2F2018%2F09%2F05%2Fgo%E8%AF%AD%E8%A8%80%E8%B4%AA%E9%A3%9F%E8%9B%87%E5%92%8Cc%E8%AF%AD%E8%A8%80%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[CSDN博客链接 GO贪食蛇小Demo利用go语言写贪食蛇游戏那么就会利用面向对象的思想来写一下，创造蛇身体对象，然后写出来，go语言写的时候我们需要调用一个c语言写的一个包，go语言可以直接调用调用c语言的函数，很方便简洁，我们先来看一下我自己写的C语言的一个包 1234567891011121314151617181920212223242526272829303132333435363738394041424344package Clib/*#include &lt;windows.h&gt;#include &lt;conio.h&gt;// 使用了WinAPI来移动控制台的光标void gotoxy(int x,int y)&#123; COORD c; c.X=x,c.Y=y; SetConsoleCursorPosition(GetStdHandle(STD_OUTPUT_HANDLE),c);&#125;// 从键盘获取一次按键，但不显示到控制台int direct()&#123; return _getch();&#125;//去掉控制台光标void hideCursor()&#123; CONSOLE_CURSOR_INFO cci; cci.bVisible = FALSE; cci.dwSize = sizeof(cci); SetConsoleCursorInfo(GetStdHandle(STD_OUTPUT_HANDLE), &amp;cci);&#125;*/import "C" // go中可以嵌入C语言的函数//设置控制台光标位置func GotoPostion(X int, Y int) &#123; //调用C语言函数 C.gotoxy(C.int(X), C.int(Y))&#125;//无显获取键盘输入的字符func Direction() (key int) &#123; key = int(C.direct()) return&#125;//设置控制台光标隐藏func HideCursor() &#123; C.hideCursor()&#125; 这个包把一些需要用到c语言的函数写进来，调用c语言的函数需要用到c语言的环境，别忘记自己电脑上要装c语言的环境奥，我们来看一下这个目录结构 首先我们的代码是放在GoCode里面下面的src目录下面，Clib里面是自己写的C语言的一个包，贪食蛇和Clib是同级别目录，在这里我们用的是goland编译器，编译器这里可以自己选择，我们编译的时候就不能单个文件编译了，因为需要调用自己的包，所以要选择多文件编译如图 我自己用的goland编译的时候需要改一下改成Directory 然后目录选到所在目录的src目录，然后设置好后就可以直接编译运行啦，当然也可以直接命令行编译运行 如图，我们可以在所在目录下面直接go build ./这样就是生成可执行文件.exe的，也可以直接使用go run命令直接编译运行， 感兴趣的小伙伴可以自己去试试啦 下面来看一下go语言写的代码，（可以自己去完善一下奥，比如加入等级，加入障碍物，蛇的速度都是自己可以调节的奥） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284package mainimport ( "Clib" "fmt" "os" "math/rand" "time")const wide int = 20const high int = 20var key int64 = 1 //关卡var food1 food //定义一个全局食物结构体//var size int = 2 //定义一个全局蛇的长度var score int = 0 //定义一个全局分数var dx int = 0var dy int = 0 //蛇的偏移量var barr1 barrier //障碍物结构体var c cake //定义一个蛋糕var FLAG bool=truetype postion struct &#123; x int y int //父类坐标&#125;type cake struct&#123; ca [5]postion&#125; //定义一个蛋糕type snake struct &#123; p [wide * high]postion size int dir byte&#125;type barrier struct &#123; barr [6]postion&#125; //障碍物结构体func (c *cake)setcake()&#123; x:=rand.Intn(wide-6)+3 y:=rand.Intn(high-6)+3 c.ca[0].x,c.ca[0].y=x,y c.ca[1].x,c.ca[1].y=x-1,y c.ca[2].x,c.ca[2].y= x-2,y c.ca[3].x,c.ca[3].y=x-1,y-1 c.ca[4].x,c.ca[4].y=x-1,y+1&#125;func (b *barrier)setbarrier()&#123; //定义一些随机障碍物 b.barr[0].x,b.barr[0].y=rand.Intn(wide-1)+1,rand.Intn(high-3)+1 b.barr[1].x,b.barr[1].y=rand.Intn(wide-1)+1,rand.Intn(high-3)+1 b.barr[2].x,b.barr[2].y=rand.Intn(wide-1)+1,rand.Intn(high-3)+1 //b.barr[3].x,b.barr[3].y=rand.Intn(wide-1)+1,rand.Intn(high-3)+1 //b.barr[4].x,b.barr[4].y=rand.Intn(wide-1)+1,rand.Intn(high-3)+1 //b.barr[5].x,b.barr[5].y=rand.Intn(wide-1)+1,rand.Intn(high-3)+1&#125;type food struct &#123; postion&#125; //食物func drawui(p postion, ch byte) &#123; Clib.GotoPostion(p.x*2+4, p.y+2+2) fmt.Fprintf(os.Stderr, "%c", ch)&#125;func (s *snake) initsnake() &#123; //蛇初始化 s.p[0].x = wide / 2 s.p[0].y = high / 2 s.p[1].x = wide/2 - 1 s.p[1].y = high / 2 //蛇头和第一个蛇结点初始化 s.dir = 'R' s.size=2 fmt.Fprintln(os.Stderr, ` #-----------------------------------------# | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | #-----------------------------------------#`) food1 = food&#123;postion&#123;rand.Intn(wide), rand.Intn(high) - 2&#125;&#125; //食物初始化 drawui(food1.postion, 'o') //画出食物 //go func()&#123; Clib.GotoPostion(46,19) fmt.Printf("正在进行第%d关，小心障碍物",key) //&#125;() go func()&#123; for&#123; time.Sleep(time.Second) num:=rand.Intn(10) if num==6&#123; c.setcake() break &#125; &#125; for i:=0;i&lt;len(c.ca);i++&#123; drawui(c.ca[i],'#') &#125; &#125;() //吃蛋糕的作用 go func()&#123; for i:=0;i&lt;len(barr1.barr);i++&#123; Clib.GotoPostion(barr1.barr[i].x,barr1.barr[i].y) drawui(barr1.barr[i],'!') &#125; &#125;() //打印出障碍物 go func() &#123; for &#123; switch Clib.Direction() &#123; case 72, 87, 119: if s.dir == 'D' &#123; break &#125; s.dir = 'U' case 65, 97, 75: if s.dir == 'R' &#123; break &#125; s.dir = 'L' case 100, 68, 77: if s.dir == 'L' &#123; break &#125; s.dir = 'R' case 83, 115, 80: if s.dir == 'U' &#123; break &#125; s.dir = 'D' case 32: s.dir = 'P' &#125; &#125; &#125;() //获取蛇跑的方向&#125;func (s *snake) playgame() &#123; //barr:=barrier&#123;postion&#123;rand.Intn(wide-5)+5,rand.Intn(high-5)+3&#125; //drawui(barr.postion,'p') for &#123; switch key &#123; case 1: time.Sleep(time.Second / 3) case 2:time.Sleep(time.Second / 5) case 3:time.Sleep(time.Second / 6) case 4:time.Sleep(time.Second / 7) case 5:time.Sleep(time.Second / 8) case 6:time.Sleep(time.Second / 9) //用来每增加一关蛇的速度加快 &#125; if s.dir == 'P' &#123; continue &#125; if s.p[0].x &lt; 0 || s.p[0].x &gt;= wide || s.p[0].y+2 &lt; 0 || s.p[0].y &gt;= high-2 &#123; Clib.GotoPostion(wide*3, high-3) FLAG=false return //如果蛇头碰墙就死亡 &#125; //if s.p[0].x==barr.postion.x&amp;&amp;s.p[0].y==barr.postion.y&#123; // Clib.GotoPostion(wide*3, high-3) // return //如果蛇头碰障碍物就死亡 //&#125; for i := 1; i &lt;s.size; i++ &#123; if s.p[0].x == s.p[i].x &amp;&amp; s.p[0].y == s.p[i].y &#123; Clib.GotoPostion(wide*3, high-3) FLAG=false return &#125; &#125; for j:=0;j&lt;len(barr1.barr);j++&#123; if s.p[0].x==barr1.barr[j].x&amp;&amp;s.p[0].y==barr1.barr[j].y&#123; Clib.GotoPostion(wide*3, high-3) FLAG=false return &#125; //碰到障碍物死亡 &#125; for m:=0;m&lt;len(c.ca);m++&#123; if s.p[0].x==c.ca[m].x&amp;&amp;s.p[0].y==c.ca[m].y&#123; s.size++ score++ &#125; if score &gt;= int(6+key*2) &#123; key++ return &#125; &#125; if s.p[0].x == food1.x &amp;&amp; s.p[0].y == food1.y &#123; s.size++ score++ if score &gt;= int(6+key*2) &#123; key++ return &#125; //画蛇 //food1 = food&#123;postion&#123;rand.Intn(wide), rand.Intn(high) - 2&#125;&#125; for &#123; flag := true temp := food&#123;postion&#123;rand.Intn(wide), rand.Intn(high) - 2&#125;&#125; for i := 1; i &lt; s.size; i++ &#123; if (temp.postion.x == s.p[i].x &amp;&amp; temp.postion.y == s.p[i].y) &#123; flag = false break &#125; &#125; for i:=0;i&lt;len(barr1.barr);i++&#123; if temp.postion.x==barr1.barr[i].x&amp;&amp;temp.postion.y==barr1.barr[i].y&#123; flag=false break &#125; &#125; if flag == true &#123; food1 = temp break &#125; &#125; drawui(food1.postion, 'o') &#125; switch s.dir &#123; case 'U': dx = 0 dy = -1 case 'D': dx = 0 dy = 1 case 'L': dx = -1 dy = 0 case 'R': dx = 1 dy = 0 &#125; lp := s.p[s.size-1] //蛇尾位置 for i := s.size - 1; i &gt; 0; i-- &#123; s.p[i] = s.p[i-1] drawui(s.p[i], '*') &#125; drawui(lp, ' ') //蛇尾画空格 s.p[0].x += dx s.p[0].y += dy //更新蛇头 drawui(s.p[0], 'O') //画蛇头 &#125;&#125;func main() &#123; rand.Seed(time.Now().UnixNano()) var s snake for k:=1;k&lt;=6;k++&#123; //用来循环6次代表6个关卡，这里可以自己设置多少关卡 s.initsnake() //初始化 barr1.setbarrier() //障碍物 s.playgame() //玩游戏开始 if FLAG==false&#123; //这个代表蛇死亡返回的，所以这样就退出了 Clib.GotoPostion(46,21) fmt.Printf("你已死亡，第%d关总分：%d分",k, score) break &#125; Clib.GotoPostion(46,21) fmt.Printf("第%d关总分：%d分,稍等进入下一关",k, score) //key++ time.Sleep(time.Second * 5) //延时5秒 Clib.Cls() //每一关清屏一下 //size=2 score=0 //每一关分数置为0 &#125; time.Sleep(time.Second * 5) //延时5秒&#125;]]></content>
      <categories>
        <category>GO语言</category>
      </categories>
      <tags>
        <tag>小Demo</tag>
        <tag>go语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C语言贪食蛇实现]]></title>
    <url>%2F2018%2F09%2F05%2FC%E8%AF%AD%E8%A8%80%E8%B4%AA%E9%A3%9F%E8%9B%87%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[CSDN博客 贪食蛇小Demo我们先来看一下C语言的贪食蛇代码，相对于面向对象的的语言，C语言是一门面向过程的语言，C语言写出来的代码都是顺着平常的思路来一步一步实现的，我们先来看C语言的代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;windows.h&gt;#include&lt;time.h&gt;//函数声明区void Pos(int x, int y);//光标位置设定void muban();//打印模板void initSnake();//蛇身的初始化void creatFood();//创建食物char reDirection();//识别方向int snakeMove();//蛇移动int crossWall();//不能穿墙int eatSelf();//不能吃自己typedef struct Snake//相当于蛇一个节点&#123; int x;//横坐标 int y;//纵坐标 struct Snake *next;&#125;snake;snake *head;//头指针snake *p;//用来遍历snake *food1;//用来标记的char status='L';//初始方向的状态，解决开始会动的问题int score=0;//分数int add=10;//一个食物的分int leap=0;//用来标志是否结束，0没有，1代表蛇死了代表结束了int endleap=0;//结束标志 1就是结束int sleepTime=500;void initSnake()//蛇身初始化，给定一个长度，用结构体表示是蛇的骨架，真正要显示出来是打印▇&#123; int i; snake *tail;//尾指针 tail=(snake*)malloc(sizeof(snake));//第一个节点/头结点 tail-&gt;x=30;//2的倍数，因为方块的长是两个单位 tail-&gt;y=10;//1个单位 tail-&gt;next=NULL; for(i=1;i&lt;=4;i++)//尾插法 &#123; head=(snake*)malloc(sizeof(snake));//申请一个节点 head-&gt;next=tail;//连接成链 head-&gt;x=30-2*i;//下一个节点的位置 head-&gt;y=10; tail=head; &#125; //遍历打印出来 while(tail!=NULL) &#123; Pos(tail-&gt;x,tail-&gt;y); printf("▇"); tail=tail-&gt;next; &#125;&#125;char reDirection()//识别用户按下的键值 保留方向值&#123; if(GetAsyncKeyState(VK_F7))//热键 &#123; if(sleepTime&gt;300)//最多减到300 &#123; sleepTime-=50;//每次减50 add++;//每次食物加1分 &#125; &#125; if(GetAsyncKeyState(VK_F8)) &#123; if(sleepTime&lt;800)//最多加到800 &#123; sleepTime+=50;//每次加50 add--;//每次食物减1分 &#125; &#125; if(GetAsyncKeyState(VK_UP)&amp;&amp;status!='D') status='U'; if(GetAsyncKeyState(VK_DOWN)&amp;&amp;status!='U') status='D'; if(GetAsyncKeyState(VK_LEFT)&amp;&amp;status!='R') status='L'; if(GetAsyncKeyState(VK_RIGHT)&amp;&amp;status!='L') status='R'; return status;&#125;void Pos(int x, int y)//设置光标位置，从哪里开始输出&#123; COORD pos;//表示一个字符在控制台屏幕上的坐标，左上角(0,0) HANDLE hOutput; pos.X = x; pos.Y = y; hOutput = GetStdHandle(STD_OUTPUT_HANDLE);//返回标准的输入、输出或错误的设备的句柄，也就是获得输入、输出/错误的屏幕缓冲区的句柄 SetConsoleCursorPosition(hOutput, pos);&#125;void creatFood()//创建食物&#123; snake *food;//创造一个食物 food=(snake*)malloc(sizeof(snake)); srand((unsigned int)time(NULL));//随着时间变化，产生不一样种子，就会得到没规律的食物 while(food-&gt;x%2!=0) &#123; food-&gt;x=rand()%56+2; &#125; food-&gt;y=rand()%23+1; //上面虽然解决了食物不会出现在城墙里，没有考虑食物出现在蛇本身里面 p=head;//用p来遍历 while(p!=NULL)//解决食物出现在蛇本身 &#123; if(food-&gt;x==p-&gt;x&amp;&amp;food-&gt;y==p-&gt;y) &#123; free(food); creatFood(); &#125; p=p-&gt;next; &#125; Pos(food-&gt;x,food-&gt;y); food1=food;//food1用来标记的作用 printf("▇"); Pos(70,20);//解决有光标闪烁的办法 printf("您的分数是:%d",score);&#125;void muban()&#123; int i; for(i=0;i&lt;=60;i+=2)//方块水平方向占两个单位 &#123; Pos(i,0); printf("▇");//上行 Pos(i,26); printf("▇");//下行 &#125; for(i=0;i&lt;=25;i+=1)//方块垂直方向占1个单位 &#123; Pos(0,i);//左列 printf("▇"); Pos(60,i);//右列 printf("▇"); &#125;&#125;int snakeMove()&#123; snake *nexthead; nexthead=(snake*)malloc(sizeof(snake)); if(status=='R')//向右走 &#123; nexthead-&gt;x=head-&gt;x+2; nexthead-&gt;y=head-&gt;y; if(nexthead-&gt;x==food1-&gt;x&amp;&amp;nexthead-&gt;y==food1-&gt;y)//吃掉了食物 &#123; nexthead-&gt;next=head; head=nexthead; p=head;//p用来从头遍历，打印方块 while(p!=NULL) &#123; Pos(p-&gt;x,p-&gt;y); printf("▇"); p=p-&gt;next; &#125;//吃掉了食物得创造 score=score+add; creatFood(); &#125; else//没有食物 &#123; nexthead-&gt;next=head; head=nexthead; p=head;//p用来从头遍历，打印方块 while(p-&gt;next-&gt;next!=NULL) &#123; Pos(p-&gt;x,p-&gt;y); printf("▇"); p=p-&gt;next; &#125; Pos(p-&gt;next-&gt;x,p-&gt;next-&gt;y); printf(" ");//会带来一个光标闪烁 Pos(70,20);//解决办法 printf("您的分数是:%d",score); free(p-&gt;next); p-&gt;next=NULL; &#125; &#125; if(status=='L')//向左走 &#123; nexthead-&gt;x=head-&gt;x-2; nexthead-&gt;y=head-&gt;y; if(nexthead-&gt;x==food1-&gt;x&amp;&amp;nexthead-&gt;y==food1-&gt;y)//吃掉了食物 &#123; nexthead-&gt;next=head; head=nexthead; p=head;//p用来从头遍历，打印方块 while(p!=NULL) &#123; Pos(p-&gt;x,p-&gt;y); printf("▇"); p=p-&gt;next; &#125;//吃掉了食物得创造 score=score+add; creatFood(); &#125; else//没有食物 &#123; nexthead-&gt;next=head; head=nexthead; p=head;//p用来从头遍历，打印方块 while(p-&gt;next-&gt;next!=NULL) &#123; Pos(p-&gt;x,p-&gt;y); printf("▇"); p=p-&gt;next; &#125; Pos(p-&gt;next-&gt;x,p-&gt;next-&gt;y); printf(" "); Pos(70,20);//解决办法 printf("您的分数是:%d",score); free(p-&gt;next); p-&gt;next=NULL; &#125; &#125; if(status=='U')//向上走 &#123; nexthead-&gt;x=head-&gt;x; nexthead-&gt;y=head-&gt;y-1; if(nexthead-&gt;x==food1-&gt;x&amp;&amp;nexthead-&gt;y==food1-&gt;y)//吃掉了食物 &#123; nexthead-&gt;next=head; head=nexthead; p=head;//p用来从头遍历，打印方块 while(p!=NULL) &#123; Pos(p-&gt;x,p-&gt;y); printf("▇"); p=p-&gt;next; &#125;//吃掉了食物得创造 score=score+add; creatFood(); &#125; else//没有食物 &#123; nexthead-&gt;next=head; head=nexthead; p=head;//p用来从头遍历，打印方块 while(p-&gt;next-&gt;next!=NULL) &#123; Pos(p-&gt;x,p-&gt;y); printf("▇"); p=p-&gt;next; &#125; Pos(p-&gt;next-&gt;x,p-&gt;next-&gt;y); printf(" "); Pos(70,20);//解决办法 printf("您的分数是:%d",score); free(p-&gt;next); p-&gt;next=NULL; &#125; &#125; if(status=='D')//向下走 &#123; nexthead-&gt;x=head-&gt;x; nexthead-&gt;y=head-&gt;y+1; if(nexthead-&gt;x==food1-&gt;x&amp;&amp;nexthead-&gt;y==food1-&gt;y)//吃掉了食物 &#123; nexthead-&gt;next=head; head=nexthead; p=head;//p用来从头遍历，打印方块 while(p!=NULL) &#123; Pos(p-&gt;x,p-&gt;y); printf("▇"); p=p-&gt;next; &#125;//吃掉了食物得创造 score=score+add; creatFood(); &#125; else//没有食物 &#123; nexthead-&gt;next=head; head=nexthead; p=head;//p用来从头遍历，打印方块 while(p-&gt;next-&gt;next!=NULL) &#123; Pos(p-&gt;x,p-&gt;y); printf("▇"); p=p-&gt;next; &#125; Pos(p-&gt;next-&gt;x,p-&gt;next-&gt;y); printf(" "); Pos(70,20);//解决办法 printf("您的分数是:%d",score); free(p-&gt;next); p-&gt;next=NULL; &#125; &#125; Sleep(sleepTime);//蛇移动的速度，里面是毫秒，越大速度越慢 status=reDirection();//判别下方向先 if(crossWall()==1||eatSelf()==1) //exit(0);//直接把程序关闭了 endleap=1; return endleap;&#125;int crossWall()//判断蛇有没穿透墙&#123; if(head-&gt;x==0||head-&gt;y==0||head-&gt;x==60||head-&gt;y==25) leap=1; return leap;&#125;int eatSelf()//判断是否咬到了自己&#123; snake *q;//遍历的 q=head-&gt;next; while(q!=NULL) &#123; if(q-&gt;x==head-&gt;x&amp;&amp;head-&gt;y==q-&gt;y) leap=1; q=q-&gt;next; &#125; return leap;&#125;//打印食物的时候会出现光标，解决办法就是引开它int main()&#123; muban();//打印模板 initSnake();//初始化蛇 creatFood();//创建食物 while(1)//死循环，让蛇一直动起来，直到蛇死了 &#123; if(snakeMove()==1)//判断是否结束 &#123; Pos(70,23); printf("蛇死了"); system("pause");//用来暂停 Pos(70,24);//解决press any key to continue 在该地点打印 大家试下 break; &#125; &#125; printf("是否继续游戏，y or n：");//y 继续 if(getch()=='y')//重新游戏 &#123; //蛇一开始就死了，因为全局变量没有恢复原值，仍然保留上一局的值 status='L';//初始方向的状态，解决开始会动的问题 score=0;//分数 add=10;//一个食物的分 leap=0;//用来标志是否结束，0没有，1代表蛇死了代表结束了 endleap=0;//结束标志 1就是结束 sleepTime=500; system("cls");//清理屏幕 main();//自己调用自己 看不一样的编译器，vc6.0允许调用自己 &#125; if(getch()=='n') &#123; Pos(70,25);//定一个位置，再打印press exit(0);//退出程序 &#125; return 0;&#125;//蛇的速度变化，每个食物的分数增加//是否继续游戏//按键的作用 在C语言中，我们利用定义一个一个函数模块来实现蛇的基础实现，然后定义蛇的一个结构体，利用链表的知识来串联蛇身体，来让蛇身连接起来并走动起来。 /*go语言实现的贪食蛇请见博下一章/]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>小Demo</tag>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C和Go相互调用]]></title>
    <url>%2F2018%2F09%2F05%2FC%E5%92%8CGo%E7%9B%B8%E4%BA%92%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[转载处：https://colobu.com/2018/08/28/c-and-go-calling-interaction/ C和Go相互调用C可以调用Go，并且Go可以调用C， 如果更进一步呢， C--&gt;Go--&gt;C 或者 Go--&gt;C--&gt;Go的调用如何实现？ 本文通过两个简单的例子帮助你了解这两种复杂的调用关系。本文不涉及两者之间的复杂的数据转换，官方文章C? Go? Cgo!、wiki/cgo和cmd/cgo有一些介绍。 Go–&gt;C–&gt;GoGo程序调用C实现的函数，然后C实现的函数又调用Go实现的函数。 1、首先，我们新建一个hello.go的文件： hello.go 1`package mainimport "C"import "fmt"//export HelloFromGofunc HelloFromGo() &#123; fmt.Printf("Hello from Go!\n")&#125;` 它定义了一个HelloFromGo函数，注意这个函数是一个纯的Go函数，我们定义它的输出符号为HelloFromGo。 2、接着我们新建一个hello.c的文件： 12345678#include &lt;stdio.h&gt;#include &quot;_cgo_export.h&quot;int helloFromC() &#123; printf(&quot;Hi from C\n&quot;); //call Go function HelloFromGo(); return 0;&#125; 这个c文件定义了一个C函数helloFromC,内部它会调用我们刚才定义的HelloFromGo函数。 这样，我们实现了C调用Go: C--&gt;Go,下面我们再实现Go调用C。 3、最后新建一个main.go文件： 123456789package main/*extern int helloFromC();*/import &quot;C&quot;func main() &#123; //call c function C.helloFromC()&#125; 它调用第二步实现的C函数helloFromC。 运行测试一下： 123$ go run .Hi from CHello from Go! 可以看到，期望的函数调用正常的运行。第一行是C函数的输出，第二行是Go函数的输出。 C–&gt;Go–&gt;C第二个例子演示了C程序调用Go实现的函数，然后Go实现的函数又调用C实现的函数。 1、首先新建一个hello.c文件： 12345#include &lt;stdio.h&gt;int helloFromC() &#123; printf(&quot;Hi from C\n&quot;); return 0;&#125; 它定义了一个纯C实现的函数。 2、接着新建一个hello.go文件： 1234567891011121314// go build -o hello.so -buildmode=c-shared .package main/*extern int helloFromC();*/import &quot;C&quot;import &quot;fmt&quot;//export HelloFromGofunc HelloFromGo() &#123; fmt.Printf(&quot;Hello from Go!\n&quot;) C.helloFromC()&#125;func main() &#123;&#125; 它实现了一个Go函数HelloFromGo,内部实现调用了C实现的函数helloFromC,这样我们就实现了Go--&gt;C。 注意包名设置为package main，并且增加一个空的main函数。 运行go build -o hello.so -buildmode=c-shared .生成一个C可以调用的库，这调命令执行完后会生成hello.so文件和hello.h文件。 3、最后新建一个文件夹，随便起个名字，比如main 将刚才生成的hello.so文件和hello.h文件复制到main文件夹，并在main文件夹中新建一个文件main.c: 123456789#include &lt;stdio.h&gt;#include &quot;hello.h&quot;int main() &#123; printf(&quot;use hello lib from C:\n&quot;); HelloFromGo(); return 0;&#125; 运行gcc -o main main.c hello.so生成可执行文件main, 运行main: 1234$ ./mainuse hello lib from C:Hello from Go!Hi from C 第一行输出来自main.c,第二行来自Go函数，第三行来自hello.c中的C函数，这样我们就实现了C--&gt;Go--C的复杂调用。 C--&gt;Go--&gt;C的状态变量我们来分析第二步中的一个特殊的场景， 为了下面我们好区分，我们给程序标记一下， 记为C1--&gt;Go--&gt;C2, C2的程序修改一下，加入一个状态变量a,并且函数helloFromC中会打印a的地址和值，也会将a加一。 123456#include &lt;stdio.h&gt;int a = 1;int helloFromC() &#123; printf(&quot;Hi from C: %p, %d\n&quot;, &amp;a, a++); return 0;&#125; 然后修改main.c程序,让它既通过Go嗲用C1.helloFromC,又直接调用C1.helloFromC,看看多次调用的时候a的指针是否一致，并且a的值是否有变化。 1234567891011121314#include &lt;stdio.h&gt;#include &quot;hello.h&quot;int main() &#123; printf(&quot;use hello lib from C:\n&quot;); // 1. 直接调用C函数 helloFromC(); // 2. 调用Go函数 HelloFromGo(); // 3. 直接调用C函数 helloFromC(); return 0;&#125; 激动人心的时候到了。我们不同的编译方式会产生不同的结果。 1、gcc -o main main.c hello.so 和第二步相同的编译方式，编译出main并执行， 因为hello.so中包含C1.helloFromC实现，所以可以正常执行。 123456./mainuse hello lib from C:Hi from C: 0x10092a370, 1Hello from Go!Hi from C: 0x10092a370, 2Hi from C: 0x10092a370, 3 可以看到a的指针是同一个值，无论通过Go函数改变还是通过C函数改变都是更改的同一个变量。 nm可以查看生成的main的符号： 1234567nm main U _HelloFromGo0000000100000000 T __mh_execute_header U _helloFromC0000000100000f10 T _main U _printf U dyld_stub_binder U代表这个符号是未定义的符号，通过动态库链接进来。 2、 gcc -o main main.c hello.so ../hello.c 我们编译的时候直接链接hello.c的实现，然后运行main: 123456./mainuse hello lib from C:Hi from C: 0x104888020, 1Hello from Go!Hi from C: 0x1049f7370, 1Hi from C: 0x104888020, 2 可以看到a是不同的两个变量。 nm可以查看生成的main的符号： 12345678nm main U _HelloFromGo0000000100000000 T __mh_execute_header0000000100001020 D _a0000000100000f10 T _helloFromC0000000100000ec0 T _main U _printf U dyld_stub_binder 可以看到_a是初始化的环境变量，_helloFromC的类型是T而不是U,代表它是一个全局的Text符号,这和上一步是不一样的]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>go语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链以太坊相关资料]]></title>
    <url>%2F2018%2F09%2F04%2F%E5%8C%BA%E5%9D%97%E9%93%BE%E4%BB%A5%E5%A4%AA%E5%9D%8A%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99%2F</url>
    <content type="text"><![CDATA[收集整理了一些免费区块链、以太坊技术开发相关的文件，有需要的可以下载，文件链接： web3.js API官方文档中文版：https://pan.baidu.com/s/1hOV9hEzi7hFxJCL4LTvC6g 以太坊官方文档中文版 ：https://pan.baidu.com/s/1ktODJKLMBmkOsi8MPrpIJA 以太坊白皮书中文版 ：https://pan.baidu.com/s/1bzAFnzJ35hlQxJ2J4Oj-Ow Solidity的官方文档中文版 ：https://pan.baidu.com/s/18yp9XjEqAHpiFm2ZSCygHw Truffle的官方文档中文版 ：https://pan.baidu.com/s/1y6SVd7lSLUHK21YF5FzIUQ C#区块链编程指南 ：https://pan.baidu.com/s/1sJPLqp1eQqkG7jmxqwn3EA 区块链技术指南： ：https://pan.baidu.com/s/13cJxAa80I6iMCczA04CZhg 精通比特币中文版： ：https://pan.baidu.com/s/1lz6te3wcQuNJm28rFvBfxg Node.js区块链开发 ：https://pan.baidu.com/s/1Ldpn0DvJ5LgLqwix6eWgyg geth使用指南文档中文版 ：https://pan.baidu.com/s/1M0WxhmumF_fRqzt_cegnag 以太坊DApp开发环境搭建-Ubuntu : https://pan.baidu.com/s/10qL4q-uKooMehv9X2R1qSA 以太坊DApp开发环境搭建-windows ：https://pan.baidu.com/s/1cyYkhIJIFuI2oyxM9Ut0eA 以太坊DApp开发私链搭建-Ubuntu : https://pan.baidu.com/s/1aBOFZT2bCjD2o0EILBWs-g 以太坊DApp开发私链搭建-windows ：https://pan.baidu.com/s/10Y6F1cqUltZNN99aJv9kAA 以太坊ganache CLI命令行参数详解：https://pan.baidu.com/s/1lnknFkwenacaeM4asOcBdg 使用truflle和infura部署以太坊合约：https://pan.baidu.com/s/1PTxSVff2vHSVUihYczRRqw IPFS安装部署与开发环境搭建-windows：https://pan.baidu.com/s/1bnhDvqCoOgAqEBZXMtVbRg EOS.IO教程： EOS智能合约与DApp开发入门：http://t.cn/RealN1W 以太坊教程： 以太坊DApp开发实战入门：http://t.cn/RmeEwxJ 以太坊node.js电商实战：http://t.cn/RnmDmaD C#开发以太坊区块链的教程：http://t.cn/ReYjplC java开发以太坊区块链的教程，web3j开发详解：http://t.cn/RrpULLJ PHP开发以太坊区块链的教程：http://t.cn/RrRAlAO python用web3.py开发以太坊区块链应用的教程：http://t.cn/RdXcpVD]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>以太坊</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链中的双花问题]]></title>
    <url>%2F2018%2F09%2F04%2F%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%AD%E7%9A%84%E5%8F%8C%E8%8A%B1%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[区块链中的“双花”问题我们举个简单的例子，比如你在商场刷卡买东西。这个行为面临三种危险： 首先，刷卡这个行为，验证的是你的信用卡信息，也就是说只要给刷卡机提供同样的信息，就能从你的账户里把钱刷走。没错，很多朋友都听说过，有犯罪组织专门从事复制卡信息的勾当，然后“盗刷”你的卡。在一些不发达国家的小店里刷卡就特别容易中招。 其次，负责记账和结算的卡组织和银行的服务器可能被黑客攻破，造成数据泄露和伪造交易。回想这些年一波又一波某某大公司数据库被黑客攻入的新闻，这危险并非危言耸听。（好吧，认真的geek会说这里用词应该是cracker骇客而非hacker黑客，不过这年头认真的人越来越少了） 最后，还有一种可能，就是用卡人自己可能利用系统网络延迟，在进行第一笔交易、用完所有额度后，趁系统还没记账把额度扣完，立刻进行第二笔交易，形成诈骗。当然目前的结算系统延迟极小，这情况不太可能，不过像在优惠券或者抢购资格这种另外搭建的相对脆弱的系统上还是有可能的。 网上支付也一样，犯罪分子可以用特殊手段（例如木马，伪造WIFI等）截获你跟服务器之间的传递数据，如果商家加密技术太弱的话信息就可能被破解——嗯，某国很多时候数据干脆是不加密的。所以大家才一直被警告不要乱装程序、不要连可疑的WiFi。 区块链是怎么处理这些问题的呢？我们以比特币交易为例，逐条分析。 首先，比特币拥有者想要完成某项交易，比如买手机吧，他会向全网广播：我小A向小B支付1个比特币（嗯，这金额现在大致可以买个5个iPhone 8）。 与这条信息一起的，还有一条加密信息，这条信息是用Hash函数对上一条信息加密生成一个摘要后，再用A的私钥进行加密的（称为私钥“签名”）。 接收到这条信息的B和其他用户先用同样的Hash函数对明文信息生成摘要，再用A的公钥对加密信息进行解密，如果解密得到的摘要与明文生成的摘要相同，便认为信息确实是A发出的，且没有经过篡改。 A的公钥和Hash是公开的，私钥则无法算出，只有A知道，这样就既保证了交易的达成，又保证了A的信息无法被窃取。 其次，由在POW（运算力证明）中胜出的矿工负责这段时间的记账，事先完全无法知道究竟哪个矿工来记账，黑客也就无从黑起，除非碰运气。 最后，在传统系统中因为结算速度极快而不太可能的情况，在比特币网络中反而可能性比较大。因为没有中心化的管理者，交易确认的时间要长很多，使得这种诈骗有可能实现，这就是比特币的double spending双重花费问题，简称“双花”。 对于双花问题，比特币网络，或者说区块链网络，是这么应对的： -每笔交易都需要先确认对应比特币之前的状态，如果它之前已经被标记为花掉，那么新的交易会被拒绝。 -如果先发起一笔交易，在它被确认前，也就是这个时间段的交易还未被记账成区块block时，进行矛盾的第二笔交易，那么在记账时，这些交易会被拒绝。 -上面只是小伎俩，现在tricky的部分开始了。如果诈骗者刻意把第一笔交易向一半网络进行广播，把第二笔交易向另一半网络广播——这个诈骗者智商还挺高——然后两边正好有两个矿工几乎同时取得记账权，把各自记的block发布给大家的话（这个概率很低），网络是不是会混乱呢，区块链的规则是这样的：先选择任意一个账本都可以，这时候原来统一的账本出现了分叉： 但是在两个账本中各只有一笔交易，诈骗者不会有好处。接下来，下一个矿工选择在A基础上继续记账的话，A分支就会比B分支更长，根据区块链的规则，最长的分支会被认可，短的分支会被放弃，账本还是会回归为一个，交易也只有一笔有效： -那么如果这个诈骗犯真的智商非常高，他会这么做：如果是A分支被认可（B也一样），相应交易确认，拿到商品之后，立刻自己变身矿工，争取到连续两次记账权，然后在B分支上连加两个block，就像这样： 于是B分支成为认可的分支，A被舍弃，A分支中的交易不再成立，但他已经拿到商品，诈骗成功。 在B分支落后的情况下要强行让它超过A分支，其实是挺难的，假设诈骗者掌握了全网1%的计算能力，那么他争取到记账权的概率就是1%，两次就是10的负4次方。但这个概率还没有太低。 应对办法呢？建议大家在一笔交易确认后，也就是一个block被记下来之后，再等5个block，也就是等6个block被确认后再把交易对应的商品交付。这样，诈骗者还能追上的概率就几乎为0了。除非…… 如果诈骗者掌握了全网50%以上的计算力，那么，即使落后很多，他追上也只是时间问题，这就是比特币的“51%攻击”。 这就是区块链需要警惕的问题。虽然在比特币网络中，用户已经极多，全网算力总和非常大，如果真掌握50%以上，也不用靠这个诈骗了，挖矿的收益都更高。但是在小的区块链网络中呢？况且，没有50%以上的算力，还是有机会成功的，只是概率低而已。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>双花问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[什么是区块链]]></title>
    <url>%2F2018%2F09%2F04%2F%E4%BB%80%E4%B9%88%E6%98%AF%E5%8C%BA%E5%9D%97%E9%93%BE%2F</url>
    <content type="text"><![CDATA[【定义】区块链（Blockchain）是指通过去中心化和去信任的方式集体维护一个可靠数据库的技术方案。该技术方案让参与系统中的任意多个节点，把一段时间系统内全部信息交流的数据，通过密码学算法计算和记录到一个数据块（block），并且生成该数据块的指纹用于链接（chain）下个数据块和校验，系统所有参与节点来共同认定记录是否为真。 区块链是一种类似于NoSQL（非关系型数据库）这样的技术解决方案统称，并不是某种特定技术，能够通过很多编程语言和架构来实现区块链技术。并且实现区块链的方式种类也有很多，目前常见的包括POW（Proof of Work，工作量证明），POS（Proof of Stake，权益证明），DPOS（Delegate Proof of Stake，股份授权证明机制）等。 区块链的概念首次在论文《比特币：一种点对点的电子现金系统（Bitcoin: A Peer-to-Peer Electronic Cash System）》中提出，作者为自称中本聪（Satoshi Nakamoto）的个人（或团体）。因此可以把比特币看成区块链的首个在金融支付领域中的应用。 【通俗解释】无论多大的系统或者多小的网站，一般在它背后都有数据库。那么这个数据库由谁来维护？在一般情况下，谁负责运营这个网络或者系统，那么就由谁来进行维护。如果是微信数据库肯定是腾讯团队维护，淘宝的数据库就是阿里的团队在维护。大家一定认为这种方式是天经地义的，但是区块链技术却不是这样。 如果我们把数据库想象成是一个账本：比如支付宝就是很典型的账本，任何数据的改变就是记账型的。数据库的维护我们可以认为是很简单的记账方式。在区块链的世界也是这样，区块链系统中的每一个人都有机会参与记账。系统会在一段时间内，可能选择十秒钟内，也可能十分钟，选出这段时间记账最快最好的人，由这个人来记账，他会把这段时间数据库的变化和账本的变化记在一个区块（block）中，我们可以把这个区块想象成一页纸上，系统在确认记录正确后，会把过去账本的数据指纹链接（chain）这张纸上，然后把这张纸发给整个系统里面其他的所有人。然后周而复始，系统会寻找下一个记账又快又好的人，而系统中的其他所有人都会获得整个账本的副本。这也就意味着这个系统每一个人都有一模一样的账本，这种技术，我们就称之为区块链技术（Blockchain），也称为分布式账本技术。 由于每个人（计算机）都有一模一样的账本，并且每个人（计算机）都有着完全相等的权利，因此不会由于单个人（计算机）失去联系或宕机，而导致整个系统崩溃。既然有一模一样的账本，就意味着所有的数据都是公开透明的，每一个人可以看到每一个账户上到底有什么数字变化。它非常有趣的特性就是，其中的数据无法篡改。因为系统会自动比较，会认为相同数量最多的账本是真的账本，少部分和别人数量不一样的账本是虚假的账本。在这种情况下，任何人篡改自己的账本是没有任何意义的，因为除非你能够篡改整个系统里面大部分节点。如果整个系统节点只有五个、十个节点也许还容易做到，但是如果有上万个甚至上十万个，并且还分布在互联网上的任何角落，除非某个人能控制世界上大多数的电脑，否则不太可能篡改这样大型的区块链。 【要素】结合区块链的定义，我们认为必须具有如下四点要素才能被称为公开区块链技术，如果只具有前3点要素，我们将认为其为私有区块链技术（私有链）。 1、点对点的对等网络（权力对等、物理点对点连接） 2、可验证的数据结构（可验证的PKC体系，不可篡改数据库） 3、分布式的共识机制（解决拜占庭将军问题，解决双重支付） 4、纳什均衡的博弈设计（合作是演化稳定的策略） 【特性】结合定义区块链的定义，区块链会现实出四个主要的特性：去中心化（Decentralized）、去信任（Trustless）、集体维护（Collectively maintain）、可靠数据库（Reliable Database）。并且由四个特征会引申出另外2个特征：开源（Open Source）、隐私保护（Anonymity）。如果一个系统不具备这些特征，将不能视其为基于区块链技术的应用。 去中心化（Decentralized）：整个网络没有中心化的硬件或者管理机构，任意节点之间的权利和义务都是均等的，且任一节点的损坏或者失去都会不影响整个系统的运作。因此也可以认为区块链系统具有极好的健壮性。 去信任（Trustless）：参与整个系统中的每个节点之间进行数据交换是无需互相信任的，整个系统的运作规则是公开透明的，所有的数据内容也是公开的，因此在系统指定的规则范围和时间范围内，节点之间是不能也无法欺骗其它节点。 集体维护（Collectively maintain）：系统中的数据块由整个系统中所有具有维护功能的节点来共同维护的，而这些具有维护功能的节点是任何人都可以参与的。 可靠数据库（Reliable Database）：整个系统将通过分数据库的形式，让每个参与节点都能获得一份完整数据库的拷贝。除非能够同时控制整个系统中超过51%的节点，否则单个节点上对数据库的修改是无效的，也无法影响其他节点上的数据内容。因此参与系统中的节点越多和计算能力越强，该系统中的数据安全性越高。 开源（Open Source）：由于整个系统的运作规则必须是公开透明的，所以对于程序而言，整个系统必定会是开源的。 隐私保护（Anonymity）：由于节点和节点之间是无需互相信任的，因此节点和节点之间无需公开身份，在系统中的每个参与的节点的隐私都是受到保护。 【区块链意义之一 ：解决拜占庭将军问题】区块链解决的核心问题不是“数字货币”，而是在信息不对称、不确定的环境下，如何建立满足经济活动赖以发生、发展的“信任”生态体系。而这个问题称之为“拜占庭将军问题”，也可称为“拜占庭容错”或者“两军问题”，这是一个分布式系统中进行信息机交互时面临的难题，即在整个网络中的任意节点都无法信任与之通信的对方时，如何能创建出共识基础来进行安全的信息交互而无需担心数据被篡改。区块链使用算法证明机制来保证整个网络的安全，借助它，整个系统中的所有节点能够在去信任的环境下自动安全的交换数据。更多介绍请参见《比特币与拜占庭将军问题》。 【区块链意义之二：实现跨国价值转移】互联网诞生最初，最早核心解决的问题是信息制造和传输，我们可以通过互联网将信息快速生成并且复制到全世界每一个有着网络的角落，但是它尚始终不能解决价值转移和信用转移。这里所谓的价值转移是指，在网络中每个人都能够认可和确认的方式，将某一部分价值精确的从某一个地址转移到另一个地址，而且必须确保当价值转移后，原来的地址减少了被转移的部分，而新的地址增加了所转移的价值。这里说的价值可以是货币资产，也可以是某种实体资产或者虚拟资产（包括有价证券、金融衍生品等）。而这操作的结果必须获得所有参与方的认可，且其结果不能受到任何某一方的操纵。 在目前的互联网中也有各种各样的金融体系，也有许多政府银行提供或者第三方提供的支付系统，但是它还是依靠中心化的方案来解决。所谓中心化的方案，就是通过某个公司或者政府信用作为背书，将所有的价值转移计算放在一个中心服务器（集群）中，尽管所有的计算也是由程序自动完成，但是却必须信任这个中心化的人或者机构。事实上通过中心化的信用背书来解决，也只能将信用局限在一定的机构、地区或者国家的范围之内。由此可以看出，必须要解决的这个根本问题，那就是信用。所以价值转移的核心问题是跨国信用共识。 在如此纷繁复杂的全球体系中，要凭空建立一个全球性的信用共识体系是很难的，由于每个国家的政治、经济和文化情况不同，对于两个国家的企业和政府完全互信是几乎做不到的，这也就意味着无论是以个人抑或企业政府的信用进行背书，对于跨国之间的价值交换即使可以完成，也有着巨大的时间和经济成本。但是在漫长的人类历史中，无论每个国家的宗教、政治和文化是如何的不同，唯一能取得共识的是数学（基础科学）。因此，可以毫不夸张的说，数学（算法）是全球文明的最大公约数，也是全球人类获得最多共识的基础。如果我们以数学算法（程序）作为背书，所有的规则都建立一个公开透明的数学算法（程序）之上，能够让所有不同政治文化背景的人群获得共识。 【未来的发展】互联网将使得全球之间的互动越来越紧密，伴随而来的就是巨大的信任鸿沟。目前现有的主流数据库技术架构都是私密且中心化的，在这个架构上是永远无法解决价值转移和互信问题。所以区块链技术有可能将成为下一代数据库架构。通过去中心化技术，将能够在大数据的基础上完成数学（算法）背书、全球互信这个巨大的进步。 区块链技术作为一种特定分布式存取数据技术，它通过网络中多个参与计算的节点开共同参与数据的计算和记录，并且互相验证其信息的有效性（防伪）。从这一点来，区块链技术也是一种特定的数据库技术。互联网刚刚进入大数据时代，但是从目前来看，大数据还处于非常基础的阶段。但是当进入到区块链数据库阶段，将进入到真正的强信任背书的大数据时代。这里面的所有数据都获得坚不可摧的质量，任何人都没有能力也没有必要去质疑。 也许我们现在正处在一个重大的转折点之上——和工业革命所带来的深刻变革几乎相同的重大转折的早期阶段。不仅仅是新技术指数级、数字化和组合式的进步与变革，更多的惊喜也许还会在我们前面。在未来的24个月里，这个星球所增长的计算机算力和记录的数据将会超过所有历史阶段的总和。在过去的24个月里，这个增值可能已经超过了1000倍。这些数字化的数据信息还在以比摩尔定律更快的速度增长。区块链技术将不仅仅应用在金融支付领域，而是将会扩展到目前所有应用范围，诸如去中心化的微博、微信、搜索、租房，甚至是打车软件都有可能会出现。因为区块链将可以让人类无地域限制的、去信任的方式来进行大规模协作。 我们这一代人将很可能会幸运地经历人类历史上两个最让人吃惊的事件，地球上的所有人和所有机器通过区块链技术以前所未有的互信展开了空前的大规模协作，其次就是基于此真正的人工智能将被创造出来。这两个时间将会深深地改变这个世界的经济发展模式。创业者、企业家、科学家以及各种各样的极客将利用这个充裕的世界去创造能让我们震惊和快乐。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[拜占庭将军问题]]></title>
    <url>%2F2018%2F09%2F04%2F%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%B0%86%E5%86%9B%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[拜占庭将军问题（Byzantine failures）是由莱斯利·兰伯特提出的点对点通信中的基本问题。含义是在存在消息丢失的不可靠信道上试图通过消息传递的方式达到一致性是不可能的。因此对一致性的研究一般假设信道是可靠的，或不存在本问题。这个难题也被称为“拜占庭容错”、“拜占庭将军问题”、或者“两军问题”。 拜占庭将军问题是一个协议问题，拜占庭帝国军队的将军们必须全体一致的决定是否攻击某一支敌军。问题是这些将军在地理上是分隔开来的，并且将军中存在叛徒。叛徒可以任意行动以达到以下目标：欺骗某些将军采取进攻行动；促成一个不是所有将军都同意的决定，如当将军们不希望进攻时促成进攻行动；或者迷惑某些将军，使他们无法做出决定。如果叛徒达到了这些目的之一，则任何攻击行动的结果都是注定要失败的，只有完全达成一致的努力才能获得胜利。 拜占庭假设是对现实世界的模型化，由于硬件错误、网络拥塞或断开以及遭到恶意攻击，计算机和网络可能出现不可预料的行为。拜占庭容错协议必须处理这些失效，并且这些协议还要满足所要解决的问题要求的规范。 首先，不要把比特币当成一种货币，而是一个总账。它是个电子账本，网络上的每一个参与者的电脑都会有一份账本的备份，并且所有的备份都是在实时的持续的更新、对账、以及同步着。每一个参与者都能在这本账本里记上一笔，这一笔记录着一定数量的币从一个参与者那里被发送到另一个参与者那里，并且每一条这样的记录都接着就实时的广播到网络了，所以在每一台电脑上的每一分份拷贝都是几乎同时更新的，并且所有的账本拷贝都保持着同步。这本公开的分布式的账本就可以称为“区块链（blockchain）”，并且它使用了BT技术以保证所有的拷贝都是同步的。 可以把比特币当作一个对于在分布式系统领域的一个复杂的算法难题的通用解决方法。 这一问题的趣味非正式表述如下：想象一下，在拜占庭时代有一个墙高壁厚的城邦，拜占庭，高墙之内是它的邻居想象不到之多的财富。它被其他10个城邦所环绕，这10个城邦也很富饶，但和拜占庭相比就微不足道了。它的十个邻居都觊觎拜占庭的财富，并希望侵略并占领它。 但是，拜占庭的防御是如此的强大，没有一个相邻的城邦能够成功入侵。任何单个城邦的入侵行动都会失败，而入侵者的军队也会被歼灭，使得其自身容易遭到其他九个城邦的入侵和劫掠。这十个城邦之间也互相觊觎对方的财富并持续互相对抗着。而且，拜占庭的防御如此之强，十个邻居的一半以上同时进攻才能攻破它。 也就是说，如果六个或者更多的相邻敌军一起进攻，他们就会成功并获得拜占庭的财富。然而，如果其中有一个或者更多背叛了其他人，答应一起入侵但在其他人进攻的时候又不干了，也就导致只有五支或者更少的军队在同时进攻，那么所有的进攻军队都会被歼灭，并随后被其他的（包括背叛他们的那（几）个）邻居所劫掠。这是一个由不互相信任的各方构成的网络，但他们又必须一起努力以完成共同的使命。 而且，是个邻居之间通讯和协调统计时间的唯一途径是通过骑马在他们之间传递信息。他们不能聚在一个地方开个会（所有的王都不互相信任他们的安全在自己的城堡或者军队范围之外能够得到保障）。然而，他们可以在任意时间以任意频率派出任意数量的信使到任意的对方。每条信息都包含类似如下的内容：“我将在第四天的6点钟进攻，你愿意加入吗？”。 如果收信人同意了，他们就会在原信上附上一份签名了的/认证了的/盖了图章的/验证了的回应，然后把新合并了的信息的拷贝再次发送给九个邻居，要求他们也如此这样做。最后的目标是，通过在原始信息链上盖上他们所有十个人的图章，让他们在时间上达成共识。最后的结果是，会有一个盖有十个同意同一时间的图章信息链，可能还会有一些被抛弃了的包含部分但不是全部图章的信息链。 但是，问题在于如果每个城邦向其他九个城邦派出一名信使，那么就是十个城邦每个派出了九名信使，也就是在任何一个时间又总计90次的传输，并且每个城市分别收到九个信息，可能每一封都写着不同的进攻时间。除此以外，部分城邦会答应超过一个的攻击时间，故意背叛发起人，所以他们将重新广播超过一条的信息链。这个系统迅速变质成不可信的信息和攻击时间相互矛盾的纠结体。 比特币通过对这个系统做出一个简单的（事后看是简单的）修改解决了这个问题，它为发送信息加入了成本，这降低了信息传递的速率，并加入了一个随机元素以保证在一个时间只有一个城邦可以进行广播。它加入的成本是“工作量证明”，并且它是基于计算一个随机哈希算法的。哈希是一种算法，它唯一做的事情就是获得一些输入然后进行计算，并得到一串64位的随机数字和字母的字符串，就像这个： 1d70298566aa2f1a66d892dc31fedce6147b5bf509e28d29627078d9a01a8f86b 在比特币的世界中，输入数据包括了到当前时间点的整个总账（区块链）。并且尽管单个哈希值用现在的计算机可以几乎即时的计算出来，但只有一个前13个字符是0的哈希值结果可以被比特币系统接受成为“工作量证明”。这样一个13个0的哈希值是极其不可能与罕见的，并且在当前需要花费整个比特币网络大约10分钟的时间来找到一个。在一台网络中的机器随机的找到一个有效哈希值之前，上十亿个的无效值会被计算出来，这就是减慢信息传递速率并使得整个系统可用的“工作量证明”。下面是一个例子： 123f51d0199c4a6d9f6da230b579d850698dff6f695b47d868cc1165c0ce74df5e1d70298566aa2f1a66d892dc31fedce6147b5bf509e28d29627078d9a01a8f86b119c506ceaa18a973a5dbcfbf23253bc970114edd1063bd1288fbba468dcb7f8 在找到一个有效值之前，成百万上亿个更多的类似上面这样的字符串被计算出来…… 1000000000000084b6550604bf21ad8a955b945a0f78c3408c5002af3cdcc14f5 那台发现下一个有效哈希值的机器（或者说在我们类比中的城邦），把所有的之前的信息放到一起，附上它自己的，以及它的签名/印章/诸如此类，并向网络中的其他机器广播出去。只要其他网络中的机器接收到并验证通过了这个13个0的哈希值和附着在上面的信息，他们就会停止他们当下的计算，使用新的信息更新他们的总账拷贝，然后把新更新的总账/区块链作为哈希算法的输入，再次开始计算哈希值。哈希计算竞赛从一个新的开始点重新开始。如此这般，网络持续同步着，所有网络上的电脑都使用着同一版本的总账。 与此同时，每一次成功找到有效哈希值以及区块链更新的间隔大概是10分钟（这是故意的，算法难度每两周调整一次以保证网络一直需要花费10分钟来找到一个有效的哈希值）。在那10分钟以内，网络上的参与者发送信息并完成交易，并且因为网络上的每一条机器都是使用同一个总账，所有的这些交易和信息都会进入遍布全网的每一份总账拷贝。当区块链更新并在全网同步之后，所有的在之前的10分钟内进入区块链的交易也被更新并同步了。因此分散的交易记录是在所有的参与者之间进行对账和同步的。 最后，在个人向网络输入一笔交易的时候，他们使用内嵌在比特币客户端的标准公钥加密工具来同时他们的私钥以及接收者的公钥来为这笔交易签名。这对应于拜占庭将军问题中他们用来签名和验证消息时使用的“印章”。因此，哈希计算速率的限制，加上公钥加密，使得一个不可信网络变成了一个可信的网络，使得所有参与者可以在某些事情上达成一致（比如说攻击时间、或者一系列的交易、域名记录、政治投票系统、或者任何其他的需要分布式协议的地方）。 这里是比特币为何如此特别的关键：它代表了一个对于一个困难的算法上的难题的解决方案，这一解决方案在一系列的历史事件发生之前是不可能的，这些事件有： 互联网的创造 公钥加密算法的发明 点对点Bitorrent(BT)协议的发明。BT协议最开始是开发来用于在网络上的相对小的用户子集之间共享许多文件的，但比特币用它来在所有用户之间共享单个文件。 人们意识到，在系统中添加一个简单的时间延迟，同时使用公钥加密算法以验证每笔交易，可以解决这个问题。 如果说一些最棒的想法在事后看来是很简单的，那么上述的第四点就完全符合条件，尽管整个项目是站在了巨人的肩膀上的。 最后，这一对于拜占庭将军问题的解决方案，可以推广到任何核心问题是在分布式网络上缺乏信任的领域。如我们已经提到乐的，人们正在为互联网建设一个分布式的域名系统，以及为政治选举建设分布式的投票系统（还没有网站）。如果人们认为单纯的文件分享搅乱了这个世界，那么比特币解决方案和协议才刚刚打开洪水的闸门。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>拜占庭将军问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[队列的链式存储结构]]></title>
    <url>%2F2018%2F09%2F04%2F%E9%98%9F%E5%88%97%E7%9A%84%E9%93%BE%E5%BC%8F%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[队列的链式存储结构，其实就是线性表的单链表，只不过它只能尾进头出而已，我们把它简称为链队列。 为了操作上的方便，我们将队头指针指向链队列的头结点，而队尾指针指向终端结点。链队列示意图： 当队列为空时，front和rear都指向头结点 实例代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package mainimport ( "errors" "fmt")type qelemType int//数据节点(链表形式)type QNode struct &#123; data qelemType next *QNode&#125;type queuePtr *QNode//定义队列type LinkQueue struct &#123; front, rear queuePtr&#125;//创建头结点func createHeadNode(q *LinkQueue) &#123; s := queuePtr(new(QNode)) s.next = nil q.front = s q.rear = s&#125;//如队列操作func enQueue(q *LinkQueue, e qelemType) &#123; s := queuePtr(new(QNode)) s.data = e s.next = nil //队尾为空 q.rear.next = s q.rear = s //rear指向新添加的数据（保证指向最后一个元素）&#125;//出队列func deQueue(q *LinkQueue) (err error, res qelemType) &#123; if q.front == q.rear &#123; err = errors.New("队列为空，没有数据出队列") return &#125; s := q.front.next res = s.data q.front.next = s.next if q.rear == s &#123; q.rear = q.front &#125; return&#125;func main() &#123; var p LinkQueue /* 注意 需要创建头结点，不然头结点为空，操作它的.next 会发生异常,异常信息如下： panic: runtime error: invalid memory address or nil pointer dereference [signal 0xc0000005 code=0x0 addr=0x0 pc=0x48b5c9] */ createHeadNode(&amp;p) enQueue(&amp;p, qelemType(123)) enQueue(&amp;p, qelemType(345)) enQueue(&amp;p, qelemType(567)) _, res := deQueue(&amp;p) fmt.Println(res) _, res = deQueue(&amp;p) fmt.Println(res) _, res = deQueue(&amp;p) fmt.Println(res) err, res := deQueue(&amp;p) fmt.Println(err, res)&#125; 运行效果：]]></content>
      <categories>
        <category>数据结构和算法</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>单链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go语言之陷阱for range]]></title>
    <url>%2F2018%2F09%2F04%2Fgo%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%99%B7%E9%98%B1for-range%2F</url>
    <content type="text"><![CDATA[在go语言中，遍历有两种方法，一种就是for的普通方法，还有一种就是for range的遍历，但是在使用for range时，如果使用不当，就会出现一些问题比如我们下面先来看一个例题 123456789101112131415161718192021package mainimport "fmt"type Student struct&#123; Name string Age int&#125; //一个学生结构体func main()&#123; m:=make(map[string]*Student) //声明一个映射 stus:=[]Student&#123; &#123;"宋",22&#125;, &#123;"高",23&#125;, &#123;"徐",24&#125;, &#123;"李",25&#125;, &#125; //一个学生类切片 for _,stu:=range stus&#123; m[stu.Name]=&amp;stu //遍历赋值给映射 &#125; for _,value:=range m&#123; fmt.Println(*value) //遍历打印出来 &#125;&#125; 我们的代码是把stus这个结构体切片里面的内容用for range赋值给m映射，看起来代码好像没什么问题，一次循环赋值一次循环打印，那我们来看一下打印结果是什么 打印结果竟然是这样，为什么都是一样的呢，而且是结构体切片最后的一个元素，看下面这张图 这是因为我们第一次使用for range遍历的时候 我们是使用零时变量stu的地址来传给m的，而且零时变量stu每次的地址都是不会变的，所以一直到遍历最后一次就会把最后一个值的地址传给m，这就导致了m里面的值都是一样，我们可以试着来打印一下地址来看看 我们先来打印一下m看看 看到没，这四个地址竟然都是一样的，这就是因为用stu零时变量去地址去传的话地址都是一样的，那样传值就达不到预期的效果，所以一定要小心这个陷阱，那我们上面应该怎样改就可以完整的传值呢 看到没，我们可以在for range里面弄一个stu1来接受零时变量stu的值，然后取stu1的地址传值，这样就不会出错啦，我们来看看打印结果 这样我们每次的地址也不一样了，打印出来的结果也就正确达到预期的结果了，因为map是无序的所以打印出来也是无序的，切忌用for range的时候小心陷阱]]></content>
      <categories>
        <category>GO语言</category>
      </categories>
      <tags>
        <tag>go语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go语言错误捕获和panic异常]]></title>
    <url>%2F2018%2F09%2F04%2Fgo%E8%AF%AD%E8%A8%80%E9%94%99%E8%AF%AF%E6%8D%95%E8%8E%B7%E5%92%8Cpanic%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[在Go语言中我们首先来看一下err错误信息，我们先来看一段代码 123456789101112131415161718192021222324252627package mainimport ( "fmt" "errors")func calc(a int, b int) (v int, err error) &#123; //捕获错误信息 if b == 0 &#123; //如果代码中出现错误 可以使用errors.New()创建错误信息 err = errors.New("除数不能为0") return &#125; v = a / b return&#125;func main() &#123; a := 10 b := 0 v, err := calc(a, b) //根据错误信息进行处理 if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Println(v) &#125; //fmt.Println(v)&#125; 在这里我们可以接收到错误信息并打印出来，我们先看一下会报错吗？结果显示部会报错的，因为我们接收到了错误并打印出来了 我们看这里并没有报错，而是打印出了错误 信息， 在Go中我们还可以直接调用panic函数来终止程序， 我们来看这张图，这张图里面我们给数组定义为10个长度，然后下面直接调用下标为10的数组，这样会出什么错误呢，这样就是数组下标超出范围，因为数组下标是从0开始到长度减一，我们来看一下编译器运行的结果报什么错， 编译提示panic异常，然后提示数组下标越界，这是因为当我们写程序时，比如遇到一些错误比如：数组下标越界，空指针异常，野指针这些错误的时候，系统就会调用自己本身的panic函数，那么我们自己在写程序的时候也是可以调用panic函数的，下面来看这段代码 12345678910111213package mainimport "fmt"func main() &#123; fmt.Println("hello world1") fmt.Println("hello world2") fmt.Println("hello world3") //程序可以运行 但是遇到panic停止 //当程序遇到panic时 会自动崩溃 panic("终止程序") fmt.Println("hello world4") fmt.Println("hello world5") fmt.Println("hello world6")&#125; 我们来看一下运行结果 在这里我们看到，只打印了上面的三句话，当遇到panic函数的时候就会程序崩溃，然后下面的程序停止执行，我们不仅仅可以使用panic来终止程序，我们还可以捕获错误后继续执行程序，我们来看下一段代码 12345678910111213141516171819202122package mainimport "fmt"func test(i int) &#123; var arr [10]int //优先使用错误拦截 在错误出现之前进行拦截 在错误出现后进行错误捕获 //错误拦截必须配合defer使用 通过匿名函数使用 defer func() &#123; //恢复程序的控制权 err := recover() if err != nil &#123; fmt.Println(err) &#125; &#125;() arr[i] = 123 //err panic fmt.Println(arr)&#125;func main() &#123; i := 10 test(i) fmt.Println("hello world")&#125; 看这段代码，然后我们来看一下运行结果 第一句话直接打印出了错误：运行时错误，数组下标越界，但是程序并没有终止而是继续运行下去了这是为什么了， 如图所示，这里我们延迟调用了一下，因为recover必须和defer配合使用，并且调用一定要在错误出现之前调用才有效果，这样捕获到了错误并且恢复了程序的控制权。]]></content>
      <categories>
        <category>GO语言</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>错误捕获</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go语言切片深入讲解]]></title>
    <url>%2F2018%2F09%2F03%2Fgo%E8%AF%AD%E8%A8%80%E5%88%87%E7%89%87%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[我们在上一篇的切片讲解中，我们讲解到在go语言中 map和切片都是传引用（地址），也就是在调用函数的时候都是可以直接修改变量的值，关于切片，在某种程度上表面上来说也是可以这样说的，我们先来看一下一个小小的例题 1234567891011package mainimport &quot;fmt&quot;func Change(s []int)&#123; s[0]=11 s[1]=22&#125;func main()&#123; slice:=[]int&#123;1,2,3,4,5&#125; Change(slice) fmt.Println(slice)&#125; 我们先来看一下结果 我们可以看到切片当作函数参数的时候调用之后值确实改变了，这也间接的可以认为切片是地址传递，但是我们想要了解的更深入的话可以继续了解下去 我们继续来看一个小例子 123456789101112package mainimport "fmt"func Add(s []int)&#123; s=append(s,6,7,8)&#125;func main()&#123; slice:=[]int&#123;1,2,3,4,5&#125; Add(slice) fmt.Println(slice)&#125; 在这里函数调用了append这个函数来增加切片的个数， 我们可以清晰的看到打印的结果并没有变，我们在之前讲到过这里是因为append扩容使得地址发生了变化，所以不是指向原来的切片也就导致了并不是在原来的切片上面增加了，这就说到了切片的本质，在这里详细说一下，切片的本质不是指向数组的指针，而是一种新定义的一种数据结构，这个数据结构里面包含一个指针，len，还有cap， 12345type slice struct &#123; *Pointer len cap &#125; 看到没，切片的本质是这样一个数据结构，而且在函数调用的时候切片做的其实是一个值的传递！！！只不过这个值是一个包含指针，长度，容量的一个结构体的值，这样我们一想就可以一目了然的知道了为什么前面我们所说的切片是地址传递了吧，那是因为他传的那个值里面包含一个指针，所以函数调用的时候就可以用这个值里面的指针来操作原来的切片，我们看如下的一张图片， 我们看上面的图就可以更加的明白了，在函数调用的时候首先，在栈区里面main函数会得到一块内存（栈帧），然后调用testFunc函数的时候testFunc也会得到一块内存（栈帧），然后调用的时候把切片的值传递给形参，注意这里的值是包含一个指针，长度，容量的结构体值，我们在使用一般操作的时候不会改变那个地址，所以会正常操作main函数里面的切片，当我们使用append函数的时候就会导致保存的指针值发生变化，那样就会保存一个新的地址，操作也会在新的地方操作，这样的话原来的切片就不会发生变化，当testFunc函数调用完毕后，我们的testFunc函数就会释放，而原来的切片也没有得到改变，这就是我们所看到的，这才是切片的本质 所以最后得到的总结就是：切片当作参数传递的时候是值传递，但是这个值不是一个普通的值，而是一个包含指针，长度，容量的值，如果有不懂的也可以尝试着去看一看源码。 附图：（内存的微讲解）]]></content>
      <categories>
        <category>GO语言</category>
      </categories>
      <tags>
        <tag>go语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go语言切片微讲解]]></title>
    <url>%2F2018%2F09%2F03%2Fgo%E8%AF%AD%E8%A8%80%E5%88%87%E7%89%87%E5%BE%AE%E8%AE%B2%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[传递参数时分为值传递和地址传递，go语言中切片和map是地址传递，但是切片传递要有一个注意事项 例如： 123456789package mainfunc test(a []int)&#123; a=append(a,1,2,3)&#125;func main()&#123; var s []int=[]int&#123;89,4,5,6&#125; test(s) fmt.Println(s)&#125; 在这里里面为什么调用函数后切片没有变化呢，切片不是地址传递吗？这是因为在test函数里面用了append()函数,在调用函数时，在栈区里面把1 2 3 添加到a里面然后重新分配了地址，而原来的s切片还是指向原来地址，根本没有变，所以在main函数里面打印出s还是原来的，不会改变，那么如何做到用了append后改变原来切片的值呢 如下 1234567891011package mainimport "fmt"func test(a []int)(b []int)&#123; b=append(a,1,2,3,7) return&#125;func main()&#123; var s []int=[]int&#123;9,10&#125; s=test(s) fmt.Println(s)&#125; 我们可以用return 把改变后的地址传回去这样就可以了 切片用append函数的时候一定要注意，因为如果容量不足的时候会自动扩充，如果原来的地址后面没有足够的空间那么就会重新找一个足够大的空间来储存，所以切片利用append的时候地址是有可能变化的。]]></content>
      <categories>
        <category>GO语言</category>
      </categories>
      <tags>
        <tag>go语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[插入排序]]></title>
    <url>%2F2018%2F09%2F02%2F%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[插入排序在上一章中我们讲了算法排序中的最简单的冒泡排序，今天我们来讲解一下插入排序，后续将讲解快速排序，归并排序，希尔排序，二叉排序，这些等等，后续的排序都是在时间复杂度和空间复杂度上面优于这两种的，所以我们今天先来讲解一下插入排序 我们先来看以下的一张图 为了方便排序，我们一般将数据的第一个元素作为有序组，其他视为待插入组，图中以升序为例子进行讲解。 我们将第一个元素作为有序的数组，然后将后面的元素视为无序的，将后面的无序组第一个元素和有序组最后一个元素比较，如果符合要求就插入进去然后有序组就多一个，无序组就少一个 第二次排序的时候有序组就为两个元素，有序组的最后一个元素拿出来继续和无序组的第一个相比，然后再插入一个，这样有序组就又多了一个，无序组少一个 这样一直循环到某个条件，这样无序组就没有了，剩下的都是有序组，这样排序就完成了。 我们来看一下代码怎样实现，在这里我们就用GO语言来实现，在某些方面个人觉得go写的代码比C/C++要少很多，更加方便一点 12345678910111213141516package mainimport "fmt"func main() &#123; var arr [10]int = [10]int&#123;9, 1, 3, 4, 7, 5, 2, 10, 11, 8&#125; //插入排序 var temp ,j int //临时变量temp for i := 1; i &lt; len(arr); i++ &#123; //遍历无序数组,下标1开始 if arr[i] &lt; arr[i-1] &#123; //无序组第一个小于有序组最后一个才进入否则直接下一个元素 temp=arr[i] //用变量temp取出arr[i]的元素值 for j=i-1;j&gt;=0&amp;&amp;arr[j]&gt;temp;j--&#123; //这里面temp不能写成arr[i]是因为下面 arr[j+1]=arr[j] // 有一个arr[j+1]=arr[j]那样会导致arr[i]会变 &#125; arr[j+1]=temp //因为上面经过了j--所以这里需要arr[j+1]，for循环后就找到位置填充temp，也就是之前取出来的arr[i] &#125; &#125; fmt.Println(arr)&#125; 下面你可以自己去实现一下了，后续将讲解更难的排序方法。]]></content>
      <categories>
        <category>数据结构和算法</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>排序问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode|无重复字符的最长子串]]></title>
    <url>%2F2018%2F09%2F02%2F%E6%AF%8F%E6%97%A5%E4%B8%80%E9%81%93%E7%BC%96%E7%A8%8B%E7%AE%97%E6%B3%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[今天的题目为： 给定一个字符串，找出不含有重复字符的最长子串的长度。 示例 1: 123输入: &quot;abcabcbb&quot;输出: 3 解释: 无重复字符的最长子串是 &quot;abc&quot;，其长度为 3。 示例 2: 123输入: &quot;bbbbb&quot;输出: 1解释: 无重复字符的最长子串是 &quot;b&quot;，其长度为 1。 示例 3: 1234输入: "pwwkew"输出: 3解释: 无重复字符的最长子串是 "wke"，其长度为 3。 请注意，答案必须是一个子串，"pwke" 是一个子序列 而不是子串。 首先来思路分析：我们可以先第一次把所有不重复的字符串分割一下保存下来，这样就可以找到这一次的不重复的子字符串最长的 然后在一次一次往后面移动，这样就可以找出所有不重复的子字符串，最后再求出最大值。 比如： abcd ahjiklo字符串 我们第一次从头开始寻找，找到不重复的子字符串，那就有两个，一个为abcd另外一个为ahjiklo,如果单单重上面看那么最长的不重复子字符串就是ahjiklo，但是我们需要的不是这个，那么我们就需要再循环一次，每次把第一个字符去掉然后再寻找，比如这一次把a去掉那么找出的最长子字符串就是bcdahjiklo，这个是最长的，然后再把本次的第一个字符去掉一直循环，这样到最后找出最长的子字符串， 复杂度分析：当然，这种方法可以算是一种暴力解决的方法，没有什么技巧性，时间复杂度也是最复杂的，O（n3）的复杂度，当然如果想要优化的话可以自己去研究一下奥。 代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344package mainimport "fmt"func lengthOfLongestSubstring(str string) int &#123; //每次求出的最大值返回 s:=[]byte(str) //先把字符串转为byte类型的切片 slice:=make([]string,0)//ased//aerfch//risdud //定义一个字符串切片，可以把无重复的字符串字段保存进去flag: for i:=0;i&lt;len(s);i++&#123; for j:=i-1;j&gt;=0;j--&#123; if s[i]==s[j]&#123; //这里遍历用来找出无重复字符串段 slice=append(slice,string(s[:i])) //把无重复字符段放切片里面去 s=s[i:] //切片往后移 goto flag; //在新切片里面再次循环直到找出无重复字符段放进字符串切片里面 &#125; &#125; &#125; slice=append(slice,string(s)) //把最后一个放进切片，如果整个字符串都没有重复那么就这一个 //fmt.Println(slice) max:=len(slice[0]) for k:=0;k&lt;len(slice);k++&#123; //循环找出这一次的最大值 if len(slice[k])&gt;max&#123; max=len(slice[k]) &#125; &#125; return max //返回本次最大值&#125;func main()&#123; var str string fmt.Printf("请输入一个字符串\n") fmt.Scanf("%s",&amp;str) var max int for i:=len(str);i&gt;0;i--&#123; tmp:=lengthOfLongestSubstring(str) //每求一次最大值往后退一次，确保能得到真正的最大值 if tmp&gt;max&#123; max=tmp &#125; str=str[1:] //每次用切片割掉第一个元素 &#125; fmt.Println(max) //输出最大值，这里也可以输出最长的子字符串&#125; 这样就可以求出来了，如果想要优化的伙伴可以自己去稍加研究。]]></content>
      <categories>
        <category>数据结构和算法</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>编程题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一条简单区块链的实现]]></title>
    <url>%2F2018%2F09%2F02%2F%E4%B8%80%E6%9D%A1%E7%AE%80%E5%8D%95%E5%8C%BA%E5%9D%97%E9%93%BE%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[在上一章中我们讲解了一个简单的区块创建，那么我们今天来讲解一下一条简单区块链的实现 思路分析： 创建一个创世块，就是区块链的头 //上一章节中讲解了如果实现一个区块的简单实现 定义一个结构体，用来保存区块链中的区块，结构体里面的元素可以就是那条链 用方法来实现区块的添加，每次调用方法都加进相应的区块 第一步实现 1234567type Block struct &#123; //创建一个区块的结构体 Time int64 //时间戳 Data []byte //数据信息 PreviousHash []byte //前一个哈希值 Hash []byte //当前的哈希&#125; 第二步实现 123type Blockchain struct&#123; //创建一个区块链类型 blocks []*Block //一系列区块储存，这里用切片来保存&#125; 第三步实现 123456789101112func (blockchain *Blockchain)Addblock(data string)&#123; //添加区块的方法 newblock:=Block&#123;&#125; //一个新区块 newblock.Data=[]byte(data) //初始化数据 newblock.PreviousHash=blockchain.blocks[len(blockchain.blocks)-1].Hash //得到前一个区块的哈希 newblock.Sethash() //得到哈希 blockchain.blocks=append(blockchain.blocks,&amp;newblock) //新区块添加到这条链当中&#125;func Newblockchain()*Blockchain&#123; // 创建一条新的区块链 blos:=Blockchain&#123;[]*Block&#123;Firstblock()&#125;&#125; //初始化 return &amp;blos&#125; 这样新的区块链就完成的差不多了，加上上一章的简单实现区块链的代码就已经实现了，下面我们整理一下将得到如下的代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package mainimport ( "time" "strconv" "bytes" "crypto/sha256" "fmt")/*一个简单的区块链创建*/type Block struct &#123; //创建一个区块的结构体 Time int64 //时间戳 Data []byte //数据信息 PreviousHash []byte //前一个哈希值 Hash []byte //当前的哈希&#125;type Blockchain struct&#123; //创建一个区块链类型 blocks []*Block //一系列区块储存，这里用切片来保存&#125;func (blockchain *Blockchain)Addblock(data string)&#123; //添加区块的方法 newblock:=Block&#123;&#125; //一个新区块 newblock.Data=[]byte(data) //初始化数据 newblock.PreviousHash=blockchain.blocks[len(blockchain.blocks)-1].Hash //得到前一个区块的哈希 newblock.Sethash() //得到哈希 blockchain.blocks=append(blockchain.blocks,&amp;newblock) //新区块添加到这条链当中&#125;func Newblockchain()*Blockchain&#123; // 创建一条新的区块链 blos:=Blockchain&#123;[]*Block&#123;Firstblock()&#125;&#125; //初始化 return &amp;blos&#125;func Firstblock()*Block&#123; firstblock:=Newblock("firstblock",[]byte&#123;&#125;) return firstblock&#125;func (block *Block)Sethash()&#123; timer:=[]byte(strconv.FormatInt(block.Time,10)) herds:=bytes.Join([][]byte&#123;timer,[]byte(block.Data),block.PreviousHash&#125;,[]byte&#123;&#125;) hash:=sha256.Sum256(herds) block.Hash=hash[:]&#125;func Newblock(data string,prevhash []byte)*Block&#123; block:=Block&#123;&#125; block.Time=time.Now().Unix() block.Data=[]byte(data) block.PreviousHash=prevhash block.Sethash() return &amp;block&#125;func main() &#123; //创建一个区块链 blocks:=Newblockchain() blocks.Addblock("seng one BTC to sary") //信息（数据）为seng one BTC to sary 添加到区块链中 blocks.Addblock("send two ETH to wuman")//信息（数据）为send two ETH to wuman 添加到区块链中 blocks.Addblock("send one ADA to zijian")//信息（数据）为send one ADA to zijian 添加到区块链中 for _,v:=range blocks.blocks&#123; //循环遍历打印一下看结果 fmt.Println("=======================================") fmt.Printf("data=:%s\n",v.Data) fmt.Printf("prevhash:=%x\n",v.PreviousHash) fmt.Printf("hash:=%x\n",v.Hash) &#125;&#125; 我们来看一下结果：]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo+github博客搭建]]></title>
    <url>%2F2018%2F09%2F01%2F%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA1%2F</url>
    <content type="text"><![CDATA[技术小白搭建个人博客 github+hexo本文主要讲解博客的搭建过程，next主题优化，next配置文件详解等。 不做过多介绍了，快速开始 准备安装软件依次安装 1、Node.js 2、Git 注册github访问https://github.com/ 右上角signup uername 最好都用小写，因为最后建立的博客地址是：http://username.github.io；邮箱十分重要，GitHub 上很多通知都是通过邮箱的。 创建Repository Repository 名字应该是http://username.github.io。比如我的username 就是wumansgy 其他的可以选择添加一些描述也可以选择默认什么也不添加 ，点击creat repository 配置和使用Github开始–所有应用–找到git bash 配置SSH keysssh keys就是用来使本地git 项目与github联系 1. 检查SSH keys的设置首先要检查自己电脑上现有的 SSH key： 1$ cd ~/. ssh 如果显示“No such file or directory”，说明这是你第一次使用 git 2、生成新的 SSH Key：123$ ssh-keygen -t rsa -C &quot;邮件地址@youremail.com&quot;Generating public/private rsa key pair.Enter file in which to save the key (/Users/your_user_directory/.ssh/id_rsa):&lt;回车就好&gt; 【提示1】这里的邮箱地址，输入注册 Github 的邮箱地址； 【提示2】「-C」的是大写的「C」 然后系统会要你输入密码： 12Enter passphrase (empty for no passphrase):&lt;设置密码&gt;Enter same passphrase again:&lt;再次输入密码&gt; 在回车中会提示你输入一个密码，这个密码会在你提交项目时使用，如果为空的话提交项目时则不用输入。这个设置是防止别人往你的项目里提交内容。 注意：输入密码的时候没有输入痕迹的，不要以为什么也没有输入。 最后看到这样的界面，就成功设置ssh key了： 3、添加SSH Key到GitHub在本地文件夹找到id_rsa.pub文件，看上面的图片第四行的位置告诉你存在哪里了 没找到的勾选一下文件扩展名 隐藏的项目 .ssh文件夹里记事本打开这个文件复制全部内容到 github相应位置。不要着急…（记得期末考试复习概率论看汤家凤老师的视频时老师的口头禅…） 你的github主页 点击头像后边的箭头（为什么我每次想要上传头像都没反应呢？希望有知道的小伙伴能看到告诉我一下） Title最好写，随便写。网上有说不写title也有可能后期出现乱七八糟的错误 Key部分就是放刚才复制的内容啦 点击Add SSH key 测试git bash 里 输入以下代码 不要改任何一个字 我就是自作聪明以为代表的是自己注册时候的邮箱然后… 1$ ssh -T git@github.com 如果得到以下反馈 123The authenticity of host &apos;GitHub.com (207.97.227.239)&apos; can&apos;t be established.RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.Are you sure you want to continue connecting (yes/no) 输入yes回车 1Enter passphrase for key &apos;/c/Users/lenovo/.ssh/id_rsa&apos;: 输入刚才设置的密码回车 设置用户信息现在已经可以通过 SSH 链接到 GitHub 啦!当然还需要完善一些个人信息: 12$ git config --global user.name &quot;wuyalan&quot;//输入注册时的username$ git config --global user.email &quot;alan.wyl@foxmail.com&quot;//填写注册邮箱 GitHub 也是用这些信息来做权限的处理，输入下面的代码进行个人信息的设置，把名称和邮箱替换成你自己的，名字必须是你的真名，而不是GitHub的昵称。 SSH Key配置成功本机已成功连接到 github。 如有问题，请重新设置。常见错误请参考： 错误1 错误2 搭建hexo博客利用npm命令安装hexo 12$ cd$ npm install -g hexo 1. 创建独立博客项目文件夹 安装完成后，关掉前面那个 Git Bash 窗口。在本地创建一个与 Repository 中博客项目同名的文件夹（如E:[http://username.github.io]）在文件夹上点击鼠标右键，选择 Git bash here； 【提示】在进行博客搭建工作时，每次使用命令都要在 H:[http://username.github.io] 目录下。 执行下面的指令，Hexo 就会自动在 H:[http://username.github.io]文件夹建立独立博客所需要的所有文件啦！ 1$ hexo init 2. 安装依赖包 1$ npm install 3. 确保git部署 1$ npm install hexo-deployer-git --save 4.本地查看 现在已经搭建好本地的 Hexo 博客了，执行完下面的命令就可以到浏览器输入 localhost:4000 查看到啦 12$ hexo g$ hexo s hexo g 每次进行相应改动都要hexo g 生成一下 hexo s 启动服务预览 5. 用Hexo克隆主题 执行完 hexo init 命令后会给一个默认的主题：landscape 你可以到官网找你喜欢的主题进行下载 hexo themes 知乎：有哪些好看的 Hexo 主题？ 找到它所在的 Github Repository （怎么找，我喜欢的那个，恰好博主放了他的github地址，emmm） 找到之后通过git命令下载 在主题的repository点击clone 复制一下那个地址 1$ git clone +复制的地址+themes/archer 后面就是clone之后放到你本地的博客文件夹themes文件夹下 名字纹archer的文件 我下载的是archer主题~（有喜欢同样的小伙伴在个性化自己主题的时候欢迎来交流一下呀~真的是技术小白~还没研究清楚要怎么改，不过主题作者也会在readme说明的，细心看就是） 6. 修改整站配置文件 自己把 http://blog.io 中文件都点开看一遍，主要配置文件是 _config.yml ，可以用记事本打开，推荐使用 sublime 或者nodepad++打开。 修订清单如下，文档内有详细注释，可按注释逐个修订 博客名字及作者信息：_config.yml 个人介绍页面：about.md 代表作页面：milestone.md 博客参考 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889这里贴一份网上看到的 可以复制替换原来的 但是替换之前最好备份 可能会出错那要么你就对照着看一下改就好# Hexo Configuration## Docs: http://zespia.tw/hexo/docs/configure.html## Source: https://github.com/tommy351/hexo/# Site 这里的配置，哪项配置反映在哪里，可以参考我的博客title: My Blog #博客名subtitle: to be continued... #副标题description: My blog #给搜索引擎看的，对网站的描述，可以自定义author: Yourname #作者，在博客底部可以看到email: yourname@yourmail.com #你的联系邮箱language: zh-CN #中文。如果不填则默认英文# URL #这项暂不配置，绑定域名后，欲创建sitemap.xml需要配置该项## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and root as &apos;/child/&apos;url: http://yoursite.comroot: /permalink: :year/:month/:day/:title/tag_dir: tagsarchive_dir: archivescategory_dir: categories# Writing 文章布局、写作格式的定义，不修改new_post_name: :title.md # File name of new postsdefault_layout: postauto_spacing: false # Add spaces between asian characters and western characterstitlecase: false # Transform title into titlecasemax_open_file: 100filename_case: 0highlight: enable: true backtick_code_block: true line_number: true tab_replace:# Category &amp; Tagdefault_category: uncategorizedcategory_map:tag_map:# Archives 默认值为2，这里都修改为1，相应页面就只会列出标题，而非全文## 2: Enable pagination## 1: Disable pagination## 0: Fully Disablearchive: 1category: 1tag: 1# Server 不修改## Hexo uses Connect as a server## You can customize the logger format as defined in## http://www.senchalabs.org/connect/logger.htmlport: 4000logger: falselogger_format:# Date / Time format 日期格式，可以修改成自己喜欢的格式## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-M-Dtime_format: H:mm:ss# Pagination 每页显示文章数，可以自定义，贴主设置的是10## Set per_page to 0 to disable paginationper_page: 10pagination_dir: page# Disqus Disqus插件，我们会替换成“多说”，不修改disqus_shortname:# Extensions 这里配置站点所用主题和插件，暂时默认## Plugins: https://github.com/tommy351/hexo/wiki/Plugins## Themes: https://github.com/tommy351/hexo/wiki/Themestheme: landscapeexclude_generator:plugins:- hexo-generator-feed- hexo-generator-sitemap# Deployment 站点部署到github要配置## Docs: http://zespia.tw/hexo/docs/deploy.htmldeploy: type: git repository: branch: master 7. 启用新下载的主题 在刚打开的的_config.yml 文件中，找到“# Extensions”，把默认主题 landscape 修改为刚刚下载下来的主题名： 【提示】http://username.github.io 里有两个 config.yml 文件，一个在根目录，一个在 theme 下，现在修改的是在根目录下的。 8. 更新主题 git bash 里执行 12$ cd themes/主题名$ git pull 9. 本地查看调试 每次修改都要hexo g 生成一下 12$ hexo g #生成$ hexo s #启动本地服务，进行文章预览调试，退出服务用Ctrl+c 浏览器输入 localhost：4000 预览效果 将博客部署到http://username.github.io1. 复制SSH码进入 Github 个人主页中的 Repository，复制新建的独立博客项目:http://username.github.io 的 SSH 码 2. 编辑整站配置文件打开 H:\username.github.io_config.yml,把刚刚复制的 SSH 码粘贴到“repository：”后面，别忘了冒号后要空一格。 1234deploy: type: git repository: git@github.com:username/username.github.io.git branch: master 3. 执行下列指令即可完成部署。【提示】每次修改本地文件后，需要 hexo g 才能保存。每次使用命令时，都要在你的博客文件夹目录下 12$ hexo g$ hexo d （ps：我在第一次hexo d 的时候出现了错误，具体错误提示忘了，原因是我没有deploy 的权限 在repository的setting （这里我有一点小疑惑 为什么delete不了这个公钥呢，我想要delete是因为第一次设置时没有勾选 ..如下 emm里面的内容就是重复配置SSH key的步骤，记得勾选这个小框框，我就是没有勾选设置之后还是没有deploy成功 ） 因为我看到的教程里大多数没有讲这一部分，所以我也不确定这一步是否必须，如果有遇到相同问题的小伙伴可以参考 ） 【提示】如果在配置 SSH key 时设置了密码，执行 hexo d 命令上传文件时需要输入密码进行确认，会出现一个小框框。 输入密码之后在浏览器输入： username.github.io 如果得到你想要的效果，那么恭喜你，博客已经搭建好啦！ 允许你偷偷激动一下…哈哈哈 之后就是写博文了，我还没开始…要好好写博客好好写博客 你看技术大神们哪个没有自己的优秀博客。 不懂技术的小伙伴也可以在自己的小天地写文，很爽又很有逼格是不是~ 我的博客地址：进入 next主题使用及优化启用主题与所有 Hexo 主题启用的模式一样。 当 克隆/下载 完成后，打开 站点配置文件， 找到 theme 字段，并将其值更改为 next。 启用 NexT 主题 1theme: next 到此，NexT 主题安装完成。下一步我们将验证主题是否正确启用。在切换主题之后、验证之前， 我们最好使用 hexo clean 来清除 Hexo 的缓存。 选择 SchemeScheme 是 NexT 提供的一种特性，借助于 Scheme，NexT 为你提供多种不同的外观。同时，几乎所有的配置都可以 在 Scheme 之间共用。目前 NexT 支持三种 Scheme，他们是： Muse - 默认 Scheme，这是 NexT 最初的版本，黑白主调，大量留白 Mist - Muse 的紧凑版本，整洁有序的单栏外观 Pisces - 双栏 Scheme，小家碧玉似的清新 Scheme 的切换通过更改 主题配置文件，搜索 scheme 关键字。 你会看到有三行 scheme 的配置，将你需用启用的 scheme 前面注释 # 去除即可。 选择 Pisces Scheme 123#scheme: Muse#scheme: Mistscheme: Pisces 设置 语言编辑 站点配置文件， 将 language 设置成你所需要的语言。建议明确设置你所需要的语言，例如选用简体中文，配置如下： 1language: zh-CN Local Search添加百度/谷歌/本地 自定义站点内容搜索 安装 hexo-generator-searchdb，在站点的根目录下执行以下命令： 1$ npm install hexo-generator-searchdb --save 编辑 站点配置文件，新增以下内容到任意位置： 12345search: path: search.xml field: post format: html limit: 10000 编辑 主题配置文件，启用本地搜索功能： 123# Local searchlocal_search: enable: true 文章模块的美化文章内代码美化 行内代码在主题目录下，将source/css/_custom/custom.styl文件修改如下： 123456789//行内代码样式code &#123; color: #ff7600; background: #fbf7f8; border: 1px solid #d6d6d6; padding:1px 4px; word-break: break-all; border-radius:4px;&#125; 区块代码在主题目录下，修改config.yml文件： 12# 样式可选： normal | night | night eighties | night blue | night brighthighlight_theme: night 文章结束语 添加模块文件 在主题目录下layout/_macro中新建 passage-end-tag.swig文件,并添加以下内容： 1234567&lt;div&gt; &#123;% if not is_index %&#125; &lt;div style=&quot;text-align:center;color: #ccc;font-size:14px;&quot;&gt; -------------本文结束&lt;i class=&quot;fa fa-paw&quot;&gt;&lt;/i&gt;感谢您的阅读------------- &lt;/div&gt; &#123;% endif %&#125;&lt;/div&gt; 导入模板文件 在layout/_macro/post.swig文件中，找到： 123&#123;#####################&#125;&#123;### END POST BODY ###&#125;&#123;#####################&#125; 在上面代码之前添加： 12345&lt;div&gt; &#123;% if not is_index %&#125; &#123;% include &apos;passage-end-tag.swig&apos; %&#125; &#123;% endif %&#125;&lt;/div&gt; 配置在主题配置文件中添加： 123# 文章末尾添加“本文结束”标记passage_end_tag: enabled: true 增强文章底部版权信息 增加文章md文件的头部信息中添加copyright: true时，添加版权声明 增加文章标题、发布时间、更新时间等信息 在目录 next/layout/_macro/下添加 my-copyright.swig： 123456789101112131415161718192021222324252627282930&#123;% if page.copyright %&#125;&lt;div class=&quot;my_post_copyright&quot;&gt; &lt;script src=&quot;//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js&quot;&gt;&lt;/script&gt; &lt;!-- JS库 sweetalert 可修改路径 --&gt; &lt;script src=&quot;https://cdn.bootcss.com/jquery/2.0.0/jquery.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;https://unpkg.com/sweetalert/dist/sweetalert.min.js&quot;&gt;&lt;/script&gt; &lt;p&gt;&lt;span&gt;本文标题:&lt;/span&gt;&lt;a href=&quot;&#123;&#123; url_for(page.path) &#125;&#125;&quot;&gt;&#123;&#123; page.title &#125;&#125;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;文章作者:&lt;/span&gt;&lt;a href=&quot;/&quot; title=&quot;访问 &#123;&#123; theme.author &#125;&#125; 的个人博客&quot;&gt;&#123;&#123; theme.author &#125;&#125;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;发布时间:&lt;/span&gt;&#123;&#123; page.date.format(&quot;YYYY年MM月DD日 - HH:MM&quot;) &#125;&#125;&lt;/p&gt; &lt;p&gt;&lt;span&gt;最后更新:&lt;/span&gt;&#123;&#123; page.updated.format(&quot;YYYY年MM月DD日 - HH:MM&quot;) &#125;&#125;&lt;/p&gt; &lt;p&gt;&lt;span&gt;原始链接:&lt;/span&gt;&lt;a href=&quot;&#123;&#123; url_for(page.path) &#125;&#125;&quot; title=&quot;&#123;&#123; page.title &#125;&#125;&quot;&gt;&#123;&#123; page.permalink &#125;&#125;&lt;/a&gt; &lt;span class=&quot;copy-path&quot; title=&quot;点击复制文章链接&quot;&gt;&lt;i class=&quot;fa fa-clipboard&quot; data-clipboard-text=&quot;&#123;&#123; page.permalink &#125;&#125;&quot; aria-label=&quot;复制成功！&quot;&gt;&lt;/i&gt;&lt;/span&gt; &lt;/p&gt; &lt;p&gt;&lt;span&gt;许可协议:&lt;/span&gt;&lt;i class=&quot;fa fa-creative-commons&quot;&gt;&lt;/i&gt; &lt;a rel=&quot;license&quot; href=&quot;https://creativecommons.org/licenses/by-nc-nd/4.0/&quot; target=&quot;_blank&quot; title=&quot;Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)&quot;&gt;署名-非商业性使用-禁止演绎 4.0 国际&lt;/a&gt; 转载请保留原文链接及作者。&lt;/p&gt; &lt;/div&gt;&lt;script&gt; var clipboard = new Clipboard(&apos;.fa-clipboard&apos;); $(&quot;.fa-clipboard&quot;).click(function()&#123; clipboard.on(&apos;success&apos;, function()&#123; swal(&#123; title: &quot;&quot;, text: &apos;复制成功&apos;, icon: &quot;success&quot;, showConfirmButton: true &#125;); &#125;); &#125;); &lt;/script&gt;&#123;% endif %&#125; 在目录next/source/css/_common/components/post/下添加my-post-copyright.styl： 123456789101112131415161718192021222324252627282930313233343536373839404142434445.my_post_copyright &#123; width: 85%; max-width: 45em; margin: 2.8em auto 0; padding: 0.5em 1.0em; border: 1px solid #d3d3d3; font-size: 0.93rem; line-height: 1.6em; word-break: break-all; background: rgba(255,255,255,0.4);&#125;.my_post_copyright p&#123;margin:0;&#125;.my_post_copyright span &#123; display: inline-block; width: 5.2em; color: #b5b5b5; font-weight: bold;&#125;.my_post_copyright .raw &#123; margin-left: 1em; width: 5em;&#125;.my_post_copyright a &#123; color: #808080; border-bottom:0;&#125;.my_post_copyright a:hover &#123; color: #a3d2a3; text-decoration: underline;&#125;.my_post_copyright:hover .fa-clipboard &#123; color: #000;&#125;.my_post_copyright .post-url:hover &#123; font-weight: normal;&#125;.my_post_copyright .copy-path &#123; margin-left: 1em; width: 1em; +mobile()&#123;display:none;&#125;&#125;.my_post_copyright .copy-path:hover &#123; color: #808080; cursor: pointer;&#125; 修改next/layout/_macro/post.swig，在代码 123&#123;#####################&#125;&#123;### END POST BODY ###&#125;&#123;#####################&#125; 之前添加增加如下代码： 12345&lt;div&gt; &#123;% if not is_index %&#125; &#123;% include &apos;my-copyright.swig&apos; %&#125; &#123;% endif %&#125;&lt;/div&gt; 修改next/source/css/_common/components/post/post.styl文件，在最后一行增加代码： 1@import &quot;my-post-copyright&quot; 保存重新生成即可。 微信：sgsgy5 qq:869087033 欢迎交流，搭建走了很多坑。 友情链接 参考： 技术小白搭建hexo+github博客 next最新版主题下载使用 next主题官方文档 next主题个性化教程 next主题配置文件详解 NexT v6.0+ 背景动画Canvas_nest设置无效的解决方案 给Hexo搭建的博客增加百度谷歌搜索引擎验证 添加文章字数和读取文章的时间 hexo + next主题高级配置 关于博客图片上传方法]]></content>
      <categories>
        <category>博客</category>
      </categories>
      <tags>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个简单区块的实现]]></title>
    <url>%2F2018%2F09%2F01%2F%E5%8C%BA%E5%9D%97%E9%93%BE%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B01%2F</url>
    <content type="text"><![CDATA[简单区块实现区块链技术如今已经越来越成熟，但是我们怎么深入到本质用技术的眼光来看待区块链技术，见名知意，区块链的意思就是用链条把区块链接起来，那我们先用代码来看一下，今天我们用go语言来简单的实现一个区块并打印。 我们可以先来理一下思路，我们想要实现一个区块该怎么办，思路理好然后再来代码一步一步实现 创建一个结构体来保存一个区块的信息 //大概包括时间戳，数据，前哈希，本哈希这几个数据 创建第一个区块并给其中的数据赋值，也就相当于一个创世块，注意这里创世块的前哈希传一个空值就可以 给这个区块的数据处理一下然后加密得到本区块的哈希 主函数里面打印看一下本区块的哈希 //哈希用16进制打印 大概这样思路就可以理顺了，然后我们就可以一步一步实现了 1：第一步创建一个区块结构体 1234567type Block struct &#123; //创建一个区块结构体 Timer int64 //时间戳 Data []byte //数据 prevHash []byte //前一个区块的哈希值 Hash []byte //本区块的哈希值&#125; 区块结构体创建完成，继续下一步 2：创建第一个区块 1234func Firstblosk() *Block &#123; //创建第一个区块信息，相当于一个创始块 firstblock := NewBlock("This is firstblock", []byte&#123;&#125;) //传入参数，返回结构体指针类型 return firstblock //返回的是结构体指针类型&#125; 123456789func NewBlock(data string, prevhash []byte) *Block &#123; //创建区块的函数 block1 := Block&#123;&#125; //创建一个区块结构体 block1.Timer = time.Now().Unix() //得到时间 block1.Data = []byte(data) //传入数据参数 block1.prevHash = prevhash //前一个哈希值为传入的数据 block1.setHash() //setHash 方法加密得到自己的hash return &amp;block1 //返回区块指针&#125; 用来创建第一个区块 3：给区块信息数据处理 123456func (block *Block) setHash() &#123; time := []byte(strconv.FormatInt(block.Timer, 10)) //将区块的时间转为字符切片类型，方便加密 heards := bytes.Join([][]byte&#123;time, block.Data, block.prevHash&#125;, []byte&#123;&#125;) //将时间，数据，前一个哈希拼接一下 hash := sha256.Sum256(heards) //用sha256包的Sum256函数加密 block.Hash = hash[:] //加密后的直接赋值给本哈希&#125; 4:主函数里面打印看一下本区块的哈希 //哈希用16进制打印 12345func main() &#123; firstblock := Firstblosk() fmt.Printf("%x",string(firstblock.Hash)) //16进制打印&#125; 这样一个简单的区块就创建成功了，我们把所有代码连接起来然后来看一下打印结果 123456789101112131415161718192021222324252627282930313233343536373839404142package main/*一个简单的区块创建实现*/import ( "time" "strconv" "bytes" "crypto/sha256" "fmt")type Block struct &#123; //创建一个区块结构体 Timer int64 //时间戳 Data []byte //数据 prevHash []byte //前一个区块的哈希值 Hash []byte //本区块的哈希值&#125;func (block *Block) setHash() &#123; time := []byte(strconv.FormatInt(block.Timer, 10)) //将区块的时间转为字符切片类型，方便加密 heards := bytes.Join([][]byte&#123;time, block.Data, block.prevHash&#125;, []byte&#123;&#125;) //将时间，数据，前一个哈希拼接一下 hash := sha256.Sum256(heards) //用sha256包的Sum256函数加密 block.Hash = hash[:] //加密后的直接赋值给本哈希&#125;func Firstblosk() *Block &#123; //创建第一个区块信息，相当于一个创始块 firstblock := NewBlock("This is firstblock", []byte&#123;&#125;) //传入参数，返回结构体指针类型 return firstblock //返回的是结构体指针类型&#125;func NewBlock(data string, prevhash []byte) *Block &#123; //创建区块的函数 block1 := Block&#123;&#125; //创建一个区块结构体 block1.Timer = time.Now().Unix() //得到时间 block1.Data = []byte(data) //传入数据参数 block1.prevHash = prevhash //前一个哈希值为传入的数据 block1.setHash() //setHash 方法加密得到自己的hash return &amp;block1 //返回区块指针&#125;func main() &#123; firstblock := Firstblosk() fmt.Printf("%x",string(firstblock.Hash)) //16进制打印&#125; 我们来看一下哈希打印结果 这样一个简单的区块就实现了，那么如果要实现一个简单的区块链呢？其实也按照这样的思路写下去也很容易实现，记住：区块链的本区块的哈希是下一个区块的前哈希，这样链接，下一章我们将讲解一个简单的区块链实现。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go语言中的面向对象，接口类型，工厂设计模式解读]]></title>
    <url>%2F2018%2F09%2F01%2Fgo%E8%AF%AD%E8%A8%80%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[工厂模式： 定义一个用于创建对象的接口，让子类决定实例化哪一个类抽象工厂模式：为创建一组相关或相互依赖的对象提供一个接口，而且无需指定他们的具体类个人觉得这个区别在于产品，如果产品单一，最合适用工厂模式，但是如果有多个业务品种、业务分类时，通过抽象工厂模式产生需要的对象是一种非常好的解决方式。再通俗深化理解下：工厂模式针对的是一个产品等级结构 ，抽象工厂模式针对的是面向多个产品等级结构的。工厂方法模式 抽象工厂模式针对的是一个产品等级结构 针对的是面向多个产品等级结构一个抽象产品类 多个抽象产品类可以派生出多个具体产品类 每个抽象产品类可以派生出多个具体产品类一个抽象工厂类，可以派生出多个具体工厂类 一个抽象工厂类，可以派生出多个具体工厂类每个具体工厂类只能创建一个具体产品类的实例 每个具体工厂类可以创建多个具体产品类的实例加减乘除四则运算器工厂模式举例子 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677package mainimport "fmt"type operation struct&#123; //定义一个父类两个数据 num1 float64 num2 float64&#125;type operationAdd struct&#123; //加法子类 operation&#125;func (op *operationAdd)getresult()float64&#123; //加法类的方法 return op.num1+op.num2&#125;type operationSub struct&#123; //减法子类 operation&#125;func (sub *operationSub)getresult()float64&#123; //减法类的方法 return sub.num1-sub.num2&#125;type operationMult struct&#123; //乘法子类 operation&#125;func (mult *operationMult)getresult()float64&#123; return mult.num1*mult.num2&#125;type operationDivi struct&#123; operation&#125; //除法子类func (divi *operationDivi)getresult()float64&#123; return divi.num1/divi.num2&#125;type operationer interface&#123; //定义接口 getresult() float64 //加法的方法&#125;type operationfactor struct &#123; //operation //用于创建对象的类，工厂模式&#125;func (op *operationfactor)creatoperation(ope string,num1 float64,num2 float64)float64&#123; //用于构件对象类 var result float64 switch ope &#123; case "+": add:=&amp;operationAdd&#123;operation&#123;num1,num2&#125;&#125; //按照传过来的符号来创建相应的对象 result=operationwho(add) //传递给多态的函数，直接调用 case "-": sub:=&amp;operationSub&#123;operation&#123;num1,num2&#125;&#125; result=operationwho(sub) case "*": mult:=&amp;operationMult&#123;operation&#123;num1,num2&#125;&#125; result=operationwho(mult) case "/": divi:=&amp;operationDivi&#123;operation&#123;num1,num2&#125;&#125; result=operationwho(divi) &#125; return result&#125;func operationwho(i operationer)float64&#123; return i.getresult() //此处为创建一个多态的函数&#125;func main()&#123; //m:=&amp;operationAdd&#123;operation&#123;3,4&#125;&#125; //var iop operationer //iop=m //sum:=iop.getresult() //fmt.Println(sum) var op1 operationfactor //直接创建工厂类对象 sum:=op1.creatoperation("+",9,6) //直接调用工厂类的方法 fmt.Println(sum) var op2 operationfactor sub:=op2.creatoperation("-",9,8) fmt.Println(sub) var op3 operationfactor mult:=op3.creatoperation("*",3,4) fmt.Println(mult) var op4 operationfactor div:=op4.creatoperation("/",9,10) fmt.Println(div)&#125; 在上面的例子当中，如果对面向对象没有接触的话可能会有一些不好理解，在go语言当中面向对象可能和别的语言有一些不同，go语言是利用匿名字段来实现继承，在上面的例子中多态函数的实现可以让函数调用更加方便，比如每个结构体类都有10几个甚至更多的函数，那么直接都把这些函数封装在多态的函数里面，那么每次调用直接传递一个结构体类给多态函数就直接全部调用了，这样就是很方便的]]></content>
      <categories>
        <category>GO语言</category>
      </categories>
      <tags>
        <tag>go语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go语言简单排序之冒泡和插入排序]]></title>
    <url>%2F2018%2F09%2F01%2Fgo%E8%AF%AD%E8%A8%80%E5%86%92%E6%B3%A1%E5%92%8C%E6%8F%92%E5%8F%991%2F</url>
    <content type="text"><![CDATA[编程即数学，在编程中也会遇到很多的数学问题的集合，今天我们来讲解一下编程中最常见的冒泡排序，以及冒泡排序之后的插入排序 1：冒泡排序：见名知意，冒泡在我们生活当中可以有哪些常见的事物呢，比如在生活当中，大家都见到过烧开水的状态，那么水中的气泡就会不断的往上面漂浮，应用物理学上的知识来讲就是气泡的质量比较轻，在水中有浮力，就会不断的上浮，那么我们应该怎样应用到编程中的冒泡排序呢，我们先来看一段代码，然后慢慢分析 12345678910111213141516171819package mainimport "fmt"//func main() &#123; arr := [10]int&#123;9, 1, 5, 6, 3, 7, 10, 8, 2, 4&#125; //先定义一个乱序数组 //冒泡排序 for i := 0; i &lt; 10-1; i++ &#123; //外面的循环用来循环次数 for j := 0; j &lt; 10-1-i; j++ &#123; //里面的循环用来循环 每次对比到哪里 if arr[j] &gt; arr[j+1] &#123; //数据交换 arr[j], arr[j+1] = arr[j+1], arr[j] //go语言的多个数据交换格式 //temp := arr[j] //普通数据交换格式 //arr[j] = arr[j+1] //arr[j+1] = temp &#125; &#125; &#125; fmt.Println(arr)&#125; 我们看到这个代码和这张图片，在图片中我们只写了前面几次，先来看第一次，第一个元素和第二个相比4比2大，如果第一个元素比第二个大那么就交换一下，然后第二个元素和第三个相比，如果大就交换，然后第三第四相比，第四第五相比，一直比到最后一个和倒数第一个，有没有发现这样比一次就能确定一个最大的数，而且最大的数是放在最后一个元素里面的，这样一次就是外面的外循环 1for i := 0; i &lt; 10-1; i++ &#123; //这句话就是外面的循环 然后确定第一个最大的放最后一个，那么我们然后怎么办呢 ，然后我们当然继续下一次对比然后再确定一个第二大的放在倒数第二的位置啊，最大的确定下来后，我们继续从第一个开始遍历，但是这次遍历要注意了，不需要遍历到最后一个元素，而只需遍历到倒数第二个就行了，这是为什么呢，因为最后一个元素已经确定下来是最大的了，所以就不需要对比了，我们来看内循环 12for j := 0; j &lt; 10-1-i; j++ &#123; //里面的循环用来循环 每次对比到哪里//这里的判断条件是 小于10-1-i，i是什么呢，就是外循环的次数，所以只需要对比到10-1-i就行 然后内循环每次对比相邻的两个元素，如果前面大于后面的那么就交换， 12345//数据交换 arr[j], arr[j+1] = arr[j+1], arr[j] //go语言的多个数据交换格式 //temp := arr[j] //普通数据交换格式 //arr[j] = arr[j+1] //arr[j+1] = temp 这里面数据交换 有两种格式，第一种就是GO语言里面的简单交换格式，第二种是常见的交换数据格式，需要定义一个临时变量 然后可以打印出来数组，就变成从小到大的升序数组了， 那么如果要变成降序排序怎么改呢？ 来看这句话 1if arr[j] &gt; arr[j+1] &#123; 我们只需要把这里的大于号改成小于号就行啦 不喜勿喷，谢谢哈哈插入排序后续]]></content>
      <categories>
        <category>数据结构和算法</category>
      </categories>
      <tags>
        <tag>go语言</tag>
        <tag>排序问题</tag>
      </tags>
  </entry>
</search>
